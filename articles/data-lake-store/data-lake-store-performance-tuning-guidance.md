---
title: "Recommandations en matière d’optimisation des performances d’Azure Data Lake Store | Microsoft Docs"
description: "Recommandations en matière d’optimisation des performances d’Azure Data Lake Store"
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: cgronlun
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 06/30/2017
ms.author: stewu
ms.openlocfilehash: e7ea83465328bd4c7479dec4093cd94700463854
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 07/11/2017
---
# <a name="tuning-azure-data-lake-store-for-performance"></a><span data-ttu-id="460a0-103">Paramétrage d’Azure Data Lake Store pour les performances</span><span class="sxs-lookup"><span data-stu-id="460a0-103">Tuning Azure Data Lake Store for performance</span></span>

<span data-ttu-id="460a0-104">Data Lake Store prend en charge un débit élevé pour l’analyse intensive des E/S et le déplacement des données.</span><span class="sxs-lookup"><span data-stu-id="460a0-104">Data Lake Store supports high-throughput for I/O intensive analytics and data movement.</span></span>  <span data-ttu-id="460a0-105">Dans Azure Data Lake Store, il est important d’utiliser tout le débit disponible (la quantité de données qui peuvent être lues ou écrites par seconde) pour optimiser les performances.</span><span class="sxs-lookup"><span data-stu-id="460a0-105">In Azure Data Lake Store, using all available throughput – the amount of data that can be read or written per second – is important to get the best performance.</span></span>  <span data-ttu-id="460a0-106">Pour cela, il convient d’effectuer le plus possible de lectures et d’écritures en parallèle.</span><span class="sxs-lookup"><span data-stu-id="460a0-106">This is achieved by performing as many reads and writes in parallel as possible.</span></span>

![Performances de Data Lake Store](./media/data-lake-store-performance-tuning-guidance/throughput.png)

<span data-ttu-id="460a0-108">Azure Data Lake Store peut évoluer pour fournir le débit nécessaire pour tous les scénarios d’analyse.</span><span class="sxs-lookup"><span data-stu-id="460a0-108">Azure Data Lake Store can scale to provide the necessary throughput for all analytics scenario.</span></span> <span data-ttu-id="460a0-109">Par défaut, un compte Azure Data Lake Store fournit automatiquement suffisamment de débit pour répondre aux besoins d’une vaste catégorie de cas d’usage.</span><span class="sxs-lookup"><span data-stu-id="460a0-109">By default, an Azure Data Lake Store account provides automatically enough throughput to meet the needs of a broad category of use cases.</span></span> <span data-ttu-id="460a0-110">Pour les cas où les clients atteignent la limite par défaut, le compte ADLS peut être configuré de manière à fournir un débit plus important en contactant le support de Microsoft.</span><span class="sxs-lookup"><span data-stu-id="460a0-110">For the cases where customers run into the default limit, the ADLS account can be configured to provide more throughput by contacting Microsoft support.</span></span>

## <a name="data-ingestion"></a><span data-ttu-id="460a0-111">Ingestion de données</span><span class="sxs-lookup"><span data-stu-id="460a0-111">Data ingestion</span></span>

<span data-ttu-id="460a0-112">Lors de l’ingestion de données à partir d’un système source dans ADLS, vous devez impérativement tenir compte du fait que le matériel source, le matériel réseau source et la connectivité réseau à ADLS peuvent agir comme goulot d’étranglement.</span><span class="sxs-lookup"><span data-stu-id="460a0-112">When ingesting data from a source system to ADLS, it is important to consider that the source hardware, source network hardware, and network connectivity to ADLS can be the bottleneck.</span></span>  

![Performances de Data Lake Store](./media/data-lake-store-performance-tuning-guidance/bottleneck.png)

<span data-ttu-id="460a0-114">Vous devez impérativement vous assurer que le déplacement des données n’est pas affecté par ces facteurs.</span><span class="sxs-lookup"><span data-stu-id="460a0-114">It is important to ensure that the data movement is not affected by these factors.</span></span>

### <a name="source-hardware"></a><span data-ttu-id="460a0-115">Matériel source</span><span class="sxs-lookup"><span data-stu-id="460a0-115">Source Hardware</span></span>

<span data-ttu-id="460a0-116">Que vous utilisiez des machines locales ou des machines virtuelles dans Azure, vous devez sélectionner avec soin le matériel adapté.</span><span class="sxs-lookup"><span data-stu-id="460a0-116">Whether you are using on-premises machines or VMs in Azure, you should carefully select the appropriate hardware.</span></span> <span data-ttu-id="460a0-117">Pour le matériel du disque source, préférez les disques SSD aux disques durs HDD et choisissez les disques avec les broches les plus rapides.</span><span class="sxs-lookup"><span data-stu-id="460a0-117">For Source Disk Hardware, prefer SSDs to HDDs and pick disk hardware with faster spindles.</span></span> <span data-ttu-id="460a0-118">Pour le matériel réseau source, utilisez la carte réseau la plus rapide possible.</span><span class="sxs-lookup"><span data-stu-id="460a0-118">For Source Network Hardware, use the fastest NICs possible.</span></span>  <span data-ttu-id="460a0-119">Sur Azure, nous vous recommandons des machines virtuelles Azure D14 qui sont équipées de disques et du matériel de mise en réseau suffisamment puissants.</span><span class="sxs-lookup"><span data-stu-id="460a0-119">On Azure, we recommend Azure D14 VMs which have the appropriately powerful disk and networking hardware.</span></span>

### <a name="network-connectivity-to-azure-data-lake-store"></a><span data-ttu-id="460a0-120">Connectivité réseau à Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="460a0-120">Network Connectivity to Azure Data Lake Store</span></span>

<span data-ttu-id="460a0-121">La connectivité réseau entre les données sources Azure Data Lake Store peut parfois être le goulot d’étranglement.</span><span class="sxs-lookup"><span data-stu-id="460a0-121">The network connectivity between your source data and Azure Data Lake store can sometimes be the bottleneck.</span></span> <span data-ttu-id="460a0-122">Lorsque vos données sources sont locales, envisagez d’utiliser une liaison dédiée avec [Azure ExpressRoute](https://azure.microsoft.com/en-us/services/expressroute/).</span><span class="sxs-lookup"><span data-stu-id="460a0-122">When your source data is On-Premises, consider using a dedicated link with [Azure ExpressRoute](https://azure.microsoft.com/en-us/services/expressroute/) .</span></span> <span data-ttu-id="460a0-123">Si vos données sources sont dans Azure, les performances seront meilleures lorsque les données sont dans la même région Azure que le Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="460a0-123">If your source data is in Azure, the performance will be best when the data is in the same Azure region as the Data Lake Store.</span></span>

### <a name="configure-data-ingestion-tools-for-maximum-parallelization"></a><span data-ttu-id="460a0-124">Configuration des outils d’ingestion des données pour une parallélisation maximale</span><span class="sxs-lookup"><span data-stu-id="460a0-124">Configure Data Ingestion tools for maximum parallelization</span></span>

<span data-ttu-id="460a0-125">Après avoir traité les goulots d’étranglement du matériel source et de la connectivité réseau susmentionnés, vous pouvez configurer vos outils d’ingestion.</span><span class="sxs-lookup"><span data-stu-id="460a0-125">Once you have addressed the source hardware and network connectivity bottlenecks above, you are ready to configure your ingestion tools.</span></span> <span data-ttu-id="460a0-126">Le tableau suivant résume les paramètres clés de plusieurs outils d’ingestion populaires et fournit des articles détaillés concernant le réglage des performances.</span><span class="sxs-lookup"><span data-stu-id="460a0-126">The following table summarizes the key settings for several popular ingestion tools and provides in-depth performance tuning articles for them.</span></span>  <span data-ttu-id="460a0-127">Pour en savoir plus sur l’outil à utiliser pour votre scénario, consultez cet [article](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-data-scenarios).</span><span class="sxs-lookup"><span data-stu-id="460a0-127">To learn more about which tool to use for your scenario, visit this [article](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-data-scenarios).</span></span>

| <span data-ttu-id="460a0-128">Outil</span><span class="sxs-lookup"><span data-stu-id="460a0-128">Tool</span></span>               | <span data-ttu-id="460a0-129">Paramètres</span><span class="sxs-lookup"><span data-stu-id="460a0-129">Settings</span></span>     | <span data-ttu-id="460a0-130">Détails supplémentaires</span><span class="sxs-lookup"><span data-stu-id="460a0-130">More Details</span></span>                                                                 |
|--------------------|------------------------------------------------------|------------------------------|
| <span data-ttu-id="460a0-131">PowerShell</span><span class="sxs-lookup"><span data-stu-id="460a0-131">Powershell</span></span>       | <span data-ttu-id="460a0-132">PerFileThreadCount, ConcurrentFileCount</span><span class="sxs-lookup"><span data-stu-id="460a0-132">PerFileThreadCount, ConcurrentFileCount</span></span> |  [<span data-ttu-id="460a0-133">Lien</span><span class="sxs-lookup"><span data-stu-id="460a0-133">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-get-started-powershell#performance-guidance-while-using-powershell)   |
| <span data-ttu-id="460a0-134">AdlCopy</span><span class="sxs-lookup"><span data-stu-id="460a0-134">AdlCopy</span></span>    | <span data-ttu-id="460a0-135">Unités Azure Data Lake Analytics</span><span class="sxs-lookup"><span data-stu-id="460a0-135">Azure Data Lake Analytics units</span></span>  |   [<span data-ttu-id="460a0-136">Lien</span><span class="sxs-lookup"><span data-stu-id="460a0-136">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-azure-storage-blob#performance-considerations-for-using-adlcopy)         |
| <span data-ttu-id="460a0-137">DistCp</span><span class="sxs-lookup"><span data-stu-id="460a0-137">DistCp</span></span>            | <span data-ttu-id="460a0-138">-m (mappeur)</span><span class="sxs-lookup"><span data-stu-id="460a0-138">-m (mapper)</span></span>   | [<span data-ttu-id="460a0-139">Lien</span><span class="sxs-lookup"><span data-stu-id="460a0-139">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-wasb-distcp#performance-considerations-while-using-distcp)                             |
| <span data-ttu-id="460a0-140">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="460a0-140">Azure Data Factory</span></span>| <span data-ttu-id="460a0-141">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="460a0-141">parallelCopies</span></span>    | [<span data-ttu-id="460a0-142">Lien</span><span class="sxs-lookup"><span data-stu-id="460a0-142">Link</span></span>](../data-factory/data-factory-copy-activity-performance.md)                          |
| <span data-ttu-id="460a0-143">Sqoop</span><span class="sxs-lookup"><span data-stu-id="460a0-143">Sqoop</span></span>           | <span data-ttu-id="460a0-144">fs.azure.block.size, -m (mappeur)</span><span class="sxs-lookup"><span data-stu-id="460a0-144">fs.azure.block.size, -m (mapper)</span></span>    |   [<span data-ttu-id="460a0-145">Lien</span><span class="sxs-lookup"><span data-stu-id="460a0-145">Link</span></span>](https://blogs.msdn.microsoft.com/bigdatasupport/2015/02/17/sqoop-job-performance-tuning-in-hdinsight-hadoop/)        |

## <a name="structure-your-data-set"></a><span data-ttu-id="460a0-146">Structure de votre jeu de données</span><span class="sxs-lookup"><span data-stu-id="460a0-146">Structure your data set</span></span>

<span data-ttu-id="460a0-147">Lorsque les données sont stockées dans Data Lake Store, la taille du fichier, le nombre de fichiers et la structure de dossiers ont un impact sur les performances.</span><span class="sxs-lookup"><span data-stu-id="460a0-147">When data is stored in Data Lake Store, the file size, number of files, and folder structure have an impact on performance.</span></span>  <span data-ttu-id="460a0-148">La section suivante décrit les meilleures pratiques en la matière.</span><span class="sxs-lookup"><span data-stu-id="460a0-148">The following section describes best practices in these areas.</span></span>  

### <a name="file-size"></a><span data-ttu-id="460a0-149">Taille du fichier</span><span class="sxs-lookup"><span data-stu-id="460a0-149">File size</span></span>

<span data-ttu-id="460a0-150">En règle générale, les moteurs d’analytique comme HDInsight et Azure Data Lake Analytics affichent une surcharge par fichier.</span><span class="sxs-lookup"><span data-stu-id="460a0-150">Typically, analytics engines such as HDInsight and Azure Data Lake Analytics have a per-file overhead.</span></span>  <span data-ttu-id="460a0-151">Si vous stockez vos données sous forme de petits fichiers nombreux, cela peut nuire aux performances.</span><span class="sxs-lookup"><span data-stu-id="460a0-151">If you store your data as many small files, this can negatively affect performance.</span></span>  

<span data-ttu-id="460a0-152">De manière générale, organisez vos données dans de grands fichiers pour des performances optimales.</span><span class="sxs-lookup"><span data-stu-id="460a0-152">In general, organize your data into larger sized files for better performance.</span></span>  <span data-ttu-id="460a0-153">Il convient d’organiser les jeux de données dans des fichiers de 256 Mo ou plus.</span><span class="sxs-lookup"><span data-stu-id="460a0-153">As a rule of thumb, organize data sets in files of 256MB or larger.</span></span> <span data-ttu-id="460a0-154">Dans certains cas, par exemple pour les images et les données binaires, il n’est pas possible de les traiter en parallèle.</span><span class="sxs-lookup"><span data-stu-id="460a0-154">In some cases such as images and binary data, it is not possible to process them in parallel.</span></span>  <span data-ttu-id="460a0-155">Dans ces cas, il est recommandé de créer des fichiers individuels de moins de 2 Go.</span><span class="sxs-lookup"><span data-stu-id="460a0-155">In these cases, it is recommended to keep individual files under 2GB.</span></span>

<span data-ttu-id="460a0-156">Parfois, les pipelines de données ont un contrôle limité sur les données brutes qui possèdent un grand nombre de petits fichiers.</span><span class="sxs-lookup"><span data-stu-id="460a0-156">Sometimes, data pipelines have limited control over the raw data which has lots of small files.</span></span>  <span data-ttu-id="460a0-157">Il est recommandé de faire appel à un processus de préparation qui génère des fichiers de grande taille à utiliser pour les applications en aval.</span><span class="sxs-lookup"><span data-stu-id="460a0-157">It is recommended to have a “cooking” process that generates larger files to use for downstream applications.</span></span>  

### <a name="organizing-time-series-data-in-folders"></a><span data-ttu-id="460a0-158">Organisation des données de série chronologique dans des dossiers</span><span class="sxs-lookup"><span data-stu-id="460a0-158">Organizing Time Series data in folders</span></span>

<span data-ttu-id="460a0-159">Pour les charges de travail Hive et ADLA, le nettoyage de partition de données de série chronologique peut aider certaines requêtes à lire uniquement un sous-ensemble de données, ce qui améliore les performances.</span><span class="sxs-lookup"><span data-stu-id="460a0-159">For Hive and ADLA workloads, partition pruning of time-series data can help some queries read only a subset of the data which improves performance.</span></span>    

<span data-ttu-id="460a0-160">Ces pipelines d’ingestion des données de série chronologique, organisent souvent leurs fichiers selon une structure d’appellation très structurée pour les fichiers et les dossiers.</span><span class="sxs-lookup"><span data-stu-id="460a0-160">Those pipelines that ingest time-series data, often place their files with a very structured naming for files and folders.</span></span> <span data-ttu-id="460a0-161">Découvrez ci-après un exemple très courant de données structurées par date :</span><span class="sxs-lookup"><span data-stu-id="460a0-161">Below is a very common example we see for data that is structured by date:</span></span>

    \DataSet\YYYY\MM\DD\datafile_YYYY_MM_DD.tsv

<span data-ttu-id="460a0-162">Notez que les informations de date / heure s’affichent à la fois en tant que dossiers et dans le nom de fichier.</span><span class="sxs-lookup"><span data-stu-id="460a0-162">Notice that the datetime information appears both as folders and in the filename.</span></span>

<span data-ttu-id="460a0-163">Pour la date et l’heure, le modèle suivant est récurrent.</span><span class="sxs-lookup"><span data-stu-id="460a0-163">For date and time, the following is a common pattern</span></span>

    \DataSet\YYYY\MM\DD\HH\mm\datafile_YYYY_MM_DD_HH_mm.tsv

<span data-ttu-id="460a0-164">Là encore, le type d’organisation des dossiers et fichiers sélectionné doit optimiser les plus gros fichiers et un nombre raisonnable de fichiers par dossier.</span><span class="sxs-lookup"><span data-stu-id="460a0-164">Again, the choice you make with the folder and file organization should optimize for the larger file sizes and a reasonable number of files in each folder.</span></span>

## <a name="optimizing-io-intensive-jobs-on-hadoop-and-spark-workloads-on-hdinsight"></a><span data-ttu-id="460a0-165">Optimisation des tâches à usage intensif d’E/S sur les charges de travail Hadoop et Spark sur HDInsight</span><span class="sxs-lookup"><span data-stu-id="460a0-165">Optimizing I/O intensive jobs on Hadoop and Spark workloads on HDInsight</span></span>

<span data-ttu-id="460a0-166">Ces tâches appartiennent à l’une des trois catégories suivantes :</span><span class="sxs-lookup"><span data-stu-id="460a0-166">Jobs fall into one of the following three categories:</span></span>

* <span data-ttu-id="460a0-167">**Usage intensif du processeur.**</span><span class="sxs-lookup"><span data-stu-id="460a0-167">**CPU intensive.**</span></span>  <span data-ttu-id="460a0-168">Ces tâches nécessitent de longues heures de calcul avec un minimum de temps d’E/S.</span><span class="sxs-lookup"><span data-stu-id="460a0-168">These jobs have long computation times with minimal I/O times.</span></span>  <span data-ttu-id="460a0-169">L’exemple inclut les tâches de traitement en langage naturel et Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="460a0-169">Examples include machine learning and natural language processing jobs.</span></span>  
* <span data-ttu-id="460a0-170">**Utilisation intensive de la mémoire.**</span><span class="sxs-lookup"><span data-stu-id="460a0-170">**Memory intensive.**</span></span>  <span data-ttu-id="460a0-171">Ces tâches utilisent beaucoup de mémoire.</span><span class="sxs-lookup"><span data-stu-id="460a0-171">These jobs use lots of memory.</span></span>  <span data-ttu-id="460a0-172">Exemples : PageRank et travaux d’analytique en temps réel.</span><span class="sxs-lookup"><span data-stu-id="460a0-172">Examples include PageRank and real-time analytics jobs.</span></span>  
* <span data-ttu-id="460a0-173">**Usage intensif des E/S.**</span><span class="sxs-lookup"><span data-stu-id="460a0-173">**I/O intensive.**</span></span>  <span data-ttu-id="460a0-174">La plus grande partie du temps de ces tâches est consacrée aux E/S.</span><span class="sxs-lookup"><span data-stu-id="460a0-174">These jobs spend most of their time doing I/O.</span></span>  <span data-ttu-id="460a0-175">Exemple courant : tâche de copie qui ne traite que les opérations de lecture et écriture.</span><span class="sxs-lookup"><span data-stu-id="460a0-175">A common example is a copy job which does only read and write operations.</span></span>  <span data-ttu-id="460a0-176">Autres exemples : tâches de préparation de données qui lisent une grande quantité de données, effectuent une transformation de données et réécrivent les données dans le magasin.</span><span class="sxs-lookup"><span data-stu-id="460a0-176">Other examples include data preparation jobs that read a lot of data, performs some data transformation, and then writes the data back to the store.</span></span>  

<span data-ttu-id="460a0-177">Les instructions suivantes ne s’appliquent qu’aux tâches avec un usage intensif d’E/S.</span><span class="sxs-lookup"><span data-stu-id="460a0-177">The following guidance is only applicable to I/O intensive jobs.</span></span>

### <a name="general-considerations-for-an-hdinsight-cluster"></a><span data-ttu-id="460a0-178">Considérations générales pour les clusters HDInsight</span><span class="sxs-lookup"><span data-stu-id="460a0-178">General Considerations for an HDInsight cluster</span></span>

* <span data-ttu-id="460a0-179">**Versions HDInsight.**</span><span class="sxs-lookup"><span data-stu-id="460a0-179">**HDInsight versions.**</span></span> <span data-ttu-id="460a0-180">Pour des performances optimales, utilisez la dernière version de HDInsight.</span><span class="sxs-lookup"><span data-stu-id="460a0-180">For best performance, use the latest release of HDInsight.</span></span>
* <span data-ttu-id="460a0-181">**Régions.**</span><span class="sxs-lookup"><span data-stu-id="460a0-181">**Regions.**</span></span> <span data-ttu-id="460a0-182">Placez Data Lake Store dans la même région que le cluster HDInsight.</span><span class="sxs-lookup"><span data-stu-id="460a0-182">Place the Data Lake Store in the same region as the HDInsight cluster.</span></span>  

<span data-ttu-id="460a0-183">Un cluster HDInsight est composé de deux nœuds principaux et de nœuds Worker.</span><span class="sxs-lookup"><span data-stu-id="460a0-183">An HDInsight cluster is composed of two head nodes and some worker nodes.</span></span> <span data-ttu-id="460a0-184">Chaque nœud Worker fournit une quantité spécifique de cœurs et de mémoire, déterminée par le type de machine virtuelle.</span><span class="sxs-lookup"><span data-stu-id="460a0-184">Each worker node provides a specific number of cores and memory, which is determined by the VM-type.</span></span>  <span data-ttu-id="460a0-185">Lorsque vous exécutez une tâche, YARN est le négociateur de ressource qui alloue la mémoire et les cœurs disponible pour créer des conteneurs.</span><span class="sxs-lookup"><span data-stu-id="460a0-185">When running a job, YARN is the resource negotiator that allocates the available memory and cores to create containers.</span></span>  <span data-ttu-id="460a0-186">Chaque conteneur exécute les tâches nécessaires pour terminer la tâche.</span><span class="sxs-lookup"><span data-stu-id="460a0-186">Each container runs the tasks needed to complete the job.</span></span>  <span data-ttu-id="460a0-187">Les conteneurs sont exécutés en parallèle pour traiter rapidement les tâches.</span><span class="sxs-lookup"><span data-stu-id="460a0-187">Containers run in parallel to process tasks quickly.</span></span> <span data-ttu-id="460a0-188">Par conséquent, l’exécution du plus grand nombre possible de conteneurs en parallèle permet d’améliorer les performances.</span><span class="sxs-lookup"><span data-stu-id="460a0-188">Therefore, performance is improved by running as many parallel containers as possible.</span></span>

<span data-ttu-id="460a0-189">Il existe trois couches au sein d’un cluster HDInsight qui peuvent être ajustées pour augmenter le nombre de conteneurs et utiliser tout le débit disponible.</span><span class="sxs-lookup"><span data-stu-id="460a0-189">There are three layers within an HDInsight cluster that can be tuned to increase the number of containers and use all available throughput.</span></span>  

* <span data-ttu-id="460a0-190">**Couche physique**</span><span class="sxs-lookup"><span data-stu-id="460a0-190">**Physical layer**</span></span>
* <span data-ttu-id="460a0-191">**Couche YARN**</span><span class="sxs-lookup"><span data-stu-id="460a0-191">**YARN layer**</span></span>
* <span data-ttu-id="460a0-192">**Couche de charge de travail**</span><span class="sxs-lookup"><span data-stu-id="460a0-192">**Workload layer**</span></span>

### <a name="physical-layer"></a><span data-ttu-id="460a0-193">Couche physique</span><span class="sxs-lookup"><span data-stu-id="460a0-193">Physical Layer</span></span>

<span data-ttu-id="460a0-194">**Exécutez le cluster avec le plus de nœuds et/ou les plus grosses machines virtuelles.**</span><span class="sxs-lookup"><span data-stu-id="460a0-194">**Run cluster with more nodes and/or larger sized VMs.**</span></span>  <span data-ttu-id="460a0-195">Un plus grand cluster permet d’exécuter plus de conteneurs YARN, comme le montre l’image ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="460a0-195">A larger cluster will enable you to run more YARN containers as shown in the picture below.</span></span>

![Performances de Data Lake Store](./media/data-lake-store-performance-tuning-guidance/VM.png)

<span data-ttu-id="460a0-197">**Utilisez des machines virtuelles avec davantage de bande passante réseau.**</span><span class="sxs-lookup"><span data-stu-id="460a0-197">**Use VMs with more network bandwidth.**</span></span>  <span data-ttu-id="460a0-198">La quantité de bande passante réseau peut être un goulot d’étranglement si elle moins importante que le débit Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="460a0-198">The amount of network bandwidth can be a bottleneck if there is less network bandwidth than Data Lake Store throughput.</span></span>  <span data-ttu-id="460a0-199">La taille de la bande passante réseau varie en fonction des machines virtuelles.</span><span class="sxs-lookup"><span data-stu-id="460a0-199">Different VMs will have varying network bandwidth sizes.</span></span>  <span data-ttu-id="460a0-200">Choisissez un type de machine virtuelle qui possède la plus grande bande passante possible.</span><span class="sxs-lookup"><span data-stu-id="460a0-200">Choose a VM-type that has the largest possible network bandwidth.</span></span>

### <a name="yarn-layer"></a><span data-ttu-id="460a0-201">Couche YARN</span><span class="sxs-lookup"><span data-stu-id="460a0-201">YARN Layer</span></span>

<span data-ttu-id="460a0-202">**Utilisez des conteneurs YARN plus petits.**</span><span class="sxs-lookup"><span data-stu-id="460a0-202">**Use smaller YARN containers.**</span></span>  <span data-ttu-id="460a0-203">Réduisez la taille de chaque conteneur YARN pour créer plusieurs conteneurs avec la même quantité de ressources.</span><span class="sxs-lookup"><span data-stu-id="460a0-203">Reduce the size of each YARN container to create more containers with the same amount of resources.</span></span>

![Performances de Data Lake Store](./media/data-lake-store-performance-tuning-guidance/small-containers.png)

<span data-ttu-id="460a0-205">En fonction de votre charge de travail, il y aura toujours une taille de conteneur YARN minimale requise.</span><span class="sxs-lookup"><span data-stu-id="460a0-205">Depending on your workload, there will always be a minimum YARN container size that is needed.</span></span> <span data-ttu-id="460a0-206">Si vous sélectionnez un conteneur trop petit, vos tâches rencontreront des problèmes de mémoire insuffisante.</span><span class="sxs-lookup"><span data-stu-id="460a0-206">If you pick too small a container, your jobs will run into out-of-memory issues.</span></span> <span data-ttu-id="460a0-207">En général, les conteneurs YARN ne doivent pas être inférieurs à 1 Go.</span><span class="sxs-lookup"><span data-stu-id="460a0-207">Typically YARN containers should be no smaller than 1GB.</span></span> <span data-ttu-id="460a0-208">Les conteneurs YARN de 3 Go sont courants.</span><span class="sxs-lookup"><span data-stu-id="460a0-208">It’s common to see 3GB YARN containers.</span></span> <span data-ttu-id="460a0-209">Pour certaines charges de travail, des conteneurs YARN plus grands peuvent être nécessaires.</span><span class="sxs-lookup"><span data-stu-id="460a0-209">For some workloads, you may need larger YARN containers.</span></span>  

<span data-ttu-id="460a0-210">**Augmentez le nombre de cœurs par conteneur YARN.**</span><span class="sxs-lookup"><span data-stu-id="460a0-210">**Increase cores per YARN container.**</span></span>  <span data-ttu-id="460a0-211">Augmentez le nombre de cœurs alloués à chaque conteneur pour augmenter le nombre de tâches parallèles qui s’exécutent dans chaque conteneur.</span><span class="sxs-lookup"><span data-stu-id="460a0-211">Increase the number of cores allocated to each container to increase the number of parallel tasks that run in each container.</span></span>  <span data-ttu-id="460a0-212">Cela fonctionne pour des applications comme Spark qui exécutent plusieurs tâches par conteneur.</span><span class="sxs-lookup"><span data-stu-id="460a0-212">This works for applications like Spark which run multiple tasks per container.</span></span>  <span data-ttu-id="460a0-213">Pour des applications comme Hive qui exécutent un seul thread par conteneur, il est préférable d’avoir plus de conteneurs plutôt que plus de cœurs par conteneur.</span><span class="sxs-lookup"><span data-stu-id="460a0-213">For applications like Hive which run a single thread in each container, it is better to have more containers rather than more cores per container.</span></span>   

### <a name="workload-layer"></a><span data-ttu-id="460a0-214">Couche de charge de travail</span><span class="sxs-lookup"><span data-stu-id="460a0-214">Workload Layer</span></span>

<span data-ttu-id="460a0-215">**Utilisez tous les conteneurs disponibles.**</span><span class="sxs-lookup"><span data-stu-id="460a0-215">**Use all available containers.**</span></span>  <span data-ttu-id="460a0-216">Définissez le nombre de tâches de manière à ce qu’il soit égal ou supérieur au nombre de conteneurs disponibles. Ainsi, toutes les ressources sont utilisées.</span><span class="sxs-lookup"><span data-stu-id="460a0-216">Set the number of tasks to be equal or larger than the number of available containers so that all resources are utilized.</span></span>

![Performances de Data Lake Store](./media/data-lake-store-performance-tuning-guidance/use-containers.png)

<span data-ttu-id="460a0-218">**L’échec des tâches est coûteux.**</span><span class="sxs-lookup"><span data-stu-id="460a0-218">**Failed tasks are costly.**</span></span> <span data-ttu-id="460a0-219">Si chaque tâche doit traiter une grande quantité de données, l’échec d’une tâche entraîne une nouvelle tentative coûteuse.</span><span class="sxs-lookup"><span data-stu-id="460a0-219">If each task has a large amount of data to process, then failure of a task results in an expensive retry.</span></span>  <span data-ttu-id="460a0-220">Par conséquent, il est préférable de créer davantage de tâches, chacune d’elle traitant une petite quantité de données.</span><span class="sxs-lookup"><span data-stu-id="460a0-220">Therefore, it is better to create more tasks, each of which processes a small amount of data.</span></span>

<span data-ttu-id="460a0-221">Outre les consignes générales ci-dessus, chaque application possède des paramètres différents à configurer pour cette application spécifique.</span><span class="sxs-lookup"><span data-stu-id="460a0-221">In addition to the general guidelines above, each application has different parameters available to tune for that specific application.</span></span> <span data-ttu-id="460a0-222">Le tableau suivant répertorie certains des paramètres et des liens pour paramétrer les performances pour chaque application.</span><span class="sxs-lookup"><span data-stu-id="460a0-222">The table below lists some of the parameters and links to get started with performance tuning for each application.</span></span>

| <span data-ttu-id="460a0-223">Charge de travail</span><span class="sxs-lookup"><span data-stu-id="460a0-223">Workload</span></span>               | <span data-ttu-id="460a0-224">Paramètre de définition des tâches</span><span class="sxs-lookup"><span data-stu-id="460a0-224">Parameter to set tasks</span></span>                                                         |
|--------------------|-------------------------------------------------------------------------------------|
| [<span data-ttu-id="460a0-225">Spark sur HDInsight</span><span class="sxs-lookup"><span data-stu-id="460a0-225">Spark on HDInisight</span></span>](data-lake-store-performance-tuning-spark.md)       | <ul><li><span data-ttu-id="460a0-226">Num-executors</span><span class="sxs-lookup"><span data-stu-id="460a0-226">Num-executors</span></span></li><li><span data-ttu-id="460a0-227">Executor-memory</span><span class="sxs-lookup"><span data-stu-id="460a0-227">Executor-memory</span></span></li><li><span data-ttu-id="460a0-228">Executor-cores</span><span class="sxs-lookup"><span data-stu-id="460a0-228">Executor-cores</span></span></li></ul> |
| [<span data-ttu-id="460a0-229">Hive sur HDInsight</span><span class="sxs-lookup"><span data-stu-id="460a0-229">Hive on HDInsight</span></span>](data-lake-store-performance-tuning-hive.md)    | <ul><li><span data-ttu-id="460a0-230">hive.tez.container.size</span><span class="sxs-lookup"><span data-stu-id="460a0-230">hive.tez.container.size</span></span></li></ul>         |
| [<span data-ttu-id="460a0-231">MapReduce sur HDInsight</span><span class="sxs-lookup"><span data-stu-id="460a0-231">MapReduce on HDInsight</span></span>](data-lake-store-performance-tuning-mapreduce.md)            | <ul><li><span data-ttu-id="460a0-232">Mapreduce.map.memory</span><span class="sxs-lookup"><span data-stu-id="460a0-232">Mapreduce.map.memory</span></span></li><li><span data-ttu-id="460a0-233">Mapreduce.job.maps</span><span class="sxs-lookup"><span data-stu-id="460a0-233">Mapreduce.job.maps</span></span></li><li><span data-ttu-id="460a0-234">Mapreduce.reduce.memory</span><span class="sxs-lookup"><span data-stu-id="460a0-234">Mapreduce.reduce.memory</span></span></li><li><span data-ttu-id="460a0-235">Mapreduce.job.reduces</span><span class="sxs-lookup"><span data-stu-id="460a0-235">Mapreduce.job.reduces</span></span></li></ul> |
| [<span data-ttu-id="460a0-236">Storm sur HDInsight</span><span class="sxs-lookup"><span data-stu-id="460a0-236">Storm on HDInsight</span></span>](data-lake-store-performance-tuning-storm.md)| <ul><li><span data-ttu-id="460a0-237">Nombre de processus de travail</span><span class="sxs-lookup"><span data-stu-id="460a0-237">Number of worker processes</span></span></li><li><span data-ttu-id="460a0-238">Nombre d’instances d’exécuteur de spout</span><span class="sxs-lookup"><span data-stu-id="460a0-238">Number of spout executor instances</span></span></li><li><span data-ttu-id="460a0-239">Nombre d’instances d’exécuteur de bolt</span><span class="sxs-lookup"><span data-stu-id="460a0-239">Number of bolt executor instances</span></span> </li><li><span data-ttu-id="460a0-240">Nombre de tâches de spout</span><span class="sxs-lookup"><span data-stu-id="460a0-240">Number of spout tasks</span></span></li><li><span data-ttu-id="460a0-241">Nombre de tâches de bolt</span><span class="sxs-lookup"><span data-stu-id="460a0-241">Number of bolt tasks</span></span></li></ul>|

## <a name="see-also"></a><span data-ttu-id="460a0-242">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="460a0-242">See also</span></span>
* [<span data-ttu-id="460a0-243">Présentation d’Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="460a0-243">Overview of Azure Data Lake Store</span></span>](data-lake-store-overview.md)
* [<span data-ttu-id="460a0-244">Prise en main d'Azure Data Lake Analytics</span><span class="sxs-lookup"><span data-stu-id="460a0-244">Get Started with Azure Data Lake Analytics</span></span>](../data-lake-analytics/data-lake-analytics-get-started-portal.md)
