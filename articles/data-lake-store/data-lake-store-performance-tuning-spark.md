---
title: "Recommandations en matière d’optimisation des performances d’Azure Data Lake Store Spark | Microsoft Docs"
description: "Recommandations en matière d’optimisation des performances d’Azure Data Lake Store Spark"
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: stewu
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 12/19/2016
ms.author: stewu
ms.openlocfilehash: 2109744fb7ffdfafb7a86bbea355e119718af099
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 07/11/2017
---
# <a name="performance-tuning-guidance-for-spark-on-hdinsight-and-azure-data-lake-store"></a><span data-ttu-id="300dd-103">Recommandations en matière d’optimisation des performances pour Spark sur HDInsight et Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="300dd-103">Performance tuning guidance for Spark on HDInsight and Azure Data Lake Store</span></span>

<span data-ttu-id="300dd-104">Lors du réglage des performances sur Spark, vous devez prendre en compte le nombre d’applications qui s’exécuteront sur votre cluster.</span><span class="sxs-lookup"><span data-stu-id="300dd-104">When tuning performance on Spark, you need to consider the number of apps that will be running on your cluster.</span></span>  <span data-ttu-id="300dd-105">Par défaut, vous pouvez exécuter 4 applications simultanément sur votre cluster HDI (Remarque : le paramètre par défaut est susceptible de changer).</span><span class="sxs-lookup"><span data-stu-id="300dd-105">By default, you can run 4 apps concurrently on your HDI cluster (Note: the default setting is subject to change).</span></span>  <span data-ttu-id="300dd-106">Vous pouvez décider d’utiliser moins d’applications, vous pouvez donc remplacer les paramètres par défaut et utiliser le cluster davantage pour ces applications.</span><span class="sxs-lookup"><span data-stu-id="300dd-106">You may decide to use fewer apps so you can override the default settings and use more of the cluster for those apps.</span></span>  

## <a name="prerequisites"></a><span data-ttu-id="300dd-107">Composants requis</span><span class="sxs-lookup"><span data-stu-id="300dd-107">Prerequisites</span></span>

* <span data-ttu-id="300dd-108">**Un abonnement Azure**.</span><span class="sxs-lookup"><span data-stu-id="300dd-108">**An Azure subscription**.</span></span> <span data-ttu-id="300dd-109">Consultez la page [Obtention d’un essai gratuit d’Azure](https://azure.microsoft.com/pricing/free-trial/).</span><span class="sxs-lookup"><span data-stu-id="300dd-109">See [Get Azure free trial](https://azure.microsoft.com/pricing/free-trial/).</span></span>
* <span data-ttu-id="300dd-110">**Un compte Azure Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="300dd-110">**An Azure Data Lake Store account**.</span></span> <span data-ttu-id="300dd-111">Pour savoir comment en créer un, consultez [Prise en main d'Azure Data Lake Store](data-lake-store-get-started-portal.md)</span><span class="sxs-lookup"><span data-stu-id="300dd-111">For instructions on how to create one, see [Get started with Azure Data Lake Store](data-lake-store-get-started-portal.md)</span></span>
* <span data-ttu-id="300dd-112">**Cluster Azure HDInsight** ayant accès à un compte Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="300dd-112">**Azure HDInsight cluster** with access to a Data Lake Store account.</span></span> <span data-ttu-id="300dd-113">Voir [Créer un cluster HDInsight avec Data Lake Store](data-lake-store-hdinsight-hadoop-use-portal.md).</span><span class="sxs-lookup"><span data-stu-id="300dd-113">See [Create an HDInsight cluster with Data Lake Store](data-lake-store-hdinsight-hadoop-use-portal.md).</span></span> <span data-ttu-id="300dd-114">Veillez à activer le Bureau à distance pour le cluster.</span><span class="sxs-lookup"><span data-stu-id="300dd-114">Make sure you enable Remote Desktop for the cluster.</span></span>
* <span data-ttu-id="300dd-115">**Exécution d’un cluster Spark sur Azure Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="300dd-115">**Running Spark cluster on Azure Data Lake Store**.</span></span>  <span data-ttu-id="300dd-116">Pour plus d’informations à ce sujet, consultez [Utiliser le cluster HDInsight Spark pour analyser les données dans Data Lake Store](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-use-with-data-lake-store)</span><span class="sxs-lookup"><span data-stu-id="300dd-116">For more information, see [Use HDInsight Spark cluster to analyze data in Data Lake Store](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-use-with-data-lake-store)</span></span>
* <span data-ttu-id="300dd-117">**Instructions d’optimisation des performances sur ADLS**.</span><span class="sxs-lookup"><span data-stu-id="300dd-117">**Performance tuning guidelines on ADLS**.</span></span>  <span data-ttu-id="300dd-118">Pour les concepts généraux sur les performances, consultez [Data Lake Store Performance Tuning Guidance (Recommandations en matière d’optimisation des performances de Data Lake Store)](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance)</span><span class="sxs-lookup"><span data-stu-id="300dd-118">For general performance concepts, see [Data Lake Store Performance Tuning Guidance](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance)</span></span> 

## <a name="parameters"></a><span data-ttu-id="300dd-119">parameters</span><span class="sxs-lookup"><span data-stu-id="300dd-119">Parameters</span></span>

<span data-ttu-id="300dd-120">Lors de l’exécution de travaux Spark, voici les principaux paramètres qui peuvent être paramétrés pour améliorer les performances sur ADLS :</span><span class="sxs-lookup"><span data-stu-id="300dd-120">When running Spark jobs, here are the most important settings that can be tuned to increase performance on ADLS:</span></span>

* <span data-ttu-id="300dd-121">**Num-executors** : le nombre de tâches simultanées qui peuvent être exécutées.</span><span class="sxs-lookup"><span data-stu-id="300dd-121">**Num-executors** - The number of concurrent tasks that can be executed.</span></span>

* <span data-ttu-id="300dd-122">**Executor-memory** : la quantité de mémoire allouée à chaque exécuteur.</span><span class="sxs-lookup"><span data-stu-id="300dd-122">**Executor-memory** - The amount of memory allocated to each executor.</span></span>

* <span data-ttu-id="300dd-123">**Executor-cores** : le nombre de cœurs alloués à chaque exécuteur.</span><span class="sxs-lookup"><span data-stu-id="300dd-123">**Executor-cores** - The number of cores allocated to each executor.</span></span>                     

<span data-ttu-id="300dd-124">**Num-executors** Num-executors définit le nombre maximal de tâches pouvant s’exécuter en parallèle.</span><span class="sxs-lookup"><span data-stu-id="300dd-124">**Num-executors** Num-executors will set the maximum number of tasks that can run in parallel.</span></span>  <span data-ttu-id="300dd-125">Le nombre réel de tâches qui peuvent s’exécuter en parallèle est limité par la mémoire et les ressources processeur disponibles dans votre cluster.</span><span class="sxs-lookup"><span data-stu-id="300dd-125">The actual number of tasks that can run in parallel is bounded by the memory and CPU resources available in your cluster.</span></span>

<span data-ttu-id="300dd-126">**Executor-memory** : la quantité de mémoire allouée à chaque exécuteur.</span><span class="sxs-lookup"><span data-stu-id="300dd-126">**Executor-memory** This is the amount of memory that is being allocated to each executor.</span></span>  <span data-ttu-id="300dd-127">La mémoire nécessaire pour chaque exécuteur dépend de la tâche.</span><span class="sxs-lookup"><span data-stu-id="300dd-127">The memory needed for each executor is dependent on the job.</span></span>  <span data-ttu-id="300dd-128">Pour les opérations complexes, la mémoire doit être plus élevée.</span><span class="sxs-lookup"><span data-stu-id="300dd-128">For complex operations, the memory needs to be higher.</span></span>  <span data-ttu-id="300dd-129">Pour les opérations simples telles que la lecture et l’écriture, les besoins en mémoire seront inférieurs.</span><span class="sxs-lookup"><span data-stu-id="300dd-129">For simple operations like read and write, memory requirements will be lower.</span></span>  <span data-ttu-id="300dd-130">La quantité de mémoire pour chaque exécuteur peut être consultée dans Ambari.</span><span class="sxs-lookup"><span data-stu-id="300dd-130">The amount of memory for each executor can be viewed in Ambari.</span></span>  <span data-ttu-id="300dd-131">Dans Ambari, accédez à Spark et affichez l’onglet Configurations.</span><span class="sxs-lookup"><span data-stu-id="300dd-131">In Ambari, navigate to Spark and view the Configs tab.</span></span>  

<span data-ttu-id="300dd-132">**Executor-cores** : définit la quantité de cœurs utilisés par exécuteur, ce qui détermine le nombre de threads parallèles qui peuvent être exécutés par l’exécuteur.</span><span class="sxs-lookup"><span data-stu-id="300dd-132">**Executor-cores** This sets the amount of cores used per executor, which determines the number of parallel threads that can be run per executor.</span></span>  <span data-ttu-id="300dd-133">Par exemple, si Executor-cores = 2, alors chaque exécuteur peut exécuter des 2 tâches parallèles dans l’exécuteur.</span><span class="sxs-lookup"><span data-stu-id="300dd-133">For example, if executor-cores = 2, then each executor can run 2 parallel tasks in the executor.</span></span>  <span data-ttu-id="300dd-134">La valeur à utiliser pour Executor-cores dépendra de la tâche.</span><span class="sxs-lookup"><span data-stu-id="300dd-134">The executor-cores needed will be dependent on the job.</span></span>  <span data-ttu-id="300dd-135">Les travaux intensifs en E/S ne nécessitent pas une grande quantité de mémoire par la tâche, ainsi chaque exécuteur peut gérer davantage de tâches parallèles.</span><span class="sxs-lookup"><span data-stu-id="300dd-135">I/O heavy jobs do not require a large amount of memory per task so each executor can handle more parallel tasks.</span></span>

<span data-ttu-id="300dd-136">Par défaut, deux cœurs YARN virtuels sont définis pour chaque cœur physique lors de l’exécution de Spark sur HDInsight.</span><span class="sxs-lookup"><span data-stu-id="300dd-136">By default, two virtual YARN cores are defined for each physical core when running Spark on HDInsight.</span></span>  <span data-ttu-id="300dd-137">Ce nombre offre un bon équilibre de simultanéité et de quantité de changement de contexte à partir de plusieurs threads.</span><span class="sxs-lookup"><span data-stu-id="300dd-137">This number provides a good balance of concurrecy and amount of context switching from multiple threads.</span></span>  

## <a name="guidance"></a><span data-ttu-id="300dd-138">Assistance</span><span class="sxs-lookup"><span data-stu-id="300dd-138">Guidance</span></span>

<span data-ttu-id="300dd-139">Lorsque vous exécutez des charges de travail analytiques Spark pour l’utilisation de données dans Data Lake Store, nous vous recommandons d’utiliser la version la plus récente de HDInsight pour bénéficier des meilleures performances avec Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="300dd-139">While running Spark analytic workloads to work with data in Data Lake Store, we recommend that you use the most recent HDInsight version to get the best performance with Data Lake Store.</span></span> <span data-ttu-id="300dd-140">Lorsque votre travail nécessite une grande quantité d’E/S, vous pouvez configurer certains paramètres pour améliorer les performances.</span><span class="sxs-lookup"><span data-stu-id="300dd-140">When your job is more I/O intensive, then certain parameters can be configured to improve performance.</span></span>  <span data-ttu-id="300dd-141">Azure Data Lake Store est une plateforme de stockage hautement évolutive capable de gérer un débit élevé.</span><span class="sxs-lookup"><span data-stu-id="300dd-141">Azure Data Lake Store is a highly scalable storage platform that can handle high throughput.</span></span>  <span data-ttu-id="300dd-142">Si le travail consiste principalement en une série de lectures ou d’écritures, l’augmentation de la concurrence pour les E/S à destination et en provenance d’Azure Data Lake Store peut accroître les performances.</span><span class="sxs-lookup"><span data-stu-id="300dd-142">If the job mainly consists of read or writes, then increasing concurrency for I/O to and from Azure Data Lake Store could increase performance.</span></span>

<span data-ttu-id="300dd-143">Vous disposez de plusieurs méthodes générales pour augmenter la concurrence des travaux qui nécessitent une grande quantité d’E/S.</span><span class="sxs-lookup"><span data-stu-id="300dd-143">There are a few general ways to increase concurrency for I/O intensive jobs.</span></span>

<span data-ttu-id="300dd-144">**Étape 1 : Déterminer le nombre d’applications s’exécutant sur votre cluster** : vous devez connaître le nombre d’applications en cours d’exécution sur le cluster, y compris celle en cours.</span><span class="sxs-lookup"><span data-stu-id="300dd-144">**Step 1: Determine how many apps are running on your cluster** – You should know how many apps are running on the cluster including the current one.</span></span>  <span data-ttu-id="300dd-145">Les valeurs par défaut pour chaque paramètre Spark supposent que 4 applications s’exécutent simultanément.</span><span class="sxs-lookup"><span data-stu-id="300dd-145">The default values for each Spark setting assumes that there are 4 apps running concurrently.</span></span>  <span data-ttu-id="300dd-146">Par conséquent, vous avez seulement 25 % du cluster disponible pour chaque application.</span><span class="sxs-lookup"><span data-stu-id="300dd-146">Therefore, you will only have 25% of the cluster available for each app.</span></span>  <span data-ttu-id="300dd-147">Pour obtenir de meilleures performances, vous pouvez remplacer les valeurs par défaut en modifiant le nombre d’exécuteurs.</span><span class="sxs-lookup"><span data-stu-id="300dd-147">To get better performance, you can override the defaults by changing the number of executors.</span></span>  

<span data-ttu-id="300dd-148">**Étape 2 : Configurer Executor-memory** : la première chose à définir est Executor-memory.</span><span class="sxs-lookup"><span data-stu-id="300dd-148">**Step 2: Set executor-memory** – the first thing to set is the executor-memory.</span></span>  <span data-ttu-id="300dd-149">La mémoire sera dépendante de la tâche que vous exécutez.</span><span class="sxs-lookup"><span data-stu-id="300dd-149">The memory will be dependent on the job that you are going to run.</span></span>  <span data-ttu-id="300dd-150">Vous pouvez augmenter la simultanéité en allouant de moins de mémoire par exécuteur.</span><span class="sxs-lookup"><span data-stu-id="300dd-150">You can increase concurrency by allocating less memory per executor.</span></span>  <span data-ttu-id="300dd-151">Si vous voyez des exceptions de mémoire insuffisante lors de l’exécution de votre tâche, vous devez augmenter la valeur de ce paramètre.</span><span class="sxs-lookup"><span data-stu-id="300dd-151">If you see out of memory exceptions when you run your job, then you should increase the value for this parameter.</span></span>  <span data-ttu-id="300dd-152">Une solution consiste à obtenir davantage de mémoire à l’aide d’un cluster qui possède une quantité supérieure de mémoire ou en augmentant la taille de votre cluster.</span><span class="sxs-lookup"><span data-stu-id="300dd-152">One alternative is to get more memory by using a cluster that has higher amounts of memory or increasing the size of your cluster.</span></span>  <span data-ttu-id="300dd-153">Une mémoire plus importante permettra d’utiliser plus d’exécuteurs, pour plus de simultanéité.</span><span class="sxs-lookup"><span data-stu-id="300dd-153">More memory will enable more executors to be used, which means more concurrency.</span></span>

<span data-ttu-id="300dd-154">**Étape 3 : Définir Executor-cores** : pour les charges de travail intensives qui n’ont pas d’opérations complexes, il est conseillé de commencer avec une valeur Executor-cores élevée pour augmenter le nombre de tâches parallèles par exécuteur.</span><span class="sxs-lookup"><span data-stu-id="300dd-154">**Step 3: Set executor-cores** – For I/O intensive workloads that do not have complex operations, it’s good to start with a high number of executor-cores to increase the number of parallel tasks per executor.</span></span>  <span data-ttu-id="300dd-155">Régler Executor-cores sur 4 est un bon point de départ.</span><span class="sxs-lookup"><span data-stu-id="300dd-155">Setting executor-cores to 4 is a good start.</span></span>   

    executor-cores = 4
<span data-ttu-id="300dd-156">Augmenter la valeur d’Executor-cores vous donne plus de parallélisme, vous pouvez donc expérimenter différentes valeurs pour ce paramètre.</span><span class="sxs-lookup"><span data-stu-id="300dd-156">Increasing the number of executor-cores will give you more parallelism so you can experiment with different executor-cores.</span></span>  <span data-ttu-id="300dd-157">Pour les tâches qui ont des opérations plus complexes, vous devez réduire le nombre de cœurs par exécuteur.</span><span class="sxs-lookup"><span data-stu-id="300dd-157">For jobs that have more complex operations, you should reduce the number of cores per executor.</span></span>  <span data-ttu-id="300dd-158">Si la valeur d’Executor-cores est supérieure à 4, puis le garbage collection peut devenir inefficace et dégrader les performances.</span><span class="sxs-lookup"><span data-stu-id="300dd-158">If executor-cores is set higher than 4, then garbage collection may become inefficient and degrade performance.</span></span>

<span data-ttu-id="300dd-159">**Étape 4 : Déterminer la quantité de mémoire YARN du cluster** : cette information est disponible dans Ambari.</span><span class="sxs-lookup"><span data-stu-id="300dd-159">**Step 4: Determine amount of YARN memory in cluster** – This information is available in Ambari.</span></span>  <span data-ttu-id="300dd-160">Accédez à YARN et affichez l’onglet Configurations.</span><span class="sxs-lookup"><span data-stu-id="300dd-160">Navigate to YARN and view the Configs tab.</span></span>  <span data-ttu-id="300dd-161">La mémoire YARN s’affiche dans cette fenêtre.</span><span class="sxs-lookup"><span data-stu-id="300dd-161">The YARN memory is displayed in this window.</span></span>  
<span data-ttu-id="300dd-162">Remarque : lorsque vous êtes dans la fenêtre, vous pouvez également voir la taille de conteneur YARN par défaut.</span><span class="sxs-lookup"><span data-stu-id="300dd-162">Note: while you are in the window, you can also see the default YARN container size.</span></span>  <span data-ttu-id="300dd-163">La taille du conteneur YARN est identique au paramètre de mémoire par exécuteur.</span><span class="sxs-lookup"><span data-stu-id="300dd-163">The YARN container size is the same as memory per executor paramter.</span></span>

    Total YARN memory = nodes * YARN memory per node
<span data-ttu-id="300dd-164">**Étape 5 : Calculer num-executors**</span><span class="sxs-lookup"><span data-stu-id="300dd-164">**Step 5: Calculate num-executors**</span></span>

<span data-ttu-id="300dd-165">**Calculer la contrainte de mémoire** : le paramètre num-executors est limité par la mémoire ou par le processeur.</span><span class="sxs-lookup"><span data-stu-id="300dd-165">**Calculate memory constraint** - The num-executors parameter is constrained either by memory or by CPU.</span></span>  <span data-ttu-id="300dd-166">La contrainte de mémoire est déterminée par la quantité de mémoire YARN disponible pour votre application.</span><span class="sxs-lookup"><span data-stu-id="300dd-166">The memory constraint is determined by the amount of available YARN memory for your application.</span></span>  <span data-ttu-id="300dd-167">Vous devez prendre la mémoire YARN totale et la diviser par executor-memory.</span><span class="sxs-lookup"><span data-stu-id="300dd-167">You should take total YARN memory and divide that by executor-memory.</span></span>  <span data-ttu-id="300dd-168">La mise à l’échelle de la contrainte doit être adaptée pour le nombre d’applications, nous la divisons donc par le nombre d’applications.</span><span class="sxs-lookup"><span data-stu-id="300dd-168">The constraint needs to be de-scaled for the number of apps so we divide by the number of apps.</span></span>

    Memory constraint = (total YARN memory / executor memory) / # of apps   
<span data-ttu-id="300dd-169">**Calculer la contrainte de processeur** : la contrainte de processeur est calculée comme le nombre total de cœurs virtuels divisé par le nombre de cœurs par exécuteur.</span><span class="sxs-lookup"><span data-stu-id="300dd-169">**Calculate CPU constraint** - The CPU constraint is calculated as the total virtual cores divided by the number of cores per executor.</span></span>  <span data-ttu-id="300dd-170">Il existe 2 cœurs virtuels pour chaque noyau physique.</span><span class="sxs-lookup"><span data-stu-id="300dd-170">There are 2 virtual cores for each physical core.</span></span>  <span data-ttu-id="300dd-171">Comme pour la contrainte de mémoire, nous divisons par le nombre d’applications.</span><span class="sxs-lookup"><span data-stu-id="300dd-171">Similar to the memory constraint, we have divide by the number of apps.</span></span>

    virtual cores = (nodes in cluster * # of physical cores in node * 2)
    CPU constraint = (total virtual cores / # of cores per executor) / # of apps
<span data-ttu-id="300dd-172">**Définir num-executors** : le paramètre num-executors est déterminé par la valeur minimale entre la contrainte de mémoire et la contrainte de processeur.</span><span class="sxs-lookup"><span data-stu-id="300dd-172">**Set num-executors** – The num-executors parameter is determined by taking the minimum of the memory constraint and the CPU constraint.</span></span> 

    num-executors = Min (total virtual Cores / # of cores per executor, available YARN memory / executor-memory)   
<span data-ttu-id="300dd-173">Définir un nombre plus élevé pour num-executors’augmente pas nécessairement les performances.</span><span class="sxs-lookup"><span data-stu-id="300dd-173">Setting a higher number of num-executors does not necessarily increase performance.</span></span>  <span data-ttu-id="300dd-174">Vous devez prendre en compte le fait que l’ajout d’exécuteurs ajoute une charge pour chaque exécuteur supplémentaire, ce qui peut dégrader les performances.</span><span class="sxs-lookup"><span data-stu-id="300dd-174">You should consider that adding more executors will add extra overhead for each additional executor, which can potentially degrade performance.</span></span>  <span data-ttu-id="300dd-175">Num-executors est limité par les ressources de cluster.</span><span class="sxs-lookup"><span data-stu-id="300dd-175">Num-executors is bounded by the cluster resources.</span></span>    

## <a name="example-calculation"></a><span data-ttu-id="300dd-176">Exemple de calcul</span><span class="sxs-lookup"><span data-stu-id="300dd-176">Example Calculation</span></span>

<span data-ttu-id="300dd-177">Supposons que vous possédez un cluster composé de 8 nœuds D4v2 exécutant 2 applications, dont celle que vous souhaitez exécuter.</span><span class="sxs-lookup"><span data-stu-id="300dd-177">Let’s say you currently have a cluster composed of 8 D4v2 nodes that is running 2 apps including the one you are going to run.</span></span>  

<span data-ttu-id="300dd-178">**Étape 1 : Déterminer le nombre d’applications s’exécutant sur votre cluster** : vous savez que vous avez 2 applications sur votre cluster, y compris celle que vous souhaitez exécuter.</span><span class="sxs-lookup"><span data-stu-id="300dd-178">**Step 1: Determine how many apps are running on your cluster** – you know that you have 2 apps on your cluster, including the one you are going to run.</span></span>  

<span data-ttu-id="300dd-179">**Étape 2 : Configurer executor-memory** : pour cet exemple, nous déterminons que 6 Go pour executor-memory sera suffisant pour les travaux intensifs en E/S.</span><span class="sxs-lookup"><span data-stu-id="300dd-179">**Step 2: Set executor-memory** – for this example, we determine that 6GB of executor-memory will be sufficient for I/O intensive job.</span></span>  

    executor-memory = 6GB
<span data-ttu-id="300dd-180">**Étape 3 : Définir executor-cores** : dans la mesure où il s’agit d’un travail intensif en E/S, nous pouvons définir le nombre de cœurs pour chaque exécuteur sur 4.</span><span class="sxs-lookup"><span data-stu-id="300dd-180">**Step 3: Set executor-cores** – Since this is an I/O intensive job, we can set the number of cores for each executor to 4.</span></span>  <span data-ttu-id="300dd-181">Définir le nombre de cœurs par exécuteur sur une valeur supérieure à 4 peut provoquer des problèmes de garbage collection.</span><span class="sxs-lookup"><span data-stu-id="300dd-181">Setting cores per executor to larger than 4 may cause garbage collection problems.</span></span>  

    executor-cores = 4
<span data-ttu-id="300dd-182">**Étape 4 : Déterminer la quantité de mémoire YARN du cluster** : nous accédons à Ambari pour déterminer que chaque D4v2 possède 25 Go de mémoire YARN.</span><span class="sxs-lookup"><span data-stu-id="300dd-182">**Step 4: Determine amount of YARN memory in cluster** – We navigate to Ambari to find out that each D4v2 has 25GB of YARN memory.</span></span>  <span data-ttu-id="300dd-183">Étant donné qu’il y a 8 nœuds, la mémoire YARN disponible est multipliée par 8.</span><span class="sxs-lookup"><span data-stu-id="300dd-183">Since there are 8 nodes, the available YARN memory is multiplied by 8.</span></span>

    Total YARN memory = nodes * YARN memory* per node
    Total YARN memory = 8 nodes * 25GB = 200GB
<span data-ttu-id="300dd-184">**Étape 5 : Calculer num-executors** : le paramètre num-executors est déterminé par la valeur minimale entre la contrainte de mémoire et la contrainte de processeur, divisée par le nombre d’applications exécutées sur Spark.</span><span class="sxs-lookup"><span data-stu-id="300dd-184">**Step 5: Calculate num-executors** – The num-executors parameter is determined by taking the minimum of the memory constraint and the CPU constraint divided by the # of apps running on Spark.</span></span>    

<span data-ttu-id="300dd-185">**Calculer la contrainte de mémoire** : la contrainte de mémoire est calculée comme la mémoire YARN totale divisée par la mémoire par exécuteur.</span><span class="sxs-lookup"><span data-stu-id="300dd-185">**Calculate memory constraint** – The memory constraint is calculated as the total YARN memory divided by the memory per executor.</span></span>

    Memory constraint = (total YARN memory / executor memory) / # of apps   
    Memory constraint = (200GB / 6GB) / 2   
    Memory constraint = 16 (rounded)
<span data-ttu-id="300dd-186">**Calculer la contrainte de processeur** : la contrainte de processeur est calculée comme le nombre total de cœurs YARN divisé par le nombre de cœurs par exécuteur.</span><span class="sxs-lookup"><span data-stu-id="300dd-186">**Calculate CPU constraint** - The CPU constraint is calculated as the total yarn cores divided by the number of cores per executor.</span></span>
    
    YARN cores = nodes in cluster * # of cores per node * 2   
    YARN cores = 8 nodes * 8 cores per D14 * 2 = 128
    CPU constraint = (total YARN cores / # of cores per executor) / # of apps
    CPU constraint = (128 / 4) / 2
    CPU constraint = 16
<span data-ttu-id="300dd-187">**Définir num-executors**</span><span class="sxs-lookup"><span data-stu-id="300dd-187">**Set num-executors**</span></span>

    num-executors = Min (memory constraint, CPU constraint)
    num-executors = Min (16, 16)
    num-executors = 16    

