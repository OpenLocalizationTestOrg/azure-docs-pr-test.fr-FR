---
title: "Présentation de Spark sur Azure HDInsight | Microsoft Docs"
description: "Cet article fournit une présentation Spark sur HDInsight et des différents scénarios dans lesquels vous pouvez utiliser le cluster Spark sur HDInsight."
keywords: "présentation d’apache spark,cluster spark,présentation de spark,spark sur hdinsight"
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 82334b9e-4629-4005-8147-19f875c8774e
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 05/12/2017
ms.author: nitinme
ms.openlocfilehash: acb80aa98cc978a906ccd6e4b4132a439e505bc8
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 07/11/2017
---
# <a name="introduction-to-spark-on-hdinsight"></a><span data-ttu-id="f2224-104">Présentation de Spark sur HDInsight</span><span class="sxs-lookup"><span data-stu-id="f2224-104">Introduction to Spark on HDInsight</span></span>

<span data-ttu-id="f2224-105">Cet article vous fournit une présentation de Spark sur HDInsight.</span><span class="sxs-lookup"><span data-stu-id="f2224-105">This article provides you with an introduction to Spark on HDInsight.</span></span> <span data-ttu-id="f2224-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> est une infrastructure de traitement parallèle open source qui prend en charge le traitement en mémoire pour améliorer les performances des applications d’analyse de données volumineuses.</span><span class="sxs-lookup"><span data-stu-id="f2224-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span></span> <span data-ttu-id="f2224-107">Le cluster Spark sur HDInsight est compatible avec Azure Storage (WASB) ainsi qu’avec Azure Data Lake Store afin que vos données existantes stockées dans Azure puissent être facilement traitées via un cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="f2224-107">Spark cluster on HDInsight is compatible with Azure Storage (WASB) as well as Azure Data Lake Store so your existing data stored in Azure can easily be processed via a Spark cluster.</span></span>

<span data-ttu-id="f2224-108">Lorsque vous créez un cluster Spark sur HDInsight, vous créez des ressources de calcul Azure dans lesquelles Spark est installé et configuré.</span><span class="sxs-lookup"><span data-stu-id="f2224-108">When you create a Spark cluster on HDInsight, you create Azure compute resources with Spark installed and configured.</span></span> <span data-ttu-id="f2224-109">La création d’un cluster Spark dans HDInsight ne prend que dix minutes environ.</span><span class="sxs-lookup"><span data-stu-id="f2224-109">It only takes about ten minutes to create a Spark cluster in HDInsight.</span></span> <span data-ttu-id="f2224-110">Les données à traiter sont stockées dans Azure Storage ou Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="f2224-110">The data to be processed is stored in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="f2224-111">Consultez [Utiliser Azure Storage avec HDInsight](hdinsight-hadoop-use-blob-storage.md).</span><span class="sxs-lookup"><span data-stu-id="f2224-111">See [Use Azure Storage with HDInsight](hdinsight-hadoop-use-blob-storage.md).</span></span>

<span data-ttu-id="f2224-112">**Pour créer un cluster Spark sur HDInsight**, consultez [Démarrage rapide : créer un cluster Spark sur HDInsight et exécuter une requête interactive Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="f2224-112">**To create a Spark cluster on HDInsight**, see [QuickStart: create a Spark cluster on HDInsight and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>


## <a name="what-is-apache-spark-on-azure-hdinsight"></a><span data-ttu-id="f2224-113">Qu’est-ce qu’Apache Spark sur Azure HDInsight ?</span><span class="sxs-lookup"><span data-stu-id="f2224-113">What is Apache Spark on Azure HDInsight?</span></span>
<span data-ttu-id="f2224-114">Les clusters Spark sur HDInsight proposent un service Spark entièrement géré.</span><span class="sxs-lookup"><span data-stu-id="f2224-114">Spark clusters on HDInsight offer a fully managed Spark service.</span></span> <span data-ttu-id="f2224-115">Les avantages de la création d’un cluster Spark sur HDInsight sont répertoriés ici.</span><span class="sxs-lookup"><span data-stu-id="f2224-115">Benefits of creating a Spark cluster on HDInsight are listed here.</span></span>

| <span data-ttu-id="f2224-116">Fonctionnalité</span><span class="sxs-lookup"><span data-stu-id="f2224-116">Feature</span></span> | <span data-ttu-id="f2224-117">Description</span><span class="sxs-lookup"><span data-stu-id="f2224-117">Description</span></span> |
| --- | --- |
| <span data-ttu-id="f2224-118">Facilité de création des clusters Spark</span><span class="sxs-lookup"><span data-stu-id="f2224-118">Ease of creating Spark clusters</span></span> |<span data-ttu-id="f2224-119">Vous pouvez créer un cluster Spark sur HDInsight en quelques minutes en utilisant le portail Azure, Azure PowerShell ou le Kit de développement logiciel (SDK) .NET HDInsight.</span><span class="sxs-lookup"><span data-stu-id="f2224-119">You can create a new Spark cluster on HDInsight in minutes using the Azure Portal, Azure PowerShell, or the HDInsight .NET SDK.</span></span> <span data-ttu-id="f2224-120">Consultez [Prise en main des clusters Spark dans HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span><span class="sxs-lookup"><span data-stu-id="f2224-120">See [Get started with Spark cluster in HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span></span> |
| <span data-ttu-id="f2224-121">Simplicité d'utilisation</span><span class="sxs-lookup"><span data-stu-id="f2224-121">Ease of use</span></span> |<span data-ttu-id="f2224-122">Un cluster Spark sur HDInsight inclut des blocs-notes Jupyter et Zeppelin.</span><span class="sxs-lookup"><span data-stu-id="f2224-122">Spark cluster in HDInsight include Jupyter and Zeppelin notebooks.</span></span> <span data-ttu-id="f2224-123">Vous pouvez les utiliser pour le traitement interactif et la visualisation des données.</span><span class="sxs-lookup"><span data-stu-id="f2224-123">You can use these for interactive data processing and visualization.</span></span>|
| <span data-ttu-id="f2224-124">API REST</span><span class="sxs-lookup"><span data-stu-id="f2224-124">REST APIs</span></span> |<span data-ttu-id="f2224-125">Les clusters Spark sur HDInsight comprennent [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), un serveur de travaux Spark basé sur une API REST, qui permet de soumettre et de surveiller à distance des travaux.</span><span class="sxs-lookup"><span data-stu-id="f2224-125">Spark clusters in HDInsight include [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), a REST API-based Spark job server to remotely submit and monitor jobs.</span></span> |
| <span data-ttu-id="f2224-126">Prise en charge d’Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="f2224-126">Support for Azure Data Lake Store</span></span> | <span data-ttu-id="f2224-127">Un cluster Spark sur HDInsight peut être configuré pour utiliser Azure Data Lake Store en tant que stockage supplémentaire, mais aussi en tant que stockage principal (uniquement avec les clusters HDInsight 3.5).</span><span class="sxs-lookup"><span data-stu-id="f2224-127">Spark cluster on HDInsight can be configured to use Azure Data Lake Store as an additional storage, as well as primary storage (only with HDInsight 3.5 clusters) .</span></span> <span data-ttu-id="f2224-128">Pour plus d’informations sur Data Lake Store, consultez [Vue d’ensemble d’Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md).</span><span class="sxs-lookup"><span data-stu-id="f2224-128">For more information on Data Lake Store, see [Overview of Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md).</span></span> |
| <span data-ttu-id="f2224-129">Intégration aux services Azure</span><span class="sxs-lookup"><span data-stu-id="f2224-129">Integration with Azure services</span></span> |<span data-ttu-id="f2224-130">Un cluster Spark sur HDInsight est fourni avec un connecteur à Azure Event Hubs.</span><span class="sxs-lookup"><span data-stu-id="f2224-130">Spark cluster on HDInsight comes with a connector to Azure Event Hubs.</span></span> <span data-ttu-id="f2224-131">Les clients peuvent créer des applications de diffusion en continu en utilisant Event Hubs, en plus de [Kafka](http://kafka.apache.org/), qui est déjà disponible dans Spark.</span><span class="sxs-lookup"><span data-stu-id="f2224-131">Customers can build streaming applications using the Event Hubs, in addition to [Kafka](http://kafka.apache.org/), which is already available as part of Spark.</span></span> |
| <span data-ttu-id="f2224-132">Prise en charge du serveur R</span><span class="sxs-lookup"><span data-stu-id="f2224-132">Support for R Server</span></span> | <span data-ttu-id="f2224-133">Vous pouvez configurer un serveur R sur un cluster Spark HDInsight pour exécuter des calculs R distribués à la vitesse d’un cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="f2224-133">You can set up a R Server on HDInsight Spark cluster to run distributed R computations with the speeds promised with a Spark cluster.</span></span> <span data-ttu-id="f2224-134">Pour plus d’informations, consultez la section [Prise en main de R Server sur HDInsight](hdinsight-hadoop-r-server-get-started.md).</span><span class="sxs-lookup"><span data-stu-id="f2224-134">For more information, see [Get started using R Server on HDInsight](hdinsight-hadoop-r-server-get-started.md).</span></span> |
| <span data-ttu-id="f2224-135">Intégration à des environnements de développement intégrés tiers</span><span class="sxs-lookup"><span data-stu-id="f2224-135">Integration with third-party IDEs</span></span> | <span data-ttu-id="f2224-136">HDInsight fournit des plug-ins pour IDE tels qu’IntelliJ IDEA et Eclipse que vous pouvez utiliser pour créer et soumettre des applications sur un cluster Spark HDInsight.</span><span class="sxs-lookup"><span data-stu-id="f2224-136">HDInsight provides plugins for IDEs like IntelliJ IDEA and Eclipse that you can use to create and submit applications to an HDInsight Spark cluster.</span></span> <span data-ttu-id="f2224-137">Pour plus d’informations, consultez [Utiliser le kit de ressources Azure pour IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) et [Utiliser le kit de ressources Azure pour Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span><span class="sxs-lookup"><span data-stu-id="f2224-137">For more information see [Use Azure Toolkit for IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) and [Use Azure Toolkit for Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span></span>|
| <span data-ttu-id="f2224-138">Requêtes simultanées</span><span class="sxs-lookup"><span data-stu-id="f2224-138">Concurrent Queries</span></span> |<span data-ttu-id="f2224-139">Les clusters Spark sur HDInsight prennent en charge les requêtes simultanées.</span><span class="sxs-lookup"><span data-stu-id="f2224-139">Spark clusters in HDInsight support concurrent queries.</span></span> <span data-ttu-id="f2224-140">Ainsi, plusieurs requêtes d’un même utilisateur ou plusieurs requêtes de différents utilisateurs et applications peuvent partager les mêmes ressources de cluster.</span><span class="sxs-lookup"><span data-stu-id="f2224-140">This enables multiple queries from one user or multiple queries from various users and applications to share the same cluster resources.</span></span> |
| <span data-ttu-id="f2224-141">Mise en cache sur des disques SSD</span><span class="sxs-lookup"><span data-stu-id="f2224-141">Caching on SSDs</span></span> |<span data-ttu-id="f2224-142">Vous pouvez choisir de mettre en cache des données en mémoire ou dans les disques SSD attachés aux nœuds de cluster.</span><span class="sxs-lookup"><span data-stu-id="f2224-142">You can choose to cache data either in memory or in SSDs attached to the cluster nodes.</span></span> <span data-ttu-id="f2224-143">La mise en cache en mémoire fournit les meilleures performances de requêtes, mais peut s’avérer coûteuse. La mise en cache sur des disques SSD constitue une très bonne option pour améliorer les performances des requêtes sans nécessité de créer un cluster d’une taille requise pour tenir l’ensemble du jeu de données en mémoire.</span><span class="sxs-lookup"><span data-stu-id="f2224-143">Caching in memory provides the best query performance but could be expensive; caching in SSDs provides a great option for improving query performance without the need to create a cluster of a size that is required to fit the entire dataset in memory.</span></span> |
| <span data-ttu-id="f2224-144">Intégration aux outils décisionnels</span><span class="sxs-lookup"><span data-stu-id="f2224-144">Integration with BI Tools</span></span> |<span data-ttu-id="f2224-145">Les clusters Spark sur HDInsight fournissent des connecteurs pour certains outils décisionnels, notamment [Power BI](http://www.powerbi.com/) et [Tableau](http://www.tableau.com/products/desktop), pour l’analyse des données.</span><span class="sxs-lookup"><span data-stu-id="f2224-145">Spark clusters on HDInsight provide connectors for  BI tools such as [Power BI](http://www.powerbi.com/) and [Tableau](http://www.tableau.com/products/desktop) for data analytics.</span></span> |
| <span data-ttu-id="f2224-146">Bibliothèques Anaconda préchargées</span><span class="sxs-lookup"><span data-stu-id="f2224-146">Pre-loaded Anaconda libraries</span></span> |<span data-ttu-id="f2224-147">Les clusters Spark sur HDInsight sont fournis avec des bibliothèques Anaconda préinstallées.</span><span class="sxs-lookup"><span data-stu-id="f2224-147">Spark clusters on HDInsight come with Anaconda libraries pre-installed.</span></span> <span data-ttu-id="f2224-148">[Anaconda](http://docs.continuum.io/anaconda/) fournit près de 200 bibliothèques pour l’apprentissage automatique, l’analyse des données, la visualisation, etc.</span><span class="sxs-lookup"><span data-stu-id="f2224-148">[Anaconda](http://docs.continuum.io/anaconda/) provides close to 200 libraries for machine learning, data analysis, visualization, etc.</span></span> |
| <span data-ttu-id="f2224-149">Extensibilité</span><span class="sxs-lookup"><span data-stu-id="f2224-149">Scalability</span></span> |<span data-ttu-id="f2224-150">Bien que vous puissiez spécifier le nombre de nœuds dans votre cluster lors de sa création, vous pourriez souhaiter augmenter ou réduire la taille du cluster pour l’adapter à votre charge de travail.</span><span class="sxs-lookup"><span data-stu-id="f2224-150">Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match workload.</span></span> <span data-ttu-id="f2224-151">Tous les clusters HDInsight vous permettent de modifier le nombre de nœuds du cluster.</span><span class="sxs-lookup"><span data-stu-id="f2224-151">All HDInsight clusters allow you to change the number of nodes in the cluster.</span></span> <span data-ttu-id="f2224-152">En outre, les clusters Spark peuvent être supprimés sans perte de données puisque toutes les données sont stockées dans Azure Storage ou Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="f2224-152">Also, Spark clusters can be dropped with no loss of data since all the data is stored in Azure Storage or Data Lake Store.</span></span> |
| <span data-ttu-id="f2224-153">Support technique 24 heures sur 24, 7 jours sur 7</span><span class="sxs-lookup"><span data-stu-id="f2224-153">24/7 Support</span></span> |<span data-ttu-id="f2224-154">Les clusters Spark sur HDInsight sont fournis avec un support technique à l’échelle de l’entreprise assuré 24 heures sur 24, 7 jours sur 7 et un contrat de niveau de service de 99,9 % de disponibilité.</span><span class="sxs-lookup"><span data-stu-id="f2224-154">Spark clusters on HDInsight come with  enterprise-level 24/7 support and an SLA of 99.9% up-time.</span></span> |

## <a name="what-are-the-use-cases-for-spark-on-hdinsight"></a><span data-ttu-id="f2224-155">Quels sont les cas d’utilisation de Spark sur HDInsight ?</span><span class="sxs-lookup"><span data-stu-id="f2224-155">What are the use cases for Spark on HDInsight?</span></span>
<span data-ttu-id="f2224-156">Les clusters Spark sur HDInsight autorisent les principaux scénarios suivants.</span><span class="sxs-lookup"><span data-stu-id="f2224-156">Spark clusters in HDInsight enable the following key scenarios.</span></span>

### <a name="interactive-data-analysis-and-bi"></a><span data-ttu-id="f2224-157">Analyse des données interactive et Power BI</span><span class="sxs-lookup"><span data-stu-id="f2224-157">Interactive data analysis and BI</span></span>
[<span data-ttu-id="f2224-158">Consulter un didacticiel</span><span class="sxs-lookup"><span data-stu-id="f2224-158">Look at a tutorial</span></span>](hdinsight-apache-spark-use-bi-tools.md)

<span data-ttu-id="f2224-159">Apache Spark sur HDInsight stocke les données dans Azure Storage ou Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="f2224-159">Apache Spark in HDInsight stores data in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="f2224-160">Des experts et des décideurs clés peuvent analyser les données, générer les rapports correspondants et utiliser Microsoft Power BI pour créer des rapports interactifs à partir des données analysées.</span><span class="sxs-lookup"><span data-stu-id="f2224-160">Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI to build interactive reports from the analyzed data.</span></span> <span data-ttu-id="f2224-161">Les analystes peuvent démarrer à partir des données non structurées/semi-structurées dans le stockage du cluster, définir un schéma pour les données à l’aide des blocs-notes, puis générer des modèles de données à l’aide de Microsoft Power BI.</span><span class="sxs-lookup"><span data-stu-id="f2224-161">Analysts can start from unstructured/semi structured data in cluster storage, define a schema for the data using notebooks, and then build data models using Microsoft Power BI.</span></span> <span data-ttu-id="f2224-162">Les clusters Spark sur HDInsight prennent également en charge plusieurs outils décisionnels tiers comme Tableau, grâce auxquels ils constituent une plateforme idéale pour les analystes de données, les experts et les décideurs clés.</span><span class="sxs-lookup"><span data-stu-id="f2224-162">Spark clusters in HDInsight also support a number of third party BI tools such as Tableau making it an ideal platform for data analysts, business experts, and key decision makers.</span></span>

### <a name="spark-machine-learning"></a><span data-ttu-id="f2224-163">Spark Machine Learning</span><span class="sxs-lookup"><span data-stu-id="f2224-163">Spark Machine Learning</span></span>
[<span data-ttu-id="f2224-164">Consulter un didacticiel : prédiction des températures d’un bâtiment en utilisant des données HVAC</span><span class="sxs-lookup"><span data-stu-id="f2224-164">Look at a tutorial: Predict building temperatures uisng HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)

[<span data-ttu-id="f2224-165">Consulter un didacticiel : prédiction des résultats d’inspections alimentaires</span><span class="sxs-lookup"><span data-stu-id="f2224-165">Look at a tutorial: Predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)

<span data-ttu-id="f2224-166">Apache Spark est fourni avec [MLlib](http://spark.apache.org/mllib/), bibliothèque d’apprentissage automatique basée sur Spark que vous pouvez utiliser à partir d’un cluster Spark sur HDInsight.</span><span class="sxs-lookup"><span data-stu-id="f2224-166">Apache Spark comes with [MLlib](http://spark.apache.org/mllib/), a machine learning library built on top of Spark that you can use from a Spark cluster in HDInsight.</span></span> <span data-ttu-id="f2224-167">Un cluster Spark sur HDInsight inclut également Anaconda, une distribution de Python avec une variété de packages pour l’apprentissage automatique.</span><span class="sxs-lookup"><span data-stu-id="f2224-167">Spark cluster on HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning.</span></span> <span data-ttu-id="f2224-168">Ajoutez à cela la prise en charge intégrée des blocs-notes Jupyter et Zeppelin, et vous disposez d’un environnement haut de gamme pour la création d’applications d’apprentissage automatique.</span><span class="sxs-lookup"><span data-stu-id="f2224-168">Couple this with a built-in support for Jupyter and Zeppelin notebooks, and you have a top-of-the-line environment for creating machine learning applications.</span></span>

### <a name="spark-streaming-and-real-time-data-analysis"></a><span data-ttu-id="f2224-169">Analyse des données de diffusion en continu et en temps réel Spark</span><span class="sxs-lookup"><span data-stu-id="f2224-169">Spark streaming and real-time data analysis</span></span>
[<span data-ttu-id="f2224-170">Consulter un didacticiel</span><span class="sxs-lookup"><span data-stu-id="f2224-170">Look at a tutorial</span></span>](hdinsight-apache-spark-eventhub-streaming.md)

<span data-ttu-id="f2224-171">Les clusters Spark sur HDInsight offrent une prise en charge améliorée de la création de solutions d’analyse en temps réel.</span><span class="sxs-lookup"><span data-stu-id="f2224-171">Spark clusters in HDInsight offer a rich support for building real-time analytics solutions.</span></span> <span data-ttu-id="f2224-172">Si Spark possède déjà des connecteurs pour la réception des données provenant de nombreuses sources telles que les sockets Kafka, Flume, Twitter, ZeroMQ ou TCP, Spark dans HDInsight ajoute la prise en charge de première classe de la réception des données provenant d’Azure Event Hubs.</span><span class="sxs-lookup"><span data-stu-id="f2224-172">While Spark already has connectors to ingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs.</span></span> <span data-ttu-id="f2224-173">La fonctionnalité Event Hubs est le service de file d’attente le plus largement utilisé sur Azure.</span><span class="sxs-lookup"><span data-stu-id="f2224-173">Event Hubs are the most widely used queuing service on Azure.</span></span> <span data-ttu-id="f2224-174">Grâce à leur prise en charge immédiate des concentrateurs d’événements, les clusters Spark sur HDInsight constituent une plateforme idéale pour créer un pipeline d’analyse en temps réel.</span><span class="sxs-lookup"><span data-stu-id="f2224-174">Having an out-of-the-box support for Event Hubs makes Spark clusters in HDInsight an ideal platform for building real time analytics pipeline.</span></span>

## <span data-ttu-id="f2224-175"><a name="next-steps"></a>Quels sont les composants inclus dans un cluster Spark ?</span><span class="sxs-lookup"><span data-stu-id="f2224-175"><a name="next-steps"></a>What components are included as part of a Spark cluster?</span></span>
<span data-ttu-id="f2224-176">Les clusters Spark sur HDInsight incluent les composants suivants qui sont disponibles dans les clusters par défaut.</span><span class="sxs-lookup"><span data-stu-id="f2224-176">Spark clusters in HDInsight include the following components that are available on the clusters by default.</span></span>

* <span data-ttu-id="f2224-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span><span class="sxs-lookup"><span data-stu-id="f2224-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span></span> <span data-ttu-id="f2224-178">Comprend Spark Core, Spark SQL, les API de diffusion en continu Spark, GraphX et MLlib.</span><span class="sxs-lookup"><span data-stu-id="f2224-178">Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.</span></span>
* [<span data-ttu-id="f2224-179">Anaconda</span><span class="sxs-lookup"><span data-stu-id="f2224-179">Anaconda</span></span>](http://docs.continuum.io/anaconda/)
* [<span data-ttu-id="f2224-180">Livy</span><span class="sxs-lookup"><span data-stu-id="f2224-180">Livy</span></span>](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)
* [<span data-ttu-id="f2224-181">Bloc-notes Jupyter</span><span class="sxs-lookup"><span data-stu-id="f2224-181">Jupyter notebook</span></span>](https://jupyter.org)
* [<span data-ttu-id="f2224-182">Bloc-notes Zeppelin</span><span class="sxs-lookup"><span data-stu-id="f2224-182">Zeppelin notebook</span></span>](http://zeppelin-project.org/)

<span data-ttu-id="f2224-183">Les clusters Spark sur HDInsight fournissent également un [pilote ODBC](http://go.microsoft.com/fwlink/?LinkId=616229) pour la connectivité aux clusters Spark sur HDInsight à partir d’outils décisionnels comme Microsoft Power BI et Tableau.</span><span class="sxs-lookup"><span data-stu-id="f2224-183">Spark clusters on HDInsight also provide an [ODBC driver](http://go.microsoft.com/fwlink/?LinkId=616229) for connectivity to Spark clusters in HDInsight from BI tools such as Microsoft Power BI and Tableau.</span></span>

## <a name="where-do-i-start"></a><span data-ttu-id="f2224-184">Par où commencer ?</span><span class="sxs-lookup"><span data-stu-id="f2224-184">Where do I start?</span></span>
<span data-ttu-id="f2224-185">Commencez par créer un cluster Spark sur HDInsight.</span><span class="sxs-lookup"><span data-stu-id="f2224-185">Start with creating a Spark cluster on HDInsight.</span></span> <span data-ttu-id="f2224-186">Consultez [Démarrage rapide : créer un cluster Spark sur HDInsight Linux et exécuter une requête interactive à l’aide de Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="f2224-186">See [QuickStart: create a Spark cluster on HDInsight Linux and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> 

## <a name="next-steps"></a><span data-ttu-id="f2224-187">Étapes suivantes</span><span class="sxs-lookup"><span data-stu-id="f2224-187">Next Steps</span></span>
### <a name="scenarios"></a><span data-ttu-id="f2224-188">Scénarios</span><span class="sxs-lookup"><span data-stu-id="f2224-188">Scenarios</span></span>
* [<span data-ttu-id="f2224-189">Spark avec BI : effectuez une analyse interactive des données à l’aide de Spark dans HDInsight avec des outils BI</span><span class="sxs-lookup"><span data-stu-id="f2224-189">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="f2224-190">Spark avec Machine Learning : Utiliser Spark dans HDInsight pour l’analyse de la température de bâtiments à l’aide de données HVAC</span><span class="sxs-lookup"><span data-stu-id="f2224-190">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="f2224-191">Spark avec Machine Learning : Utiliser Spark dans HDInsight pour prédire les résultats de l’inspection des aliments</span><span class="sxs-lookup"><span data-stu-id="f2224-191">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="f2224-192">Streaming Spark : Utiliser Spark dans HDInsight pour créer des applications de diffusion en continu en temps réel</span><span class="sxs-lookup"><span data-stu-id="f2224-192">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="f2224-193">Analyse des journaux de site web à l’aide de Spark dans HDInsight</span><span class="sxs-lookup"><span data-stu-id="f2224-193">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="f2224-194">Créer et exécuter des applications</span><span class="sxs-lookup"><span data-stu-id="f2224-194">Create and run applications</span></span>
* [<span data-ttu-id="f2224-195">Créer une application autonome avec Scala</span><span class="sxs-lookup"><span data-stu-id="f2224-195">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="f2224-196">Exécuter des tâches à distance avec Livy sur un cluster Spark</span><span class="sxs-lookup"><span data-stu-id="f2224-196">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="f2224-197">Outils et extensions</span><span class="sxs-lookup"><span data-stu-id="f2224-197">Tools and extensions</span></span>
* [<span data-ttu-id="f2224-198">Utilisez le plugin d’outils HDInsight pour IntelliJ IDEA pour créer et soumettre des applications Spark Scala</span><span class="sxs-lookup"><span data-stu-id="f2224-198">Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="f2224-199">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely) (Utiliser le plug-in Outils HDInsight pour IntelliJ IDEA pour déboguer des applications Spark à distance)</span><span class="sxs-lookup"><span data-stu-id="f2224-199">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="f2224-200">Utiliser des bloc-notes Zeppelin avec un cluster Spark sur HDInsight</span><span class="sxs-lookup"><span data-stu-id="f2224-200">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="f2224-201">Noyaux disponibles pour le bloc-notes Jupyter dans un cluster Spark pour HDInsight</span><span class="sxs-lookup"><span data-stu-id="f2224-201">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="f2224-202">Utiliser des packages externes avec les blocs-notes Jupyter</span><span class="sxs-lookup"><span data-stu-id="f2224-202">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="f2224-203">Install Jupyter on your computer and connect to an HDInsight Spark cluster (Installer Jupyter sur un ordinateur et se connecter au cluster Spark sur HDInsight)</span><span class="sxs-lookup"><span data-stu-id="f2224-203">Install Jupyter on your computer and connect to an HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="f2224-204">Gestion des ressources</span><span class="sxs-lookup"><span data-stu-id="f2224-204">Manage resources</span></span>
* [<span data-ttu-id="f2224-205">Gérer les ressources du cluster Apache Spark dans Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="f2224-205">Manage resources for the Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="f2224-206">Track and debug jobs running on an Apache Spark cluster in HDInsight (Suivi et débogage des tâches en cours d’exécution sur un cluster Apache Spark dans HDInsight)</span><span class="sxs-lookup"><span data-stu-id="f2224-206">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
* <span data-ttu-id="f2224-207">[Problèmes connus d’Apache Spark sur Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span><span class="sxs-lookup"><span data-stu-id="f2224-207">[Known issues of Apache Spark in Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span></span>
