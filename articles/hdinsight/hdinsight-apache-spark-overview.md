---
title: tooSpark aaaIntroduction sur Azure HDInsight | Documents Microsoft
description: "Cet article fournit une présentation tooSpark sur HDInsight et hello différents scénarios dans lesquels vous pouvez utiliser le cluster Spark sur HDInsight."
keywords: "Nouveautés spark d’apache, cluster spark, introduction toospark, spark sur hdinsight"
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 82334b9e-4629-4005-8147-19f875c8774e
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 05/12/2017
ms.author: nitinme
ms.openlocfilehash: 41996e733618b8534469fa239b980ac50161a535
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 10/06/2017
---
# <a name="introduction-toospark-on-hdinsight"></a><span data-ttu-id="0d486-104">TooSpark introduction sur HDInsight</span><span class="sxs-lookup"><span data-stu-id="0d486-104">Introduction tooSpark on HDInsight</span></span>

<span data-ttu-id="0d486-105">Cet article vous offre une tooSpark introduction sur HDInsight.</span><span class="sxs-lookup"><span data-stu-id="0d486-105">This article provides you with an introduction tooSpark on HDInsight.</span></span> <span data-ttu-id="0d486-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> est une infrastructure de traitement en parallèle open source qui prend en charge en mémoire traitement tooboost les performances de hello big-applications de données analytiques.</span><span class="sxs-lookup"><span data-stu-id="0d486-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> is an open-source parallel processing framework that supports in-memory processing tooboost hello performance of big-data analytic applications.</span></span> <span data-ttu-id="0d486-107">Le cluster Spark sur HDInsight est compatible avec Azure Storage (WASB) ainsi qu’avec Azure Data Lake Store afin que vos données existantes stockées dans Azure puissent être facilement traitées via un cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="0d486-107">Spark cluster on HDInsight is compatible with Azure Storage (WASB) as well as Azure Data Lake Store so your existing data stored in Azure can easily be processed via a Spark cluster.</span></span>

<span data-ttu-id="0d486-108">Lorsque vous créez un cluster Spark sur HDInsight, vous créez des ressources de calcul Azure dans lesquelles Spark est installé et configuré.</span><span class="sxs-lookup"><span data-stu-id="0d486-108">When you create a Spark cluster on HDInsight, you create Azure compute resources with Spark installed and configured.</span></span> <span data-ttu-id="0d486-109">Il n’accepte qu’environ dix minutes de cluster toocreate un Spark dans HDInsight.</span><span class="sxs-lookup"><span data-stu-id="0d486-109">It only takes about ten minutes toocreate a Spark cluster in HDInsight.</span></span> <span data-ttu-id="0d486-110">Hello toobe de données traitée est stockée dans le stockage Azure ou Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="0d486-110">hello data toobe processed is stored in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="0d486-111">Consultez [Utiliser Azure Storage avec HDInsight](hdinsight-hadoop-use-blob-storage.md).</span><span class="sxs-lookup"><span data-stu-id="0d486-111">See [Use Azure Storage with HDInsight](hdinsight-hadoop-use-blob-storage.md).</span></span>

<span data-ttu-id="0d486-112">**cluster de toocreate un Spark sur HDInsight**, consultez [démarrage rapide : créer un cluster Spark sur HDInsight et exécuter des requêtes interactives à l’aide du bloc-notes](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="0d486-112">**toocreate a Spark cluster on HDInsight**, see [QuickStart: create a Spark cluster on HDInsight and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>


## <a name="what-is-apache-spark-on-azure-hdinsight"></a><span data-ttu-id="0d486-113">Qu’est-ce qu’Apache Spark sur Azure HDInsight ?</span><span class="sxs-lookup"><span data-stu-id="0d486-113">What is Apache Spark on Azure HDInsight?</span></span>
<span data-ttu-id="0d486-114">Les clusters Spark sur HDInsight proposent un service Spark entièrement géré.</span><span class="sxs-lookup"><span data-stu-id="0d486-114">Spark clusters on HDInsight offer a fully managed Spark service.</span></span> <span data-ttu-id="0d486-115">Les avantages de la création d’un cluster Spark sur HDInsight sont répertoriés ici.</span><span class="sxs-lookup"><span data-stu-id="0d486-115">Benefits of creating a Spark cluster on HDInsight are listed here.</span></span>

| <span data-ttu-id="0d486-116">Fonctionnalité</span><span class="sxs-lookup"><span data-stu-id="0d486-116">Feature</span></span> | <span data-ttu-id="0d486-117">Description</span><span class="sxs-lookup"><span data-stu-id="0d486-117">Description</span></span> |
| --- | --- |
| <span data-ttu-id="0d486-118">Facilité de création des clusters Spark</span><span class="sxs-lookup"><span data-stu-id="0d486-118">Ease of creating Spark clusters</span></span> |<span data-ttu-id="0d486-119">Vous pouvez créer un nouveau cluster Spark sur HDInsight en quelques minutes à l’aide de hello portail Azure, Azure PowerShell ou hello HDInsight .NET SDK.</span><span class="sxs-lookup"><span data-stu-id="0d486-119">You can create a new Spark cluster on HDInsight in minutes using hello Azure Portal, Azure PowerShell, or hello HDInsight .NET SDK.</span></span> <span data-ttu-id="0d486-120">Consultez [Prise en main des clusters Spark dans HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span><span class="sxs-lookup"><span data-stu-id="0d486-120">See [Get started with Spark cluster in HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span></span> |
| <span data-ttu-id="0d486-121">Simplicité d'utilisation</span><span class="sxs-lookup"><span data-stu-id="0d486-121">Ease of use</span></span> |<span data-ttu-id="0d486-122">Un cluster Spark sur HDInsight inclut des blocs-notes Jupyter et Zeppelin.</span><span class="sxs-lookup"><span data-stu-id="0d486-122">Spark cluster in HDInsight include Jupyter and Zeppelin notebooks.</span></span> <span data-ttu-id="0d486-123">Vous pouvez les utiliser pour le traitement interactif et la visualisation des données.</span><span class="sxs-lookup"><span data-stu-id="0d486-123">You can use these for interactive data processing and visualization.</span></span>|
| <span data-ttu-id="0d486-124">API REST</span><span class="sxs-lookup"><span data-stu-id="0d486-124">REST APIs</span></span> |<span data-ttu-id="0d486-125">Incluent des clusters Spark dans HDInsight [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), une basée sur l’API REST de Spark travail serveur tooremotely submit et moniteur de travaux.</span><span class="sxs-lookup"><span data-stu-id="0d486-125">Spark clusters in HDInsight include [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), a REST API-based Spark job server tooremotely submit and monitor jobs.</span></span> |
| <span data-ttu-id="0d486-126">Prise en charge d’Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="0d486-126">Support for Azure Data Lake Store</span></span> | <span data-ttu-id="0d486-127">Cluster Spark sur HDInsight peut être configuré toouse Azure Data Lake Store un stockage supplémentaire, ainsi que d’un stockage principal (uniquement avec les clusters HDInsight 3.5).</span><span class="sxs-lookup"><span data-stu-id="0d486-127">Spark cluster on HDInsight can be configured toouse Azure Data Lake Store as an additional storage, as well as primary storage (only with HDInsight 3.5 clusters) .</span></span> <span data-ttu-id="0d486-128">Pour plus d’informations sur Data Lake Store, consultez [Vue d’ensemble d’Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md).</span><span class="sxs-lookup"><span data-stu-id="0d486-128">For more information on Data Lake Store, see [Overview of Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md).</span></span> |
| <span data-ttu-id="0d486-129">Intégration aux services Azure</span><span class="sxs-lookup"><span data-stu-id="0d486-129">Integration with Azure services</span></span> |<span data-ttu-id="0d486-130">Cluster Spark sur HDInsight est fourni avec un tooAzure connecteur concentrateurs d’événements.</span><span class="sxs-lookup"><span data-stu-id="0d486-130">Spark cluster on HDInsight comes with a connector tooAzure Event Hubs.</span></span> <span data-ttu-id="0d486-131">Les clients peuvent créer des applications de diffusion en continu à l’aide de concentrateurs d’événements hello, en outre trop[Kafka](http://kafka.apache.org/), qui est déjà disponible dans le cadre de Spark.</span><span class="sxs-lookup"><span data-stu-id="0d486-131">Customers can build streaming applications using hello Event Hubs, in addition too[Kafka](http://kafka.apache.org/), which is already available as part of Spark.</span></span> |
| <span data-ttu-id="0d486-132">Prise en charge du serveur R</span><span class="sxs-lookup"><span data-stu-id="0d486-132">Support for R Server</span></span> | <span data-ttu-id="0d486-133">Vous pouvez configurer un serveur R sur HDInsight Spark cluster toorun distributed calculs de R avec des vitesses hello promis avec un cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="0d486-133">You can set up a R Server on HDInsight Spark cluster toorun distributed R computations with hello speeds promised with a Spark cluster.</span></span> <span data-ttu-id="0d486-134">Pour plus d’informations, consultez la section [Prise en main de R Server sur HDInsight](hdinsight-hadoop-r-server-get-started.md).</span><span class="sxs-lookup"><span data-stu-id="0d486-134">For more information, see [Get started using R Server on HDInsight](hdinsight-hadoop-r-server-get-started.md).</span></span> |
| <span data-ttu-id="0d486-135">Intégration à des environnements de développement intégrés tiers</span><span class="sxs-lookup"><span data-stu-id="0d486-135">Integration with third-party IDEs</span></span> | <span data-ttu-id="0d486-136">HDInsight fournit les plug-ins pour l’IDE comme ne se produise IntelliJ et que vous pouvez utiliser toocreate et soumettre des applications tooan cluster HDInsight Spark d’Eclipse.</span><span class="sxs-lookup"><span data-stu-id="0d486-136">HDInsight provides plugins for IDEs like IntelliJ IDEA and Eclipse that you can use toocreate and submit applications tooan HDInsight Spark cluster.</span></span> <span data-ttu-id="0d486-137">Pour plus d’informations, consultez [Utiliser le kit de ressources Azure pour IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) et [Utiliser le kit de ressources Azure pour Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span><span class="sxs-lookup"><span data-stu-id="0d486-137">For more information see [Use Azure Toolkit for IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) and [Use Azure Toolkit for Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span></span>|
| <span data-ttu-id="0d486-138">Requêtes simultanées</span><span class="sxs-lookup"><span data-stu-id="0d486-138">Concurrent Queries</span></span> |<span data-ttu-id="0d486-139">Les clusters Spark sur HDInsight prennent en charge les requêtes simultanées.</span><span class="sxs-lookup"><span data-stu-id="0d486-139">Spark clusters in HDInsight support concurrent queries.</span></span> <span data-ttu-id="0d486-140">Cela permet à plusieurs requêtes à partir d’un utilisateur ou de plusieurs requêtes à partir de différents utilisateurs et applications tooshare hello les mêmes ressources de cluster.</span><span class="sxs-lookup"><span data-stu-id="0d486-140">This enables multiple queries from one user or multiple queries from various users and applications tooshare hello same cluster resources.</span></span> |
| <span data-ttu-id="0d486-141">Mise en cache sur des disques SSD</span><span class="sxs-lookup"><span data-stu-id="0d486-141">Caching on SSDs</span></span> |<span data-ttu-id="0d486-142">Vous pouvez choisir les données toocache en mémoire ou dans SSDs attaché toohello les nœuds de cluster.</span><span class="sxs-lookup"><span data-stu-id="0d486-142">You can choose toocache data either in memory or in SSDs attached toohello cluster nodes.</span></span> <span data-ttu-id="0d486-143">La mise en cache dans la mémoire fournit de meilleures performances des requêtes hello mais peut être coûteuse ; mise en cache dans les disques SSD fournit une option intéressante pour améliorer les performances des requêtes sans nécessité de hello toocreate un cluster dont la taille est requis toofit hello dataset entier en mémoire.</span><span class="sxs-lookup"><span data-stu-id="0d486-143">Caching in memory provides hello best query performance but could be expensive; caching in SSDs provides a great option for improving query performance without hello need toocreate a cluster of a size that is required toofit hello entire dataset in memory.</span></span> |
| <span data-ttu-id="0d486-144">Intégration aux outils décisionnels</span><span class="sxs-lookup"><span data-stu-id="0d486-144">Integration with BI Tools</span></span> |<span data-ttu-id="0d486-145">Les clusters Spark sur HDInsight fournissent des connecteurs pour certains outils décisionnels, notamment [Power BI](http://www.powerbi.com/) et [Tableau](http://www.tableau.com/products/desktop), pour l’analyse des données.</span><span class="sxs-lookup"><span data-stu-id="0d486-145">Spark clusters on HDInsight provide connectors for  BI tools such as [Power BI](http://www.powerbi.com/) and [Tableau](http://www.tableau.com/products/desktop) for data analytics.</span></span> |
| <span data-ttu-id="0d486-146">Bibliothèques Anaconda préchargées</span><span class="sxs-lookup"><span data-stu-id="0d486-146">Pre-loaded Anaconda libraries</span></span> |<span data-ttu-id="0d486-147">Les clusters Spark sur HDInsight sont fournis avec des bibliothèques Anaconda préinstallées.</span><span class="sxs-lookup"><span data-stu-id="0d486-147">Spark clusters on HDInsight come with Anaconda libraries pre-installed.</span></span> <span data-ttu-id="0d486-148">[Anaconda](http://docs.continuum.io/anaconda/) fournit les bibliothèques too200 fermer pour l’apprentissage, analyse, visualisation, etc..</span><span class="sxs-lookup"><span data-stu-id="0d486-148">[Anaconda](http://docs.continuum.io/anaconda/) provides close too200 libraries for machine learning, data analysis, visualization, etc.</span></span> |
| <span data-ttu-id="0d486-149">Extensibilité</span><span class="sxs-lookup"><span data-stu-id="0d486-149">Scalability</span></span> |<span data-ttu-id="0d486-150">Bien que vous pouvez spécifier le nombre de hello de nœuds dans votre cluster lors de la création, vous souhaitez toogrow ou réduire la charge du cluster toomatch hello.</span><span class="sxs-lookup"><span data-stu-id="0d486-150">Although you can specify hello number of nodes in your cluster during creation, you may want toogrow or shrink hello cluster toomatch workload.</span></span> <span data-ttu-id="0d486-151">Tous les clusters HDInsight autorisent un nombre de hello toochange de nœuds dans un cluster de hello.</span><span class="sxs-lookup"><span data-stu-id="0d486-151">All HDInsight clusters allow you toochange hello number of nodes in hello cluster.</span></span> <span data-ttu-id="0d486-152">En outre, les clusters de Spark peuvent être supprimés sans perte de données comme toutes les données hello est stocké dans le stockage Azure ou Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="0d486-152">Also, Spark clusters can be dropped with no loss of data since all hello data is stored in Azure Storage or Data Lake Store.</span></span> |
| <span data-ttu-id="0d486-153">Support technique 24 heures sur 24, 7 jours sur 7</span><span class="sxs-lookup"><span data-stu-id="0d486-153">24/7 Support</span></span> |<span data-ttu-id="0d486-154">Les clusters Spark sur HDInsight sont fournis avec un support technique à l’échelle de l’entreprise assuré 24 heures sur 24, 7 jours sur 7 et un contrat de niveau de service de 99,9 % de disponibilité.</span><span class="sxs-lookup"><span data-stu-id="0d486-154">Spark clusters on HDInsight come with  enterprise-level 24/7 support and an SLA of 99.9% up-time.</span></span> |

## <a name="what-are-hello-use-cases-for-spark-on-hdinsight"></a><span data-ttu-id="0d486-155">Quelles sont les cas d’usage hello pour Spark sur HDInsight ?</span><span class="sxs-lookup"><span data-stu-id="0d486-155">What are hello use cases for Spark on HDInsight?</span></span>
<span data-ttu-id="0d486-156">Clusters Spark dans HDInsight activer hello les scénarios clés suivants.</span><span class="sxs-lookup"><span data-stu-id="0d486-156">Spark clusters in HDInsight enable hello following key scenarios.</span></span>

### <a name="interactive-data-analysis-and-bi"></a><span data-ttu-id="0d486-157">Analyse des données interactive et Power BI</span><span class="sxs-lookup"><span data-stu-id="0d486-157">Interactive data analysis and BI</span></span>
[<span data-ttu-id="0d486-158">Consulter un didacticiel</span><span class="sxs-lookup"><span data-stu-id="0d486-158">Look at a tutorial</span></span>](hdinsight-apache-spark-use-bi-tools.md)

<span data-ttu-id="0d486-159">Apache Spark sur HDInsight stocke les données dans Azure Storage ou Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="0d486-159">Apache Spark in HDInsight stores data in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="0d486-160">Experts de l’entreprise et décideurs peuvent analyser et générer des rapports sur ces données et utiliser Microsoft Power BI toobuild des rapports interactifs à partir des données de hello analysé.</span><span class="sxs-lookup"><span data-stu-id="0d486-160">Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI toobuild interactive reports from hello analyzed data.</span></span> <span data-ttu-id="0d486-161">Les analystes peuvent démarrer à partir des données non structurées/semi structurée dans le stockage de cluster, définir un schéma pour les données de salutation à l’aide d’ordinateurs portables et puis générer des modèles à l’aide de Microsoft Power BI.</span><span class="sxs-lookup"><span data-stu-id="0d486-161">Analysts can start from unstructured/semi structured data in cluster storage, define a schema for hello data using notebooks, and then build data models using Microsoft Power BI.</span></span> <span data-ttu-id="0d486-162">Les clusters Spark sur HDInsight prennent également en charge plusieurs outils décisionnels tiers comme Tableau, grâce auxquels ils constituent une plateforme idéale pour les analystes de données, les experts et les décideurs clés.</span><span class="sxs-lookup"><span data-stu-id="0d486-162">Spark clusters in HDInsight also support a number of third party BI tools such as Tableau making it an ideal platform for data analysts, business experts, and key decision makers.</span></span>

### <a name="spark-machine-learning"></a><span data-ttu-id="0d486-163">Spark Machine Learning</span><span class="sxs-lookup"><span data-stu-id="0d486-163">Spark Machine Learning</span></span>
[<span data-ttu-id="0d486-164">Consulter un didacticiel : prédiction des températures d’un bâtiment en utilisant des données HVAC</span><span class="sxs-lookup"><span data-stu-id="0d486-164">Look at a tutorial: Predict building temperatures uisng HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)

[<span data-ttu-id="0d486-165">Consulter un didacticiel : prédiction des résultats d’inspections alimentaires</span><span class="sxs-lookup"><span data-stu-id="0d486-165">Look at a tutorial: Predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)

<span data-ttu-id="0d486-166">Apache Spark est fourni avec [MLlib](http://spark.apache.org/mllib/), bibliothèque d’apprentissage automatique basée sur Spark que vous pouvez utiliser à partir d’un cluster Spark sur HDInsight.</span><span class="sxs-lookup"><span data-stu-id="0d486-166">Apache Spark comes with [MLlib](http://spark.apache.org/mllib/), a machine learning library built on top of Spark that you can use from a Spark cluster in HDInsight.</span></span> <span data-ttu-id="0d486-167">Un cluster Spark sur HDInsight inclut également Anaconda, une distribution de Python avec une variété de packages pour l’apprentissage automatique.</span><span class="sxs-lookup"><span data-stu-id="0d486-167">Spark cluster on HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning.</span></span> <span data-ttu-id="0d486-168">Ajoutez à cela la prise en charge intégrée des blocs-notes Jupyter et Zeppelin, et vous disposez d’un environnement haut de gamme pour la création d’applications d’apprentissage automatique.</span><span class="sxs-lookup"><span data-stu-id="0d486-168">Couple this with a built-in support for Jupyter and Zeppelin notebooks, and you have a top-of-the-line environment for creating machine learning applications.</span></span>

### <a name="spark-streaming-and-real-time-data-analysis"></a><span data-ttu-id="0d486-169">Analyse des données de diffusion en continu et en temps réel Spark</span><span class="sxs-lookup"><span data-stu-id="0d486-169">Spark streaming and real-time data analysis</span></span>
[<span data-ttu-id="0d486-170">Consulter un didacticiel</span><span class="sxs-lookup"><span data-stu-id="0d486-170">Look at a tutorial</span></span>](hdinsight-apache-spark-eventhub-streaming.md)

<span data-ttu-id="0d486-171">Les clusters Spark sur HDInsight offrent une prise en charge améliorée de la création de solutions d’analyse en temps réel.</span><span class="sxs-lookup"><span data-stu-id="0d486-171">Spark clusters in HDInsight offer a rich support for building real-time analytics solutions.</span></span> <span data-ttu-id="0d486-172">Alors que Spark a déjà des données des connecteurs tooingest provenant de sources telles que les sockets Kafka, Flume, Twitter, ZeroMQ ou TCP, Spark dans HDInsight ajoute la prise en charge de première classe pour la réception des données à partir d’Azure Event Hubs.</span><span class="sxs-lookup"><span data-stu-id="0d486-172">While Spark already has connectors tooingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs.</span></span> <span data-ttu-id="0d486-173">Concentrateurs d’événements sont hello les files d’attente de service plus largement utilisés dans Azure.</span><span class="sxs-lookup"><span data-stu-id="0d486-173">Event Hubs are hello most widely used queuing service on Azure.</span></span> <span data-ttu-id="0d486-174">Grâce à leur prise en charge immédiate des concentrateurs d’événements, les clusters Spark sur HDInsight constituent une plateforme idéale pour créer un pipeline d’analyse en temps réel.</span><span class="sxs-lookup"><span data-stu-id="0d486-174">Having an out-of-the-box support for Event Hubs makes Spark clusters in HDInsight an ideal platform for building real time analytics pipeline.</span></span>

## <span data-ttu-id="0d486-175"><a name="next-steps"></a>Quels sont les composants inclus dans un cluster Spark ?</span><span class="sxs-lookup"><span data-stu-id="0d486-175"><a name="next-steps"></a>What components are included as part of a Spark cluster?</span></span>
<span data-ttu-id="0d486-176">Clusters de Spark dans HDInsight incluent hello suivant des composants qui sont disponibles sur les clusters hello par défaut.</span><span class="sxs-lookup"><span data-stu-id="0d486-176">Spark clusters in HDInsight include hello following components that are available on hello clusters by default.</span></span>

* <span data-ttu-id="0d486-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span><span class="sxs-lookup"><span data-stu-id="0d486-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span></span> <span data-ttu-id="0d486-178">Comprend Spark Core, Spark SQL, les API de diffusion en continu Spark, GraphX et MLlib.</span><span class="sxs-lookup"><span data-stu-id="0d486-178">Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.</span></span>
* [<span data-ttu-id="0d486-179">Anaconda</span><span class="sxs-lookup"><span data-stu-id="0d486-179">Anaconda</span></span>](http://docs.continuum.io/anaconda/)
* [<span data-ttu-id="0d486-180">Livy</span><span class="sxs-lookup"><span data-stu-id="0d486-180">Livy</span></span>](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)
* [<span data-ttu-id="0d486-181">Bloc-notes Jupyter</span><span class="sxs-lookup"><span data-stu-id="0d486-181">Jupyter notebook</span></span>](https://jupyter.org)
* [<span data-ttu-id="0d486-182">Bloc-notes Zeppelin</span><span class="sxs-lookup"><span data-stu-id="0d486-182">Zeppelin notebook</span></span>](http://zeppelin-project.org/)

<span data-ttu-id="0d486-183">Les clusters Spark sur HDInsight offrent également une [pilote ODBC](http://go.microsoft.com/fwlink/?LinkId=616229) pour les clusters de tooSpark de connectivité dans HDInsight à partir des Outils BI telles que Microsoft Power BI et de Tableau.</span><span class="sxs-lookup"><span data-stu-id="0d486-183">Spark clusters on HDInsight also provide an [ODBC driver](http://go.microsoft.com/fwlink/?LinkId=616229) for connectivity tooSpark clusters in HDInsight from BI tools such as Microsoft Power BI and Tableau.</span></span>

## <a name="where-do-i-start"></a><span data-ttu-id="0d486-184">Par où commencer ?</span><span class="sxs-lookup"><span data-stu-id="0d486-184">Where do I start?</span></span>
<span data-ttu-id="0d486-185">Commencez par créer un cluster Spark sur HDInsight.</span><span class="sxs-lookup"><span data-stu-id="0d486-185">Start with creating a Spark cluster on HDInsight.</span></span> <span data-ttu-id="0d486-186">Consultez [Démarrage rapide : créer un cluster Spark sur HDInsight Linux et exécuter une requête interactive à l’aide de Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="0d486-186">See [QuickStart: create a Spark cluster on HDInsight Linux and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> 

## <a name="next-steps"></a><span data-ttu-id="0d486-187">Étapes suivantes</span><span class="sxs-lookup"><span data-stu-id="0d486-187">Next Steps</span></span>
### <a name="scenarios"></a><span data-ttu-id="0d486-188">Scénarios</span><span class="sxs-lookup"><span data-stu-id="0d486-188">Scenarios</span></span>
* [<span data-ttu-id="0d486-189">Spark avec BI : effectuez une analyse interactive des données à l’aide de Spark dans HDInsight avec des outils BI</span><span class="sxs-lookup"><span data-stu-id="0d486-189">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="0d486-190">Spark avec Machine Learning : utilisez Spark dans HDInsight pour l’analyse de la température des bâtiments à l’aide des données des systèmes HVAC</span><span class="sxs-lookup"><span data-stu-id="0d486-190">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="0d486-191">Spark avec Machine Learning : Spark utilisation dans résultats de l’inspection alimentaires toopredict HDInsight</span><span class="sxs-lookup"><span data-stu-id="0d486-191">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="0d486-192">Streaming Spark : Utiliser Spark dans HDInsight pour créer des applications de diffusion en continu en temps réel</span><span class="sxs-lookup"><span data-stu-id="0d486-192">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="0d486-193">Analyse des journaux de site web à l’aide de Spark dans HDInsight</span><span class="sxs-lookup"><span data-stu-id="0d486-193">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="0d486-194">Créer et exécuter des applications</span><span class="sxs-lookup"><span data-stu-id="0d486-194">Create and run applications</span></span>
* [<span data-ttu-id="0d486-195">Créer une application autonome avec Scala</span><span class="sxs-lookup"><span data-stu-id="0d486-195">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="0d486-196">Exécuter des tâches à distance avec Livy sur un cluster Spark</span><span class="sxs-lookup"><span data-stu-id="0d486-196">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="0d486-197">Outils et extensions</span><span class="sxs-lookup"><span data-stu-id="0d486-197">Tools and extensions</span></span>
* [<span data-ttu-id="0d486-198">Utiliser le plug-in des outils HDInsight pour IntelliJ idée toocreate et soumettre des applications les plus importantes Spark Scala</span><span class="sxs-lookup"><span data-stu-id="0d486-198">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applicatons</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="0d486-199">Utiliser des plug-in des outils HDInsight pour les applications de Spark toodebug IntelliJ idée à distance</span><span class="sxs-lookup"><span data-stu-id="0d486-199">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="0d486-200">Utiliser des bloc-notes Zeppelin avec un cluster Spark sur HDInsight</span><span class="sxs-lookup"><span data-stu-id="0d486-200">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="0d486-201">Noyaux disponibles pour le bloc-notes Jupyter dans un cluster Spark pour HDInsight</span><span class="sxs-lookup"><span data-stu-id="0d486-201">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="0d486-202">Utiliser des packages externes avec les blocs-notes Jupyter</span><span class="sxs-lookup"><span data-stu-id="0d486-202">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="0d486-203">Installer Notebook sur votre ordinateur et vous connecter tooan cluster HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="0d486-203">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="0d486-204">Gestion des ressources</span><span class="sxs-lookup"><span data-stu-id="0d486-204">Manage resources</span></span>
* [<span data-ttu-id="0d486-205">Gérer les ressources de cluster d’Apache Spark hello dans Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="0d486-205">Manage resources for hello Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="0d486-206">Track and debug jobs running on an Apache Spark cluster in HDInsight (Suivi et débogage des tâches en cours d’exécution sur un cluster Apache Spark dans HDInsight)</span><span class="sxs-lookup"><span data-stu-id="0d486-206">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
* <span data-ttu-id="0d486-207">[Problèmes connus d’Apache Spark sur Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span><span class="sxs-lookup"><span data-stu-id="0d486-207">[Known issues of Apache Spark in Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span></span>
