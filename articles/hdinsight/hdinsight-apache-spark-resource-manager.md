---
title: "Gérer des ressources pour un cluster Apache Spark sur Azure HDInsight | Microsoft Docs"
description: "Découvrez comment utiliser la gestion des ressources pour les clusters Spark sur Azure HDInsight pour obtenir de meilleures performances."
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 9da7d4e3-458e-4296-a628-77b14643f7e4
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/21/2017
ms.author: nitinme
ms.openlocfilehash: 952fa15162a40bccb3f8c7a88508556757ca6675
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 08/03/2017
---
# <a name="manage-resources-for-apache-spark-cluster-on-azure-hdinsight"></a><span data-ttu-id="f75b0-103">Gérer les ressources du cluster Apache Spark dans Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="f75b0-103">Manage resources for Apache Spark cluster on Azure HDInsight</span></span> 

<span data-ttu-id="f75b0-104">Dans cet article, vous allez découvrir comment accéder aux interfaces comme l’IU d’Ambari et l’IU de Yarn, ainsi qu’au serveur d’historique Spark associé à votre cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="f75b0-104">In this article you will learn how to access the interfaces like Ambari UI, YARN UI, and the Spark History Server associated with your Spark cluster.</span></span> <span data-ttu-id="f75b0-105">Vous allez également découvrir comment ajuster la configuration du cluster afin d’optimiser les performances.</span><span class="sxs-lookup"><span data-stu-id="f75b0-105">You will also learn about how to tune the cluster configuration for optimal performance.</span></span>

<span data-ttu-id="f75b0-106">**Configuration requise :**</span><span class="sxs-lookup"><span data-stu-id="f75b0-106">**Prerequisites:**</span></span>

<span data-ttu-id="f75b0-107">Vous devez disposer des éléments suivants :</span><span class="sxs-lookup"><span data-stu-id="f75b0-107">You must have the following:</span></span>

* <span data-ttu-id="f75b0-108">Un abonnement Azure.</span><span class="sxs-lookup"><span data-stu-id="f75b0-108">An Azure subscription.</span></span> <span data-ttu-id="f75b0-109">Consultez la page [Obtention d’un essai gratuit d’Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="f75b0-109">See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>
* <span data-ttu-id="f75b0-110">Un cluster Apache Spark sur HDInsight.</span><span class="sxs-lookup"><span data-stu-id="f75b0-110">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="f75b0-111">Pour obtenir des instructions, consultez [Création de clusters Apache Spark dans Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="f75b0-111">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="how-do-i-launch-the-ambari-web-ui"></a><span data-ttu-id="f75b0-112">Comment lancer l’interface utilisateur web Ambari ?</span><span class="sxs-lookup"><span data-stu-id="f75b0-112">How do I launch the Ambari Web UI?</span></span>
1. <span data-ttu-id="f75b0-113">Dans le tableau d’accueil du [portail Azure](https://portal.azure.com/), cliquez sur la vignette de votre cluster Spark (si vous l’avez épinglé au tableau d’accueil).</span><span class="sxs-lookup"><span data-stu-id="f75b0-113">From the [Azure Portal](https://portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</span></span> <span data-ttu-id="f75b0-114">Vous pouvez également accéder à votre cluster sous **Parcourir tout** > **Clusters HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-114">You can also navigate to your cluster under **Browse All** > **HDInsight Clusters**.</span></span>
2. <span data-ttu-id="f75b0-115">Dans le panneau du cluster Spark, cliquez sur **Tableau de bord**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-115">From the Spark cluster blade, click **Dashboard**.</span></span> <span data-ttu-id="f75b0-116">Lorsque vous y êtes invité, entrez les informations d’identification d’administrateur pour le cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="f75b0-116">When prompted, enter the admin credentials for the Spark cluster.</span></span>

    <span data-ttu-id="f75b0-117">![Lancer Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Démarrer le gestionnaire de ressources")</span><span class="sxs-lookup"><span data-stu-id="f75b0-117">![Launch Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Start Resource Manager")</span></span>
3. <span data-ttu-id="f75b0-118">Cela doit lancer l’interface utilisateur web Ambari comme indiqué ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="f75b0-118">This should launch the Ambari Web UI, as shown below.</span></span>

    <span data-ttu-id="f75b0-119">![Interface utilisateur web Ambari](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Interface utilisateur web Ambari")</span><span class="sxs-lookup"><span data-stu-id="f75b0-119">![Ambari Web UI](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span></span>   

## <a name="how-do-i-launch-the-spark-history-server"></a><span data-ttu-id="f75b0-120">Comment lancer le serveur d’historique Spark ?</span><span class="sxs-lookup"><span data-stu-id="f75b0-120">How do I launch the Spark History Server?</span></span>
1. <span data-ttu-id="f75b0-121">Dans le tableau d’accueil du [portail Azure](https://portal.azure.com/), cliquez sur la vignette de votre cluster Spark (si vous l’avez épinglé au tableau d’accueil).</span><span class="sxs-lookup"><span data-stu-id="f75b0-121">From the [Azure Portal](https://portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</span></span>
2. <span data-ttu-id="f75b0-122">Dans le panneau du cluster, sous **Liens rapides**, cliquez sur **Tableau de bord du cluster**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-122">From the cluster blade, under **Quick Links**, click **Cluster Dashboard**.</span></span> <span data-ttu-id="f75b0-123">Dans le panneau **Tableau de bord du cluster** , cliquez sur **Serveur d’historique Spark**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-123">In the **Cluster Dashboard** blade, click **Spark History Server**.</span></span>

    <span data-ttu-id="f75b0-124">![Serveur d’historique Spark](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Serveur d’historique Spark")</span><span class="sxs-lookup"><span data-stu-id="f75b0-124">![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark History Server")</span></span>

    <span data-ttu-id="f75b0-125">Lorsque vous y êtes invité, entrez les informations d’identification d’administrateur pour le cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="f75b0-125">When prompted, enter the admin credentials for the Spark cluster.</span></span>

## <a name="how-do-i-launch-the-yarn-ui"></a><span data-ttu-id="f75b0-126">Comment lancer l’interface utilisateur web Yarn ?</span><span class="sxs-lookup"><span data-stu-id="f75b0-126">How do I launch the Yarn UI?</span></span>
<span data-ttu-id="f75b0-127">Vous pouvez utiliser l’interface utilisateur YARN pour surveiller les applications en cours d’exécution sur le cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="f75b0-127">You can use the YARN UI to monitor applications that are currently running on the Spark cluster.</span></span>

1. <span data-ttu-id="f75b0-128">Dans le panneau du cluster, cliquez sur **Tableau de bord du cluster**, puis sur **YARN**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-128">From the cluster blade, click **Cluster Dashboard**, and then click **YARN**.</span></span>

    ![Lancer l’interface utilisateur Yarn](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png)

   > [!TIP]
   > <span data-ttu-id="f75b0-130">Vous pouvez également lancer l’interface utilisateur de YARN à partir de celle d’Ambari.</span><span class="sxs-lookup"><span data-stu-id="f75b0-130">Alternatively, you can also launch the YARN UI from the Ambari UI.</span></span> <span data-ttu-id="f75b0-131">Pour lancer l’interface utilisateur d’Ambari, dans le panneau du cluster, cliquez sur **Tableau de bord du cluster**, puis sur **Tableau de bord de cluster HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-131">To launch the Ambari UI, from the cluster blade, click **Cluster Dashboard**, and then click **HDInsight Cluster Dashboard**.</span></span> <span data-ttu-id="f75b0-132">À partir de l’interface utilisateur d’Ambari, cliquez successivement sur **YARN**, **Quick Links** (Liens rapides), le gestionnaire de ressources actif et **ResourceManager UI** (IU de ResourceManager).</span><span class="sxs-lookup"><span data-stu-id="f75b0-132">From the Ambari UI, click **YARN**, click **Quick Links**, click the active resource manager, and then click **ResourceManager UI**.</span></span>
   >
   >

## <a name="what-is-the-optimum-cluster-configuration-to-run-spark-applications"></a><span data-ttu-id="f75b0-133">Quelle est la configuration de cluster optimale pour l’exécution des applications Spark ?</span><span class="sxs-lookup"><span data-stu-id="f75b0-133">What is the optimum cluster configuration to run Spark applications?</span></span>
<span data-ttu-id="f75b0-134">Les trois paramètres clés pouvant être utilisés pour la configuration de Spark selon la configuration requise pour l’application sont `spark.executor.instances`, `spark.executor.cores` et `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="f75b0-134">The three key parameters that can be used for Spark configuration depending on application requirements are `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span></span> <span data-ttu-id="f75b0-135">Un exécuteur est un processus lancé pour une application Spark.</span><span class="sxs-lookup"><span data-stu-id="f75b0-135">An Executor is a process launched for a Spark application.</span></span> <span data-ttu-id="f75b0-136">Il s’exécute sur le nœud de travail et est chargé d’effectuer les tâches de l’application.</span><span class="sxs-lookup"><span data-stu-id="f75b0-136">It runs on the worker node and is responsible to carry out the tasks for the application.</span></span> <span data-ttu-id="f75b0-137">Le nombre d’exécuteurs par défaut et les tailles d’exécuteur de chaque cluster sont calculés en fonction du nombre de nœuds de travail et de leur taille.</span><span class="sxs-lookup"><span data-stu-id="f75b0-137">The default number of executors and the executor sizes for each cluster is calculated based on the number of worker nodes and the worker node size.</span></span> <span data-ttu-id="f75b0-138">Ils sont stockés dans `spark-defaults.conf` sur les nœuds principaux du cluster.</span><span class="sxs-lookup"><span data-stu-id="f75b0-138">These are stored in `spark-defaults.conf` on the cluster head nodes.</span></span>

<span data-ttu-id="f75b0-139">Les trois paramètres de configuration peuvent être configurés au niveau du cluster (pour toutes les applications qui s’exécutent sur le cluster) ou spécifiés pour chaque application.</span><span class="sxs-lookup"><span data-stu-id="f75b0-139">The three configuration parameters can be configured at the cluster level (for all applications that run on the cluster) or can be specified for each individual application as well.</span></span>

### <a name="change-the-parameters-using-ambari-ui"></a><span data-ttu-id="f75b0-140">Modifier les paramètres à l’aide de l’interface utilisateur d’Ambari</span><span class="sxs-lookup"><span data-stu-id="f75b0-140">Change the parameters using Ambari UI</span></span>
1. <span data-ttu-id="f75b0-141">À partir de l’interface utilisateur d’Ambari, cliquez sur **Spark**, puis sur **Configs (Configurations)**, puis développez **Custom spark-defaults (Personnaliser les valeurs Spark par défaut)**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-141">From the Ambari UI click **Spark**, click **Configs**, and then expand **Custom spark-defaults**.</span></span>

    ![Définir des paramètres à l’aide d’Ambari](./media/hdinsight-apache-spark-resource-manager/set-parameters-using-ambari.png)
2. <span data-ttu-id="f75b0-143">Les valeurs par défaut conviennent si vous souhaitez exécuter simultanément 4 applications Spark sur le cluster.</span><span class="sxs-lookup"><span data-stu-id="f75b0-143">The default values are good to have 4 Spark applications run concurrently on the cluster.</span></span> <span data-ttu-id="f75b0-144">Vous pouvez modifier ces valeurs dans l’interface utilisateur, comme indiqué ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="f75b0-144">You can changes these values from the user interface, as shown below.</span></span>

    ![Définir des paramètres à l’aide d’Ambari](./media/hdinsight-apache-spark-resource-manager/set-executor-parameters.png)
3. <span data-ttu-id="f75b0-146">Cliquez sur **Save (Enregistrer)** pour enregistrer les modifications de la configuration.</span><span class="sxs-lookup"><span data-stu-id="f75b0-146">Click **Save** to save the configuration changes.</span></span> <span data-ttu-id="f75b0-147">En haut de la page, vous êtes invité à redémarrer tous les services concernés.</span><span class="sxs-lookup"><span data-stu-id="f75b0-147">At the top of the page, you will be prompted to restart all the affected services.</span></span> <span data-ttu-id="f75b0-148">Cliquez sur **Restart (Redémarrer)**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-148">Click **Restart**.</span></span>

    ![Redémarrer les services](./media/hdinsight-apache-spark-resource-manager/restart-services.png)

### <a name="change-the-parameters-for-an-application-running-in-jupyter-notebook"></a><span data-ttu-id="f75b0-150">Modifier les paramètres d’une application exécutée dans un bloc-notes Jupyter</span><span class="sxs-lookup"><span data-stu-id="f75b0-150">Change the parameters for an application running in Jupyter notebook</span></span>
<span data-ttu-id="f75b0-151">Pour les applications exécutées dans le bloc-notes Jupyter, vous pouvez utiliser la commande magique `%%configure` pour procéder aux modifications de la configuration.</span><span class="sxs-lookup"><span data-stu-id="f75b0-151">For applications running in the Jupyter notebook, you can use the `%%configure` magic to make the configuration changes.</span></span> <span data-ttu-id="f75b0-152">Dans l’idéal, vous devez apporter ces modifications au début de l’application, avant d’exécuter la première cellule de code.</span><span class="sxs-lookup"><span data-stu-id="f75b0-152">Ideally, you must make such changes at the beginning of the application, before you run your first code cell.</span></span> <span data-ttu-id="f75b0-153">De ce fait, la configuration est appliquée à la session Livy lors de sa création.</span><span class="sxs-lookup"><span data-stu-id="f75b0-153">This ensures that the configuration is applied to the Livy session, when it gets created.</span></span> <span data-ttu-id="f75b0-154">Si vous souhaitez modifier la configuration ultérieurement dans l’application, vous devez utiliser le paramètre `-f` .</span><span class="sxs-lookup"><span data-stu-id="f75b0-154">If you want to change the configuration at a later stage in the application, you must use the `-f` parameter.</span></span> <span data-ttu-id="f75b0-155">Néanmoins, en procédant ainsi, toute la progression de l’application sera perdue.</span><span class="sxs-lookup"><span data-stu-id="f75b0-155">However, by doing so all progress in the application will be lost.</span></span>

<span data-ttu-id="f75b0-156">L’extrait de code ci-dessous montre comment modifier la configuration d’une application exécutée dans Jupyter.</span><span class="sxs-lookup"><span data-stu-id="f75b0-156">The snippet below shows how to change the configuration for an application running in Jupyter.</span></span>

    %%configure
    {"executorMemory": "3072M", "executorCores": 4, "numExecutors":10}

<span data-ttu-id="f75b0-157">Les paramètres de configuration doivent être passés en tant que chaîne JSON et spécifiés sur la ligne suivant la commande magique, comme indiqué dans l’exemple de colonne.</span><span class="sxs-lookup"><span data-stu-id="f75b0-157">Configuration parameters must be passed in as a JSON string and must be on the next line after the magic, as shown in the example column.</span></span>

### <a name="change-the-parameters-for-an-application-submitted-using-spark-submit"></a><span data-ttu-id="f75b0-158">Modifier les paramètres d’une application soumise à l’aide du script spark-submit</span><span class="sxs-lookup"><span data-stu-id="f75b0-158">Change the parameters for an application submitted using spark-submit</span></span>
<span data-ttu-id="f75b0-159">La commande suivante est un exemple de modification des paramètres de configuration d’une application de lot soumise à l’aide de `spark-submit`.</span><span class="sxs-lookup"><span data-stu-id="f75b0-159">Following command is an example of how to change the configuration parameters for a batch application that is submitted using `spark-submit`.</span></span>

    spark-submit --class <the application class to execute> --executor-memory 3072M --executor-cores 4 –-num-executors 10 <location of application jar file> <application parameters>

### <a name="change-the-parameters-for-an-application-submitted-using-curl"></a><span data-ttu-id="f75b0-160">Modifier les paramètres d’une application soumise à l’aide de cURL</span><span class="sxs-lookup"><span data-stu-id="f75b0-160">Change the parameters for an application submitted using cURL</span></span>
<span data-ttu-id="f75b0-161">La commande suivante est un exemple de modification des paramètres de configuration d’une application de lot soumise à l’aide de cURL.</span><span class="sxs-lookup"><span data-stu-id="f75b0-161">Following command is an example of how to change the configuration parameters for a batch application that is submitted using using cURL.</span></span>

    curl -k -v -H 'Content-Type: application/json' -X POST -d '{"file":"<location of application jar file>", "className":"<the application class to execute>", "args":[<application parameters>], "numExecutors":10, "executorMemory":"2G", "executorCores":5' localhost:8998/batches

### <a name="how-do-i-change-these-parameters-on-a-spark-thrift-server"></a><span data-ttu-id="f75b0-162">Comment modifier ces paramètres sur un serveur Thrift Spark ?</span><span class="sxs-lookup"><span data-stu-id="f75b0-162">How do I change these parameters on a Spark Thrift Server?</span></span>
<span data-ttu-id="f75b0-163">Le serveur Thrift Spark fournit un accès JDBC/ODBC à un cluster Spark et est utilisé pour les requêtes SQL Spark.</span><span class="sxs-lookup"><span data-stu-id="f75b0-163">Spark Thrift Server provides JDBC/ODBC access to a Spark cluster and is used to service Spark SQL queries.</span></span> <span data-ttu-id="f75b0-164">Les outils tels que Power BI, Tableau, etc.</span><span class="sxs-lookup"><span data-stu-id="f75b0-164">Tools like Power BI, Tableau etc.</span></span> <span data-ttu-id="f75b0-165">utilisent le protocole ODBC pour communiquer avec le serveur Thrift Spark afin d’exécuter des requêtes SQL Spark en tant qu’application Spark.</span><span class="sxs-lookup"><span data-stu-id="f75b0-165">use ODBC protocol to communicate with Spark Thrift Server to execute Spark SQL queries as a Spark Application.</span></span> <span data-ttu-id="f75b0-166">Lors de la création d’un cluster Spark, deux instances du serveur Thrift Spark sont démarrées, une par nœud principal.</span><span class="sxs-lookup"><span data-stu-id="f75b0-166">When a Spark cluster is created, two instances of the Spark Thrift Server are started, one on each head node.</span></span> <span data-ttu-id="f75b0-167">Chaque serveur Thrift Spark apparaît en tant qu’application Spark dans l’interface utilisateur de YARN.</span><span class="sxs-lookup"><span data-stu-id="f75b0-167">Each Spark Thrift Server is visible as a Spark application in the YARN UI.</span></span>

<span data-ttu-id="f75b0-168">Le serveur Thrift Spark utilise l’allocation d’exécuteur dynamique de Spark. Le code `spark.executor.instances` n’est donc pas utilisé.</span><span class="sxs-lookup"><span data-stu-id="f75b0-168">Spark Thrift Server uses Spark dynamic executor allocation and hence the `spark.executor.instances` is not used.</span></span> <span data-ttu-id="f75b0-169">En revanche, le serveur Thrift Spark utilise `spark.dynamicAllocation.minExecutors` et `spark.dynamicAllocation.maxExecutors` pour indiquer le nombre d’exécuteurs.</span><span class="sxs-lookup"><span data-stu-id="f75b0-169">Instead, Spark Thrift Server uses `spark.dynamicAllocation.minExecutors` and `spark.dynamicAllocation.maxExecutors` to specify the executor count.</span></span> <span data-ttu-id="f75b0-170">Les paramètres de configuration `spark.executor.cores` et `spark.executor.memory` permettent de modifier la taille de l’exécuteur.</span><span class="sxs-lookup"><span data-stu-id="f75b0-170">The configuration parameters `spark.executor.cores` and `spark.executor.memory` is used to modify the executor size.</span></span> <span data-ttu-id="f75b0-171">Vous pouvez modifier ces paramètres comme indiqué ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="f75b0-171">You can change these parameters as shown below.</span></span>

* <span data-ttu-id="f75b0-172">Développez la catégorie **Advanced spark-thrift-sparkconf** pour mettre à jour les paramètres `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors` et `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="f75b0-172">Expand the **Advanced spark-thrift-sparkconf** category to update the parameters `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, and `spark.executor.memory`.</span></span>

    ![Configurer le serveur Thrift Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-1.png)    
* <span data-ttu-id="f75b0-174">Développez la catégorie **Custom spark-thrift-sparkconf** pour mettre à jour le paramètre `spark.executor.cores`.</span><span class="sxs-lookup"><span data-stu-id="f75b0-174">Expand the **Custom spark-thrift-sparkconf** category to update the parameter `spark.executor.cores`.</span></span>

    ![Configurer le serveur Thrift Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-2.png)

### <a name="how-do-i-change-the-driver-memory-of-the-spark-thrift-server"></a><span data-ttu-id="f75b0-176">Comment modifier la mémoire du pilote du serveur Thrift Spark ?</span><span class="sxs-lookup"><span data-stu-id="f75b0-176">How do I change the driver memory of the Spark Thrift Server?</span></span>
<span data-ttu-id="f75b0-177">La mémoire du pilote du serveur Thrift Spark est configurée sur 25 % de la taille de la mémoire RAM du nœud principal, sous réserve que la taille totale de la mémoire RAM du nœud principal soit supérieure à 14 Go.</span><span class="sxs-lookup"><span data-stu-id="f75b0-177">Spark Thrift Server driver memory is configured to 25% of the head node RAM size, provided the total RAM size of the head node is greater than 14GB.</span></span> <span data-ttu-id="f75b0-178">Vous pouvez utiliser l’interface utilisateur d’Ambari pour modifier la configuration de la mémoire du pilote, comme indiqué ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="f75b0-178">You can use the Ambari UI to change the driver memory configuration, as shown below.</span></span>

* <span data-ttu-id="f75b0-179">À partir de l’interface utilisateur d’Ambari, cliquez sur **Spark**, puis sur **Configs (Configurations)**, développez **Advanced spark-env**, puis indiquez la valeur de **spark_thrift_cmd_opts**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-179">From the Ambari UI click **Spark**, click **Configs**, expand **Advanced spark-env**, and then provide the value for **spark_thrift_cmd_opts**.</span></span>

    ![Configurer la mémoire RAM du serveur Thrift Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-ram.png)

## <a name="i-do-not-use-bi-with-spark-cluster-how-do-i-take-the-resources-back"></a><span data-ttu-id="f75b0-181">Je n’utilise pas d’outils décisionnels avec le cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="f75b0-181">I do not use BI with Spark cluster.</span></span> <span data-ttu-id="f75b0-182">Comment reprendre des ressources ?</span><span class="sxs-lookup"><span data-stu-id="f75b0-182">How do I take the resources back?</span></span>
<span data-ttu-id="f75b0-183">Étant donné que nous utilisons l’allocation dynamique de Spark, les seules ressources consommées par le serveur Thrift sont celles des deux applications maîtres.</span><span class="sxs-lookup"><span data-stu-id="f75b0-183">Since we use Spark dynamic allocation, the only resources that are consumed by thrift server are the resources for the two application masters.</span></span> <span data-ttu-id="f75b0-184">Pour libérer ces ressources, vous devez arrêter l’exécution des services du serveur Thrift sur le cluster.</span><span class="sxs-lookup"><span data-stu-id="f75b0-184">To reclaim these resources you must stop the Thrift Server services running on the cluster.</span></span>

1. <span data-ttu-id="f75b0-185">À partir de l’interface utilisateur d’Ambari, dans le volet gauche, cliquez sur **Spark**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-185">From the Ambari UI, from the left pane, click **Spark**.</span></span>
2. <span data-ttu-id="f75b0-186">Dans la page suivante, cliquez sur **Spark Thrift Servers (Serveur Thrift Spark)**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-186">In the next page, click **Spark Thrift Servers**.</span></span>

    ![Redémarrer le serveur Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-1.png)
3. <span data-ttu-id="f75b0-188">Vous devez voir les deux nœuds principaux sur lesquels le serveur Thrift Spark s’exécute.</span><span class="sxs-lookup"><span data-stu-id="f75b0-188">You should see the two headnodes on which the Spark Thrift Server is running.</span></span> <span data-ttu-id="f75b0-189">Cliquez sur l’un des nœuds principaux.</span><span class="sxs-lookup"><span data-stu-id="f75b0-189">Click one of the headnodes.</span></span>

    ![Redémarrer le serveur Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-2.png)
4. <span data-ttu-id="f75b0-191">La page suivante répertorie tous les services exécutés sur ce nœud principal.</span><span class="sxs-lookup"><span data-stu-id="f75b0-191">The next page lists all the services running on that headnode.</span></span> <span data-ttu-id="f75b0-192">Dans la liste, cliquez sur le bouton de la liste déroulante en regard de Serveur Thrift Spark, puis cliquez sur **Stop (Arrêter)**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-192">From the list click the drop-down button next to Spark Thrift Server, and then click **Stop**.</span></span>

    ![Redémarrer le serveur Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-3.png)
5. <span data-ttu-id="f75b0-194">Répétez également ces étapes sur l’autre nœud principal.</span><span class="sxs-lookup"><span data-stu-id="f75b0-194">Repeat these steps on the other headnode as well.</span></span>

## <a name="my-jupyter-notebooks-are-not-running-as-expected-how-can-i-restart-the-service"></a><span data-ttu-id="f75b0-195">Mes blocs-notes Jupyter ne s’exécutent pas comme prévu.</span><span class="sxs-lookup"><span data-stu-id="f75b0-195">My Jupyter notebooks are not running as expected.</span></span> <span data-ttu-id="f75b0-196">Comment redémarrer le service ?</span><span class="sxs-lookup"><span data-stu-id="f75b0-196">How can I restart the service?</span></span>
<span data-ttu-id="f75b0-197">Lancez l’interface utilisateur web Ambari comme indiqué ci-dessus.</span><span class="sxs-lookup"><span data-stu-id="f75b0-197">Launch the Ambari Web UI as shown above.</span></span> <span data-ttu-id="f75b0-198">Dans le volet de navigation gauche, cliquez sur **Jupyter**, sur **Actions de service**, puis sur **Redémarrer tout**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-198">From the left navigation pane, click **Jupyter**, click **Service Actions**, and then click **Restart All**.</span></span> <span data-ttu-id="f75b0-199">Cela permet au service Jupyter de démarrer sur tous les nœuds principaux.</span><span class="sxs-lookup"><span data-stu-id="f75b0-199">This will start the Jupyter service on all the headnodes.</span></span>

    ![Restart Jupyter](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png "Restart Jupyter")

## <a name="how-do-i-know-if-i-am-running-out-of-resources"></a><span data-ttu-id="f75b0-200">Comment savoir si mes ressources sont épuisées ?</span><span class="sxs-lookup"><span data-stu-id="f75b0-200">How do I know if I am running out of resources?</span></span>
<span data-ttu-id="f75b0-201">Lancez l’interface utilisateur web Yarn comme indiqué ci-dessus.</span><span class="sxs-lookup"><span data-stu-id="f75b0-201">Launch the Yarn UI as shown above.</span></span> <span data-ttu-id="f75b0-202">Dans la table des mesures de Cluster située en haut de l’écran, vérifiez les valeurs des colonnes **Mémoire utilisée** et **Mémoire totale**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-202">In Cluster Metrics table on top of the screen, check values of **Memory Used** and **Memory Total** columns.</span></span> <span data-ttu-id="f75b0-203">Si les 2 valeurs sont très proches, le nombre de ressources ne sera peut-être pas suffisant pour démarrer l’application suivante.</span><span class="sxs-lookup"><span data-stu-id="f75b0-203">If the 2 values are very close, there might not be enough resources to start the next application.</span></span> <span data-ttu-id="f75b0-204">Cela s’applique également aux colonnes **VCores utilisés** et **Total des VCores**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-204">The same applies to the **VCores Used** and **VCores Total** columns.</span></span> <span data-ttu-id="f75b0-205">En outre, dans la vue principale, si une application est restée dans l’état **ACCEPTÉ** et n’est pas passée à l’état **EN COURS D’EXÉCUTION** ou **Échec**. Cela peut également indiquer que le nombre de ressources est insuffisant pour démarrer.</span><span class="sxs-lookup"><span data-stu-id="f75b0-205">Also, in the main view, if there is an application stayed in **ACCEPTED** state and not transitioning into **RUNNING** nor **FAILED** state, this could also be an indication that it is not getting enough resources to start.</span></span>

    ![Resource Limit](./media/hdinsight-apache-spark-resource-manager/resource-limit.png "Resource Limit")

## <a name="how-do-i-kill-a-running-application-to-free-up-resource"></a><span data-ttu-id="f75b0-206">Comment arrêter une application en cours d’exécution afin de libérer des ressources ?</span><span class="sxs-lookup"><span data-stu-id="f75b0-206">How do I kill a running application to free up resource?</span></span>
1. <span data-ttu-id="f75b0-207">Dans l’interface utilisateur Yarn, dans le volet gauche, cliquez sur **En cours d’exécution**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-207">In the Yarn UI, from the left panel, click **Running**.</span></span> <span data-ttu-id="f75b0-208">Dans la liste des applications en cours d’exécution, déterminez l’application à arrêter, puis cliquez sur l’**ID**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-208">From the list of running applications, determine the application to be killed and click on the **ID**.</span></span>

    <span data-ttu-id="f75b0-209">![Arrêter App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Arrêter App1")</span><span class="sxs-lookup"><span data-stu-id="f75b0-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span></span>

2. <span data-ttu-id="f75b0-210">Cliquez sur **Arrêter l’application** dans le coin supérieur droit, puis cliquez sur **OK**.</span><span class="sxs-lookup"><span data-stu-id="f75b0-210">Click **Kill Application** on the top right corner, then click **OK**.</span></span>

    <span data-ttu-id="f75b0-211">![Arrêter App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Arrêter App2")</span><span class="sxs-lookup"><span data-stu-id="f75b0-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span></span>

## <a name="see-also"></a><span data-ttu-id="f75b0-212">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="f75b0-212">See also</span></span>
* [<span data-ttu-id="f75b0-213">Track and debug jobs running on an Apache Spark cluster in HDInsight (Suivi et débogage des tâches en cours d’exécution sur un cluster Apache Spark dans HDInsight)</span><span class="sxs-lookup"><span data-stu-id="f75b0-213">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

### <a name="for-data-analysts"></a><span data-ttu-id="f75b0-214">Pour les analystes de données</span><span class="sxs-lookup"><span data-stu-id="f75b0-214">For data analysts</span></span>

* [<span data-ttu-id="f75b0-215">Spark avec Machine Learning : Utiliser Spark dans HDInsight pour l’analyse de la température de bâtiments à l’aide de données HVAC</span><span class="sxs-lookup"><span data-stu-id="f75b0-215">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="f75b0-216">Spark avec Machine Learning : Utiliser Spark dans HDInsight pour prédire les résultats de l’inspection des aliments</span><span class="sxs-lookup"><span data-stu-id="f75b0-216">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="f75b0-217">Analyse des journaux de site web à l’aide de Spark dans HDInsight</span><span class="sxs-lookup"><span data-stu-id="f75b0-217">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)
* [<span data-ttu-id="f75b0-218">Application Insight telemetry data analysis using Spark in HDInsight (Analyse des données de télémétrie Application Insight à l’aide de Spark dans HDInsight)</span><span class="sxs-lookup"><span data-stu-id="f75b0-218">Application Insight telemetry data analysis using Spark in HDInsight</span></span>](hdinsight-spark-analyze-application-insight-logs.md)
* [<span data-ttu-id="f75b0-219">Utiliser Caffe sur Azure HDInsight Spark pour une formation approfondie échelonnée</span><span class="sxs-lookup"><span data-stu-id="f75b0-219">Use Caffe on Azure HDInsight Spark for distributed deep learning</span></span>](hdinsight-deep-learning-caffe-spark.md)

### <a name="for-spark-developers"></a><span data-ttu-id="f75b0-220">Pour les développeurs Spark</span><span class="sxs-lookup"><span data-stu-id="f75b0-220">For Spark developers</span></span>

* [<span data-ttu-id="f75b0-221">Créer une application autonome avec Scala</span><span class="sxs-lookup"><span data-stu-id="f75b0-221">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="f75b0-222">Exécuter des tâches à distance avec Livy sur un cluster Spark</span><span class="sxs-lookup"><span data-stu-id="f75b0-222">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
* [<span data-ttu-id="f75b0-223">Utilisation du plugin d’outils HDInsight pour IntelliJ IDEA pour créer et soumettre des applications Spark Scala</span><span class="sxs-lookup"><span data-stu-id="f75b0-223">Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="f75b0-224">Streaming Spark : Utiliser Spark dans HDInsight pour créer des applications de diffusion en continu en temps réel</span><span class="sxs-lookup"><span data-stu-id="f75b0-224">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="f75b0-225">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely) (Utiliser le plug-in Outils HDInsight pour IntelliJ IDEA pour déboguer des applications Spark à distance)</span><span class="sxs-lookup"><span data-stu-id="f75b0-225">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="f75b0-226">Utiliser des bloc-notes Zeppelin avec un cluster Spark sur HDInsight</span><span class="sxs-lookup"><span data-stu-id="f75b0-226">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="f75b0-227">Noyaux disponibles pour le bloc-notes Jupyter dans un cluster Spark pour HDInsight</span><span class="sxs-lookup"><span data-stu-id="f75b0-227">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="f75b0-228">Utiliser des packages externes avec les blocs-notes Jupyter</span><span class="sxs-lookup"><span data-stu-id="f75b0-228">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="f75b0-229">Install Jupyter on your computer and connect to an HDInsight Spark cluster (Installer Jupyter sur un ordinateur et se connecter au cluster Spark sur HDInsight)</span><span class="sxs-lookup"><span data-stu-id="f75b0-229">Install Jupyter on your computer and connect to an HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)
