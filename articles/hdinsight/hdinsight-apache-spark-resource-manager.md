---
title: cluster de ressources aaaManage pour Apache Spark sur Azure HDInsight | Documents Microsoft
description: "Découvrez comment gérer les ressources pour les clusters Spark sur Azure HDInsight pour de meilleures performances toouse."
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 9da7d4e3-458e-4296-a628-77b14643f7e4
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/21/2017
ms.author: nitinme
ms.openlocfilehash: e18682a24f77494db884105f9db03c0a350ddad6
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 10/06/2017
---
# <a name="manage-resources-for-apache-spark-cluster-on-azure-hdinsight"></a><span data-ttu-id="efff8-103">Gérer les ressources du cluster Apache Spark dans Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="efff8-103">Manage resources for Apache Spark cluster on Azure HDInsight</span></span> 

<span data-ttu-id="efff8-104">Dans cet article, vous allez apprendre comment tooaccess les interfaces de hello, Ambari UI, l’interface utilisateur des fils et hello Spark historique serveur associé à votre cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="efff8-104">In this article you will learn how tooaccess hello interfaces like Ambari UI, YARN UI, and hello Spark History Server associated with your Spark cluster.</span></span> <span data-ttu-id="efff8-105">Vous découvrirez également comment tootune hello configuration du cluster pour des performances optimales.</span><span class="sxs-lookup"><span data-stu-id="efff8-105">You will also learn about how tootune hello cluster configuration for optimal performance.</span></span>

<span data-ttu-id="efff8-106">**Configuration requise :**</span><span class="sxs-lookup"><span data-stu-id="efff8-106">**Prerequisites:**</span></span>

<span data-ttu-id="efff8-107">Vous devez disposer de hello :</span><span class="sxs-lookup"><span data-stu-id="efff8-107">You must have hello following:</span></span>

* <span data-ttu-id="efff8-108">Un abonnement Azure.</span><span class="sxs-lookup"><span data-stu-id="efff8-108">An Azure subscription.</span></span> <span data-ttu-id="efff8-109">Consultez la page [Obtention d’un essai gratuit d’Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="efff8-109">See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>
* <span data-ttu-id="efff8-110">Un cluster Apache Spark sur HDInsight.</span><span class="sxs-lookup"><span data-stu-id="efff8-110">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="efff8-111">Pour obtenir des instructions, consultez [Création de clusters Apache Spark dans Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="efff8-111">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="how-do-i-launch-hello-ambari-web-ui"></a><span data-ttu-id="efff8-112">Comment lancer hello l’interface utilisateur de Ambari Web ?</span><span class="sxs-lookup"><span data-stu-id="efff8-112">How do I launch hello Ambari Web UI?</span></span>
1. <span data-ttu-id="efff8-113">À partir de hello [Azure Portal](https://portal.azure.com/), à partir du tableau d’accueil hello, cliquez sur la vignette hello pour votre cluster Spark (si vous avez épinglé il toohello tableau d’accueil).</span><span class="sxs-lookup"><span data-stu-id="efff8-113">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span> <span data-ttu-id="efff8-114">Vous pouvez également naviguer cluster tooyour sous **parcourir tous les** > **Clusters HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="efff8-114">You can also navigate tooyour cluster under **Browse All** > **HDInsight Clusters**.</span></span>
2. <span data-ttu-id="efff8-115">Dans le panneau de cluster Spark hello, cliquez sur **tableau de bord**.</span><span class="sxs-lookup"><span data-stu-id="efff8-115">From hello Spark cluster blade, click **Dashboard**.</span></span> <span data-ttu-id="efff8-116">Lorsque vous y êtes invité, entrez les informations d’identification du admin de hello pour le cluster Spark de hello.</span><span class="sxs-lookup"><span data-stu-id="efff8-116">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

    <span data-ttu-id="efff8-117">![Lancer Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Démarrer le gestionnaire de ressources")</span><span class="sxs-lookup"><span data-stu-id="efff8-117">![Launch Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Start Resource Manager")</span></span>
3. <span data-ttu-id="efff8-118">Cela devrait s’ouvrir hello l’interface utilisateur de Ambari Web, comme indiqué ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="efff8-118">This should launch hello Ambari Web UI, as shown below.</span></span>

    <span data-ttu-id="efff8-119">![Interface utilisateur web Ambari](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Interface utilisateur web Ambari")</span><span class="sxs-lookup"><span data-stu-id="efff8-119">![Ambari Web UI](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span></span>   

## <a name="how-do-i-launch-hello-spark-history-server"></a><span data-ttu-id="efff8-120">Comment lancer hello Spark historique serveur ?</span><span class="sxs-lookup"><span data-stu-id="efff8-120">How do I launch hello Spark History Server?</span></span>
1. <span data-ttu-id="efff8-121">À partir de hello [Azure Portal](https://portal.azure.com/), à partir du tableau d’accueil hello, cliquez sur la vignette hello pour votre cluster Spark (si vous avez épinglé il toohello tableau d’accueil).</span><span class="sxs-lookup"><span data-stu-id="efff8-121">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span>
2. <span data-ttu-id="efff8-122">À partir de hello cluster panneau, sous **liens rapides**, cliquez sur **tableau de bord de Cluster**.</span><span class="sxs-lookup"><span data-stu-id="efff8-122">From hello cluster blade, under **Quick Links**, click **Cluster Dashboard**.</span></span> <span data-ttu-id="efff8-123">Bonjour **tableau de bord de Cluster** panneau, cliquez sur **Spark historique Server**.</span><span class="sxs-lookup"><span data-stu-id="efff8-123">In hello **Cluster Dashboard** blade, click **Spark History Server**.</span></span>

    <span data-ttu-id="efff8-124">![Serveur d’historique Spark](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Serveur d’historique Spark")</span><span class="sxs-lookup"><span data-stu-id="efff8-124">![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark History Server")</span></span>

    <span data-ttu-id="efff8-125">Lorsque vous y êtes invité, entrez les informations d’identification du admin de hello pour le cluster Spark de hello.</span><span class="sxs-lookup"><span data-stu-id="efff8-125">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

## <a name="how-do-i-launch-hello-yarn-ui"></a><span data-ttu-id="efff8-126">Comment lancer hello fils UI ?</span><span class="sxs-lookup"><span data-stu-id="efff8-126">How do I launch hello Yarn UI?</span></span>
<span data-ttu-id="efff8-127">Vous pouvez utiliser hello fils UI toomonitor applications en cours d’exécution sur le cluster de Spark hello.</span><span class="sxs-lookup"><span data-stu-id="efff8-127">You can use hello YARN UI toomonitor applications that are currently running on hello Spark cluster.</span></span>

1. <span data-ttu-id="efff8-128">Dans le panneau de cluster hello, cliquez sur **tableau de bord de Cluster**, puis cliquez sur **fils**.</span><span class="sxs-lookup"><span data-stu-id="efff8-128">From hello cluster blade, click **Cluster Dashboard**, and then click **YARN**.</span></span>

    ![Lancer l’interface utilisateur Yarn](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png)

   > [!TIP]
   > <span data-ttu-id="efff8-130">Ou bien, vous pouvez également lancer hello l’interface utilisateur des fils de hello Ambari UI.</span><span class="sxs-lookup"><span data-stu-id="efff8-130">Alternatively, you can also launch hello YARN UI from hello Ambari UI.</span></span> <span data-ttu-id="efff8-131">toolaunch hello Ambari UI, à partir du Panneau de cluster hello, cliquez sur **tableau de bord de Cluster**, puis cliquez sur **tableau de bord de Cluster HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="efff8-131">toolaunch hello Ambari UI, from hello cluster blade, click **Cluster Dashboard**, and then click **HDInsight Cluster Dashboard**.</span></span> <span data-ttu-id="efff8-132">À partir de hello Ambari UI, cliquez sur **fils**, cliquez sur **liens rapides**et cliquez sur Gestionnaire de ressources actif hello, puis cliquez sur **ResourceManager UI**.</span><span class="sxs-lookup"><span data-stu-id="efff8-132">From hello Ambari UI, click **YARN**, click **Quick Links**, click hello active resource manager, and then click **ResourceManager UI**.</span></span>
   >
   >

## <a name="what-is-hello-optimum-cluster-configuration-toorun-spark-applications"></a><span data-ttu-id="efff8-133">Nouveautés d’applications de Spark toorun hello cluster optimales configuration ?</span><span class="sxs-lookup"><span data-stu-id="efff8-133">What is hello optimum cluster configuration toorun Spark applications?</span></span>
<span data-ttu-id="efff8-134">paramètres de clé Hello trois qui peuvent être utilisés pour la configuration de Spark selon les spécifications de l’application sont `spark.executor.instances`, `spark.executor.cores`, et `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="efff8-134">hello three key parameters that can be used for Spark configuration depending on application requirements are `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span></span> <span data-ttu-id="efff8-135">Un exécuteur est un processus lancé pour une application Spark.</span><span class="sxs-lookup"><span data-stu-id="efff8-135">An Executor is a process launched for a Spark application.</span></span> <span data-ttu-id="efff8-136">Il s’exécute sur le nœud de travail hello et est responsable toocarry tâches hello pour une application hello.</span><span class="sxs-lookup"><span data-stu-id="efff8-136">It runs on hello worker node and is responsible toocarry out hello tasks for hello application.</span></span> <span data-ttu-id="efff8-137">nombre d’exécuteurs hello exécuteur tailles et pour chaque cluster par défaut de Hello est calculé en fonction nombre de hello de nœuds de travail et la taille du nœud travail hello.</span><span class="sxs-lookup"><span data-stu-id="efff8-137">hello default number of executors and hello executor sizes for each cluster is calculated based on hello number of worker nodes and hello worker node size.</span></span> <span data-ttu-id="efff8-138">Ils sont stockés dans `spark-defaults.conf` sur nœuds principaux d’un cluster hello.</span><span class="sxs-lookup"><span data-stu-id="efff8-138">These are stored in `spark-defaults.conf` on hello cluster head nodes.</span></span>

<span data-ttu-id="efff8-139">trois paramètres de configuration Hello peuvent être configurées au niveau du cluster hello (pour toutes les applications qui s’exécutent sur le cluster de hello) ou peuvent être spécifiés pour chaque application également.</span><span class="sxs-lookup"><span data-stu-id="efff8-139">hello three configuration parameters can be configured at hello cluster level (for all applications that run on hello cluster) or can be specified for each individual application as well.</span></span>

### <a name="change-hello-parameters-using-ambari-ui"></a><span data-ttu-id="efff8-140">Modifier les paramètres de hello à l’aide de Ambari UI</span><span class="sxs-lookup"><span data-stu-id="efff8-140">Change hello parameters using Ambari UI</span></span>
1. <span data-ttu-id="efff8-141">À partir de hello Ambari UI, cliquez sur **Spark**, cliquez sur **configurations**, puis développez **personnalisé spark-defaults**.</span><span class="sxs-lookup"><span data-stu-id="efff8-141">From hello Ambari UI click **Spark**, click **Configs**, and then expand **Custom spark-defaults**.</span></span>

    ![Définir des paramètres à l’aide d’Ambari](./media/hdinsight-apache-spark-resource-manager/set-parameters-using-ambari.png)
2. <span data-ttu-id="efff8-143">valeurs par défaut de Hello sont bonnes toohave 4 Spark aux applications d’exécuter simultanément sur le cluster de hello.</span><span class="sxs-lookup"><span data-stu-id="efff8-143">hello default values are good toohave 4 Spark applications run concurrently on hello cluster.</span></span> <span data-ttu-id="efff8-144">Vous pouvez modifications ces valeurs à partir de l’interface utilisateur de hello, comme indiqué ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="efff8-144">You can changes these values from hello user interface, as shown below.</span></span>

    ![Définir des paramètres à l’aide d’Ambari](./media/hdinsight-apache-spark-resource-manager/set-executor-parameters.png)
3. <span data-ttu-id="efff8-146">Cliquez sur **enregistrer** modifications de configuration toosave hello.</span><span class="sxs-lookup"><span data-stu-id="efff8-146">Click **Save** toosave hello configuration changes.</span></span> <span data-ttu-id="efff8-147">En hello haut hello, vous serez invité toorestart tous hello les services affectés.</span><span class="sxs-lookup"><span data-stu-id="efff8-147">At hello top of hello page, you will be prompted toorestart all hello affected services.</span></span> <span data-ttu-id="efff8-148">Cliquez sur **Restart (Redémarrer)**.</span><span class="sxs-lookup"><span data-stu-id="efff8-148">Click **Restart**.</span></span>

    ![Redémarrer les services](./media/hdinsight-apache-spark-resource-manager/restart-services.png)

### <a name="change-hello-parameters-for-an-application-running-in-jupyter-notebook"></a><span data-ttu-id="efff8-150">Modifier les paramètres d’une application en cours d’exécution dans un bloc-notes jupyter hello</span><span class="sxs-lookup"><span data-stu-id="efff8-150">Change hello parameters for an application running in Jupyter notebook</span></span>
<span data-ttu-id="efff8-151">Pour les applications en cours d’exécution dans un bloc-notes jupyter de hello, vous pouvez utiliser hello `%%configure` magique de modifications de configuration toomake hello.</span><span class="sxs-lookup"><span data-stu-id="efff8-151">For applications running in hello Jupyter notebook, you can use hello `%%configure` magic toomake hello configuration changes.</span></span> <span data-ttu-id="efff8-152">Dans l’idéal, vous devez apporter ces modifications devant l’application hello, avant d’exécuter la première cellule de code hello.</span><span class="sxs-lookup"><span data-stu-id="efff8-152">Ideally, you must make such changes at hello beginning of hello application, before you run your first code cell.</span></span> <span data-ttu-id="efff8-153">Cela garantit que la configuration hello est appliqué toohello Livy session, lorsque celui-ci est créé.</span><span class="sxs-lookup"><span data-stu-id="efff8-153">This ensures that hello configuration is applied toohello Livy session, when it gets created.</span></span> <span data-ttu-id="efff8-154">Si vous voulez que la configuration de hello toochange à un stade ultérieur dans l’application hello, vous devez utiliser hello `-f` paramètre.</span><span class="sxs-lookup"><span data-stu-id="efff8-154">If you want toochange hello configuration at a later stage in hello application, you must use hello `-f` parameter.</span></span> <span data-ttu-id="efff8-155">Toutefois, en procédant ainsi, tous les progrès Bonjour application seront perdue.</span><span class="sxs-lookup"><span data-stu-id="efff8-155">However, by doing so all progress in hello application will be lost.</span></span>

<span data-ttu-id="efff8-156">extrait de code Hello ci-dessous montre comment toochange hello configuration d’une application en cours d’exécution dans le bloc-notes.</span><span class="sxs-lookup"><span data-stu-id="efff8-156">hello snippet below shows how toochange hello configuration for an application running in Jupyter.</span></span>

    %%configure
    {"executorMemory": "3072M", "executorCores": 4, "numExecutors":10}

<span data-ttu-id="efff8-157">Paramètres de configuration doivent être passées comme une chaîne JSON et doivent être sur la ligne suivante de hello après magique de hello, comme indiqué dans l’exemple, la colonne hello.</span><span class="sxs-lookup"><span data-stu-id="efff8-157">Configuration parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span>

### <a name="change-hello-parameters-for-an-application-submitted-using-spark-submit"></a><span data-ttu-id="efff8-158">Modifier les paramètres d’une application soumise à l’aide de hello spark-submit</span><span class="sxs-lookup"><span data-stu-id="efff8-158">Change hello parameters for an application submitted using spark-submit</span></span>
<span data-ttu-id="efff8-159">Commande suivante est un exemple de comment toochange hello pour une application de traitement par lots est envoyée à l’aide des paramètres de configuration `spark-submit`.</span><span class="sxs-lookup"><span data-stu-id="efff8-159">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using `spark-submit`.</span></span>

    spark-submit --class <hello application class tooexecute> --executor-memory 3072M --executor-cores 4 –-num-executors 10 <location of application jar file> <application parameters>

### <a name="change-hello-parameters-for-an-application-submitted-using-curl"></a><span data-ttu-id="efff8-160">Modifier les paramètres de hello pour une demande envoyée à l’aide de cURL</span><span class="sxs-lookup"><span data-stu-id="efff8-160">Change hello parameters for an application submitted using cURL</span></span>
<span data-ttu-id="efff8-161">Commande suivante est un exemple de comment toochange hello les paramètres de configuration pour une application de traitement par lots est soumise à l’aide de cURL.</span><span class="sxs-lookup"><span data-stu-id="efff8-161">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using using cURL.</span></span>

    curl -k -v -H 'Content-Type: application/json' -X POST -d '{"file":"<location of application jar file>", "className":"<hello application class tooexecute>", "args":[<application parameters>], "numExecutors":10, "executorMemory":"2G", "executorCores":5' localhost:8998/batches

### <a name="how-do-i-change-these-parameters-on-a-spark-thrift-server"></a><span data-ttu-id="efff8-162">Comment modifier ces paramètres sur un serveur Thrift Spark ?</span><span class="sxs-lookup"><span data-stu-id="efff8-162">How do I change these parameters on a Spark Thrift Server?</span></span>
<span data-ttu-id="efff8-163">Spark Thrift Server offre JDBC/ODBC accès tooa Spark cluster et est utilisé tooservice requêtes Spark SQL.</span><span class="sxs-lookup"><span data-stu-id="efff8-163">Spark Thrift Server provides JDBC/ODBC access tooa Spark cluster and is used tooservice Spark SQL queries.</span></span> <span data-ttu-id="efff8-164">Les outils tels que Power BI, Tableau, etc.</span><span class="sxs-lookup"><span data-stu-id="efff8-164">Tools like Power BI, Tableau etc.</span></span> <span data-ttu-id="efff8-165">utilisez ODBC protocole toocommunicate avec des requêtes de Spark SQL tooexecute Spark Thrift serveur comme une Application Spark.</span><span class="sxs-lookup"><span data-stu-id="efff8-165">use ODBC protocol toocommunicate with Spark Thrift Server tooexecute Spark SQL queries as a Spark Application.</span></span> <span data-ttu-id="efff8-166">Lors de la création d’un cluster Spark, deux instances de hello Spark Thrift Server sont démarrés, un sur chaque nœud principal.</span><span class="sxs-lookup"><span data-stu-id="efff8-166">When a Spark cluster is created, two instances of hello Spark Thrift Server are started, one on each head node.</span></span> <span data-ttu-id="efff8-167">Chaque serveur de Thrift Spark apparaît sous la forme d’une application Spark Bonjour fils UI.</span><span class="sxs-lookup"><span data-stu-id="efff8-167">Each Spark Thrift Server is visible as a Spark application in hello YARN UI.</span></span>

<span data-ttu-id="efff8-168">Spark Thrift Server utilise l’allocation dynamique de l’exécuteur de nouvelles et par conséquent hello `spark.executor.instances` n’est pas utilisé.</span><span class="sxs-lookup"><span data-stu-id="efff8-168">Spark Thrift Server uses Spark dynamic executor allocation and hence hello `spark.executor.instances` is not used.</span></span> <span data-ttu-id="efff8-169">En revanche, Spark Thrift serveur utilise `spark.dynamicAllocation.minExecutors` et `spark.dynamicAllocation.maxExecutors` nombre d’exécuteur toospecify hello.</span><span class="sxs-lookup"><span data-stu-id="efff8-169">Instead, Spark Thrift Server uses `spark.dynamicAllocation.minExecutors` and `spark.dynamicAllocation.maxExecutors` toospecify hello executor count.</span></span> <span data-ttu-id="efff8-170">paramètres de configuration de Hello `spark.executor.cores` et `spark.executor.memory` est toomodify hello exécuteur taille utilisée.</span><span class="sxs-lookup"><span data-stu-id="efff8-170">hello configuration parameters `spark.executor.cores` and `spark.executor.memory` is used toomodify hello executor size.</span></span> <span data-ttu-id="efff8-171">Vous pouvez modifier ces paramètres comme indiqué ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="efff8-171">You can change these parameters as shown below.</span></span>

* <span data-ttu-id="efff8-172">Développez hello **avancé spark-thrift-sparkconf** paramètres de catégorie tooupdate hello `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, et `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="efff8-172">Expand hello **Advanced spark-thrift-sparkconf** category tooupdate hello parameters `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, and `spark.executor.memory`.</span></span>

    ![Configurer le serveur Thrift Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-1.png)    
* <span data-ttu-id="efff8-174">Développez hello **personnalisé spark-thrift-sparkconf** paramètre de catégorie tooupdate hello `spark.executor.cores`.</span><span class="sxs-lookup"><span data-stu-id="efff8-174">Expand hello **Custom spark-thrift-sparkconf** category tooupdate hello parameter `spark.executor.cores`.</span></span>

    ![Configurer le serveur Thrift Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-2.png)

### <a name="how-do-i-change-hello-driver-memory-of-hello-spark-thrift-server"></a><span data-ttu-id="efff8-176">Comment modifier les hello pilote de mémoire de hello Spark Thrift serveur ?</span><span class="sxs-lookup"><span data-stu-id="efff8-176">How do I change hello driver memory of hello Spark Thrift Server?</span></span>
<span data-ttu-id="efff8-177">Spark Thrift Server pilote mémoire est configuré too25 de taille du nœud principal RAM hello, condition hello totale de mémoire RAM de nœud principal de hello est supérieur à 14 Go.</span><span class="sxs-lookup"><span data-stu-id="efff8-177">Spark Thrift Server driver memory is configured too25% of hello head node RAM size, provided hello total RAM size of hello head node is greater than 14GB.</span></span> <span data-ttu-id="efff8-178">Vous pouvez utiliser hello Ambari UI toochange hello pilote configuration de la mémoire, comme illustré ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="efff8-178">You can use hello Ambari UI toochange hello driver memory configuration, as shown below.</span></span>

* <span data-ttu-id="efff8-179">À partir de hello Ambari UI, cliquez sur **Spark**, cliquez sur **configurations**, développez **avancé spark-env**, puis indiquez la valeur hello pour **spark_thrift_cmd_opts**.</span><span class="sxs-lookup"><span data-stu-id="efff8-179">From hello Ambari UI click **Spark**, click **Configs**, expand **Advanced spark-env**, and then provide hello value for **spark_thrift_cmd_opts**.</span></span>

    ![Configurer la mémoire RAM du serveur Thrift Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-ram.png)

## <a name="i-do-not-use-bi-with-spark-cluster-how-do-i-take-hello-resources-back"></a><span data-ttu-id="efff8-181">Je n’utilise pas d’outils décisionnels avec le cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="efff8-181">I do not use BI with Spark cluster.</span></span> <span data-ttu-id="efff8-182">Comment rétablir les ressources hello en ?</span><span class="sxs-lookup"><span data-stu-id="efff8-182">How do I take hello resources back?</span></span>
<span data-ttu-id="efff8-183">Étant donné que nous utilisons l’allocation dynamique Spark, hello uniquement les ressources qui sont consommés par le serveur de thrift hello ressources sont des formes de base hello deux applications.</span><span class="sxs-lookup"><span data-stu-id="efff8-183">Since we use Spark dynamic allocation, hello only resources that are consumed by thrift server are hello resources for hello two application masters.</span></span> <span data-ttu-id="efff8-184">tooreclaim ces ressources, que vous devez arrêter hello Thrift Server services s’exécutant sur un cluster de hello.</span><span class="sxs-lookup"><span data-stu-id="efff8-184">tooreclaim these resources you must stop hello Thrift Server services running on hello cluster.</span></span>

1. <span data-ttu-id="efff8-185">À partir de hello Ambari UI, à partir du volet de gauche hello, cliquez sur **Spark**.</span><span class="sxs-lookup"><span data-stu-id="efff8-185">From hello Ambari UI, from hello left pane, click **Spark**.</span></span>
2. <span data-ttu-id="efff8-186">Dans la page suivante de hello, cliquez sur **Spark Thrift serveurs**.</span><span class="sxs-lookup"><span data-stu-id="efff8-186">In hello next page, click **Spark Thrift Servers**.</span></span>

    ![Redémarrer le serveur Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-1.png)
3. <span data-ttu-id="efff8-188">Vous devez voir les deux headnodes hello sur quel hello Spark Thrift Server est en cours d’exécution.</span><span class="sxs-lookup"><span data-stu-id="efff8-188">You should see hello two headnodes on which hello Spark Thrift Server is running.</span></span> <span data-ttu-id="efff8-189">Cliquez sur un des hello headnodes.</span><span class="sxs-lookup"><span data-stu-id="efff8-189">Click one of hello headnodes.</span></span>

    ![Redémarrer le serveur Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-2.png)
4. <span data-ttu-id="efff8-191">page suivante de Hello répertorie tous les services de hello en cours d’exécution sur ce nœud principal.</span><span class="sxs-lookup"><span data-stu-id="efff8-191">hello next page lists all hello services running on that headnode.</span></span> <span data-ttu-id="efff8-192">À partir de la liste de hello cliquez tooSpark suivant du bouton de liste déroulante hello Thrift serveur, puis cliquez sur **arrêter**.</span><span class="sxs-lookup"><span data-stu-id="efff8-192">From hello list click hello drop-down button next tooSpark Thrift Server, and then click **Stop**.</span></span>

    ![Redémarrer le serveur Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-3.png)
5. <span data-ttu-id="efff8-194">Répétez ces étapes sur hello autre nœud principal également.</span><span class="sxs-lookup"><span data-stu-id="efff8-194">Repeat these steps on hello other headnode as well.</span></span>

## <a name="my-jupyter-notebooks-are-not-running-as-expected-how-can-i-restart-hello-service"></a><span data-ttu-id="efff8-195">Mes blocs-notes Jupyter ne s’exécutent pas comme prévu.</span><span class="sxs-lookup"><span data-stu-id="efff8-195">My Jupyter notebooks are not running as expected.</span></span> <span data-ttu-id="efff8-196">Comment puis-je redémarrer le service de hello ?</span><span class="sxs-lookup"><span data-stu-id="efff8-196">How can I restart hello service?</span></span>
<span data-ttu-id="efff8-197">Lancez hello l’interface utilisateur de Ambari Web comme indiqué ci-dessus.</span><span class="sxs-lookup"><span data-stu-id="efff8-197">Launch hello Ambari Web UI as shown above.</span></span> <span data-ttu-id="efff8-198">Dans le volet de navigation gauche hello, cliquez sur **Notebook**, cliquez sur **Actions Service**, puis cliquez sur **redémarrer tous les**.</span><span class="sxs-lookup"><span data-stu-id="efff8-198">From hello left navigation pane, click **Jupyter**, click **Service Actions**, and then click **Restart All**.</span></span> <span data-ttu-id="efff8-199">Cela démarre hello Notebook service sur tous les hello headnodes.</span><span class="sxs-lookup"><span data-stu-id="efff8-199">This will start hello Jupyter service on all hello headnodes.</span></span>

    ![Restart Jupyter](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png "Restart Jupyter")

## <a name="how-do-i-know-if-i-am-running-out-of-resources"></a><span data-ttu-id="efff8-200">Comment savoir si mes ressources sont épuisées ?</span><span class="sxs-lookup"><span data-stu-id="efff8-200">How do I know if I am running out of resources?</span></span>
<span data-ttu-id="efff8-201">Lancez hello fils UI comme indiqué ci-dessus.</span><span class="sxs-lookup"><span data-stu-id="efff8-201">Launch hello Yarn UI as shown above.</span></span> <span data-ttu-id="efff8-202">Dans la table des métriques de Cluster sur l’écran hello, vérifiez les valeurs de **mémoire utilisée** et **mémoire totale** colonnes.</span><span class="sxs-lookup"><span data-stu-id="efff8-202">In Cluster Metrics table on top of hello screen, check values of **Memory Used** and **Memory Total** columns.</span></span> <span data-ttu-id="efff8-203">Si les valeurs hello 2 sont très proches, il peut-être pas suffisamment ressources toostart hello prochaine application.</span><span class="sxs-lookup"><span data-stu-id="efff8-203">If hello 2 values are very close, there might not be enough resources toostart hello next application.</span></span> <span data-ttu-id="efff8-204">Hello valable toohello **VCores utilisé** et **VCores Total** colonnes.</span><span class="sxs-lookup"><span data-stu-id="efff8-204">hello same applies toohello **VCores Used** and **VCores Total** columns.</span></span> <span data-ttu-id="efff8-205">En outre, dans la vue principale de hello, s’il existe une application séjourné dans **accepté** état et la passe ne pas par **en cours d’exécution** ni **n’a pas pu** d’état, cela peut également indiquer une qu’il ne reçoit pas suffisamment toostart de ressources.</span><span class="sxs-lookup"><span data-stu-id="efff8-205">Also, in hello main view, if there is an application stayed in **ACCEPTED** state and not transitioning into **RUNNING** nor **FAILED** state, this could also be an indication that it is not getting enough resources toostart.</span></span>

    ![Resource Limit](./media/hdinsight-apache-spark-resource-manager/resource-limit.png "Resource Limit")

## <a name="how-do-i-kill-a-running-application-toofree-up-resource"></a><span data-ttu-id="efff8-206">Comment mettre fin en cours d’exécution toofree application ressource ?</span><span class="sxs-lookup"><span data-stu-id="efff8-206">How do I kill a running application toofree up resource?</span></span>
1. <span data-ttu-id="efff8-207">Bonjour fils UI, à partir du volet de gauche hello, cliquez sur **en cours d’exécution**.</span><span class="sxs-lookup"><span data-stu-id="efff8-207">In hello Yarn UI, from hello left panel, click **Running**.</span></span> <span data-ttu-id="efff8-208">À partir de la liste de hello des applications en cours d’exécution, déterminez hello application toobe arrêtés, puis cliquez sur hello **ID**.</span><span class="sxs-lookup"><span data-stu-id="efff8-208">From hello list of running applications, determine hello application toobe killed and click on hello **ID**.</span></span>

    <span data-ttu-id="efff8-209">![Arrêter App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Arrêter App1")</span><span class="sxs-lookup"><span data-stu-id="efff8-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span></span>

2. <span data-ttu-id="efff8-210">Cliquez sur **arrêter l’Application** sur hello coin supérieur droit, puis cliquez sur **OK**.</span><span class="sxs-lookup"><span data-stu-id="efff8-210">Click **Kill Application** on hello top right corner, then click **OK**.</span></span>

    <span data-ttu-id="efff8-211">![Arrêter App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Arrêter App2")</span><span class="sxs-lookup"><span data-stu-id="efff8-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span></span>

## <a name="see-also"></a><span data-ttu-id="efff8-212">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="efff8-212">See also</span></span>
* [<span data-ttu-id="efff8-213">Track and debug jobs running on an Apache Spark cluster in HDInsight (Suivi et débogage des tâches en cours d’exécution sur un cluster Apache Spark dans HDInsight)</span><span class="sxs-lookup"><span data-stu-id="efff8-213">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

### <a name="for-data-analysts"></a><span data-ttu-id="efff8-214">Pour les analystes de données</span><span class="sxs-lookup"><span data-stu-id="efff8-214">For data analysts</span></span>

* [<span data-ttu-id="efff8-215">Spark avec Machine Learning : utilisez Spark dans HDInsight pour l’analyse de la température des bâtiments à l’aide des données des systèmes HVAC</span><span class="sxs-lookup"><span data-stu-id="efff8-215">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="efff8-216">Spark avec Machine Learning : Spark utilisation dans résultats de l’inspection alimentaires toopredict HDInsight</span><span class="sxs-lookup"><span data-stu-id="efff8-216">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="efff8-217">Analyse des journaux de site web à l’aide de Spark dans HDInsight</span><span class="sxs-lookup"><span data-stu-id="efff8-217">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)
* [<span data-ttu-id="efff8-218">Application Insight telemetry data analysis using Spark in HDInsight (Analyse des données de télémétrie Application Insight à l’aide de Spark dans HDInsight)</span><span class="sxs-lookup"><span data-stu-id="efff8-218">Application Insight telemetry data analysis using Spark in HDInsight</span></span>](hdinsight-spark-analyze-application-insight-logs.md)
* [<span data-ttu-id="efff8-219">Utiliser Caffe sur Azure HDInsight Spark pour une formation approfondie échelonnée</span><span class="sxs-lookup"><span data-stu-id="efff8-219">Use Caffe on Azure HDInsight Spark for distributed deep learning</span></span>](hdinsight-deep-learning-caffe-spark.md)

### <a name="for-spark-developers"></a><span data-ttu-id="efff8-220">Pour les développeurs Spark</span><span class="sxs-lookup"><span data-stu-id="efff8-220">For Spark developers</span></span>

* [<span data-ttu-id="efff8-221">Créer une application autonome avec Scala</span><span class="sxs-lookup"><span data-stu-id="efff8-221">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="efff8-222">Exécution de travaux à distance avec Livy sur un cluster Spark</span><span class="sxs-lookup"><span data-stu-id="efff8-222">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
* [<span data-ttu-id="efff8-223">Utiliser le plug-in des outils HDInsight pour IntelliJ idée toocreate et soumettre des applications de Spark Scala</span><span class="sxs-lookup"><span data-stu-id="efff8-223">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="efff8-224">Streaming Spark : Utiliser Spark dans HDInsight pour créer des applications de diffusion en continu en temps réel</span><span class="sxs-lookup"><span data-stu-id="efff8-224">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="efff8-225">Utiliser des plug-in des outils HDInsight pour les applications de Spark toodebug IntelliJ idée à distance</span><span class="sxs-lookup"><span data-stu-id="efff8-225">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="efff8-226">Utiliser des bloc-notes Zeppelin avec un cluster Spark sur HDInsight</span><span class="sxs-lookup"><span data-stu-id="efff8-226">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="efff8-227">Noyaux disponibles pour le bloc-notes Jupyter dans un cluster Spark pour HDInsight</span><span class="sxs-lookup"><span data-stu-id="efff8-227">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="efff8-228">Utiliser des packages externes avec les blocs-notes Jupyter</span><span class="sxs-lookup"><span data-stu-id="efff8-228">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="efff8-229">Installer Notebook sur votre ordinateur et vous connecter tooan cluster HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="efff8-229">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)
