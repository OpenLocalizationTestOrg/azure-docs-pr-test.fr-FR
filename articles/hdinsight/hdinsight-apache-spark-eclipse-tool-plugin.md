---
title: "Kit de ressources Azure pour Eclipse - Créer des applications Scala pour HDInsight Spark | Microsoft Docs"
description: "Utilisez les outils HDInsight dans le kit de ressources Azure pour Eclipse pour développer des applications Spark écrites en Scala et envoyez-les à un cluster HDInsight Spark, directement à partir de l’IDE Eclipse."
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: f6c79550-5803-4e13-b541-e86c4abb420b
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/24/2017
ms.author: nitinme
ms.openlocfilehash: 4bcb1987a62c0b7f4965e6fd257315e820004238
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 08/29/2017
---
# <a name="use-azure-toolkit-for-eclipse-to-create-spark-applications-for-an-hdinsight-cluster"></a><span data-ttu-id="50e0e-103">Utiliser le kit de ressources Azure pour Eclipse pour créer des applications Spark pour un cluster HDInsight</span><span class="sxs-lookup"><span data-stu-id="50e0e-103">Use Azure Toolkit for Eclipse to create Spark applications for an HDInsight cluster</span></span>

<span data-ttu-id="50e0e-104">Utilisez HDInsight Tools du kit de ressources Azure pour Eclipse pour développer des applications Spark écrites en Scala et envoyez-les à un cluster Azure HDInsight Spark, directement à partir de l’environnement de développement intégré (IDE) Eclipse.</span><span class="sxs-lookup"><span data-stu-id="50e0e-104">Use HDInsight Tools in Azure Toolkit for Eclipse to develop Spark applications written in Scala and submit them to an Azure HDInsight Spark cluster, directly from the Eclipse IDE.</span></span> <span data-ttu-id="50e0e-105">Vous pouvez utiliser le plug-in HDInsight Tools de différentes manières :</span><span class="sxs-lookup"><span data-stu-id="50e0e-105">You can use the HDInsight Tools plug-in in a few different ways:</span></span>

* <span data-ttu-id="50e0e-106">Pour développer une application Spark Scala et l’envoyer à un cluster HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="50e0e-106">To develop and submit a Scala Spark application on an HDInsight Spark cluster</span></span>
* <span data-ttu-id="50e0e-107">Pour accéder à vos ressources de cluster Azure HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="50e0e-107">To access your Azure HDInsight Spark cluster resources</span></span>
* <span data-ttu-id="50e0e-108">Pour développer et exécuter une application Spark Scala localement</span><span class="sxs-lookup"><span data-stu-id="50e0e-108">To develop and run a Scala Spark application locally</span></span>

> [!IMPORTANT]
> <span data-ttu-id="50e0e-109">Cet outil peut être utilisé pour créer des applications et les envoyer à un cluster HDInsight Spark sur Linux uniquement.</span><span class="sxs-lookup"><span data-stu-id="50e0e-109">This tool can be used to create and submit applications only for an HDInsight Spark cluster on Linux.</span></span>
> 
> 

## <a name="prerequisites"></a><span data-ttu-id="50e0e-110">Composants requis</span><span class="sxs-lookup"><span data-stu-id="50e0e-110">Prerequisites</span></span>

* <span data-ttu-id="50e0e-111">Un cluster Apache Spark sur HDInsight.</span><span class="sxs-lookup"><span data-stu-id="50e0e-111">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="50e0e-112">Pour obtenir des instructions, consultez [Création de clusters Apache Spark dans Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="50e0e-112">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>
* <span data-ttu-id="50e0e-113">Oracle Java Development Kit version 8, qui est utilisé pour l’exécution d’IDE Eclipse.</span><span class="sxs-lookup"><span data-stu-id="50e0e-113">Oracle Java Development Kit version 8, which is used for the Eclipse IDE runtime.</span></span> <span data-ttu-id="50e0e-114">Vous pouvez le télécharger à partir du [site web Oracle](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html).</span><span class="sxs-lookup"><span data-stu-id="50e0e-114">You can download it from the [Oracle website](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html).</span></span>
* <span data-ttu-id="50e0e-115">IDE Eclipse.</span><span class="sxs-lookup"><span data-stu-id="50e0e-115">Eclipse IDE.</span></span> <span data-ttu-id="50e0e-116">Cet article utilise Eclipse Neon.</span><span class="sxs-lookup"><span data-stu-id="50e0e-116">This article uses Eclipse Neon.</span></span> <span data-ttu-id="50e0e-117">Vous pouvez l’installer à partir du [site web Eclipse](https://www.eclipse.org/downloads/).</span><span class="sxs-lookup"><span data-stu-id="50e0e-117">You can install it from the [Eclipse website](https://www.eclipse.org/downloads/).</span></span>   
* <span data-ttu-id="50e0e-118">Kit de développement logiciel (SDK) Spark.</span><span class="sxs-lookup"><span data-stu-id="50e0e-118">Spark SDK.</span></span> <span data-ttu-id="50e0e-119">Vous pouvez le télécharger à partir de [GitHub](http://go.microsoft.com/fwlink/?LinkID=723585&clcid=0x409).</span><span class="sxs-lookup"><span data-stu-id="50e0e-119">You can download it from [GitHub](http://go.microsoft.com/fwlink/?LinkID=723585&clcid=0x409).</span></span>


## <a name="install-hdinsight-tools-in-azure-toolkit-for-eclipse-and-scala-plugin"></a><span data-ttu-id="50e0e-120">Installer les outils HDInsight dans la boîte à outils Azure pour Eclipse et plug-in Scala</span><span class="sxs-lookup"><span data-stu-id="50e0e-120">Install HDInsight Tools in Azure Toolkit for Eclipse and Scala Plugin</span></span>
### <a name="install-hdinsight-tools"></a><span data-ttu-id="50e0e-121">Installer HDInsight Tools</span><span class="sxs-lookup"><span data-stu-id="50e0e-121">Install HDInsight Tools</span></span>
<span data-ttu-id="50e0e-122">HDInsight Tools pour Eclipse est disponible dans le cadre du kit de ressources Azure pour Eclipse.</span><span class="sxs-lookup"><span data-stu-id="50e0e-122">HDInsight Tools for Eclipse is available as part of Azure Toolkit for Eclipse.</span></span> <span data-ttu-id="50e0e-123">Pour plus d’informations sur l’installation, voir [Installation du kit de ressources Azure pour Eclipse](../azure-toolkit-for-eclipse-installation.md).</span><span class="sxs-lookup"><span data-stu-id="50e0e-123">For installation instructions, see [Installing Azure Toolkit for Eclipse](../azure-toolkit-for-eclipse-installation.md).</span></span>
### <a name="install-scala-plugin"></a><span data-ttu-id="50e0e-124">Installer le plug-in Scala</span><span class="sxs-lookup"><span data-stu-id="50e0e-124">Install Scala Plugin</span></span>
<span data-ttu-id="50e0e-125">Lorsque vous ouvrez le Intellij, l’outils HDInsight automatique détecte si vous avez installé le plug-in Scala ou non.</span><span class="sxs-lookup"><span data-stu-id="50e0e-125">When you open the Intellij, the HDInsight Tools auto detects whether you installed Scala plugin or not.</span></span> <span data-ttu-id="50e0e-126">Cliquez sur **OK** pour continuer, suivez les instructions pour installer le Marketplace d’Eclipse.</span><span class="sxs-lookup"><span data-stu-id="50e0e-126">Click **OK** to continue and follow the instructions to install by the Eclipse Marketplace.</span></span>

 ![Le plug-in Scala automatiquement installer](./media/hdinsight-apache-spark-eclipse-tool-plugin/auto-install-scala.png)

## <a name="sign-in-to-your-azure-subscription"></a><span data-ttu-id="50e0e-128">Connectez-vous à votre abonnement Azure :</span><span class="sxs-lookup"><span data-stu-id="50e0e-128">Sign in to your Azure subscription</span></span>
1. <span data-ttu-id="50e0e-129">Démarrez l’IDE Eclipse et ouvrez l’Explorateur Azure.</span><span class="sxs-lookup"><span data-stu-id="50e0e-129">Start the Eclipse IDE and open Azure Explorer.</span></span> <span data-ttu-id="50e0e-130">Dans le menu **Window** (Fenêtre), cliquez sur **Show View** (Afficher la vue), puis sur **Other** (Autre).</span><span class="sxs-lookup"><span data-stu-id="50e0e-130">On the **Window** menu, click **Show View**, and then click **Other**.</span></span> <span data-ttu-id="50e0e-131">Dans la boîte de dialogue qui s’ouvre, développez **Azure**, cliquez sur **Explorateur Azure**, puis sur **OK**.</span><span class="sxs-lookup"><span data-stu-id="50e0e-131">In the dialog box that opens, expand **Azure**, click **Azure Explorer**, and then click **OK**.</span></span>

    ![Boîte de dialogue Affichage](./media/hdinsight-apache-spark-eclipse-tool-plugin/view-explorer-1.png)
2. <span data-ttu-id="50e0e-133">Cliquez avec le bouton droit sur le nœud **Azure**, puis cliquez sur **Se connecter**.</span><span class="sxs-lookup"><span data-stu-id="50e0e-133">Right-click the **Azure** node, and then click **Sign in**.</span></span>
3. <span data-ttu-id="50e0e-134">Dans la boîte de dialogue **Azure Sign in (Connexion à Azure)**, choisissez la méthode d’authentification, cliquez sur **Se connecter** et entrez vos informations d’identification Azure.</span><span class="sxs-lookup"><span data-stu-id="50e0e-134">In the **Azure Sign In** dialog box, choose the authentication method, click **Sign in**, and enter your Azure credentials.</span></span>
   
    ![Boîte de dialogue Connexion à Azure](./media/hdinsight-apache-spark-eclipse-tool-plugin/view-explorer-2.png)
4. <span data-ttu-id="50e0e-136">Une fois que vous êtes connecté, la boîte de dialogue **Sélectionner des abonnements** répertorie tous les abonnements Azure associés aux informations d’identification.</span><span class="sxs-lookup"><span data-stu-id="50e0e-136">After you're signed in, the **Select Subscriptions** dialog box lists all the Azure subscriptions associated with the credentials.</span></span> <span data-ttu-id="50e0e-137">Cliquez sur **Sélectionner** pour fermer la boîte de dialogue.</span><span class="sxs-lookup"><span data-stu-id="50e0e-137">Click **Select** to close the dialog box.</span></span>

    ![Boîte de dialogue Sélectionner des abonnements](./media/hdinsight-apache-spark-eclipse-tool-plugin/Select-Subscriptions.png)
5. <span data-ttu-id="50e0e-139">Dans l’onglet **Explorateur Azure**, développez **HDInsight** pour afficher les clusters HDInsight Spark de votre abonnement.</span><span class="sxs-lookup"><span data-stu-id="50e0e-139">On the **Azure Explorer** tab, expand **HDInsight** to see the HDInsight Spark clusters under your subscription.</span></span>
   
    ![Clusters HDInsight Spark dans l’Explorateur Azure](./media/hdinsight-apache-spark-eclipse-tool-plugin/view-explorer-3.png)
6. <span data-ttu-id="50e0e-141">Vous pouvez développer davantage un nœud de nom de cluster pour voir les ressources (par exemple, les comptes de stockage) associées au cluster.</span><span class="sxs-lookup"><span data-stu-id="50e0e-141">You can further expand a cluster name node to see the resources (for example, storage accounts) associated with the cluster.</span></span>
   
    ![Développement d’un nom de cluster pour voir les ressources](./media/hdinsight-apache-spark-eclipse-tool-plugin/view-explorer-4.png)



## <a name="set-up-a-spark-scala-project-for-an-hdinsight-spark-cluster"></a><span data-ttu-id="50e0e-143">Configuration d’un projet Spark Scala pour un cluster HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="50e0e-143">Set up a Spark Scala project for an HDInsight Spark cluster</span></span>

1. <span data-ttu-id="50e0e-144">Dans l’espace de travail IDE Eclipse, cliquez sur **File** (Fichier), sur **New** (Nouveau), puis sur **Project** (Projet).</span><span class="sxs-lookup"><span data-stu-id="50e0e-144">In the Eclipse IDE workspace, click **File**, click **New**, and then click **Project**.</span></span> 
2. <span data-ttu-id="50e0e-145">Dans l’Assistant New Project (Nouveau projet), développez **HDInsight**, sélectionnez **Spark on HDInsight (Scala)** (Spark sur HDInsight [Scala]), puis cliquez sur **Next** (Suivant).</span><span class="sxs-lookup"><span data-stu-id="50e0e-145">In the New Project wizard, expand **HDInsight**, select **Spark on HDInsight (Scala)**, and then click **Next**.</span></span>

    ![Sélection du projet Spark sur HDInsight (Scala)](./media/hdinsight-apache-spark-eclipse-tool-plugin/create-hdi-scala-app-2.png)
3. <span data-ttu-id="50e0e-147">L’assistant automatique de création de projets Scala détecte si vous avez installé le plug-in Scala ou non.</span><span class="sxs-lookup"><span data-stu-id="50e0e-147">The Scala project creation wizard auto detects whether you installed Scala plugin or not.</span></span> <span data-ttu-id="50e0e-148">Cliquez sur **OK** pour poursuivre le téléchargement du plug-in Scala, puis suivez les instructions pour redémarrer Eclipse.</span><span class="sxs-lookup"><span data-stu-id="50e0e-148">Click **OK** to continue downloading the Scala plugin, then follow the instructions to restart Eclipse.</span></span>

    ![vérification Scala](./media/hdinsight-apache-spark-eclipse-tool-plugin/auto-install-scala-2.png)
4. <span data-ttu-id="50e0e-150">Dans la boîte de dialogue **New HDInsight Scala Project** (Nouveau projet HDInsight Scala), indiquez les valeurs suivantes, puis cliquez sur **Next** (Suivant) :</span><span class="sxs-lookup"><span data-stu-id="50e0e-150">In the **New HDInsight Scala Project** dialog box, provide the following values, and then click **Next**:</span></span>
   * <span data-ttu-id="50e0e-151">Entrez un nom pour le projet.</span><span class="sxs-lookup"><span data-stu-id="50e0e-151">Enter a name for the project.</span></span>
   * <span data-ttu-id="50e0e-152">Dans la zone **JRE**, vérifiez que l’option **Use an execution environment JRE** (Utiliser un environnement d’exécution JRE) est définie sur **JavaSE-1.7** ou version ultérieure.</span><span class="sxs-lookup"><span data-stu-id="50e0e-152">In the **JRE** area, make sure that **Use an execution environment JRE** is set to **JavaSE-1.7** or later.</span></span>
   * <span data-ttu-id="50e0e-153">Vérifiez que le Kit de développement logiciel (SDK) Spark est défini sur l’emplacement où vous avez téléchargé le Kit de développement logiciel (SDK).</span><span class="sxs-lookup"><span data-stu-id="50e0e-153">Make sure that Spark SDK is set to the location where you downloaded the SDK.</span></span> <span data-ttu-id="50e0e-154">Le lien vers l’emplacement de téléchargement est inclus dans la section [Composants requis](#prerequisites), plus haut dans cet article.</span><span class="sxs-lookup"><span data-stu-id="50e0e-154">The link to the download location is included in the [prerequisites](#prerequisites) earlier in this article.</span></span> <span data-ttu-id="50e0e-155">Vous pouvez également télécharger le Kit de développement logiciel (SDK) à partir du lien inclus dans la boîte de dialogue.</span><span class="sxs-lookup"><span data-stu-id="50e0e-155">You can also download the SDK from the link included in the dialog box.</span></span>

    ![Boîte de dialogue New HDInsight Scala Project (Nouveau projet HDInsight Scala)](./media/hdinsight-apache-spark-eclipse-tool-plugin/create-hdi-scala-app-3.png)
5.  <span data-ttu-id="50e0e-157">Dans la boîte de dialogue suivante, cliquez sur l’onglet **Libraries** (Bibliothèques), conservez les valeurs par défaut, puis cliquez sur **Finish** (Terminer).</span><span class="sxs-lookup"><span data-stu-id="50e0e-157">In the next dialog box, click the **Libraries** tab and keep the defaults, and then click **Finish**.</span></span> 
   
    ![Onglet Libraries (Bibliothèques)](./media/hdinsight-apache-spark-eclipse-tool-plugin/create-hdi-scala-app-4.png)
  
## <a name="create-a-scala-application-for-an-hdinsight-spark-cluster"></a><span data-ttu-id="50e0e-159">Créer une application Scala pour un cluster HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="50e0e-159">Create a Scala application for an HDInsight Spark cluster</span></span>

1. <span data-ttu-id="50e0e-160">Dans l’IDE Eclipse, dans Package Explorer (Explorateur de packages), développez le projet créé précédemment, cliquez avec le bouton droit sur **src**, pointez sur **New** (Nouveau), puis cliquez sur **Other** (Autre).</span><span class="sxs-lookup"><span data-stu-id="50e0e-160">In the Eclipse IDE, from Package Explorer, expand the project that you created earlier, right-click **src**, point to **New**, and then click **Other**.</span></span>
2. <span data-ttu-id="50e0e-161">Dans la boîte de dialogue **Select a wizard** (Sélectionner un Assistant), développez **Scala Wizards** (Assistants Scala), cliquez sur **Scala Object** (Objet Scala), puis cliquez sur **Next** (Suivant).</span><span class="sxs-lookup"><span data-stu-id="50e0e-161">In the **Select a wizard** dialog box, expand **Scala Wizards**, click **Scala Object**, and then click **Next**.</span></span>
   
    ![Boîte de dialogue Select a wizard (Sélectionner un Assistant)](./media/hdinsight-apache-spark-eclipse-tool-plugin/create-scala-proj-1.png)
3. <span data-ttu-id="50e0e-163">Dans la boîte de dialogue **Create New File** (Créer un nouveau fichier), entrez un nom pour l’objet, puis cliquez sur **Finish** (Terminer).</span><span class="sxs-lookup"><span data-stu-id="50e0e-163">In the **Create New File** dialog box, enter a name for the object, and then click **Finish**.</span></span>
   
    ![Boîte de dialogue Create New File (Créer un fichier)](./media/hdinsight-apache-spark-eclipse-tool-plugin/create-scala-proj-2.png)
4. <span data-ttu-id="50e0e-165">Collez le code suivant dans l’éditeur de texte :</span><span class="sxs-lookup"><span data-stu-id="50e0e-165">Paste the following code in the text editor:</span></span>
   
        import org.apache.spark.SparkConf
        import org.apache.spark.SparkContext
   
        object MyClusterApp{
          def main (arg: Array[String]): Unit = {
            val conf = new SparkConf().setAppName("MyClusterApp")
            val sc = new SparkContext(conf)
   
            val rdd = sc.textFile("wasb:///HdiSamples/HdiSamples/SensorSampleData/hvac/HVAC.csv")
   
            //find the rows that have only one digit in the seventh column in the CSV
            val rdd1 =  rdd.filter(s => s.split(",")(6).length() == 1)
   
            rdd1.saveAsTextFile("wasb:///HVACOut")
          }        
        }
5. <span data-ttu-id="50e0e-166">Exécutez l’application sur un cluster HDInsight Spark :</span><span class="sxs-lookup"><span data-stu-id="50e0e-166">Run the application on an HDInsight Spark cluster:</span></span>
   
   1. <span data-ttu-id="50e0e-167">Dans Package Explorer (Explorateur de packages), cliquez avec le bouton droit sur le nom du projet, puis sélectionnez **Submit Spark Application to HDInsight** (Envoyer l’application Spark à HDInsight).</span><span class="sxs-lookup"><span data-stu-id="50e0e-167">From Package Explorer, right-click the project name, and then select **Submit Spark Application to HDInsight**.</span></span>        
   2. <span data-ttu-id="50e0e-168">Dans la boîte de dialogue **Spark Submission** (Envoi Spark), entrez les valeurs suivantes, puis cliquez sur **Submit (Envoyer)** :</span><span class="sxs-lookup"><span data-stu-id="50e0e-168">In the **Spark Submission** dialog box, provide the following values, and then click **Submit**:</span></span>
      
      * <span data-ttu-id="50e0e-169">Pour **Cluster Name**(Nom du cluster), sélectionnez le cluster HDInsight Spark sur lequel vous souhaitez exécuter votre application.</span><span class="sxs-lookup"><span data-stu-id="50e0e-169">For **Cluster Name**, select the HDInsight Spark cluster on which you want to run your application.</span></span>
      * <span data-ttu-id="50e0e-170">Sélectionnez un artefact à partir du projet Eclipse ou choisissez-en un sur un disque dur.</span><span class="sxs-lookup"><span data-stu-id="50e0e-170">Select an artifact from the Eclipse project, or select one from a hard drive.</span></span> <span data-ttu-id="50e0e-171">La valeur par défaut dépend de l’élément sur lequel vous cliquez avec le bouton droit dans l’Explorateur de package.</span><span class="sxs-lookup"><span data-stu-id="50e0e-171">The default value depends on the item you right-click from package explorer.</span></span>
      * <span data-ttu-id="50e0e-172">Dans la liste déroulante **Main class name** (Nom de la classe principale), l’Assistant Envoi affiche tous les noms des objets de votre projet sélectionné.</span><span class="sxs-lookup"><span data-stu-id="50e0e-172">In the **Main class name** dropdownlist, submission wizard displays all object names from your selected project.</span></span> <span data-ttu-id="50e0e-173">Sélectionnez-en un ou entrez-en un que vous souhaitez exécuter.</span><span class="sxs-lookup"><span data-stu-id="50e0e-173">Select or input one that you want to run.</span></span> <span data-ttu-id="50e0e-174">Si vous sélectionnez un artefact à partir du disque dur, vous devez entrer le nom de la classe principale vous-même.</span><span class="sxs-lookup"><span data-stu-id="50e0e-174">If you select artifact from hard disk, you need input main class name by yourself.</span></span> 
      * <span data-ttu-id="50e0e-175">Étant donné que le code d’application dans cet exemple n’exige aucun argument de ligne de commande et qu’il ne référence pas de fichiers JAR ou d’autres fichiers, vous pouvez laisser les autres zones de texte vides.</span><span class="sxs-lookup"><span data-stu-id="50e0e-175">Because the application code in this example does not require any command-line arguments or reference JARs or files, you can leave the remaining text boxes empty.</span></span>
        
       ![Boîte de dialogue Spark Submission (Envoi Spark)](./media/hdinsight-apache-spark-eclipse-tool-plugin/create-scala-proj-3.png)
   3. <span data-ttu-id="50e0e-177">L’onglet **Spark Submission** (Envoi Spark) doit commencer à afficher la progression.</span><span class="sxs-lookup"><span data-stu-id="50e0e-177">The **Spark Submission** tab should start displaying the progress.</span></span> <span data-ttu-id="50e0e-178">Vous pouvez arrêter l’application en cliquant sur le bouton rouge dans la fenêtre **Spark Submission** (Envoi Spark).</span><span class="sxs-lookup"><span data-stu-id="50e0e-178">You can stop the application by clicking the red button in the **Spark Submission** window.</span></span> <span data-ttu-id="50e0e-179">Vous pouvez également afficher les journaux pour cette exécution d’application spécifique en cliquant sur l’icône en forme de globe (indiquée par la zone bleue dans l’image).</span><span class="sxs-lookup"><span data-stu-id="50e0e-179">You can also view the logs for this specific application run by clicking the globe icon (denoted by the blue box in the image).</span></span>
      
       ![Fenêtre Spark Submission (Envoi Spark)](./media/hdinsight-apache-spark-eclipse-tool-plugin/create-scala-proj-4.png)

## <a name="access-and-manage-hdinsight-spark-clusters-by-using-hdinsight-tools-in-azure-toolkit-for-eclipse"></a><span data-ttu-id="50e0e-181">Accéder aux clusters HDInsight Spark et les gérer à l’aide de HDInsight Tools dans le kit de ressources Azure pour Eclipse</span><span class="sxs-lookup"><span data-stu-id="50e0e-181">Access and manage HDInsight Spark clusters by using HDInsight Tools in Azure Toolkit for Eclipse</span></span>
<span data-ttu-id="50e0e-182">Vous pouvez effectuer diverses opérations à l’aide de HDInsight Tools, y compris en accédant à la sortie du travail.</span><span class="sxs-lookup"><span data-stu-id="50e0e-182">You can perform various operations by using HDInsight Tools, including accessing the job output.</span></span>

### <a name="access-the-job-view"></a><span data-ttu-id="50e0e-183">Accéder à la vue des travaux</span><span class="sxs-lookup"><span data-stu-id="50e0e-183">Access the job view</span></span>
1. <span data-ttu-id="50e0e-184">Dans Azure Explorer, développez **HDInsight**, développez le nom du cluster Spark, puis cliquez sur **Travaux**.</span><span class="sxs-lookup"><span data-stu-id="50e0e-184">In Azure Explorer, expand **HDInsight**, expand the Spark cluster name, and then click **Jobs**.</span></span> 

    ![Nœud Vue de la tâche](./media/hdinsight-apache-spark-intellij-tool-plugin/job-view-node.png)

2. <span data-ttu-id="50e0e-186">Cliquez sur le **travaux** nœud.</span><span class="sxs-lookup"><span data-stu-id="50e0e-186">Click on the **Jobs** node.</span></span> <span data-ttu-id="50e0e-187">Les outils HDInsight détecte automatiquement si vous avez installé le plug-in de clipse E (fx) ou non.</span><span class="sxs-lookup"><span data-stu-id="50e0e-187">The HDInsight Tools auto-detects whether you installed the E(fx)clipse plugin or not.</span></span> <span data-ttu-id="50e0e-188">Cliquez sur **OK** pour continuer, suivez les instructions pour installer le Marketplace Eclipse et redémarrer Eclipse.</span><span class="sxs-lookup"><span data-stu-id="50e0e-188">Click **OK** to continue and follow the instructions to install the Eclipse Marketplace and restart Eclipse.</span></span>

    ![Installer E(fx)clipse](./media/hdinsight-apache-spark-eclipse-tool-plugin/auto-install-efxclipse.png)

3. <span data-ttu-id="50e0e-190">Ouvrez la vue des travaux à partir du nœud **Tâches**.</span><span class="sxs-lookup"><span data-stu-id="50e0e-190">Open the Job View from the **Jobs** node.</span></span> <span data-ttu-id="50e0e-191">Dans le volet droit, l’onglet **Spark Job View** (Affichage des travaux Spark) affiche toutes les applications qui ont été exécutées sur le cluster.</span><span class="sxs-lookup"><span data-stu-id="50e0e-191">In the right pane, the **Spark Job View** tab displays all the applications that were run on the cluster.</span></span> <span data-ttu-id="50e0e-192">Cliquez sur le nom de l’application pour laquelle vous souhaitez afficher plus de détails.</span><span class="sxs-lookup"><span data-stu-id="50e0e-192">Click the name of the application for which you want to see more details.</span></span>

    ![Détails de l’application](./media/hdinsight-apache-spark-intellij-tool-plugin/view-job-logs.png)
4. <span data-ttu-id="50e0e-194">Si vous pointez sur le graphique de travail, il affiche base informations du travail en cours d’exécution.</span><span class="sxs-lookup"><span data-stu-id="50e0e-194">If you hover on the job graph, it displays basic running job info.</span></span> <span data-ttu-id="50e0e-195">En cliquant sur le graphique de la tâche affiche le graphique des étapes et les informations générés par chaque tâche.</span><span class="sxs-lookup"><span data-stu-id="50e0e-195">Clicking on the job graph shows the stages graph and info that every job generates.</span></span>

    ![Détails des étapes du travail](./media/hdinsight-apache-spark-intellij-tool-plugin/Job-graph-stage-info.png)

5. <span data-ttu-id="50e0e-197">Les journaux fréquemment utilisées, notamment les pilotes Stderr, Stdout de pilote et des informations de répertoire, sont répertoriées dans le **journal** onglet.</span><span class="sxs-lookup"><span data-stu-id="50e0e-197">Frequently used logs, including Driver Stderr, Driver Stdout, and Directory Info, are listed in the **Log** tab.</span></span>

    ![Détails des journaux](./media/hdinsight-apache-spark-intellij-tool-plugin/Job-log-info.png)
6. <span data-ttu-id="50e0e-199">Vous pouvez également ouvrir l’interface utilisateur de l’historique Spark et l’interface utilisateur YARN (au niveau de l’application) en cliquant sur les liens hypertexte correspondants en haut de la fenêtre.</span><span class="sxs-lookup"><span data-stu-id="50e0e-199">You can also open the Spark history UI and the YARN UI (at the application level) by clicking the respective hyperlink at the top of the window.</span></span>

### <a name="access-the-storage-container-for-the-cluster"></a><span data-ttu-id="50e0e-200">Accéder au conteneur de stockage du cluster</span><span class="sxs-lookup"><span data-stu-id="50e0e-200">Access the storage container for the cluster</span></span>
1. <span data-ttu-id="50e0e-201">Dans l’Explorateur Azure, développez le nœud racine **HDInsight** pour afficher la liste des clusters HDInsight Spark disponibles.</span><span class="sxs-lookup"><span data-stu-id="50e0e-201">In Azure Explorer, expand the **HDInsight** root node to see a list of HDInsight Spark clusters that are available.</span></span>
2. <span data-ttu-id="50e0e-202">Développez le nom de cluster pour voir le compte de stockage et le conteneur de stockage par défaut du cluster.</span><span class="sxs-lookup"><span data-stu-id="50e0e-202">Expand the cluster name to see the storage account and the default storage container for the cluster.</span></span>
   
    ![Compte de stockage et conteneur de stockage par défaut](./media/hdinsight-apache-spark-eclipse-tool-plugin/view-explorer-5.png)
3. <span data-ttu-id="50e0e-204">Cliquez sur le nom du conteneur de stockage associé au cluster.</span><span class="sxs-lookup"><span data-stu-id="50e0e-204">Click the storage container name associated with the cluster.</span></span> <span data-ttu-id="50e0e-205">Dans le volet droit, double-cliquez sur le dossier **HVACOut**.</span><span class="sxs-lookup"><span data-stu-id="50e0e-205">In the right pane, double-click the **HVACOut** folder.</span></span> <span data-ttu-id="50e0e-206">Ouvrez l’un des fichiers **part-** pour afficher la sortie de l’application.</span><span class="sxs-lookup"><span data-stu-id="50e0e-206">Open one of the **part-** files to see the output of the application.</span></span>

### <a name="access-the-spark-history-server"></a><span data-ttu-id="50e0e-207">Accéder au serveur d’historique Spark</span><span class="sxs-lookup"><span data-stu-id="50e0e-207">Access the Spark history server</span></span>
1. <span data-ttu-id="50e0e-208">Dans l’Explorateur Azure, cliquez avec le bouton droit sur le nom de votre cluster Spark, puis sélectionnez **Open Spark History UI** (Ouvrir l’interface utilisateur de l’historique Spark).</span><span class="sxs-lookup"><span data-stu-id="50e0e-208">In Azure Explorer, right-click your Spark cluster name, and then select **Open Spark History UI**.</span></span> <span data-ttu-id="50e0e-209">Lorsque vous y êtes invité, entrez les informations d’identification d’administrateur pour le cluster.</span><span class="sxs-lookup"><span data-stu-id="50e0e-209">When you're prompted, enter the admin credentials for the cluster.</span></span> <span data-ttu-id="50e0e-210">Vous devez les avoir spécifiées au moment de l’approvisionnement du cluster.</span><span class="sxs-lookup"><span data-stu-id="50e0e-210">You must have specified these while provisioning the cluster.</span></span>
2. <span data-ttu-id="50e0e-211">Dans le tableau de bord du serveur d’historique Spark, utilisez le nom de l’application pour rechercher l’application que vous venez d’exécuter.</span><span class="sxs-lookup"><span data-stu-id="50e0e-211">In the Spark history server dashboard, you use the application name to look for the application that you just finished running.</span></span> <span data-ttu-id="50e0e-212">Dans le code précédent, vous définissez le nom de l’application en utilisant `val conf = new SparkConf().setAppName("MyClusterApp")`.</span><span class="sxs-lookup"><span data-stu-id="50e0e-212">In the preceding code, you set the application name by using `val conf = new SparkConf().setAppName("MyClusterApp")`.</span></span> <span data-ttu-id="50e0e-213">Le nom de votre application Spark était donc **MyClusterApp**.</span><span class="sxs-lookup"><span data-stu-id="50e0e-213">Hence, your Spark application name was **MyClusterApp**.</span></span>

### <a name="start-the-ambari-portal"></a><span data-ttu-id="50e0e-214">Démarrer le portail Ambari</span><span class="sxs-lookup"><span data-stu-id="50e0e-214">Start the Ambari portal</span></span>
1. <span data-ttu-id="50e0e-215">Dans l’Explorateur Azure, cliquez avec le bouton droit sur le nom de votre cluster Spark, puis sélectionnez **Open Cluster Management Portal (Ambari)** (Ouvrir le portail de gestion des clusters [Ambari]).</span><span class="sxs-lookup"><span data-stu-id="50e0e-215">In Azure Explorer, right-click your Spark cluster name, and then select **Open Cluster Management Portal (Ambari)**.</span></span> 
2. <span data-ttu-id="50e0e-216">Lorsque vous y êtes invité, entrez les informations d’identification d’administrateur pour le cluster.</span><span class="sxs-lookup"><span data-stu-id="50e0e-216">When you're prompted, enter the admin credentials for the cluster.</span></span> <span data-ttu-id="50e0e-217">Vous devez les avoir spécifiées au moment de l’approvisionnement du cluster.</span><span class="sxs-lookup"><span data-stu-id="50e0e-217">You must have specified these while provisioning the cluster.</span></span>

### <a name="manage-azure-subscriptions"></a><span data-ttu-id="50e0e-218">Gérer les abonnements Azure</span><span class="sxs-lookup"><span data-stu-id="50e0e-218">Manage Azure subscriptions</span></span>
<span data-ttu-id="50e0e-219">Par défaut, HDInsight Tools du kit de ressources Azure pour Eclipse répertorie les clusters Spark de tous vos abonnements Azure.</span><span class="sxs-lookup"><span data-stu-id="50e0e-219">By default, HDInsight Tools in Azure Toolkit for Eclipse lists the Spark clusters from all your Azure subscriptions.</span></span> <span data-ttu-id="50e0e-220">Si nécessaire, vous pouvez spécifier les abonnements pour lesquels vous souhaitez accéder au cluster.</span><span class="sxs-lookup"><span data-stu-id="50e0e-220">If necessary, you can specify the subscriptions for which you want to access the cluster.</span></span> 

1. <span data-ttu-id="50e0e-221">Dans l’Explorateur Azure, cliquez avec le bouton droit sur le nœud racine **Azure**, puis cliquez sur **Gérer les abonnements**.</span><span class="sxs-lookup"><span data-stu-id="50e0e-221">In Azure Explorer, right-click the **Azure** root node, and then click **Manage Subscriptions**.</span></span> 
2. <span data-ttu-id="50e0e-222">Dans la boîte de dialogue, décochez les cases concernant l’abonnement auquel vous ne souhaitez pas accéder, puis cliquez sur **Fermer**.</span><span class="sxs-lookup"><span data-stu-id="50e0e-222">In the dialog box, clear the check boxes for the subscription that you don't want to access, and then click **Close**.</span></span> <span data-ttu-id="50e0e-223">Vous pouvez également cliquer sur **Se déconnecter** si vous souhaitez vous déconnecter de votre abonnement Azure.</span><span class="sxs-lookup"><span data-stu-id="50e0e-223">You can also click **Sign Out** if you want to sign out of your Azure subscription.</span></span>

## <a name="run-a-spark-scala-application-locally"></a><span data-ttu-id="50e0e-224">Exécuter une application Spark Scala localement</span><span class="sxs-lookup"><span data-stu-id="50e0e-224">Run a Spark Scala application locally</span></span>
<span data-ttu-id="50e0e-225">Vous pouvez utiliser HDInsight Tools du kit de ressources Azure pour Eclipse pour exécuter des applications Spark Scala localement sur votre poste de travail.</span><span class="sxs-lookup"><span data-stu-id="50e0e-225">You can use HDInsight Tools in Azure Toolkit for Eclipse to run Spark Scala applications locally on your workstation.</span></span> <span data-ttu-id="50e0e-226">En règle générale, ces applications n’ont pas besoin d’accéder aux ressources de cluster telles que le conteneur de stockage, et elles peuvent être exécutées et testées localement.</span><span class="sxs-lookup"><span data-stu-id="50e0e-226">Typically, these applications don't need access to cluster resources such as a storage container, and you can run and test them locally.</span></span>

### <a name="prerequisite"></a><span data-ttu-id="50e0e-227">Configuration requise</span><span class="sxs-lookup"><span data-stu-id="50e0e-227">Prerequisite</span></span>
<span data-ttu-id="50e0e-228">Quand vous exécutez l’application Spark Scala locale sur un ordinateur Windows, vous pouvez obtenir une exception, comme l’explique le document [SPARK-2356](https://issues.apache.org/jira/browse/SPARK-2356).</span><span class="sxs-lookup"><span data-stu-id="50e0e-228">While you're running the local Spark Scala application on a Windows computer, you might get an exception as explained in [SPARK-2356](https://issues.apache.org/jira/browse/SPARK-2356).</span></span> <span data-ttu-id="50e0e-229">Cette exception est liée à l’absence du fichier **WinUtils.exe** dans Windows.</span><span class="sxs-lookup"><span data-stu-id="50e0e-229">This exception occurs because **WinUtils.exe** is missing in Windows.</span></span> 

<span data-ttu-id="50e0e-230">Pour résoudre cette erreur, vous devez [télécharger le fichier exécutable](http://public-repo-1.hortonworks.com/hdp-win-alpha/winutils.exe) vers un emplacement tel que **C:\WinUtils\bin**.</span><span class="sxs-lookup"><span data-stu-id="50e0e-230">To resolve this error, you must [download the executable](http://public-repo-1.hortonworks.com/hdp-win-alpha/winutils.exe) to a location like **C:\WinUtils\bin**.</span></span> <span data-ttu-id="50e0e-231">Vous devez ensuite ajouter la variable d’environnement **HADOOP_HOME** et définir la valeur de la variable sur **C\WinUtils**.</span><span class="sxs-lookup"><span data-stu-id="50e0e-231">You must then add the environment variable **HADOOP_HOME** and set the value of the variable to **C\WinUtils**.</span></span>

### <a name="run-a-local-spark-scala-application"></a><span data-ttu-id="50e0e-232">Exécuter une application Spark Scala locale</span><span class="sxs-lookup"><span data-stu-id="50e0e-232">Run a local Spark Scala application</span></span>
1. <span data-ttu-id="50e0e-233">Démarrez Eclipse et créez un projet.</span><span class="sxs-lookup"><span data-stu-id="50e0e-233">Start Eclipse and create a project.</span></span> <span data-ttu-id="50e0e-234">Dans la boîte de dialogue **New Project** (Nouveau projet), choisissez les options suivantes, puis cliquez sur **Next** (Suivant).</span><span class="sxs-lookup"><span data-stu-id="50e0e-234">In the **New Project** dialog box, make the following choices, and then click **Next**.</span></span>
   
   * <span data-ttu-id="50e0e-235">Dans le volet gauche, sélectionnez **HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="50e0e-235">In the left pane, select **HDInsight**.</span></span>
   * <span data-ttu-id="50e0e-236">Dans le volet droit, sélectionnez **Spark on HDInsight Local Run Sample (Scala)**(Exemple d’exécution locale de Spark sur HDInsight [Scala]).</span><span class="sxs-lookup"><span data-stu-id="50e0e-236">In the right pane, select **Spark on HDInsight Local Run Sample (Scala)**.</span></span>

    ![Boîte de dialogue Nouveau projet](./media/hdinsight-apache-spark-eclipse-tool-plugin/hdi-spark-app-local-run.png)
2. <span data-ttu-id="50e0e-238">Pour fournir les détails du projet, suivez les étapes 3 à 6 indiquées dans la section précédente [Configuration d’un projet Spark Scala pour un cluster HDInsight Spark](#set-up-a-spark-scala-project-for-an-hdinsight-spark cluster).</span><span class="sxs-lookup"><span data-stu-id="50e0e-238">To provide the project details, follow steps 3 through 6 from the earlier section [Set up a Spark Scala project for an HDInsight Spark cluster](#set-up-a-spark-scala-project-for-an-hdinsight-spark cluster).</span></span>
3. <span data-ttu-id="50e0e-239">Le modèle ajoute un exemple de code (**LogQuery**) sous le dossier **src** que vous pouvez exécuter localement sur votre ordinateur.</span><span class="sxs-lookup"><span data-stu-id="50e0e-239">The template adds a sample code (**LogQuery**) under the **src** folder that you can run locally on your computer.</span></span>
   
    ![Emplacement de LogQuery](./media/hdinsight-apache-spark-eclipse-tool-plugin/local-app.png)
4. <span data-ttu-id="50e0e-241">Cliquez avec le bouton droit sur l’application **LogQuery**, pointez sur **Run As** (Exécuter en tant que), puis cliquez sur **1 Scala Application**.</span><span class="sxs-lookup"><span data-stu-id="50e0e-241">Right-click the **LogQuery** application, point to **Run As**, and then click **1 Scala Application**.</span></span> <span data-ttu-id="50e0e-242">Une sortie semblable à celle-ci doit apparaître dans l’onglet **Console** en bas de l’écran :</span><span class="sxs-lookup"><span data-stu-id="50e0e-242">You will see an output like this in the **Console** tab at the bottom:</span></span>
   
   ![Résultat de l’exécution locale de l’application Spark](./media/hdinsight-apache-spark-eclipse-tool-plugin/hdi-spark-app-local-run-result.png)

## <a name="faq"></a><span data-ttu-id="50e0e-244">Forum Aux Questions</span><span class="sxs-lookup"><span data-stu-id="50e0e-244">FAQ</span></span>
<span data-ttu-id="50e0e-245">Pour soumettre une application à Azure Data Lake Store, choisissez le mode **interactif** pendant le processus de connexion à Azure.</span><span class="sxs-lookup"><span data-stu-id="50e0e-245">To submit an application to Azure Data Lake Store, choose **Interactive** mode during the Azure sign-in process.</span></span> <span data-ttu-id="50e0e-246">Si vous sélectionnez le mode **automatique**, vous pouvez obtenir une erreur.</span><span class="sxs-lookup"><span data-stu-id="50e0e-246">If you select **Automated** mode, you can get an error.</span></span>

![Connexion interactive](./media/hdinsight-apache-spark-eclipse-tool-plugin/interactive-authentication.png)

<span data-ttu-id="50e0e-248">À présent, nous l’avons résolue.</span><span class="sxs-lookup"><span data-stu-id="50e0e-248">Now, we resolved it.</span></span> <span data-ttu-id="50e0e-249">Vous pouvez choisir un cluster Azure Data Lake pour soumettre votre application avec n’importe quelle méthode de connexion.</span><span class="sxs-lookup"><span data-stu-id="50e0e-249">You can choose an Azure Data Lake Cluster to submit your application with any sign-in method.</span></span>

## <a name="feedback-and-known-issues"></a><span data-ttu-id="50e0e-250">Commentaires et problèmes connus</span><span class="sxs-lookup"><span data-stu-id="50e0e-250">Feedback and known issues</span></span>
<span data-ttu-id="50e0e-251">Pour l’instant, la visualisation directe des sorties Spark n’est pas prise en charge.</span><span class="sxs-lookup"><span data-stu-id="50e0e-251">Currently, viewing Spark outputs directly is not supported.</span></span>

<span data-ttu-id="50e0e-252">Si vous avez des suggestions ou des commentaires, ou que vous rencontrez des problèmes lors de l’utilisation de cet outil, n’hésitez pas à nous envoyer un e-mail à l’adresse hdivstool@microsoft.com.</span><span class="sxs-lookup"><span data-stu-id="50e0e-252">If you have any suggestions or feedback, or if you encounter any problems when using this tool, feel free to send us an email at hdivstool@microsoft.com.</span></span>

## <span data-ttu-id="50e0e-253"><a name="seealso"></a>Voir aussi</span><span class="sxs-lookup"><span data-stu-id="50e0e-253"><a name="seealso"></a>See also</span></span>
* [<span data-ttu-id="50e0e-254">Vue d’ensemble : Apache Spark sur Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="50e0e-254">Overview: Apache Spark on Azure HDInsight</span></span>](hdinsight-apache-spark-overview.md)

### <a name="scenarios"></a><span data-ttu-id="50e0e-255">Scénarios</span><span class="sxs-lookup"><span data-stu-id="50e0e-255">Scenarios</span></span>
* [<span data-ttu-id="50e0e-256">Spark avec BI : effectuez une analyse interactive des données à l’aide de Spark dans HDInsight avec des outils BI</span><span class="sxs-lookup"><span data-stu-id="50e0e-256">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="50e0e-257">Spark avec Machine Learning : Utiliser Spark dans HDInsight pour l’analyse de la température de bâtiments à l’aide de données HVAC</span><span class="sxs-lookup"><span data-stu-id="50e0e-257">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="50e0e-258">Spark avec Machine Learning : Utiliser Spark dans HDInsight pour prédire les résultats de l’inspection des aliments</span><span class="sxs-lookup"><span data-stu-id="50e0e-258">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="50e0e-259">Streaming Spark : Utiliser Spark dans HDInsight pour créer des applications de diffusion en continu en temps réel</span><span class="sxs-lookup"><span data-stu-id="50e0e-259">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="50e0e-260">Analyse des journaux de site web à l’aide de Spark dans HDInsight</span><span class="sxs-lookup"><span data-stu-id="50e0e-260">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="creating-and-running-applications"></a><span data-ttu-id="50e0e-261">Création et exécution d’applications</span><span class="sxs-lookup"><span data-stu-id="50e0e-261">Creating and running applications</span></span>
* [<span data-ttu-id="50e0e-262">Créer une application autonome avec Scala</span><span class="sxs-lookup"><span data-stu-id="50e0e-262">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="50e0e-263">Exécuter des tâches à distance avec Livy sur un cluster Spark</span><span class="sxs-lookup"><span data-stu-id="50e0e-263">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="50e0e-264">Outils et extensions</span><span class="sxs-lookup"><span data-stu-id="50e0e-264">Tools and extensions</span></span>
* [<span data-ttu-id="50e0e-265">Utiliser le kit de ressources Azure pour IntelliJ pour créer et soumettre des applications Spark Scala</span><span class="sxs-lookup"><span data-stu-id="50e0e-265">Use Azure Toolkit for IntelliJ to create and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="50e0e-266">Utiliser le kit de ressources Azure pour IntelliJ pour déboguer des applications Spark à distance via VPN</span><span class="sxs-lookup"><span data-stu-id="50e0e-266">Use Azure Toolkit for IntelliJ to debug Spark applications remotely through VPN</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="50e0e-267">Utiliser le kit de ressources Azure pour IntelliJ pour déboguer des applications Spark à distance via SSH</span><span class="sxs-lookup"><span data-stu-id="50e0e-267">Use Azure Toolkit for IntelliJ to debug Spark applications remotely through SSH</span></span>](hdinsight-apache-spark-intellij-tool-debug-remotely-through-ssh.md)
* [<span data-ttu-id="50e0e-268">Utiliser HDInsight Tools pour IntelliJ avec Hortonworks Sandbox</span><span class="sxs-lookup"><span data-stu-id="50e0e-268">Use HDInsight Tools for IntelliJ with Hortonworks Sandbox</span></span>](hdinsight-tools-for-intellij-with-hortonworks-sandbox.md)
* [<span data-ttu-id="50e0e-269">Utiliser des bloc-notes Zeppelin avec un cluster Spark sur HDInsight</span><span class="sxs-lookup"><span data-stu-id="50e0e-269">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="50e0e-270">Noyaux disponibles pour le bloc-notes Jupyter dans un cluster Spark pour HDInsight</span><span class="sxs-lookup"><span data-stu-id="50e0e-270">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="50e0e-271">Utiliser des packages externes avec les blocs-notes Jupyter</span><span class="sxs-lookup"><span data-stu-id="50e0e-271">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="50e0e-272">Installer Jupyter sur un ordinateur et se connecter au cluster Spark sur HDInsight</span><span class="sxs-lookup"><span data-stu-id="50e0e-272">Install Jupyter on your computer and connect to an HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="managing-resources"></a><span data-ttu-id="50e0e-273">Gestion des ressources</span><span class="sxs-lookup"><span data-stu-id="50e0e-273">Managing resources</span></span>
* [<span data-ttu-id="50e0e-274">Gérer les ressources du cluster Apache Spark dans Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="50e0e-274">Manage resources for the Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="50e0e-275">Suivi et débogage des tâches en cours d’exécution sur un cluster Apache Spark dans HDInsight</span><span class="sxs-lookup"><span data-stu-id="50e0e-275">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

