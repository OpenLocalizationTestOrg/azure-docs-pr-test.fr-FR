---
title: "Présentation de Data Factory, un service d’intégration de données | Microsoft Docs"
description: "Découvrez Azure Data Factory : un service d’intégration de données cloud qui gère et automatise le déplacement et la transformation des données."
keywords: "intégration de données, intégration de données cloud, description d’azure data factory"
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: cec68cb5-ca0d-473b-8ae8-35de949a009e
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 08/14/2017
ms.author: shlo
ms.openlocfilehash: bc72c4d58b98f6521dbb7420a5d05a121b0ddbda
ms.sourcegitcommit: 50e23e8d3b1148ae2d36dad3167936b4e52c8a23
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 08/18/2017
---
# <a name="introduction-to-azure-data-factory"></a><span data-ttu-id="41b4f-104">Présentation d'Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="41b4f-104">Introduction to Azure Data Factory</span></span> 
## <a name="what-is-azure-data-factory"></a><span data-ttu-id="41b4f-105">qu'est-ce qu'Azure Data Factory ?</span><span class="sxs-lookup"><span data-stu-id="41b4f-105">What is Azure Data Factory?</span></span>
<span data-ttu-id="41b4f-106">Dans le monde du Big Data, comment les entreprises exploitent-elles les données existantes ?</span><span class="sxs-lookup"><span data-stu-id="41b4f-106">In the world of big data, how is existing data leveraged in business?</span></span> <span data-ttu-id="41b4f-107">Est-il possible d’enrichir les données générées dans le cloud en utilisant des données de référence provenant de sources locales ou d’autres sources disparates ?</span><span class="sxs-lookup"><span data-stu-id="41b4f-107">Is it possible to enrich data generated in the cloud by using reference data from on-premises data sources or other disparate data sources?</span></span> <span data-ttu-id="41b4f-108">Par exemple, une entreprise qui produit des jeux collecte de nombreux journaux générés par les jeux dans le cloud.</span><span class="sxs-lookup"><span data-stu-id="41b4f-108">For example, a gaming company collects many logs produced by games in the cloud.</span></span> <span data-ttu-id="41b4f-109">Elle souhaite analyser ces journaux afin d’obtenir un aperçu des préférences des clients, des données démographiques, etc. pour identifier les opportunités de vente incitative et de vente croisée, développer des nouvelles fonctionnalités afin d’optimiser la croissance et fournir une meilleure expérience aux clients.</span><span class="sxs-lookup"><span data-stu-id="41b4f-109">It wants to analyze these logs to gain insights in to customer preferences, demographics, usage behavior etc. to identify up-sell and cross-sell opportunities, develop new compelling features to drive business growth, and provide a better experience to customers.</span></span> 

<span data-ttu-id="41b4f-110">Pour analyser ces journaux, l’entreprise doit utiliser des données de référence comme des informations sur le client, des informations sur les jeux, des informations sur la campagne marketing qui sont contenues dans un magasin de données local.</span><span class="sxs-lookup"><span data-stu-id="41b4f-110">To analyze these logs, the company needs to use the reference data such as customer information, game information, marketing campaign information that is in an on-premises data store.</span></span> <span data-ttu-id="41b4f-111">L’entreprise souhaite donc ingérer des données de journal du magasin de données cloud et des données de référence du magasin de données local.</span><span class="sxs-lookup"><span data-stu-id="41b4f-111">Therefore, the company wants to ingest log data from the cloud data store and reference data from the on-premises data store.</span></span> <span data-ttu-id="41b4f-112">Elle souhaite ensuite traite les données à l’aide de Hadoop dans le cloud (Azure HDInsight) et publier les données de résultat dans un entrepôt de données cloud comme Azure SQL Data Warehouse ou un magasin de données local tel que SQL Server.</span><span class="sxs-lookup"><span data-stu-id="41b4f-112">Then, process the data by using Hadoop in the cloud (Azure HDInsight) and publish the result data into a cloud data warehouse such as Azure SQL Data Warehouse or an on-premises data store such as SQL Server.</span></span> <span data-ttu-id="41b4f-113">Elle souhaite que ce flux de travail s’exécute une fois toutes les semaines.</span><span class="sxs-lookup"><span data-stu-id="41b4f-113">It wants this workflow to run weekly once.</span></span> 

<span data-ttu-id="41b4f-114">Elle a besoin d’une plateforme qui permet à l’entreprise de créer un flux de travail capable d’ingérer des données des magasins de données local et cloud, de transformer ou de traiter les données à l’aide de services de calcul existants comme Hadoop, puis de publier les résultats dans un magasin de données local ou cloud pour que des applications BI puissent les utiliser.</span><span class="sxs-lookup"><span data-stu-id="41b4f-114">What is needed is a platform that allows the company to create a workflow that can ingest data from both on-premises and cloud data stores, and transform or process data by using existing compute services such as Hadoop, and publish the results to an on-premises or cloud data store for BI applications to consume.</span></span> 

![Présentation de Data Factory](media/data-factory-introduction/what-is-azure-data-factory.png) 

<span data-ttu-id="41b4f-116">Azure Data Factory est la plateforme pour ce genre de scénarios.</span><span class="sxs-lookup"><span data-stu-id="41b4f-116">Azure Data Factory is the platform for this kind of scenarios.</span></span> <span data-ttu-id="41b4f-117">Il s’agit d’un **service d’intégration de données basé sur le cloud qui vous permet de créer des flux de travail orientés données dans le cloud pour orchestrer et automatiser le déplacement des données et la transformation des données**.</span><span class="sxs-lookup"><span data-stu-id="41b4f-117">It is a **cloud-based data integration service that allows you to create data-driven workflows in the cloud for orchestrating and automating data movement and data transformation**.</span></span> <span data-ttu-id="41b4f-118">Grâce à Azure Data Factory, vous pouvez créer et planifier des flux de travail orientés données (appelés pipelines) capables d’ingérer des données provenant de différents magasins de données, de traiter/transformer les données à l’aide de services de calcul comme Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics et Azure Machine Learning, et de publier des données de sortie dans des magasins de données tels qu’Azure SQL Data Warehouse pour que des applications décisionnelles (BI) puissent les utiliser.</span><span class="sxs-lookup"><span data-stu-id="41b4f-118">Using Azure Data Factory, you can create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores, process/transform the data by using compute services such as Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics, and Azure Machine Learning, and publish output data to data stores such as Azure SQL Data Warehouse for business intelligence (BI) applications to consume.</span></span>  

<span data-ttu-id="41b4f-119">Il s’agit plus d’une plateforme d’extraction et de chargement (EL) puis de transformation et chargement (TL) qu’une plateforme d’extraction, de transformation-et de chargement (ETL) traditionnelle.</span><span class="sxs-lookup"><span data-stu-id="41b4f-119">It's more of an Extract-and-Load (EL) and then Transform-and-Load (TL) platform rather than a traditional Extract-Transform-and-Load (ETL) platform.</span></span> <span data-ttu-id="41b4f-120">Les transformations effectuées visent à transformer/traiter les données à l’aide de services de calcul plutôt que d’effectuer des transformations comme celles permettant d’ajouter des colonnes dérivées, de compter le nombre de lignes, de trier les données, etc.</span><span class="sxs-lookup"><span data-stu-id="41b4f-120">The transformations that are performed are to transform/process data by using compute services rather than to perform transformations like the ones for adding derived columns, counting number of rows, sorting data, etc.</span></span> 

<span data-ttu-id="41b4f-121">Dans Azure Data Factory, les données utilisées et générées par les flux de travail sont actuellement des **données à tranches temporelles** (toutes les heures, tous les jours, toutes les semaines, etc.).</span><span class="sxs-lookup"><span data-stu-id="41b4f-121">Currently, in Azure Data Factory, the data that is consumed and produced by workflows is **time-sliced data** (hourly, daily, weekly, etc.).</span></span> <span data-ttu-id="41b4f-122">Par exemple, un pipeline peut lire des données d’entrée, traiter des données et générer des données de sortie une fois par jour.</span><span class="sxs-lookup"><span data-stu-id="41b4f-122">For example, a pipeline may read input data, process data, and produce output data once a day.</span></span> <span data-ttu-id="41b4f-123">Vous ne pouvez également exécuter un flux de travail qu’une seule fois.</span><span class="sxs-lookup"><span data-stu-id="41b4f-123">You can also run a workflow just one time.</span></span>  
  

## <a name="how-does-it-work"></a><span data-ttu-id="41b4f-124">Comment cela fonctionne-t-il ?</span><span class="sxs-lookup"><span data-stu-id="41b4f-124">How does it work?</span></span> 
<span data-ttu-id="41b4f-125">Les pipelines (flux de travail orientés données) dans Azure Data Factory effectuent généralement les trois étapes suivantes :</span><span class="sxs-lookup"><span data-stu-id="41b4f-125">The pipelines (data-driven workflows) in Azure Data Factory typically perform the following three steps:</span></span>

![Trois étapes d’Azure Data Factory](media/data-factory-introduction/three-information-production-stages.png)

### <a name="connect-and-collect"></a><span data-ttu-id="41b4f-127">Se connecter et collecter</span><span class="sxs-lookup"><span data-stu-id="41b4f-127">Connect and collect</span></span>
<span data-ttu-id="41b4f-128">Les entreprises disposent de données de divers types situées dans des sources diverses.</span><span class="sxs-lookup"><span data-stu-id="41b4f-128">Enterprises have data of various types located in disparate sources.</span></span> <span data-ttu-id="41b4f-129">Quand vous mettez en place un système de production d’informations, la première étape consiste à vous connecter à toutes les sources nécessaires de données et à leur traitement (par exemple, les services SaaS, web, FTP et de partage de fichiers), puis à déplacer les données vers un emplacement centralisé en vue de leur traitement, en fonction des besoins.</span><span class="sxs-lookup"><span data-stu-id="41b4f-129">The first step in building an information production system is to connect to all the required sources of data and processing, such as SaaS services, file shares, FTP, web services, and move the data as-needed to a centralized location for subsequent processing.</span></span>

<span data-ttu-id="41b4f-130">Sans Data Factory, les entreprises doivent concevoir des composants personnalisés chargés du déplacement des données ou écrire des services personnalisés pour intégrer ces sources de données et leur traitement.</span><span class="sxs-lookup"><span data-stu-id="41b4f-130">Without Data Factory, enterprises must build custom data movement components or write custom services to integrate these data sources and processing.</span></span> <span data-ttu-id="41b4f-131">De tels systèmes sont onéreux et leur intégration et maintenance tout particulièrement difficiles. Souvent, ils ne sont pas équipés des dispositifs de surveillance et d’alerte habituellement indispensables aux entreprises, ni même des commandes qu’un service entièrement géré peut offrir.</span><span class="sxs-lookup"><span data-stu-id="41b4f-131">It is expensive and hard to integrate and maintain such systems, and it often lacks the enterprise grade monitoring and alerting, and the controls that a fully managed service can offer.</span></span>

<span data-ttu-id="41b4f-132">Avec Data Factory, vous pouvez utiliser la fonction de copie dans un pipeline de données. L’intérêt ? Déplacer les données des magasins de données locaux et dans le cloud dans un magasin de données centralisé dans le cloud, pour les besoins d’analyse ultérieurs.</span><span class="sxs-lookup"><span data-stu-id="41b4f-132">With Data Factory, you can use the Copy Activity in a data pipeline to move data from both on-premises and cloud source data stores to a centralization data store in the cloud for further analysis.</span></span> <span data-ttu-id="41b4f-133">Par exemple, vous pouvez collecter des données d’un Azure Data Lake Store, puis les transformer à l’aide d’un service de calcul Azure Data Lake Analytics.</span><span class="sxs-lookup"><span data-stu-id="41b4f-133">For example, you can collect data in an Azure Data Lake Store and transform the data later by using an Azure Data Lake Analytics compute service.</span></span> <span data-ttu-id="41b4f-134">Vous pouvez aussi collecter des données dans un stockage Blob Azure, puis les transformer à l’aide d’un cluster Azure HDInsight Hadoop.</span><span class="sxs-lookup"><span data-stu-id="41b4f-134">Or, collect data in an Azure Blob Storage and transform data later by using an Azure HDInsight Hadoop cluster.</span></span>

### <a name="transform-and-enrich"></a><span data-ttu-id="41b4f-135">Transformer et enrichir</span><span class="sxs-lookup"><span data-stu-id="41b4f-135">Transform and enrich</span></span>
<span data-ttu-id="41b4f-136">Une fois que les données sont présentes dans un magasin de données centralisé dans le cloud, vous souhaitez que les données collectées soient traitées ou transformées à l’aide de services de calcul tels que HDInsight Hadoop, Spark, Data Lake Analytics et Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="41b4f-136">Once data is present in a centralized data store in the cloud, you want the collected data to be processed or transformed by using compute services such as HDInsight Hadoop, Spark, Data Lake Analytics, and Machine Learning.</span></span> <span data-ttu-id="41b4f-137">Vous souhaitez générer de manière fiable des données transformées selon une planification facile à gérer et contrôlée afin de fournir aux environnements de production des données approuvées.</span><span class="sxs-lookup"><span data-stu-id="41b4f-137">You want to reliably produce transformed data on a maintainable and controlled schedule to feed production environments with trusted data.</span></span> 

### <a name="publish"></a><span data-ttu-id="41b4f-138">Publier</span><span class="sxs-lookup"><span data-stu-id="41b4f-138">Publish</span></span> 
<span data-ttu-id="41b4f-139">Fournissez les données transformées issues du cloud aux sources locales, telles que SQL Server, ou conservez-les dans vos sources de stockage sur le cloud à des fins de consommation par les outils décisionnels et d’analyse, et d’autres applications.</span><span class="sxs-lookup"><span data-stu-id="41b4f-139">Deliver transformed data from the cloud to on-premises sources like SQL Server, or keep it in your cloud storage sources for consumption by business intelligence (BI) and analytics tools and other applications.</span></span>

## <a name="key-components"></a><span data-ttu-id="41b4f-140">Composants clés</span><span class="sxs-lookup"><span data-stu-id="41b4f-140">Key components</span></span>
<span data-ttu-id="41b4f-141">Un abonnement Azure peut contenir une ou plusieurs instances Azure Data Factory (ou fabriques de données).</span><span class="sxs-lookup"><span data-stu-id="41b4f-141">An Azure subscription may have one or more Azure Data Factory instances (or data factories).</span></span> <span data-ttu-id="41b4f-142">Azure Data Factory s’articule autour de quatre composants clés. Ils fonctionnent ensemble et vous dotent de la plateforme sur laquelle composer des flux de travail orientés données constitués d’étapes de déplacement et de transformation des données.</span><span class="sxs-lookup"><span data-stu-id="41b4f-142">Azure Data Factory is composed of four key components that work together to provide the platform on which you can compose data-driven workflows with steps to move and transform data.</span></span> 

### <a name="pipeline"></a><span data-ttu-id="41b4f-143">Pipeline</span><span class="sxs-lookup"><span data-stu-id="41b4f-143">Pipeline</span></span>
<span data-ttu-id="41b4f-144">Une fabrique de données peut avoir un ou plusieurs pipelines.</span><span class="sxs-lookup"><span data-stu-id="41b4f-144">A data factory may have one or more pipelines.</span></span> <span data-ttu-id="41b4f-145">Un pipeline est un groupe d’activités.</span><span class="sxs-lookup"><span data-stu-id="41b4f-145">A pipeline is a group of activities.</span></span> <span data-ttu-id="41b4f-146">Ensemble, les activités d’un pipeline effectuent une tâche.</span><span class="sxs-lookup"><span data-stu-id="41b4f-146">Together, the activities in a pipeline perform a task.</span></span> <span data-ttu-id="41b4f-147">Par exemple, un pipeline peut contenir un groupe d’activités qui ingère des données à partir d’un objet Blob Azure, puis exécute une requête Hive sur un cluster HDInsight pour partitionner les données.</span><span class="sxs-lookup"><span data-stu-id="41b4f-147">For example, a pipeline could contain a group of activities that ingests data from an Azure blob, and then run a Hive query on an HDInsight cluster to partition the data.</span></span> <span data-ttu-id="41b4f-148">L’avantage de cette opération, c’est que le pipeline vous permet de gérer les activités en tant que groupe et non pas individuellement.</span><span class="sxs-lookup"><span data-stu-id="41b4f-148">The benefit of this is that the pipeline allows you to manage the activities as a set instead of each one individually.</span></span> <span data-ttu-id="41b4f-149">Par exemple, vous pouvez déployer et planifier le pipeline, plutôt que chaque activité séparément.</span><span class="sxs-lookup"><span data-stu-id="41b4f-149">For example, you can deploy and schedule the pipeline, instead of the activities independently.</span></span> 

### <a name="activity"></a><span data-ttu-id="41b4f-150">Activité</span><span class="sxs-lookup"><span data-stu-id="41b4f-150">Activity</span></span>
<span data-ttu-id="41b4f-151">Un pipeline peut contenir une ou plusieurs activités.</span><span class="sxs-lookup"><span data-stu-id="41b4f-151">A pipeline may have one or more activities.</span></span> <span data-ttu-id="41b4f-152">Les activités définissent les actions à effectuer sur les données.</span><span class="sxs-lookup"><span data-stu-id="41b4f-152">Activities define the actions to perform on your data.</span></span> <span data-ttu-id="41b4f-153">Par exemple, vous pouvez utiliser une activité de copie pour copier des données d’une banque de données vers une autre.</span><span class="sxs-lookup"><span data-stu-id="41b4f-153">For example, you may use a Copy activity to copy data from one data store to another data store.</span></span> <span data-ttu-id="41b4f-154">De même, vous pouvez utiliser une activité Hive qui exécute une requête Hive sur un cluster Azure HDInsight afin de convertir ou d’analyser vos données.</span><span class="sxs-lookup"><span data-stu-id="41b4f-154">Similarly, you may use a Hive activity, which runs a Hive query on an Azure HDInsight cluster to transform or analyze your data.</span></span> <span data-ttu-id="41b4f-155">Data Factory prend en charge deux types d’activités : les activités de déplacement des données et les activités de transformation des données.</span><span class="sxs-lookup"><span data-stu-id="41b4f-155">Data Factory supports two types of activities: data movement activities and data transformation activities.</span></span>

### <a name="data-movement-activities"></a><span data-ttu-id="41b4f-156">Activités de déplacement des données</span><span class="sxs-lookup"><span data-stu-id="41b4f-156">Data movement activities</span></span>
<span data-ttu-id="41b4f-157">L’activité de copie dans Data Factory permet de copier les données d’un magasin de données source vers un magasin de données récepteur.</span><span class="sxs-lookup"><span data-stu-id="41b4f-157">Copy Activity in Data Factory copies data from a source data store to a sink data store.</span></span> <span data-ttu-id="41b4f-158">Data Factory prend en charge les magasins de données suivants.</span><span class="sxs-lookup"><span data-stu-id="41b4f-158">Data Factory supports the following data stores.</span></span> <span data-ttu-id="41b4f-159">Les données de n’importe quelle source peuvent être écrites dans n’importe quel récepteur.</span><span class="sxs-lookup"><span data-stu-id="41b4f-159">Data from any source can be written to any sink.</span></span> <span data-ttu-id="41b4f-160">Cliquez sur une banque de données pour découvrir comment copier des données depuis/vers cette banque.</span><span class="sxs-lookup"><span data-stu-id="41b4f-160">Click a data store to learn how to copy data to and from that store.</span></span>

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

<span data-ttu-id="41b4f-161">Pour plus d’informations, consultez l’article [Activités de déplacement des données](data-factory-data-movement-activities.md).</span><span class="sxs-lookup"><span data-stu-id="41b4f-161">For more information, see [Data Movement Activities](data-factory-data-movement-activities.md) article.</span></span>

### <a name="data-transformation-activities"></a><span data-ttu-id="41b4f-162">Activités de transformation des données</span><span class="sxs-lookup"><span data-stu-id="41b4f-162">Data transformation activities</span></span>
[!INCLUDE [data-factory-transformation-activities](../../includes/data-factory-transformation-activities.md)]

<span data-ttu-id="41b4f-163">Pour plus d’informations, consultez l’article [Activités de déplacement des données](data-factory-data-transformation-activities.md).</span><span class="sxs-lookup"><span data-stu-id="41b4f-163">For more information, see [Data Transformation Activities](data-factory-data-transformation-activities.md) article.</span></span>

### <a name="custom-net-activities"></a><span data-ttu-id="41b4f-164">Activités .NET personnalisées</span><span class="sxs-lookup"><span data-stu-id="41b4f-164">Custom .NET activities</span></span>
<span data-ttu-id="41b4f-165">Si vous devez déplacer des données vers ou à partir d’une banque de données qui n’est pas prise en charge par l’activité de copie, ou transformer des données à l’aide de votre propre logique, créez une **activité .NET personnalisée**.</span><span class="sxs-lookup"><span data-stu-id="41b4f-165">If you need to move data to/from a data store that Copy Activity doesn't support, or transform data using your own logic, create a **custom .NET activity**.</span></span> <span data-ttu-id="41b4f-166">Pour plus d’informations sur la création et l’utilisation d’une activité personnalisée, consultez [Utilisation des activités personnalisées dans un pipeline Azure Data Factory](data-factory-use-custom-activities.md).</span><span class="sxs-lookup"><span data-stu-id="41b4f-166">For details on creating and using a custom activity, see [Use custom activities in an Azure Data Factory pipeline](data-factory-use-custom-activities.md).</span></span>

### <a name="datasets"></a><span data-ttu-id="41b4f-167">Groupes de données</span><span class="sxs-lookup"><span data-stu-id="41b4f-167">Datasets</span></span>
<span data-ttu-id="41b4f-168">Une activité accepte ou non des jeux de données en tant qu’entrées et produit un ou plusieurs jeux de données en tant que sorties.</span><span class="sxs-lookup"><span data-stu-id="41b4f-168">An activity takes zero or more datasets as inputs and one or more datasets as outputs.</span></span> <span data-ttu-id="41b4f-169">Les jeux de données représentent les structures des données dans les magasins. Ils pointent ou référencent simplement en tant qu’entrées ou sorties les données que vous voulez utiliser dans vos activités.</span><span class="sxs-lookup"><span data-stu-id="41b4f-169">Datasets represent data structures within the data stores, which simply point or reference the data you want to use in your activities as inputs or outputs.</span></span> <span data-ttu-id="41b4f-170">Par exemple, un jeu de données d’objets Blob Azure spécifie le conteneur et le dossier du stockage Blob Azure à partir duquel le pipeline doit lire les données.</span><span class="sxs-lookup"><span data-stu-id="41b4f-170">For example, an Azure Blob dataset specifies the blob container and folder in the Azure Blob Storage from which the pipeline should read the data.</span></span> <span data-ttu-id="41b4f-171">Ou un jeu de données Azure SQL Table spécifie la table dans laquelle les données de sortie sont écrites par l’activité.</span><span class="sxs-lookup"><span data-stu-id="41b4f-171">Or, an Azure SQL Table dataset specifies the table to which the output data is written by the activity.</span></span> 

### <a name="linked-services"></a><span data-ttu-id="41b4f-172">Services liés</span><span class="sxs-lookup"><span data-stu-id="41b4f-172">Linked services</span></span>
<span data-ttu-id="41b4f-173">Les services liés ressemblent à des chaînes de connexion. Ils définissent les informations de connexion nécessaires à Data Factory pour se connecter à des ressources externes.</span><span class="sxs-lookup"><span data-stu-id="41b4f-173">Linked services are much like connection strings, which define the connection information needed for Data Factory to connect to external resources.</span></span> <span data-ttu-id="41b4f-174">Voyez les choses de la façon suivante : un service lié définit la connexion à la source de données et un jeu de données représente la structure des données.</span><span class="sxs-lookup"><span data-stu-id="41b4f-174">Think of it this way - a linked service defines the connection to the data source and a dataset represents the structure of the data.</span></span> <span data-ttu-id="41b4f-175">Par exemple, un service lié Stockage Azure spécifie la chaîne de connexion pour se connecter au compte de stockage Azure.</span><span class="sxs-lookup"><span data-stu-id="41b4f-175">For example, an Azure Storage linked service specifies connection string to connect to the Azure Storage account.</span></span> <span data-ttu-id="41b4f-176">Et un jeu de données blob Azure spécifie le conteneur d’objets blob et le dossier qui contient les données.</span><span class="sxs-lookup"><span data-stu-id="41b4f-176">And, an Azure Blob dataset specifies the blob container and the folder that contains the data.</span></span>   

<span data-ttu-id="41b4f-177">Data Factory fait appel aux services liés pour deux raisons :</span><span class="sxs-lookup"><span data-stu-id="41b4f-177">Linked services are used for two purposes in Data Factory:</span></span>

* <span data-ttu-id="41b4f-178">Pour représenter une **banque de données** et notamment une instance SQL Server, une base de données Oracle, un partage de fichiers locaux ou un compte de stockage d’objets blob Azure.</span><span class="sxs-lookup"><span data-stu-id="41b4f-178">To represent a **data store** including, but not limited to, an on-premises SQL Server, Oracle database, file share, or an Azure Blob Storage account.</span></span> <span data-ttu-id="41b4f-179">Pour obtenir la liste des banques de données prises en charge, consultez la section [Activités de déplacement des données](#data-movement-activities) .</span><span class="sxs-lookup"><span data-stu-id="41b4f-179">See the [Data movement activities](#data-movement-activities) section for a list of supported data stores.</span></span>
* <span data-ttu-id="41b4f-180">Pour représenter une **ressource de calcul** qui peut héberger l’exécution d’une activité.</span><span class="sxs-lookup"><span data-stu-id="41b4f-180">To represent a **compute resource** that can host the execution of an activity.</span></span> <span data-ttu-id="41b4f-181">Par exemple, l’activité HDInsightHive s’exécute sur un cluster HDInsight Hadoop.</span><span class="sxs-lookup"><span data-stu-id="41b4f-181">For example, the HDInsightHive activity runs on an HDInsight Hadoop cluster.</span></span> <span data-ttu-id="41b4f-182">Pour obtenir la liste des environnements de calcul pris en charge, consultez la section [Activités de transformation des données](#data-transformation-activities).</span><span class="sxs-lookup"><span data-stu-id="41b4f-182">See [Data transformation activities](#data-transformation-activities) section for a list of supported compute environments.</span></span>

### <a name="relationship-between-data-factory-entities"></a><span data-ttu-id="41b4f-183">Relation entre des entités Data Factory</span><span class="sxs-lookup"><span data-stu-id="41b4f-183">Relationship between Data Factory entities</span></span>
<span data-ttu-id="41b4f-184">![Diagramme : Data Factory, un service d’intégration de données cloud - Concepts clés](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figure 2.**</span><span class="sxs-lookup"><span data-stu-id="41b4f-184">![Diagram: Data Factory, a cloud data integration service - Key Concepts](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figure 2.**</span></span> <span data-ttu-id="41b4f-185">Relations entre jeu de données, activité, pipeline et service lié</span><span class="sxs-lookup"><span data-stu-id="41b4f-185">Relationships between Dataset, Activity, Pipeline, and Linked service</span></span>

## <a name="supported-regions"></a><span data-ttu-id="41b4f-186">Régions prises en charge</span><span class="sxs-lookup"><span data-stu-id="41b4f-186">Supported regions</span></span>
<span data-ttu-id="41b4f-187">Actuellement, vous pouvez créer des fabriques de données aux **États-Unis de l’Ouest**, aux **États-Unis de l’Est** et en **Europe du Nord**.</span><span class="sxs-lookup"><span data-stu-id="41b4f-187">Currently, you can create data factories in the **West US**, **East US**, and **North Europe** regions.</span></span> <span data-ttu-id="41b4f-188">Une fabrique de données peut toutefois accéder à des magasins de données et à des services de calcul situés dans d’autres régions Azure pour déplacer des données entre des magasins de données ou pour traiter des données à l’aide des services de calcul.</span><span class="sxs-lookup"><span data-stu-id="41b4f-188">However, a data factory can access data stores and compute services in other Azure regions to move data between data stores or process data using compute services.</span></span>

<span data-ttu-id="41b4f-189">Azure Data Factory ne permet pas en soi de stocker des données.</span><span class="sxs-lookup"><span data-stu-id="41b4f-189">Azure Data Factory itself does not store any data.</span></span> <span data-ttu-id="41b4f-190">Il vous permet de créer des workflows pilotés par les données afin d’orchestrer le déplacement de données entre les [banques de données prises en charge](#data-movement-activities), ainsi que le traitement des données à l’aide des [services de calcul](#data-transformation-activities) situés dans d’autres régions ou dans un environnement local.</span><span class="sxs-lookup"><span data-stu-id="41b4f-190">It lets you create data-driven workflows to orchestrate movement of data between [supported data stores](#data-movement-activities) and processing of data using [compute services](#data-transformation-activities) in other regions or in an on-premises environment.</span></span> <span data-ttu-id="41b4f-191">Il vous permet également de [surveiller et gérer des workflows](data-factory-monitor-manage-pipelines.md) au moyen de programmes et à l’aide des mécanismes de l’interface utilisateur.</span><span class="sxs-lookup"><span data-stu-id="41b4f-191">It also allows you to [monitor and manage workflows](data-factory-monitor-manage-pipelines.md) using both programmatic and UI mechanisms.</span></span>

<span data-ttu-id="41b4f-192">Même si Data Factory est disponible uniquement aux **États-Unis de l’Ouest**, aux **États-Unis de l’Est** ainsi qu’en **Europe du Nord**, le service de déplacement des données intégré à Data Factory est [mondialement](data-factory-data-movement-activities.md#global) disponible dans plusieurs régions.</span><span class="sxs-lookup"><span data-stu-id="41b4f-192">Even though Data Factory is available in only **West US**, **East US**, and **North Europe** regions, the service powering the data movement in Data Factory is available [globally](data-factory-data-movement-activities.md#global) in several regions.</span></span> <span data-ttu-id="41b4f-193">Si un magasin de données se trouve derrière un pare-feu, le déplacement des données est assuré au moyen d’une [passerelle de gestion des données](data-factory-move-data-between-onprem-and-cloud.md) installée dans votre environnement local.</span><span class="sxs-lookup"><span data-stu-id="41b4f-193">If a data store is behind a firewall, then a [Data Management Gateway](data-factory-move-data-between-onprem-and-cloud.md) installed in your on-premises environment moves the data instead.</span></span>

<span data-ttu-id="41b4f-194">Supposons que vos environnements de calcul (cluster Azure HDInsight et Azure Machine Learning, par exemple) s’exécutent hors de la région Europe de l’ouest.</span><span class="sxs-lookup"><span data-stu-id="41b4f-194">For an example, let us assume that your compute environments such as Azure HDInsight cluster and Azure Machine Learning are running out of West Europe region.</span></span> <span data-ttu-id="41b4f-195">Vous pouvez dans ce cas créer et utiliser une instance Azure Data Factory en Europe du Nord et l’utiliser pour planifier des tâches sur vos environnements de calcul en Europe de l’ouest.</span><span class="sxs-lookup"><span data-stu-id="41b4f-195">You can create and use an Azure Data Factory instance in North Europe and use it to schedule jobs on your compute environments in West Europe.</span></span> <span data-ttu-id="41b4f-196">Quelques millisecondes suffisent à Data Factory pour déclencher la tâche dans votre environnement de calcul, mais l’heure d’exécution du travail dans votre environnement informatique ne change pas.</span><span class="sxs-lookup"><span data-stu-id="41b4f-196">It takes a few milliseconds for Data Factory to trigger the job on your compute environment but the time for running the job on your computing environment does not change.</span></span>

## <a name="get-started-with-creating-a-pipeline"></a><span data-ttu-id="41b4f-197">Prise en main de la création d’un pipeline</span><span class="sxs-lookup"><span data-stu-id="41b4f-197">Get started with creating a pipeline</span></span>
<span data-ttu-id="41b4f-198">Vous pouvez utiliser un des outils ou API suivants pour créer des pipelines de données dans Azure Data Factory :</span><span class="sxs-lookup"><span data-stu-id="41b4f-198">You can use one of these tools or APIs to create data pipelines in Azure Data Factory:</span></span> 

- <span data-ttu-id="41b4f-199">Portail Azure</span><span class="sxs-lookup"><span data-stu-id="41b4f-199">Azure portal</span></span>
- <span data-ttu-id="41b4f-200">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="41b4f-200">Visual Studio</span></span>
- <span data-ttu-id="41b4f-201">PowerShell</span><span class="sxs-lookup"><span data-stu-id="41b4f-201">PowerShell</span></span>
- <span data-ttu-id="41b4f-202">API .NET</span><span class="sxs-lookup"><span data-stu-id="41b4f-202">.NET API</span></span>
- <span data-ttu-id="41b4f-203">API REST</span><span class="sxs-lookup"><span data-stu-id="41b4f-203">REST API</span></span>
- <span data-ttu-id="41b4f-204">Modèle Azure Resource Manager.</span><span class="sxs-lookup"><span data-stu-id="41b4f-204">Azure Resource Manager template.</span></span> 

<span data-ttu-id="41b4f-205">Pour découvrir comment créer des fabriques de données avec des pipelines de données, suivez les instructions pas à pas des didacticiels suivants :</span><span class="sxs-lookup"><span data-stu-id="41b4f-205">To learn how to build data factories with data pipelines, follow step-by-step instructions in the following tutorials:</span></span>

| <span data-ttu-id="41b4f-206">Didacticiel</span><span class="sxs-lookup"><span data-stu-id="41b4f-206">Tutorial</span></span> | <span data-ttu-id="41b4f-207">Description</span><span class="sxs-lookup"><span data-stu-id="41b4f-207">Description</span></span> |
| --- | --- |
| [<span data-ttu-id="41b4f-208">Déplacer des données entre deux magasins de données cloud</span><span class="sxs-lookup"><span data-stu-id="41b4f-208">Move data between two cloud data stores</span></span>](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) |<span data-ttu-id="41b4f-209">Dans ce didacticiel, vous créez une fabrique de données avec un pipeline qui **déplace des données** de Blob Storage vers la base de données SQL.</span><span class="sxs-lookup"><span data-stu-id="41b4f-209">In this tutorial, you create a data factory with a pipeline that **moves data** from Blob storage to SQL database.</span></span> |
| [<span data-ttu-id="41b4f-210">Transformer des données à l’aide du cluster Hadoop</span><span class="sxs-lookup"><span data-stu-id="41b4f-210">Transform data using Hadoop cluster</span></span>](data-factory-build-your-first-pipeline.md) |<span data-ttu-id="41b4f-211">Dans ce didacticiel, vous devez générer votre première fabrique de données Azure avec un pipeline de données qui **traite les données** en exécutant le script Hive sur un cluster Azure HDInsight (Hadoop).</span><span class="sxs-lookup"><span data-stu-id="41b4f-211">In this tutorial, you build your first Azure data factory with a data pipeline that **processes data** by running Hive script on an Azure HDInsight (Hadoop) cluster.</span></span> |
| [<span data-ttu-id="41b4f-212">Déplacer des données entre une banque de données locale et une banque de données cloud à l’aide de la passerelle de gestion des données</span><span class="sxs-lookup"><span data-stu-id="41b4f-212">Move data between an on-premises data store and a cloud data store using Data Management Gateway</span></span>](data-factory-move-data-between-onprem-and-cloud.md) |<span data-ttu-id="41b4f-213">Dans ce didacticiel, vous créez une fabrique de données avec un pipeline qui **déplace des données** d’une base de données SQL Server **locale** vers un objet blob Azure.</span><span class="sxs-lookup"><span data-stu-id="41b4f-213">In this tutorial, you build a data factory with a pipeline that **moves data** from an **on-premises** SQL Server database to an Azure blob.</span></span> <span data-ttu-id="41b4f-214">Dans le cadre de la procédure pas à pas, vous installez et configurez la passerelle de gestion des données sur votre ordinateur.</span><span class="sxs-lookup"><span data-stu-id="41b4f-214">As part of the walkthrough, you install and configure the Data Management Gateway on your machine.</span></span> |
