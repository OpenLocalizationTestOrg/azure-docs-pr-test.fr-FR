---
title: "Azure Data Factory - Forum aux Questions"
description: Forum aux Questions sur Azure Data Factory.
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: 532dec5a-7261-4770-8f54-bfe527918058
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/14/2017
ms.author: shlo
ms.openlocfilehash: 086e6b2fb9bd0ee8541401b6f0d65268926e45a5
ms.sourcegitcommit: 50e23e8d3b1148ae2d36dad3167936b4e52c8a23
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 08/18/2017
---
# <a name="azure-data-factory---frequently-asked-questions"></a><span data-ttu-id="e40ae-103">Azure Data Factory - Forum aux Questions</span><span class="sxs-lookup"><span data-stu-id="e40ae-103">Azure Data Factory - Frequently Asked Questions</span></span>
## <a name="general-questions"></a><span data-ttu-id="e40ae-104">Questions générales</span><span class="sxs-lookup"><span data-stu-id="e40ae-104">General questions</span></span>
### <a name="what-is-azure-data-factory"></a><span data-ttu-id="e40ae-105">qu'est-ce qu'Azure Data Factory ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-105">What is Azure Data Factory?</span></span>
<span data-ttu-id="e40ae-106">Data Factory est un service d’intégration de données dans le cloud qui **automatise le déplacement et la transformation des données**.</span><span class="sxs-lookup"><span data-stu-id="e40ae-106">Data Factory is a cloud-based data integration service that **automates the movement and transformation of data**.</span></span> <span data-ttu-id="e40ae-107">À la manière d’une usine, qui utilise des machines visant à transformer des matières premières en produits manufacturés, Data Factory orchestre des services existants qui collectent des données brutes et les transforment en informations prêtes à l’emploi.</span><span class="sxs-lookup"><span data-stu-id="e40ae-107">Just like a factory that runs equipment to take raw materials and transform them into finished goods, Data Factory orchestrates existing services that collect raw data and transform it into ready-to-use information.</span></span>

<span data-ttu-id="e40ae-108">Data Factory vous permet de créer des flux de travail pilotés par les données pour déplacer des données entre des magasins de données locaux et cloud et traiter/transformer des données avec des services de calcul comme Azure HDInsight et Azure Data Lake Analytics.</span><span class="sxs-lookup"><span data-stu-id="e40ae-108">Data Factory allows you to create data-driven workflows to move data between both on-premises and cloud data stores as well as process/transform data using compute services such as Azure HDInsight and Azure Data Lake Analytics.</span></span> <span data-ttu-id="e40ae-109">Après avoir créé un pipeline qui exécute l’action dont vous avez besoin, vous pouvez planifier son exécution périodique (toutes les heures, tous les jours, toutes les semaines, etc.).</span><span class="sxs-lookup"><span data-stu-id="e40ae-109">After you create a pipeline that performs the action that you need, you can schedule it to run periodically (hourly, daily, weekly etc.).</span></span>   

<span data-ttu-id="e40ae-110">Pour plus d’informations, consultez [Vue d’ensemble et concepts clés](data-factory-introduction.md).</span><span class="sxs-lookup"><span data-stu-id="e40ae-110">For more information, see [Overview & Key Concepts](data-factory-introduction.md).</span></span>

### <a name="where-can-i-find-pricing-details-for-azure-data-factory"></a><span data-ttu-id="e40ae-111">où puis-je trouver des informations de tarification pour Azure Data Factory ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-111">Where can I find pricing details for Azure Data Factory?</span></span>
<span data-ttu-id="e40ae-112">Consultez la [page de tarification de Data Factory][adf-pricing-details] pour plus d’informations sur la tarification d’Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="e40ae-112">See [Data Factory Pricing Details page][adf-pricing-details] for the pricing details for the Azure Data Factory.</span></span>  

### <a name="how-do-i-get-started-with-azure-data-factory"></a><span data-ttu-id="e40ae-113">comment prendre en main Azure Data Factory ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-113">How do I get started with Azure Data Factory?</span></span>
* <span data-ttu-id="e40ae-114">Pour obtenir une vue d'ensemble d'Azure Data Factory, consultez [Présentation d'Azure Data Factory](data-factory-introduction.md).</span><span class="sxs-lookup"><span data-stu-id="e40ae-114">For an overview of Azure Data Factory, see [Introduction to Azure Data Factory](data-factory-introduction.md).</span></span>
* <span data-ttu-id="e40ae-115">Pour obtenir un didacticiel expliquant comment **copier/déplacer des données** au moyen de l’activité de copie, consultez [Copie de données d’Azure Blob Storage vers une base de données SQL Azure](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="e40ae-115">For a tutorial on how to **copy/move data** using Copy Activity, see [Copy data from Azure Blob Storage to Azure SQL Database](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>
* <span data-ttu-id="e40ae-116">Pour obtenir un didacticiel sur la façon de **transformer des données** au moyen de l’activité Hive de HDInsight.</span><span class="sxs-lookup"><span data-stu-id="e40ae-116">For a tutorial on how to **transform data** using HDInsight Hive Activity.</span></span> <span data-ttu-id="e40ae-117">Consultez [Traiter des données en exécutant un script Hive sur un cluster Hadoop](data-factory-build-your-first-pipeline.md)</span><span class="sxs-lookup"><span data-stu-id="e40ae-117">See [Process data by running Hive script on Hadoop cluster](data-factory-build-your-first-pipeline.md)</span></span>

### <a name="what-is-the-data-factorys-region-availability"></a><span data-ttu-id="e40ae-118">dans quelle région sera disponible Data Factory ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-118">What is the Data Factory’s region availability?</span></span>
<span data-ttu-id="e40ae-119">Data Factory est disponible dans les régions **Ouest des États-Unis** et **Europe du Nord**.</span><span class="sxs-lookup"><span data-stu-id="e40ae-119">Data Factory is available in **US West** and **North Europe**.</span></span> <span data-ttu-id="e40ae-120">Les services de calcul et de stockage utilisés par les fabriques de données peuvent être proposés dans d'autres régions.</span><span class="sxs-lookup"><span data-stu-id="e40ae-120">The compute and storage services used by data factories can be in other regions.</span></span> <span data-ttu-id="e40ae-121">Consultez [Régions prises en charge](data-factory-introduction.md#supported-regions).</span><span class="sxs-lookup"><span data-stu-id="e40ae-121">See [Supported regions](data-factory-introduction.md#supported-regions).</span></span>

### <a name="what-are-the-limits-on-number-of-data-factoriespipelinesactivitiesdatasets"></a><span data-ttu-id="e40ae-122">quelles sont les limites du nombre de fabriques de données/pipelines/activités/jeux de données ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-122">What are the limits on number of data factories/pipelines/activities/datasets?</span></span>
<span data-ttu-id="e40ae-123">Consultez la section **Limites d’Azure Data Factory** de l’article [Abonnement Azure et limites, quotas et contraintes du service](../azure-subscription-service-limits.md#data-factory-limits) .</span><span class="sxs-lookup"><span data-stu-id="e40ae-123">See **Azure Data Factory Limits** section of the [Azure Subscription and Service Limits, Quotas, and Constraints](../azure-subscription-service-limits.md#data-factory-limits) article.</span></span>

### <a name="what-is-the-authoringdeveloper-experience-with-azure-data-factory-service"></a><span data-ttu-id="e40ae-124">Qu’est-il possible de faire avec le service Azure Data Factory en termes de création/développement ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-124">What is the authoring/developer experience with Azure Data Factory service?</span></span>
<span data-ttu-id="e40ae-125">Vous pouvez créer des fabriques de données en utilisant un des outils/SDK suivants :</span><span class="sxs-lookup"><span data-stu-id="e40ae-125">You can author/create data factories using one of the following tools/SDKs:</span></span>

* <span data-ttu-id="e40ae-126">**Portail Azure** : les panneaux du service Data Factory dans le portail Azure fournissent une interface utilisateur complète qui vous permet de créer des fabriques de données et des services liés.</span><span class="sxs-lookup"><span data-stu-id="e40ae-126">**Azure portal** The Data Factory blades in the Azure portal provide rich user interface for you to create data factories ad linked services.</span></span> <span data-ttu-id="e40ae-127">**Data Factory Editor**, qui fait également partie du portail, vous permet de créer facilement des services liés, des tables, des jeux de données et des pipelines en spécifiant des définitions JSON pour ces artefacts.</span><span class="sxs-lookup"><span data-stu-id="e40ae-127">The **Data Factory Editor**, which is also part of the portal, allows you to easily create linked services, tables, data sets, and pipelines by specifying JSON definitions for these artifacts.</span></span> <span data-ttu-id="e40ae-128">Consultez [Créer votre premier pipeline de données en utilisant le portail Azure](data-factory-build-your-first-pipeline-using-editor.md) pour obtenir un exemple d’utilisation du portail et de l’éditeur pour créer et déployer une fabrique de données.</span><span class="sxs-lookup"><span data-stu-id="e40ae-128">See [Build your first data pipeline using Azure portal](data-factory-build-your-first-pipeline-using-editor.md) for an example of using the portal/editor to create and deploy a data factory.</span></span>
* <span data-ttu-id="e40ae-129">**Visual Studio** : vous pouvez utiliser Visual Studio pour créer une fabrique de données Azure.</span><span class="sxs-lookup"><span data-stu-id="e40ae-129">**Visual Studio** You can use Visual Studio to create an Azure data factory.</span></span> <span data-ttu-id="e40ae-130">Pour plus d’informations, consultez [Créer votre premier pipeline de données à l’aide de Visual Studio](data-factory-build-your-first-pipeline-using-vs.md) .</span><span class="sxs-lookup"><span data-stu-id="e40ae-130">See [Build your first data pipeline using Visual Studio](data-factory-build-your-first-pipeline-using-vs.md) for details.</span></span>
* <span data-ttu-id="e40ae-131">**Azure PowerShell** : consultez [Créer et surveiller Azure Data Factory à l’aide d’Azure PowerShell](data-factory-build-your-first-pipeline-using-powershell.md) pour obtenir un didacticiel/une procédure pas à pas pour créer une fabrique de données à l’aide de PowerShell.</span><span class="sxs-lookup"><span data-stu-id="e40ae-131">**Azure PowerShell** See [Create and monitor Azure Data Factory using Azure PowerShell](data-factory-build-your-first-pipeline-using-powershell.md) for a tutorial/walkthrough for creating a data factory using PowerShell.</span></span> <span data-ttu-id="e40ae-132">Consultez [Informations de référence sur les applets de commande Data Factory][adf-powershell-reference] dans la bibliothèque MSDN pour obtenir une documentation complète sur les applets de commande Data Factory.</span><span class="sxs-lookup"><span data-stu-id="e40ae-132">See [Data Factory Cmdlet Reference][adf-powershell-reference] content on MSDN Library for a comprehensive documentation of Data Factory cmdlets.</span></span>
* <span data-ttu-id="e40ae-133">**Bibliothèque de classes .NET** Vous pouvez créer par programmation des fabriques de données à l'aide du Kit de développement logiciel (SDK) Data Factory .NET.</span><span class="sxs-lookup"><span data-stu-id="e40ae-133">**.NET Class Library** You can programmatically create data factories by using Data Factory .NET SDK.</span></span> <span data-ttu-id="e40ae-134">Consultez [Créer, surveiller et gérer des fabriques de données à l'aide du Kit de développement logiciel (SDK) .NET](data-factory-create-data-factories-programmatically.md) pour découvrir comment créer une fabrique de données à l'aide du Kit de développement logiciel (SDK) .NET.</span><span class="sxs-lookup"><span data-stu-id="e40ae-134">See [Create, monitor, and manage data factories using .NET SDK](data-factory-create-data-factories-programmatically.md) for a walkthrough of creating a data factory using .NET SDK.</span></span> <span data-ttu-id="e40ae-135">Consultez [Informations de référence sur la bibliothèque de classes Data Factory][msdn-class-library-reference] pour obtenir une documentation complète sur le Kit de développement logiciel (SDK) Data Factory .NET.</span><span class="sxs-lookup"><span data-stu-id="e40ae-135">See [Data Factory Class Library Reference][msdn-class-library-reference] for a comprehensive documentation of Data Factory .NET SDK.</span></span>
* <span data-ttu-id="e40ae-136">**API REST** Vous pouvez également utiliser l'API REST exposée par le service Azure Data Factory pour créer et déployer des fabriques de données.</span><span class="sxs-lookup"><span data-stu-id="e40ae-136">**REST API** You can also use the REST API exposed by the Azure Data Factory service to create and deploy data factories.</span></span> <span data-ttu-id="e40ae-137">Consultez [Informations de référence sur l’API REST Data Factory][msdn-rest-api-reference] pour obtenir une documentation complète de l’API REST Data Factory.</span><span class="sxs-lookup"><span data-stu-id="e40ae-137">See [Data Factory REST API Reference][msdn-rest-api-reference] for a comprehensive documentation of Data Factory REST API.</span></span>
* <span data-ttu-id="e40ae-138">**Modèle Azure Resource Manager** Consultez [Didacticiel : concevoir votre première fabrique de données Azure à l’aide du modèle Azure Resource Manager](data-factory-build-your-first-pipeline-using-arm.md) pour plus d’informations.</span><span class="sxs-lookup"><span data-stu-id="e40ae-138">**Azure Resource Manager Template** See [Tutorial: Build your first Azure data factory using Azure Resource Manager template](data-factory-build-your-first-pipeline-using-arm.md) fo details.</span></span>

### <a name="can-i-rename-a-data-factory"></a><span data-ttu-id="e40ae-139">Puis-je renommer une fabrique de données ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-139">Can I rename a data factory?</span></span>
<span data-ttu-id="e40ae-140">Non.</span><span class="sxs-lookup"><span data-stu-id="e40ae-140">No.</span></span> <span data-ttu-id="e40ae-141">Tout comme les autres ressources Azure, le nom d'une fabrique de données Azure ne peut pas être modifié.</span><span class="sxs-lookup"><span data-stu-id="e40ae-141">Like other Azure resources, the name of an Azure data factory cannot be changed.</span></span>

### <a name="can-i-move-a-data-factory-from-one-azure-subscription-to-another"></a><span data-ttu-id="e40ae-142">Puis-je déplacer une fabrique de données d’un abonnement Azure à un autre ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-142">Can I move a data factory from one Azure subscription to another?</span></span>
<span data-ttu-id="e40ae-143">Oui.</span><span class="sxs-lookup"><span data-stu-id="e40ae-143">Yes.</span></span> <span data-ttu-id="e40ae-144">Utilisez le bouton **Déplacer** sur le panneau de votre fabrique de données comme indiqué dans le graphique ci-dessous :</span><span class="sxs-lookup"><span data-stu-id="e40ae-144">Use the **Move** button on your data factory blade as shown in the following diagram:</span></span>

![Déplacer la fabrique de données](media/data-factory-faq/move-data-factory.png)

### <a name="what-are-the-compute-environments-supported-by-data-factory"></a><span data-ttu-id="e40ae-146">Quels sont les environnements de calcul pris en charge par Data Factory ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-146">What are the compute environments supported by Data Factory?</span></span>
<span data-ttu-id="e40ae-147">Le tableau suivant fournit une liste d’environnements de calcul pris en charge par Data Factory et les activités qui peuvent s’exécuter sur ces derniers.</span><span class="sxs-lookup"><span data-stu-id="e40ae-147">The following table provides a list of compute environments supported by Data Factory and the activities that can run on them.</span></span>

| <span data-ttu-id="e40ae-148">Environnement de calcul</span><span class="sxs-lookup"><span data-stu-id="e40ae-148">Compute environment</span></span> | <span data-ttu-id="e40ae-149">activités</span><span class="sxs-lookup"><span data-stu-id="e40ae-149">activities</span></span> |
| --- | --- |
| <span data-ttu-id="e40ae-150">[Cluster HDInsight à la demande](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service) ou [votre propre cluster HDInsight](data-factory-compute-linked-services.md#azure-hdinsight-linked-service)</span><span class="sxs-lookup"><span data-stu-id="e40ae-150">[On-demand HDInsight cluster](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service) or [your own HDInsight cluster](data-factory-compute-linked-services.md#azure-hdinsight-linked-service)</span></span> |<span data-ttu-id="e40ae-151">[DotNet](data-factory-use-custom-activities.md), [Hive](data-factory-hive-activity.md), [Pig](data-factory-pig-activity.md), [MapReduce](data-factory-map-reduce.md), [Diffusion en continu Hadoop](data-factory-hadoop-streaming-activity.md)</span><span class="sxs-lookup"><span data-stu-id="e40ae-151">[DotNet](data-factory-use-custom-activities.md), [Hive](data-factory-hive-activity.md), [Pig](data-factory-pig-activity.md), [MapReduce](data-factory-map-reduce.md), [Hadoop Streaming](data-factory-hadoop-streaming-activity.md)</span></span> |
| [<span data-ttu-id="e40ae-152">Azure Batch</span><span class="sxs-lookup"><span data-stu-id="e40ae-152">Azure Batch</span></span>](data-factory-compute-linked-services.md#azure-batch-linked-service) |[<span data-ttu-id="e40ae-153">DotNet</span><span class="sxs-lookup"><span data-stu-id="e40ae-153">DotNet</span></span>](data-factory-use-custom-activities.md) |
| [<span data-ttu-id="e40ae-154">Azure Machine Learning</span><span class="sxs-lookup"><span data-stu-id="e40ae-154">Azure Machine Learning</span></span>](data-factory-compute-linked-services.md#azure-machine-learning-linked-service) |[<span data-ttu-id="e40ae-155">Activités Machine Learning : exécution de lot et mise à jour de ressource</span><span class="sxs-lookup"><span data-stu-id="e40ae-155">Machine Learning activities: Batch Execution and Update Resource</span></span>](data-factory-azure-ml-batch-execution-activity.md) |
| [<span data-ttu-id="e40ae-156">Service Analytique Azure Data Lake</span><span class="sxs-lookup"><span data-stu-id="e40ae-156">Azure Data Lake Analytics</span></span>](data-factory-compute-linked-services.md#azure-data-lake-analytics-linked-service) |[<span data-ttu-id="e40ae-157">Langage U-SQL du service Analytique Data Lake</span><span class="sxs-lookup"><span data-stu-id="e40ae-157">Data Lake Analytics U-SQL</span></span>](data-factory-usql-activity.md) |
| <span data-ttu-id="e40ae-158">[Azure SQL](data-factory-compute-linked-services.md#azure-sql-linked-service), [Azure SQL Data Warehouse](data-factory-compute-linked-services.md#azure-sql-data-warehouse-linked-service), [SQL Server](data-factory-compute-linked-services.md#sql-server-linked-service)</span><span class="sxs-lookup"><span data-stu-id="e40ae-158">[Azure SQL](data-factory-compute-linked-services.md#azure-sql-linked-service), [Azure SQL Data Warehouse](data-factory-compute-linked-services.md#azure-sql-data-warehouse-linked-service), [SQL Server](data-factory-compute-linked-services.md#sql-server-linked-service)</span></span> |[<span data-ttu-id="e40ae-159">Procédure stockée</span><span class="sxs-lookup"><span data-stu-id="e40ae-159">Stored Procedure</span></span>](data-factory-stored-proc-activity.md) |

### <a name="how-does-azure-data-factory-compare-with-sql-server-integration-services-ssis"></a><span data-ttu-id="e40ae-160">Comparaison d’Azure Data Factory avec SQL Server Integration Services (SSIS)</span><span class="sxs-lookup"><span data-stu-id="e40ae-160">How does Azure Data Factory compare with SQL Server Integration Services (SSIS)?</span></span> 
<span data-ttu-id="e40ae-161">Consultez la présentation [Azure Data Factory et SSIS](http://www.sqlbits.com/Sessions/Event15/Azure_Data_Factory_vs_SSIS) faite par un de nos MVP (Most Valued Professional), Reza Rad.</span><span class="sxs-lookup"><span data-stu-id="e40ae-161">See the [Azure Data Factory vs. SSIS](http://www.sqlbits.com/Sessions/Event15/Azure_Data_Factory_vs_SSIS) presentation from one of our MVPs (Most Valued Professionals): Reza Rad.</span></span> <span data-ttu-id="e40ae-162">Certains des changements récents Data Factory peuvent ne pas figurer dans le jeu de diapositives.</span><span class="sxs-lookup"><span data-stu-id="e40ae-162">Some of the recent changes in Data Factory may not be listed in the slide deck.</span></span> <span data-ttu-id="e40ae-163">Nous ajoutons continuellement des fonctionnalités à Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="e40ae-163">We are continuously adding more capabilities to Azure Data Factory.</span></span> <span data-ttu-id="e40ae-164">Nous ajoutons continuellement des fonctionnalités à Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="e40ae-164">We are continuously adding more capabilities to Azure Data Factory.</span></span> <span data-ttu-id="e40ae-165">Nous intégrerons ces mises à jour dans la comparaison des technologies d’intégration de données de Microsoft un peu plus tard cette année.</span><span class="sxs-lookup"><span data-stu-id="e40ae-165">We will incorporate these updates into the comparison of data integration technologies from Microsoft sometime later this year.</span></span>   

## <a name="activities---faq"></a><span data-ttu-id="e40ae-166">Activités - Forum Aux Questions</span><span class="sxs-lookup"><span data-stu-id="e40ae-166">Activities - FAQ</span></span>
### <a name="what-are-the-different-types-of-activities-you-can-use-in-a-data-factory-pipeline"></a><span data-ttu-id="e40ae-167">Quels sont les différents types d’activités que vous pouvez utiliser dans un pipeline Data Factory ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-167">What are the different types of activities you can use in a Data Factory pipeline?</span></span>
* <span data-ttu-id="e40ae-168">[Activités de déplacement des données](data-factory-data-movement-activities.md) pour déplacer les données.</span><span class="sxs-lookup"><span data-stu-id="e40ae-168">[Data Movement Activities](data-factory-data-movement-activities.md) to move data.</span></span>
* <span data-ttu-id="e40ae-169">[Activités de transformation des données](data-factory-data-transformation-activities.md) pour traiter/transformer les données.</span><span class="sxs-lookup"><span data-stu-id="e40ae-169">[Data Transformation Activities](data-factory-data-transformation-activities.md) to process/transform data.</span></span>

### <a name="when-does-an-activity-run"></a><span data-ttu-id="e40ae-170">Quand une activité s'exécute-t-elle ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-170">When does an activity run?</span></span>
<span data-ttu-id="e40ae-171">Les paramètres de configuration de la **disponibilité** présents dans la table de données de sortie déterminent quand l'activité doit être exécutée.</span><span class="sxs-lookup"><span data-stu-id="e40ae-171">The **availability** configuration setting in the output data table determines when the activity is run.</span></span> <span data-ttu-id="e40ae-172">Si des jeux de données d’entrée sont spécifiés, l’activité vérifie si toutes les dépendances de données d’entrée sont satisfaites (par exemple, l’état **Prêt** ) avant de s’exécuter.</span><span class="sxs-lookup"><span data-stu-id="e40ae-172">If input datasets are specified, the activity checks whether all the input data dependencies are satisfied (that is, **Ready** state) before it starts running.</span></span>

## <a name="copy-activity---faq"></a><span data-ttu-id="e40ae-173">Activité de copie - Forum Aux Questions</span><span class="sxs-lookup"><span data-stu-id="e40ae-173">Copy Activity - FAQ</span></span>
### <a name="is-it-better-to-have-a-pipeline-with-multiple-activities-or-a-separate-pipeline-for-each-activity"></a><span data-ttu-id="e40ae-174">Est-il préférable d'avoir un pipeline avec plusieurs activités ou un pipeline distinct pour chaque activité ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-174">Is it better to have a pipeline with multiple activities or a separate pipeline for each activity?</span></span>
<span data-ttu-id="e40ae-175">Les pipelines sont censés regrouper des activités connexes.</span><span class="sxs-lookup"><span data-stu-id="e40ae-175">Pipelines are supposed to bundle related activities.</span></span> <span data-ttu-id="e40ae-176">Vous pouvez conserver les activités dans un seul pipeline si les tables qui les relient ne sont pas utilisées par d’autres activités extérieures au pipeline.</span><span class="sxs-lookup"><span data-stu-id="e40ae-176">If the datasets that connect them are not consumed by any other activity outside the pipeline, you can keep the activities in one pipeline.</span></span> <span data-ttu-id="e40ae-177">De cette façon, vous n'aurez pas besoin de relier les périodes actives du pipeline pour qu'elles s'accordent les unes avec les autres.</span><span class="sxs-lookup"><span data-stu-id="e40ae-177">This way, you would not need to chain pipeline active periods so that they align with each other.</span></span> <span data-ttu-id="e40ae-178">En outre, l’intégrité des données dans les tables internes au pipeline est mieux préservée lors de la mise à jour du pipeline.</span><span class="sxs-lookup"><span data-stu-id="e40ae-178">Also, the data integrity in the tables internal to the pipeline is better preserved when updating the pipeline.</span></span> <span data-ttu-id="e40ae-179">La mise à jour d'un pipeline arrête toutes les activités du pipeline, les supprime et les crée de nouveau.</span><span class="sxs-lookup"><span data-stu-id="e40ae-179">Pipeline update essentially stops all the activities within the pipeline, removes them, and creates them again.</span></span> <span data-ttu-id="e40ae-180">En termes de création, il peut être plus facile de voir le flux de données au sein des activités connexes dans un seul fichier JSON pour le pipeline.</span><span class="sxs-lookup"><span data-stu-id="e40ae-180">From authoring perspective, it might also be easier to see the flow of data within the related activities in one JSON file for the pipeline.</span></span>

### <a name="what-are-the-supported-data-stores"></a><span data-ttu-id="e40ae-181">Quelles sont les banques de données prises en charge ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-181">What are the supported data stores?</span></span>
<span data-ttu-id="e40ae-182">L’activité de copie dans Data Factory permet de copier les données d’un magasin de données source vers un magasin de données récepteur.</span><span class="sxs-lookup"><span data-stu-id="e40ae-182">Copy Activity in Data Factory copies data from a source data store to a sink data store.</span></span> <span data-ttu-id="e40ae-183">Data Factory prend en charge les magasins de données suivants.</span><span class="sxs-lookup"><span data-stu-id="e40ae-183">Data Factory supports the following data stores.</span></span> <span data-ttu-id="e40ae-184">Les données de n’importe quelle source peuvent être écrites dans n’importe quel récepteur.</span><span class="sxs-lookup"><span data-stu-id="e40ae-184">Data from any source can be written to any sink.</span></span> <span data-ttu-id="e40ae-185">Cliquez sur une banque de données pour découvrir comment copier des données depuis/vers cette banque.</span><span class="sxs-lookup"><span data-stu-id="e40ae-185">Click a data store to learn how to copy data to and from that store.</span></span>

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

> [!NOTE]
> <span data-ttu-id="e40ae-186">Les banques de données signalées par un astérisque (*) peuvent être locales ou résider sur une instance Azure IaaS. Elles nécessitent que vous installiez une [passerelle de gestion des données](data-factory-data-management-gateway.md) sur un ordinateur local ou Azure IaaS.</span><span class="sxs-lookup"><span data-stu-id="e40ae-186">Data stores with * can be on-premises or on Azure IaaS, and require you to install [Data Management Gateway](data-factory-data-management-gateway.md) on an on-premises/Azure IaaS machine.</span></span>

### <a name="what-are-the-supported-file-formats"></a><span data-ttu-id="e40ae-187">Quels sont les formats de fichier pris en charge ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-187">What are the supported file formats?</span></span>
[!INCLUDE [data-factory-file-format](../../includes/data-factory-file-format.md)]

### <a name="where-is-the-copy-operation-performed"></a><span data-ttu-id="e40ae-188">Où est effectuée l’opération de copie ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-188">Where is the copy operation performed?</span></span>
<span data-ttu-id="e40ae-189">Consultez la section relative au [déplacement des données disponibles à l’échelle mondiale](data-factory-data-movement-activities.md#global) pour plus d’informations.</span><span class="sxs-lookup"><span data-stu-id="e40ae-189">See [Globally available data movement](data-factory-data-movement-activities.md#global) section for details.</span></span> <span data-ttu-id="e40ae-190">En bref, lorsqu’il s’agit d’un magasin de données local, l’opération de copie est effectuée par la passerelle de gestion des données dans votre environnement local.</span><span class="sxs-lookup"><span data-stu-id="e40ae-190">In short, when an on-premises data store is involved, the copy operation is performed by the Data Management Gateway in your on-premises environment.</span></span> <span data-ttu-id="e40ae-191">Lorsque le déplacement des données se fait entre deux magasins cloud, l’opération de copie est effectuée dans la région la plus proche de l’emplacement du récepteur dans la même zone géographique.</span><span class="sxs-lookup"><span data-stu-id="e40ae-191">And, when the data movement is between two cloud stores, the copy operation is performed in the region closest to the sink location in the same geography.</span></span>

## <a name="hdinsight-activity---faq"></a><span data-ttu-id="e40ae-192">Activité de HDInsight - Forum Aux Questions</span><span class="sxs-lookup"><span data-stu-id="e40ae-192">HDInsight Activity - FAQ</span></span>
### <a name="what-regions-are-supported-by-hdinsight"></a><span data-ttu-id="e40ae-193">Quelles sont les régions prises en charge par HDInsight ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-193">What regions are supported by HDInsight?</span></span>
<span data-ttu-id="e40ae-194">Consultez la page [Tarification relative à HDInsight][hdinsight-supported-regions] ou la section Disponibilité géographique dans l’article suivant.</span><span class="sxs-lookup"><span data-stu-id="e40ae-194">See the Geographic Availability section in the following article: or [HDInsight Pricing Details][hdinsight-supported-regions].</span></span>

### <a name="what-region-is-used-by-an-on-demand-hdinsight-cluster"></a><span data-ttu-id="e40ae-195">quelle est la région utilisée par un cluster HDInsight à la demande ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-195">What region is used by an on-demand HDInsight cluster?</span></span>
<span data-ttu-id="e40ae-196">Le cluster HDInsight à la demande est créé dans la même région que le stockage que vous avez spécifié pour être utilisé avec le cluster.</span><span class="sxs-lookup"><span data-stu-id="e40ae-196">The on-demand HDInsight cluster is created in the same region where the storage you specified to be used with the cluster exists.</span></span>    

### <a name="how-to-associate-additional-storage-accounts-to-your-hdinsight-cluster"></a><span data-ttu-id="e40ae-197">Comment associer des comptes de stockage supplémentaires à votre cluster HDInsight ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-197">How to associate additional storage accounts to your HDInsight cluster?</span></span>
<span data-ttu-id="e40ae-198">Si vous utilisez votre propre cluster HDInsight (BYOC, Bring Your Own Cluster), consultez les rubriques suivantes :</span><span class="sxs-lookup"><span data-stu-id="e40ae-198">If you are using your own HDInsight Cluster (BYOC - Bring Your Own Cluster), see the following topics:</span></span>

* <span data-ttu-id="e40ae-199">[Utilisation d’un cluster HDInsight avec des comptes de stockage et des metastores secondaires][hdinsight-alternate-storage]</span><span class="sxs-lookup"><span data-stu-id="e40ae-199">[Using an HDInsight Cluster with Alternate Storage Accounts and Metastores][hdinsight-alternate-storage]</span></span>
* <span data-ttu-id="e40ae-200">[Utilisation de comptes de stockage supplémentaires avec Hive HDInsight][hdinsight-alternate-storage-2]</span><span class="sxs-lookup"><span data-stu-id="e40ae-200">[Use Additional Storage Accounts with HDInsight Hive][hdinsight-alternate-storage-2]</span></span>

<span data-ttu-id="e40ae-201">Si vous utilisez un cluster à la demande créé par le service Data Factory, spécifiez les comptes de stockage supplémentaires pour le service lié HDInsight afin que le service Data Factory puisse les inscrire en votre nom.</span><span class="sxs-lookup"><span data-stu-id="e40ae-201">If you are using an on-demand cluster that is created by the Data Factory service, specify additional storage accounts for the HDInsight linked service so that the Data Factory service can register them on your behalf.</span></span> <span data-ttu-id="e40ae-202">Dans la définition JSON pour le service lié à la demande, utilisez la propriété **additionalLinkedServiceNames** pour spécifier les comptes de stockage secondaires, comme indiqué dans l'extrait de code JSON suivant :</span><span class="sxs-lookup"><span data-stu-id="e40ae-202">In the JSON definition for the on-demand linked service, use **additionalLinkedServiceNames** property to specify alternate storage accounts as shown in the following JSON snippet:</span></span>

```JSON
{
    "name": "MyHDInsightOnDemandLinkedService",
    "properties":
    {
        "type": "HDInsightOnDemandLinkedService",
        "typeProperties": {
            "version": "3.5",
            "clusterSize": 1,
            "timeToLive": "00:05:00",
            "osType": "Linux",
            "linkedServiceName": "LinkedService-SampleData",
            "additionalLinkedServiceNames": [ "otherLinkedServiceName1", "otherLinkedServiceName2" ]
        }
    }
}
```
<span data-ttu-id="e40ae-203">Dans l'exemple ci-dessus, otherLinkedServiceName1 et otherLinkedServiceName2 représentent les services liés dont les définitions contiennent des informations d'identification nécessaires au cluster HDInsight pour accéder aux comptes de stockage secondaires.</span><span class="sxs-lookup"><span data-stu-id="e40ae-203">In the example above, otherLinkedServiceName1 and otherLinkedServiceName2 represent linked services whose definitions contain credentials that the HDInsight cluster needs to access alternate storage accounts.</span></span>

## <a name="slices---faq"></a><span data-ttu-id="e40ae-204">Tranches - Forum Aux Questions</span><span class="sxs-lookup"><span data-stu-id="e40ae-204">Slices - FAQ</span></span>
### <a name="why-are-my-input-slices-not-in-ready-state"></a><span data-ttu-id="e40ae-205">Pourquoi mes tranches d’entrée ne sont-elles pas à l’état Prêt ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-205">Why are my input slices not in Ready state?</span></span>
<span data-ttu-id="e40ae-206">L’une des erreurs les plus courantes est de ne pas définir la propriété **external** sur **true** dans le jeu de données d’entrée quand les données d’entrée sont externes à la fabrique de données (c’est-à-dire qu’elles n’ont pas été générées par celle-ci).</span><span class="sxs-lookup"><span data-stu-id="e40ae-206">A common mistake is not setting **external** property to **true** on the input dataset when the input data is external to the data factory (not produced by the data factory).</span></span>

<span data-ttu-id="e40ae-207">Dans l’exemple suivant, vous devez uniquement définir **external** sur true pour **dataset1**.</span><span class="sxs-lookup"><span data-stu-id="e40ae-207">In the following example, you only need to set **external** to true on **dataset1**.</span></span>  

<span data-ttu-id="e40ae-208">**DataFactory1** Pipeline 1 : dataset1 -> activity1 -> dataset2 -> activity2 -> dataset3 Pipeline 2 : dataset3-> activity3 -> dataset4</span><span class="sxs-lookup"><span data-stu-id="e40ae-208">**DataFactory1** Pipeline 1: dataset1 -> activity1 -> dataset2 -> activity2 -> dataset3 Pipeline 2: dataset3-> activity3 -> dataset4</span></span>

<span data-ttu-id="e40ae-209">Si vous avez une autre fabrique de données avec un pipeline qui prend dataset4 (généré par le pipeline 2 dans DataFactory1), marquez dataset4 comme un jeu de données externe, car il a été généré par une autre fabrique de données (DataFactory1, et non DataFactory2).</span><span class="sxs-lookup"><span data-stu-id="e40ae-209">If you have another data factory with a pipeline that takes dataset4 (produced by pipeline 2 in data factory 1), mark dataset4 as an external dataset because the dataset is produced by a different data factory (DataFactory1, not DataFactory2).</span></span>  

<span data-ttu-id="e40ae-210">**DataFactory2**  </span><span class="sxs-lookup"><span data-stu-id="e40ae-210">**DataFactory2**  </span></span>  
<span data-ttu-id="e40ae-211">Pipeline 1 : dataset4->activity4->dataset5</span><span class="sxs-lookup"><span data-stu-id="e40ae-211">Pipeline 1: dataset4->activity4->dataset5</span></span>

<span data-ttu-id="e40ae-212">Si la propriété « external » est définie correctement, vérifiez que les données d’entrée se trouvent bien dans l’emplacement spécifié dans la définition du jeu de données d’entrée.</span><span class="sxs-lookup"><span data-stu-id="e40ae-212">If the external property is properly set, verify whether the input data exists in the location specified in the input dataset definition.</span></span>

### <a name="how-to-run-a-slice-at-another-time-than-midnight-when-the-slice-is-being-produced-daily"></a><span data-ttu-id="e40ae-213">Comment choisir une heure d’exécution autre que minuit pour une tranche qui est générée quotidiennement ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-213">How to run a slice at another time than midnight when the slice is being produced daily?</span></span>
<span data-ttu-id="e40ae-214">Utilisez la propriété **offset** pour spécifier l’heure à laquelle la tranche doit être générée.</span><span class="sxs-lookup"><span data-stu-id="e40ae-214">Use the **offset** property to specify the time at which you want the slice to be produced.</span></span> <span data-ttu-id="e40ae-215">Pour plus d’informations sur cette propriété, consultez la section [Disponibilité du jeu de données](data-factory-create-datasets.md#dataset-availability) .</span><span class="sxs-lookup"><span data-stu-id="e40ae-215">See [Dataset availability](data-factory-create-datasets.md#dataset-availability) section for details about this property.</span></span> <span data-ttu-id="e40ae-216">Voici un exemple rapide :</span><span class="sxs-lookup"><span data-stu-id="e40ae-216">Here is a quick example:</span></span>

```json
"availability":
{
    "frequency": "Day",
    "interval": 1,
    "offset": "06:00:00"
}
```
<span data-ttu-id="e40ae-217">Les tranches quotidiennes commencent à **6 h** au lieu de minuit, qui est l’heure par défaut.</span><span class="sxs-lookup"><span data-stu-id="e40ae-217">Daily slices start at **6 AM** instead of the default midnight.</span></span>     

### <a name="how-can-i-rerun-a-slice"></a><span data-ttu-id="e40ae-218">Comment puis-je réexécuter une tranche ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-218">How can I rerun a slice?</span></span>
<span data-ttu-id="e40ae-219">Vous pouvez réexécuter une tranche de l'une des manières suivantes :</span><span class="sxs-lookup"><span data-stu-id="e40ae-219">You can rerun a slice in one of the following ways:</span></span>

* <span data-ttu-id="e40ae-220">Utilisez l’application Surveiller et gérer pour réexécuter une fenêtre d’activité ou une tranche.</span><span class="sxs-lookup"><span data-stu-id="e40ae-220">Use Monitor and Manage App to rerun an activity window or slice.</span></span> <span data-ttu-id="e40ae-221">Pour obtenir des instructions, consultez [Réexécuter les fenêtres d’activité sélectionnées](data-factory-monitor-manage-app.md#perform-batch-actions) .</span><span class="sxs-lookup"><span data-stu-id="e40ae-221">See [Rerun selected activity windows](data-factory-monitor-manage-app.md#perform-batch-actions) for instructions.</span></span>   
* <span data-ttu-id="e40ae-222">Cliquez sur **Exécuter** dans la barre de commandes du panneau **TRANCHE DE DONNÉES** de la tranche, dans le portail Azure.</span><span class="sxs-lookup"><span data-stu-id="e40ae-222">Click **Run** in the command bar on the **DATA SLICE** blade for the slice in the Azure portal.</span></span>
* <span data-ttu-id="e40ae-223">Exécutez l’applet de commande **Set-AzureRmDataFactorySliceStatus** en ayant affecté la valeur **En attente** à l’état de la tranche.</span><span class="sxs-lookup"><span data-stu-id="e40ae-223">Run **Set-AzureRmDataFactorySliceStatus** cmdlet with Status set to **Waiting** for the slice.</span></span>   

    ```PowerShell
    Set-AzureRmDataFactorySliceStatus -Status Waiting -ResourceGroupName $ResourceGroup -DataFactoryName $df -TableName $table -StartDateTime "02/26/2015 19:00:00" -EndDateTime "02/26/2015 20:00:00"
    ```
<span data-ttu-id="e40ae-224">Consultez [Set-AzureRmDataFactorySliceStatus][set-azure-datafactory-slice-status] pour plus d’informations sur l’applet de commande.</span><span class="sxs-lookup"><span data-stu-id="e40ae-224">See [Set-AzureRmDataFactorySliceStatus][set-azure-datafactory-slice-status] for details about the cmdlet.</span></span>

### <a name="how-long-did-it-take-to-process-a-slice"></a><span data-ttu-id="e40ae-225">Combien de temps dure le traitement d'une tranche ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-225">How long did it take to process a slice?</span></span>
<span data-ttu-id="e40ae-226">Utilisez l’Explorateur de fenêtres d’activité dans l’application Surveiller et gérer pour connaître la durée du traitement d’une tranche de données.</span><span class="sxs-lookup"><span data-stu-id="e40ae-226">Use Activity Window Explorer in Monitor & Manage App to know how long it took to process a data slice.</span></span> <span data-ttu-id="e40ae-227">Pour plus d’informations, consultez [Explorateur de fenêtres d’activité](data-factory-monitor-manage-app.md#activity-window-explorer) .</span><span class="sxs-lookup"><span data-stu-id="e40ae-227">See [Activity Window Explorer](data-factory-monitor-manage-app.md#activity-window-explorer) for details.</span></span>

<span data-ttu-id="e40ae-228">Vous pouvez également faire ce qui suit dans le portail Azure :</span><span class="sxs-lookup"><span data-stu-id="e40ae-228">You can also do the following in the Azure portal:</span></span>  

1. <span data-ttu-id="e40ae-229">Cliquez sur la vignette **Jeux de données** dans le panneau **DATA FACTORY** de votre fabrique de données.</span><span class="sxs-lookup"><span data-stu-id="e40ae-229">Click **Datasets** tile on the **DATA FACTORY** blade for your data factory.</span></span>
2. <span data-ttu-id="e40ae-230">Cliquez sur le jeu de données spécifique dans le panneau **Jeux de données** .</span><span class="sxs-lookup"><span data-stu-id="e40ae-230">Click the specific dataset on the **Datasets** blade.</span></span>
3. <span data-ttu-id="e40ae-231">Sélectionnez la tranche qui vous intéresse dans la liste **Tranches récentes** située dans le panneau **TABLE**.</span><span class="sxs-lookup"><span data-stu-id="e40ae-231">Select the slice that you are interested in from the **Recent slices** list on the **TABLE** blade.</span></span>
4. <span data-ttu-id="e40ae-232">Cliquez sur l'exécution dans la liste **Exécutions d’activité** située dans le panneau **TRANCHE DE DONNÉES**.</span><span class="sxs-lookup"><span data-stu-id="e40ae-232">Click the activity run from the **Activity Runs** list on the **DATA SLICE** blade.</span></span>
5. <span data-ttu-id="e40ae-233">Cliquez sur la vignette **Propriétés** dans le panneau **DÉTAILS DE L’EXÉCUTION D’ACTIVITÉ**.</span><span class="sxs-lookup"><span data-stu-id="e40ae-233">Click **Properties** tile on the **ACTIVITY RUN DETAILS** blade.</span></span>
6. <span data-ttu-id="e40ae-234">Une valeur doit apparaître dans le champ **DURÉE** .</span><span class="sxs-lookup"><span data-stu-id="e40ae-234">You should see the **DURATION** field with a value.</span></span> <span data-ttu-id="e40ae-235">Il s’agit du temps nécessaire pour traiter la tranche.</span><span class="sxs-lookup"><span data-stu-id="e40ae-235">This value is the time taken to process the slice.</span></span>   

### <a name="how-to-stop-a-running-slice"></a><span data-ttu-id="e40ae-236">Comment arrêter une tranche en cours d'exécution ?</span><span class="sxs-lookup"><span data-stu-id="e40ae-236">How to stop a running slice?</span></span>
<span data-ttu-id="e40ae-237">Si vous devez arrêter l’exécution du pipeline, vous pouvez utiliser l’applet de commande [Suspend-AzureRmDataFactoryPipeline](/powershell/module/azurerm.datafactories/suspend-azurermdatafactorypipeline) .</span><span class="sxs-lookup"><span data-stu-id="e40ae-237">If you need to stop the pipeline from executing, you can use [Suspend-AzureRmDataFactoryPipeline](/powershell/module/azurerm.datafactories/suspend-azurermdatafactorypipeline) cmdlet.</span></span> <span data-ttu-id="e40ae-238">Actuellement, l'interruption du pipeline n'arrête pas les exécutions de tranche en cours.</span><span class="sxs-lookup"><span data-stu-id="e40ae-238">Currently, suspending the pipeline does not stop the slice executions that are in progress.</span></span> <span data-ttu-id="e40ae-239">Une fois que les exécutions en cours sont terminées, aucune tranche supplémentaire n'est récupérée.</span><span class="sxs-lookup"><span data-stu-id="e40ae-239">Once the in-progress executions finish, no extra slice is picked up.</span></span>

<span data-ttu-id="e40ae-240">Si vous voulez vraiment arrêter immédiatement toutes les exécutions, le seul moyen est de supprimer le pipeline et de le recréer.</span><span class="sxs-lookup"><span data-stu-id="e40ae-240">If you really want to stop all the executions immediately, the only way would be to delete the pipeline and create it again.</span></span> <span data-ttu-id="e40ae-241">Si vous choisissez de supprimer le pipeline, il est INUTILE de supprimer les tables et les services liés qu'il utilise.</span><span class="sxs-lookup"><span data-stu-id="e40ae-241">If you choose to delete the pipeline, you do NOT need to delete tables and linked services used by the pipeline.</span></span>

[create-factory-using-dotnet-sdk]: data-factory-create-data-factories-programmatically.md
[msdn-class-library-reference]: /dotnet/api/microsoft.azure.management.datafactories.models
[msdn-rest-api-reference]: /rest/api/datafactory/

[adf-powershell-reference]: /powershell/resourcemanager/azurerm.datafactories/v2.3.0/azurerm.datafactories
[azure-portal]: http://portal.azure.com
[set-azure-datafactory-slice-status]: /powershell/resourcemanager/azurerm.datafactories/v2.3.0/set-azurermdatafactoryslicestatus

[adf-pricing-details]: http://go.microsoft.com/fwlink/?LinkId=517777
[hdinsight-supported-regions]: http://azure.microsoft.com/pricing/details/hdinsight/
[hdinsight-alternate-storage]: http://social.technet.microsoft.com/wiki/contents/articles/23256.using-an-hdinsight-cluster-with-alternate-storage-accounts-and-metastores.aspx
[hdinsight-alternate-storage-2]: http://blogs.msdn.com/b/cindygross/archive/2014/05/05/use-additional-storage-accounts-with-hdinsight-hive.aspx
