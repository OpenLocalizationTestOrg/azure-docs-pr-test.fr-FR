---
title: "Créer votre première fabrique de données Azure (Visual Studio) | Microsoft Docs"
description: "Dans ce didacticiel, vous allez créer un exemple de pipeline Azure Data Factory avec Visual Studio."
services: data-factory
documentationcenter: 
author: spelluru
manager: jhubbard
editor: monicar
ms.assetid: 7398c0c9-7a03-4628-94b3-f2aaef4a72c5
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: hero-article
ms.date: 07/10/2017
ms.author: spelluru
ms.openlocfilehash: 77042219cbe698a33ab9447aa952586772897241
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 08/29/2017
---
# <a name="tutorial-create-a-data-factory-by-using-visual-studio"></a><span data-ttu-id="8ad03-103">Didacticiel : Créer une fabrique de données à l’aide de Visual Studio</span><span class="sxs-lookup"><span data-stu-id="8ad03-103">Tutorial: Create a data factory by using Visual Studio</span></span>
> [!div class="op_single_selector" title="Tools/SDKs"]
> * [<span data-ttu-id="8ad03-104">Vue d’ensemble et étapes préalables requises</span><span class="sxs-lookup"><span data-stu-id="8ad03-104">Overview and prerequisites</span></span>](data-factory-build-your-first-pipeline.md)
> * [<span data-ttu-id="8ad03-105">Portail Azure</span><span class="sxs-lookup"><span data-stu-id="8ad03-105">Azure portal</span></span>](data-factory-build-your-first-pipeline-using-editor.md)
> * [<span data-ttu-id="8ad03-106">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="8ad03-106">Visual Studio</span></span>](data-factory-build-your-first-pipeline-using-vs.md)
> * [<span data-ttu-id="8ad03-107">PowerShell</span><span class="sxs-lookup"><span data-stu-id="8ad03-107">PowerShell</span></span>](data-factory-build-your-first-pipeline-using-powershell.md)
> * [<span data-ttu-id="8ad03-108">Modèle Resource Manager</span><span class="sxs-lookup"><span data-stu-id="8ad03-108">Resource Manager Template</span></span>](data-factory-build-your-first-pipeline-using-arm.md)
> * [<span data-ttu-id="8ad03-109">API REST</span><span class="sxs-lookup"><span data-stu-id="8ad03-109">REST API</span></span>](data-factory-build-your-first-pipeline-using-rest-api.md)

<span data-ttu-id="8ad03-110">Ce didacticiel vous explique comment créer une fabrique de données Azure à l’aide de Visual Studio.</span><span class="sxs-lookup"><span data-stu-id="8ad03-110">This tutorial shows you how to create an Azure data factory by using Visual Studio.</span></span> <span data-ttu-id="8ad03-111">Vous allez créer un projet Visual Studio à l’aide du modèle de projet Data Factory, puis définir des entités Data Factory (services liés, jeux de données et pipeline) au format JSON et vous allez terminer en publiant/déployant ces entités dans le cloud.</span><span class="sxs-lookup"><span data-stu-id="8ad03-111">You create a Visual Studio project using the Data Factory project template, define Data Factory entities (linked services, datasets, and pipeline) in JSON format, and then publish/deploy these entities to the cloud.</span></span> 

<span data-ttu-id="8ad03-112">Le pipeline dans ce didacticiel a une activité : **Activité HDInsight Hive**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-112">The pipeline in this tutorial has one activity: **HDInsight Hive activity**.</span></span> <span data-ttu-id="8ad03-113">Cette activité exécute un script Hive sur un cluster HDInsight qui transforme des données d’entrée pour produire des données de sortie.</span><span class="sxs-lookup"><span data-stu-id="8ad03-113">This activity runs a hive script on an Azure HDInsight cluster that transforms input data to produce output data.</span></span> <span data-ttu-id="8ad03-114">Le pipeline est programmé pour s’exécuter une fois par mois entre les heures de début et de fin spécifiées.</span><span class="sxs-lookup"><span data-stu-id="8ad03-114">The pipeline is scheduled to run once a month between the specified start and end times.</span></span> 

> [!NOTE]
> <span data-ttu-id="8ad03-115">Ce didacticiel n’explique pas comment copier des données à l’aide d’Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="8ad03-115">This tutorial does not show how copy data by using Azure Data Factory.</span></span> <span data-ttu-id="8ad03-116">Pour un didacticiel sur la copie de données à l’aide d’Azure Data Factory, consultez [Copie de données Blob Storage vers une base de données SQL à l’aide de Data Factory](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="8ad03-116">For a tutorial on how to copy data using Azure Data Factory, see [Tutorial: Copy data from Blob Storage to SQL Database](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>
> 
> <span data-ttu-id="8ad03-117">Un pipeline peut contenir plusieurs activités.</span><span class="sxs-lookup"><span data-stu-id="8ad03-117">A pipeline can have more than one activity.</span></span> <span data-ttu-id="8ad03-118">En outre, vous pouvez chaîner deux activités (une après l’autre) en configurant le jeu de données de sortie d’une activité en tant que jeu de données d’entrée de l’autre activité.</span><span class="sxs-lookup"><span data-stu-id="8ad03-118">And, you can chain two activities (run one activity after another) by setting the output dataset of one activity as the input dataset of the other activity.</span></span> <span data-ttu-id="8ad03-119">Pour plus d’informations, consultez [Planification et exécution dans Data Factory](data-factory-scheduling-and-execution.md#multiple-activities-in-a-pipeline).</span><span class="sxs-lookup"><span data-stu-id="8ad03-119">For more information, see [scheduling and execution in Data Factory](data-factory-scheduling-and-execution.md#multiple-activities-in-a-pipeline).</span></span>


## <a name="walkthrough-create-and-publish-data-factory-entities"></a><span data-ttu-id="8ad03-120">Procédure pas à pas : Création et publication d’entités Data Factory</span><span class="sxs-lookup"><span data-stu-id="8ad03-120">Walkthrough: Create and publish Data Factory entities</span></span>
<span data-ttu-id="8ad03-121">Voici les étapes à effectuer dans le cadre de cette procédure pas à pas :</span><span class="sxs-lookup"><span data-stu-id="8ad03-121">Here are the steps you perform as part of this walkthrough:</span></span>

1. <span data-ttu-id="8ad03-122">Créez deux services liés : **AzureStorageLinkedService1** et **HDInsightOnDemandLinkedService1**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-122">Create two linked services: **AzureStorageLinkedService1** and **HDInsightOnDemandLinkedService1**.</span></span> 
   
    <span data-ttu-id="8ad03-123">Dans ce didacticiel, les données d’entrée et de sortie de l’activité Hive se trouvent dans le même Stockage Blob Azure.</span><span class="sxs-lookup"><span data-stu-id="8ad03-123">In this tutorial, both input and output data for the hive activity are in the same Azure Blob Storage.</span></span> <span data-ttu-id="8ad03-124">Vous utilisez un cluster HDInsight à la demande pour traiter les données d’entrée existantes afin de produire les données de sortie.</span><span class="sxs-lookup"><span data-stu-id="8ad03-124">You use an on-demand HDInsight cluster to process existing input data to produce output data.</span></span> <span data-ttu-id="8ad03-125">Le cluster HDInsight à la demande est automatiquement créé pour vous par Azure Data Factory au moment de l’exécution, lorsque les données d’entrée sont prêtes à être traitées.</span><span class="sxs-lookup"><span data-stu-id="8ad03-125">The on-demand HDInsight cluster is automatically created for you by Azure Data Factory at run time when the input data is ready to be processed.</span></span> <span data-ttu-id="8ad03-126">Vous devez lier vos magasins de données ou vos services de calcul à votre fabrique de données, de façon que le service Data Factory puisse s’y connecter au moment de l’exécution.</span><span class="sxs-lookup"><span data-stu-id="8ad03-126">You need to link your data stores or computes to your data factory so that the Data Factory service can connect to them at runtime.</span></span> <span data-ttu-id="8ad03-127">Par conséquent, vous liez votre compte de stockage Azure à la fabrique de données à l’aide d’AzureStorageLinkedService1 et vous liez un cluster HDInsight à la demande à l’aide de HDInsightOnDemandLinkedService1.</span><span class="sxs-lookup"><span data-stu-id="8ad03-127">Therefore, you link your Azure Storage Account to the data factory by using the AzureStorageLinkedService1, and link an on-demand HDInsight cluster by using the HDInsightOnDemandLinkedService1.</span></span> <span data-ttu-id="8ad03-128">Lors de la publication, vous spécifiez le nom de la fabrique de données à créer ou une fabrique de données existante.</span><span class="sxs-lookup"><span data-stu-id="8ad03-128">When publishing, you specify the name for the data factory to be created or an existing data factory.</span></span>  
2. <span data-ttu-id="8ad03-129">Créez deux jeux de données : **InputDataset** et **OutputDataset**, qui représentent les données d’entrée/de sortie stockées dans le Stockage Blob Azure.</span><span class="sxs-lookup"><span data-stu-id="8ad03-129">Create two datasets: **InputDataset** and **OutputDataset**, which represent the input/output data that is stored in the Azure blob storage.</span></span> 
   
    <span data-ttu-id="8ad03-130">Ces définitions de jeu de données font référence au service lié Azure Storage que vous avez créé à l’étape précédente.</span><span class="sxs-lookup"><span data-stu-id="8ad03-130">These dataset definitions refer to the Azure Storage linked service you created in the previous step.</span></span> <span data-ttu-id="8ad03-131">Pour InputDataset, vous spécifiez le conteneur de blobs (adfgetstarted) et le dossier (inputdata) qui contient un blob avec les données d’entrée.</span><span class="sxs-lookup"><span data-stu-id="8ad03-131">For the InputDataset, you specify the blob container (adfgetstarted) and the folder (inptutdata) that contains a blob with the input data.</span></span> <span data-ttu-id="8ad03-132">Pour OutputDataset, vous spécifiez le conteneur de blobs (adfgetstarted) et le dossier (partitioneddata) qui contient les données de sortie.</span><span class="sxs-lookup"><span data-stu-id="8ad03-132">For the OutputDataset, you specify the blob container (adfgetstarted) and the folder (partitioneddata) that holds the output data.</span></span> <span data-ttu-id="8ad03-133">Vous spécifiez également d’autres propriétés telles que la structure, la disponibilité et la stratégie.</span><span class="sxs-lookup"><span data-stu-id="8ad03-133">You also specify other properties such as structure, availability, and policy.</span></span>
3. <span data-ttu-id="8ad03-134">Créez un pipeline nommé **MyFirstPipeline**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-134">Create a pipeline named **MyFirstPipeline**.</span></span> 
  
    <span data-ttu-id="8ad03-135">Dans cette procédure pas à pas, le pipeline a une seule activité : **Activité HDInsight Hive**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-135">In this walkthrough, the pipeline has only one activity: **HDInsight Hive Activity**.</span></span> <span data-ttu-id="8ad03-136">Cette activité transforme des données d’entrée pour produire des données de sortie en exécutant un script Hive sur un cluster HDInsight à la demande.</span><span class="sxs-lookup"><span data-stu-id="8ad03-136">This activity transform input data to produce output data by running a hive script on an on-demand HDInsight cluster.</span></span> <span data-ttu-id="8ad03-137">Pour en savoir plus sur l’activité Hive, consultez [Transformer des données à l’aide d’une activité Hive dans Azure Data Factory](data-factory-hive-activity.md).</span><span class="sxs-lookup"><span data-stu-id="8ad03-137">To learn more about hive activity, see [Hive Activity](data-factory-hive-activity.md)</span></span> 
4. <span data-ttu-id="8ad03-138">Créez une fabrique de données nommée **DataFactoryUsingVS**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-138">Create a data factory named **DataFactoryUsingVS**.</span></span> <span data-ttu-id="8ad03-139">Déployez la fabrique de données et toutes les entités Data Factory (services liés, tables et pipeline).</span><span class="sxs-lookup"><span data-stu-id="8ad03-139">Deploy the data factory and all Data Factory entities (linked services, tables, and the pipeline).</span></span>
5. <span data-ttu-id="8ad03-140">Après la publication, utilisez les panneaux du portail Azure et l’application de surveillance et gestion pour surveiller le pipeline.</span><span class="sxs-lookup"><span data-stu-id="8ad03-140">After you publish, you use Azure portal blades and Monitoring & Management App to monitor the pipeline.</span></span> 
  
### <a name="prerequisites"></a><span data-ttu-id="8ad03-141">Composants requis</span><span class="sxs-lookup"><span data-stu-id="8ad03-141">Prerequisites</span></span>
1. <span data-ttu-id="8ad03-142">Lisez l’article [Vue d’ensemble du didacticiel](data-factory-build-your-first-pipeline.md) et effectuez les étapes **préalables** .</span><span class="sxs-lookup"><span data-stu-id="8ad03-142">Read through [Tutorial Overview](data-factory-build-your-first-pipeline.md) article and complete the **prerequisite** steps.</span></span> <span data-ttu-id="8ad03-143">Vous pouvez également sélectionner l’option **Vue d’ensemble et étapes préalables requises** de la liste déroulante figurant en haut de la page pour basculer vers l’article correspondant.</span><span class="sxs-lookup"><span data-stu-id="8ad03-143">You can also select the **Overview and prerequisites** option in the drop-down list at the top to switch to the article.</span></span> <span data-ttu-id="8ad03-144">Une fois les étapes préalables suivies, revenez à cet article en sélectionnant l’option **Visual Studio** dans la liste déroulante.</span><span class="sxs-lookup"><span data-stu-id="8ad03-144">After you complete the prerequisites, switch back to this article by selecting **Visual Studio** option in the drop-down list.</span></span>
2. <span data-ttu-id="8ad03-145">Pour créer des instances Data Factory, vous devez avoir un rôle de [collaborateur de fabrique de données](../active-directory/role-based-access-built-in-roles.md#data-factory-contributor) au niveau de l’abonnement/du groupe de ressources.</span><span class="sxs-lookup"><span data-stu-id="8ad03-145">To create Data Factory instances, you must be a member of the [Data Factory Contributor](../active-directory/role-based-access-built-in-roles.md#data-factory-contributor) role at the subscription/resource group level.</span></span>  
3. <span data-ttu-id="8ad03-146">Les composants suivants doivent être installés sur votre ordinateur :</span><span class="sxs-lookup"><span data-stu-id="8ad03-146">You must have the following installed on your computer:</span></span>
   * <span data-ttu-id="8ad03-147">Visual Studio 2013 ou Visual Studio 2015</span><span class="sxs-lookup"><span data-stu-id="8ad03-147">Visual Studio 2013 or Visual Studio 2015</span></span>
   * <span data-ttu-id="8ad03-148">Téléchargez le Kit de développement logiciel (SDK) Azure pour Visual Studio 2013 ou Visual Studio 2015.</span><span class="sxs-lookup"><span data-stu-id="8ad03-148">Download Azure SDK for Visual Studio 2013 or Visual Studio 2015.</span></span> <span data-ttu-id="8ad03-149">Accédez à la [page de téléchargement d’Azure](https://azure.microsoft.com/downloads/), puis cliquez sur **VS 2013** ou **VS 2015** dans la section **.NET**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-149">Navigate to [Azure Download Page](https://azure.microsoft.com/downloads/) and click **VS 2013** or **VS 2015** in the **.NET** section.</span></span>
   * <span data-ttu-id="8ad03-150">Téléchargez le dernier plug-in Azure Data Factory pour Visual Studio : [VS 2013](https://visualstudiogallery.msdn.microsoft.com/754d998c-8f92-4aa7-835b-e89c8c954aa5) ou [VS 2015](https://visualstudiogallery.msdn.microsoft.com/371a4cf9-0093-40fa-b7dd-be3c74f49005).</span><span class="sxs-lookup"><span data-stu-id="8ad03-150">Download the latest Azure Data Factory plugin for Visual Studio: [VS 2013](https://visualstudiogallery.msdn.microsoft.com/754d998c-8f92-4aa7-835b-e89c8c954aa5) or [VS 2015](https://visualstudiogallery.msdn.microsoft.com/371a4cf9-0093-40fa-b7dd-be3c74f49005).</span></span> <span data-ttu-id="8ad03-151">Vous pouvez également mettre à jour le plug-in en procédant comme suit : dans le menu, cliquez sur **Outils** -> **Extensions et mises à jour** -> **En ligne** -> **Galerie Visual Studio** -> **Outils Microsoft Azure Data Factory pour Visual Studio** -> **Mettre à jour**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-151">You can also update the plugin by doing the following steps: On the menu, click **Tools** -> **Extensions and Updates** -> **Online** -> **Visual Studio Gallery** -> **Microsoft Azure Data Factory Tools for Visual Studio** -> **Update**.</span></span>

<span data-ttu-id="8ad03-152">À présent, utilisons Visual Studio pour créer une fabrique de données Azure.</span><span class="sxs-lookup"><span data-stu-id="8ad03-152">Now, let's use Visual Studio to create an Azure data factory.</span></span>

### <a name="create-visual-studio-project"></a><span data-ttu-id="8ad03-153">Création d’un projet Visual Studio</span><span class="sxs-lookup"><span data-stu-id="8ad03-153">Create Visual Studio project</span></span>
1. <span data-ttu-id="8ad03-154">Lancez **Visual Studio 2013** ou **Visual Studio 2015**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-154">Launch **Visual Studio 2013** or **Visual Studio 2015**.</span></span> <span data-ttu-id="8ad03-155">Cliquez sur **Fichier**, pointez le curseur de la souris sur **Nouveau**, puis cliquez sur **Projet**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-155">Click **File**, point to **New**, and click **Project**.</span></span> <span data-ttu-id="8ad03-156">La boîte de dialogue **Nouveau projet** doit s’afficher.</span><span class="sxs-lookup"><span data-stu-id="8ad03-156">You should see the **New Project** dialog box.</span></span>  
2. <span data-ttu-id="8ad03-157">Dans la boîte de dialogue **Nouveau projet**, sélectionnez le modèle **DataFactory**, puis cliquez sur **Projet Data Factory vide**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-157">In the **New Project** dialog, select the **DataFactory** template, and click **Empty Data Factory Project**.</span></span>   

    ![Boîte de dialogue Nouveau projet](./media/data-factory-build-your-first-pipeline-using-vs/new-project-dialog.png)
3. <span data-ttu-id="8ad03-159">Entrez le **nom** du projet, son **emplacement** et le nom de la **solution**, puis cliquez sur **OK**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-159">Enter a **name** for the project, **location**, and a name for the **solution**, and click **OK**.</span></span>

    ![Explorateur de solutions](./media/data-factory-build-your-first-pipeline-using-vs/solution-explorer.png)

### <a name="create-linked-services"></a><span data-ttu-id="8ad03-161">Créer des services liés</span><span class="sxs-lookup"><span data-stu-id="8ad03-161">Create linked services</span></span>
<span data-ttu-id="8ad03-162">Au cours de cette étape, vous allez créer deux services liés : **Stockage Azure** et **HDInsight à la demande**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-162">In this step, you create two linked services: **Azure Storage** and **HDInsight on-demand**.</span></span> 

<span data-ttu-id="8ad03-163">Le service lié Stockage Azure lie votre compte de stockage Azure à la fabrique de données en fournissant les informations de connexion.</span><span class="sxs-lookup"><span data-stu-id="8ad03-163">The Azure Storage linked service links your Azure Storage account to the data factory by providing the connection information.</span></span> <span data-ttu-id="8ad03-164">Le service Data Factory utilise la chaîne de connexion à partir du paramètre de service lié pour se connecter au stockage Azure lors de l’exécution.</span><span class="sxs-lookup"><span data-stu-id="8ad03-164">Data Factory service uses the connection string from the linked service setting to connect to the Azure storage at runtime.</span></span> <span data-ttu-id="8ad03-165">Ce stockage contient les données d’entrée et de sortie pour le pipeline et le fichier de script Hive utilisé par l’activité Hive.</span><span class="sxs-lookup"><span data-stu-id="8ad03-165">This storage holds input and output data for the pipeline, and the hive script file used by the hive activity.</span></span> 

<span data-ttu-id="8ad03-166">Avec le service lié HDInsight à la demande, le cluster HDInsight à la demande est automatiquement créé au moment de l’exécution, lorsque les données d’entrée sont prêtes à être traitées.</span><span class="sxs-lookup"><span data-stu-id="8ad03-166">With on-demand HDInsight linked service, The HDInsight cluster is automatically created at runtime when the input data is ready to processed.</span></span> <span data-ttu-id="8ad03-167">Le cluster est supprimé une fois le traitement terminé et au terme du délai d’inactivité spécifié.</span><span class="sxs-lookup"><span data-stu-id="8ad03-167">The cluster is deleted after it is done processing and idle for the specified amount of time.</span></span> 

> [!NOTE]
> <span data-ttu-id="8ad03-168">Vous créez une fabrique de données en spécifiant son nom et ses paramètres au moment de la publication de votre solution Data Factory.</span><span class="sxs-lookup"><span data-stu-id="8ad03-168">You create a data factory by specifying its name and settings at the time of publishing your Data Factory solution.</span></span>

#### <a name="create-azure-storage-linked-service"></a><span data-ttu-id="8ad03-169">Créer le service lié Azure Storage</span><span class="sxs-lookup"><span data-stu-id="8ad03-169">Create Azure Storage linked service</span></span>
1. <span data-ttu-id="8ad03-170">Dans l’Explorateur de solutions, cliquez avec le bouton droit sur **Services liés**, pointez sur **Ajouter**, puis cliquez sur **Nouvel élément**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-170">Right-click **Linked Services** in the solution explorer, point to **Add**, and click **New Item**.</span></span>      
2. <span data-ttu-id="8ad03-171">Dans la boîte de dialogue **Ajouter un nouvel élément**, sélectionnez **Service lié Azure Storage** dans la liste, puis cliquez sur **Ajouter**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-171">In the **Add New Item** dialog box, select **Azure Storage Linked Service** from the list, and click **Add**.</span></span>
    <span data-ttu-id="8ad03-172">![Service lié Azure Storage](./media/data-factory-build-your-first-pipeline-using-vs/new-azure-storage-linked-service.png)</span><span class="sxs-lookup"><span data-stu-id="8ad03-172">![Azure Storage Linked Service](./media/data-factory-build-your-first-pipeline-using-vs/new-azure-storage-linked-service.png)</span></span>
3. <span data-ttu-id="8ad03-173">Remplacez `<accountname>` et `<accountkey>` par le nom de votre compte de stockage Azure et par sa clé.</span><span class="sxs-lookup"><span data-stu-id="8ad03-173">Replace `<accountname>` and `<accountkey>` with the name of your Azure storage account and its key.</span></span> <span data-ttu-id="8ad03-174">Pour savoir comment obtenir votre clé d’accès de stockage, reportez-vous aux informations sur l’affichage, la copie et la régénération de clés d’accès de stockage dans [Gérer votre compte de stockage](../storage/common/storage-create-storage-account.md#manage-your-storage-account).</span><span class="sxs-lookup"><span data-stu-id="8ad03-174">To learn how to get your storage access key, see the information about how to view, copy, and regenerate storage access keys in [Manage your storage account](../storage/common/storage-create-storage-account.md#manage-your-storage-account).</span></span>
    <span data-ttu-id="8ad03-175">![Service lié Azure Storage](./media/data-factory-build-your-first-pipeline-using-vs/azure-storage-linked-service.png)</span><span class="sxs-lookup"><span data-stu-id="8ad03-175">![Azure Storage Linked Service](./media/data-factory-build-your-first-pipeline-using-vs/azure-storage-linked-service.png)</span></span>
4. <span data-ttu-id="8ad03-176">Enregistrez le fichier **AzureStorageLinkedService1.json** .</span><span class="sxs-lookup"><span data-stu-id="8ad03-176">Save the **AzureStorageLinkedService1.json** file.</span></span>

#### <a name="create-azure-hdinsight-linked-service"></a><span data-ttu-id="8ad03-177">Créer le service lié Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="8ad03-177">Create Azure HDInsight linked service</span></span>
1. <span data-ttu-id="8ad03-178">Dans l’**Explorateur de solutions**, cliquez avec le bouton droit sur **Services liés**, pointez sur **Ajouter** puis cliquez sur **Nouvel élément**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-178">In the **Solution Explorer**, right-click **Linked Services**, point to **Add**, and click **New Item**.</span></span>
2. <span data-ttu-id="8ad03-179">Sélectionnez **Service lié à la demande HDInsight** puis cliquez sur **Ajouter**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-179">Select **HDInsight On Demand Linked Service**, and click **Add**.</span></span>
3. <span data-ttu-id="8ad03-180">Remplacez le code **JSON** par le code JSON suivant :</span><span class="sxs-lookup"><span data-stu-id="8ad03-180">Replace the **JSON** with the following JSON:</span></span>

     ```json
    {
        "name": "HDInsightOnDemandLinkedService",
        "properties": {
        "type": "HDInsightOnDemand",
            "typeProperties": {
                "version": "3.5",
                "clusterSize": 1,
                "timeToLive": "00:05:00",
                "osType": "Linux",
                "linkedServiceName": "AzureStorageLinkedService1"
            }
        }
    }
    ```

    <span data-ttu-id="8ad03-181">Le tableau suivant décrit les propriétés JSON utilisées dans l'extrait de code :</span><span class="sxs-lookup"><span data-stu-id="8ad03-181">The following table provides descriptions for the JSON properties used in the snippet:</span></span>

    <span data-ttu-id="8ad03-182">Propriété</span><span class="sxs-lookup"><span data-stu-id="8ad03-182">Property</span></span> | <span data-ttu-id="8ad03-183">Description</span><span class="sxs-lookup"><span data-stu-id="8ad03-183">Description</span></span>
    -------- | ----------- 
    <span data-ttu-id="8ad03-184">ClusterSize</span><span class="sxs-lookup"><span data-stu-id="8ad03-184">ClusterSize</span></span> | <span data-ttu-id="8ad03-185">Spécifie la taille du cluster HDInsight Hadoop.</span><span class="sxs-lookup"><span data-stu-id="8ad03-185">Specifies the size of the HDInsight Hadoop cluster.</span></span>
    <span data-ttu-id="8ad03-186">TimeToLive</span><span class="sxs-lookup"><span data-stu-id="8ad03-186">TimeToLive</span></span> | <span data-ttu-id="8ad03-187">Spécifie la durée d’inactivité du cluster HDInsight avant sa suppression.</span><span class="sxs-lookup"><span data-stu-id="8ad03-187">Specifies that the idle time for the HDInsight cluster, before it is deleted.</span></span>
    <span data-ttu-id="8ad03-188">linkedServiceName</span><span class="sxs-lookup"><span data-stu-id="8ad03-188">linkedServiceName</span></span> | <span data-ttu-id="8ad03-189">Spécifie le compte de stockage utilisé pour stocker les journaux générés par le cluster HDInsight Hadoop.</span><span class="sxs-lookup"><span data-stu-id="8ad03-189">Specifies the storage account that is used to store the logs that are generated by HDInsight Hadoop cluster.</span></span> 

    > [!IMPORTANT]
    > <span data-ttu-id="8ad03-190">Le cluster HDInsight crée un **conteneur par défaut** dans le Stockage Blob que vous avez spécifié dans le code JSON (linkedServiceName).</span><span class="sxs-lookup"><span data-stu-id="8ad03-190">The HDInsight cluster creates a **default container** in the blob storage you specified in the JSON (linkedServiceName).</span></span> <span data-ttu-id="8ad03-191">HDInsight ne supprime pas ce conteneur lorsque le cluster est supprimé.</span><span class="sxs-lookup"><span data-stu-id="8ad03-191">HDInsight does not delete this container when the cluster is deleted.</span></span> <span data-ttu-id="8ad03-192">Ce comportement est normal.</span><span class="sxs-lookup"><span data-stu-id="8ad03-192">This behavior is by design.</span></span> <span data-ttu-id="8ad03-193">Avec le service lié HDInsight à la demande, un cluster HDInsight est créé dès qu’une tranche est traitée, à moins qu’il n’existe un cluster actif (timeToLive).</span><span class="sxs-lookup"><span data-stu-id="8ad03-193">With on-demand HDInsight linked service, a HDInsight cluster is created every time a slice is processed unless there is an existing live cluster (timeToLive).</span></span> <span data-ttu-id="8ad03-194">Ce cluster est supprimé, une fois le traitement terminé.</span><span class="sxs-lookup"><span data-stu-id="8ad03-194">The cluster is automatically deleted when the processing is done.</span></span>
    > 
    > <span data-ttu-id="8ad03-195">Comme un nombre croissant de tranches sont traitées, vous voyez un grand nombre de conteneurs dans votre stockage d’objets blob Azure.</span><span class="sxs-lookup"><span data-stu-id="8ad03-195">As more slices are processed, you see many containers in your Azure blob storage.</span></span> <span data-ttu-id="8ad03-196">Si vous n’en avez pas besoin pour dépanner les travaux, il se peut que vous deviez les supprimer pour réduire les frais de stockage.</span><span class="sxs-lookup"><span data-stu-id="8ad03-196">If you do not need them for troubleshooting of the jobs, you may want to delete them to reduce the storage cost.</span></span> <span data-ttu-id="8ad03-197">Les noms de ces conteneurs sont conformes au modèle suivant : `adf<yourdatafactoryname>-<linkedservicename>-datetimestamp`.</span><span class="sxs-lookup"><span data-stu-id="8ad03-197">The names of these containers follow a pattern: `adf<yourdatafactoryname>-<linkedservicename>-datetimestamp`.</span></span> <span data-ttu-id="8ad03-198">Utilisez des outils tels que [Microsoft Storage Explorer](http://storageexplorer.com/) pour supprimer des conteneurs dans votre stockage d’objets blob Azure.</span><span class="sxs-lookup"><span data-stu-id="8ad03-198">Use tools such as [Microsoft Storage Explorer](http://storageexplorer.com/) to delete containers in your Azure blob storage.</span></span>

    <span data-ttu-id="8ad03-199">Pour plus d’informations sur les propriétés JSON, consultez [Service lié à la demande Azure HDInsight](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service).</span><span class="sxs-lookup"><span data-stu-id="8ad03-199">For more information about JSON properties, see [Compute linked services](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service) article.</span></span> 
4. <span data-ttu-id="8ad03-200">Enregistrez le fichier **HDInsightOnDemandLinkedService1.json** .</span><span class="sxs-lookup"><span data-stu-id="8ad03-200">Save the **HDInsightOnDemandLinkedService1.json** file.</span></span>

### <a name="create-datasets"></a><span data-ttu-id="8ad03-201">Créer des jeux de données</span><span class="sxs-lookup"><span data-stu-id="8ad03-201">Create datasets</span></span>
<span data-ttu-id="8ad03-202">Dans cette étape, vous créez des jeux de données afin de représenter les données d’entrée et de sortie pour le traitement Hive.</span><span class="sxs-lookup"><span data-stu-id="8ad03-202">In this step, you create datasets to represent the input and output data for Hive processing.</span></span> <span data-ttu-id="8ad03-203">Ces jeux de données font référence au service **AzureStorageLinkedService1** que vous avez créé précédemment dans ce didacticiel.</span><span class="sxs-lookup"><span data-stu-id="8ad03-203">These datasets refer to the **AzureStorageLinkedService1** you have created earlier in this tutorial.</span></span> <span data-ttu-id="8ad03-204">Le service lié pointe vers un compte de stockage Azure, et les jeux de données spécifient le conteneur, le dossier et le nom de fichier dans le stockage qui contient les données d’entrée et de sortie.</span><span class="sxs-lookup"><span data-stu-id="8ad03-204">The linked service points to an Azure Storage account and datasets specify container, folder, file name in the storage that holds input and output data.</span></span>   

#### <a name="create-input-dataset"></a><span data-ttu-id="8ad03-205">Créer le jeu de données d’entrée</span><span class="sxs-lookup"><span data-stu-id="8ad03-205">Create input dataset</span></span>
1. <span data-ttu-id="8ad03-206">Dans l’**Explorateur de solutions**, cliquez avec le bouton droit sur **Tables**, pointez sur **Ajouter**, puis cliquez sur **Nouvel élément**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-206">In the **Solution Explorer**, right-click **Tables**, point to **Add**, and click **New Item**.</span></span>
2. <span data-ttu-id="8ad03-207">Sélectionnez **Objet blob Azure** dans la liste, changez le nom du fichier en **InputDataSet.json**, puis cliquez sur **Ajouter**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-207">Select **Azure Blob** from the list, change the name of the file to **InputDataSet.json**, and click **Add**.</span></span>
3. <span data-ttu-id="8ad03-208">Remplacez le code **JSON** dans l’éditeur par l’extrait de code JSON suivant :</span><span class="sxs-lookup"><span data-stu-id="8ad03-208">Replace the **JSON** in the editor with the following JSON snippet:</span></span>

    ```json
    {
        "name": "AzureBlobInput",
        "properties": {
            "type": "AzureBlob",
            "linkedServiceName": "AzureStorageLinkedService1",
            "typeProperties": {
                "fileName": "input.log",
                "folderPath": "adfgetstarted/inputdata",
                "format": {
                    "type": "TextFormat",
                    "columnDelimiter": ","
                }
            },
            "availability": {
                "frequency": "Month",
                "interval": 1
            },
            "external": true,
            "policy": {}
        }
    }
    ```
    <span data-ttu-id="8ad03-209">Cet extrait de code JSON définit un jeu de données appelé **AzureBlobInput** qui représente les données d’entrée de l’activité Hive dans le pipeline.</span><span class="sxs-lookup"><span data-stu-id="8ad03-209">This JSON snippet defines a dataset called **AzureBlobInput** that represents input data for the hive activity in the pipeline.</span></span> <span data-ttu-id="8ad03-210">Vous indiquez que les données d’entrée se trouvent dans le conteneur de blobs nommé `adfgetstarted` et dans le dossier nommé `inputdata`.</span><span class="sxs-lookup"><span data-stu-id="8ad03-210">You specify that the input data is located in the blob container called `adfgetstarted` and the folder called `inputdata`.</span></span>

    <span data-ttu-id="8ad03-211">Le tableau suivant décrit les propriétés JSON utilisées dans l'extrait de code :</span><span class="sxs-lookup"><span data-stu-id="8ad03-211">The following table provides descriptions for the JSON properties used in the snippet:</span></span>

    <span data-ttu-id="8ad03-212">Propriété</span><span class="sxs-lookup"><span data-stu-id="8ad03-212">Property</span></span> | <span data-ttu-id="8ad03-213">Description</span><span class="sxs-lookup"><span data-stu-id="8ad03-213">Description</span></span> |
    -------- | ----------- |
    <span data-ttu-id="8ad03-214">type</span><span class="sxs-lookup"><span data-stu-id="8ad03-214">type</span></span> |<span data-ttu-id="8ad03-215">La propriété de type est définie sur **AzureBlob**, car les données se trouvent dans le Stockage Blob Azure.</span><span class="sxs-lookup"><span data-stu-id="8ad03-215">The type property is set to **AzureBlob** because data resides in Azure Blob Storage.</span></span>
    <span data-ttu-id="8ad03-216">linkedServiceName</span><span class="sxs-lookup"><span data-stu-id="8ad03-216">linkedServiceName</span></span> | <span data-ttu-id="8ad03-217">Fait référence au service AzureStorageLinkedService1 que vous avez créé précédemment.</span><span class="sxs-lookup"><span data-stu-id="8ad03-217">Refers to the AzureStorageLinkedService1 you created earlier.</span></span>
    <span data-ttu-id="8ad03-218">fileName</span><span class="sxs-lookup"><span data-stu-id="8ad03-218">fileName</span></span> |<span data-ttu-id="8ad03-219">Cette propriété est facultative.</span><span class="sxs-lookup"><span data-stu-id="8ad03-219">This property is optional.</span></span> <span data-ttu-id="8ad03-220">Si vous omettez cette propriété, tous les fichiers spécifiés dans le paramètre folderPath sont récupérés.</span><span class="sxs-lookup"><span data-stu-id="8ad03-220">If you omit this property, all the files from the folderPath are picked.</span></span> <span data-ttu-id="8ad03-221">Dans le cas présent, seul le fichier input.log est traité.</span><span class="sxs-lookup"><span data-stu-id="8ad03-221">In this case, only the input.log is processed.</span></span>
    <span data-ttu-id="8ad03-222">type</span><span class="sxs-lookup"><span data-stu-id="8ad03-222">type</span></span> | <span data-ttu-id="8ad03-223">Les fichiers journaux sont au format texte : nous utilisons donc TextFormat.</span><span class="sxs-lookup"><span data-stu-id="8ad03-223">The log files are in text format, so we use TextFormat.</span></span> |
    <span data-ttu-id="8ad03-224">columnDelimiter</span><span class="sxs-lookup"><span data-stu-id="8ad03-224">columnDelimiter</span></span> | <span data-ttu-id="8ad03-225">Les colonnes des fichiers journaux sont délimitées par une virgule (`,`)</span><span class="sxs-lookup"><span data-stu-id="8ad03-225">columns in the log files are delimited by the comma character (`,`)</span></span>
    <span data-ttu-id="8ad03-226">frequency/interval</span><span class="sxs-lookup"><span data-stu-id="8ad03-226">frequency/interval</span></span> | <span data-ttu-id="8ad03-227">La fréquence est définie sur Mois et l’intervalle est 1, ce qui signifie que les segments d’entrée sont disponibles mensuellement.</span><span class="sxs-lookup"><span data-stu-id="8ad03-227">frequency set to Month and interval is 1, which means that the input slices are available monthly.</span></span>
    <span data-ttu-id="8ad03-228">external</span><span class="sxs-lookup"><span data-stu-id="8ad03-228">external</span></span> | <span data-ttu-id="8ad03-229">Cette propriété a la valeur true si les données d’entrée de l’activité ne sont pas générées par le pipeline.</span><span class="sxs-lookup"><span data-stu-id="8ad03-229">This property is set to true if the input data for the activity is not generated by the pipeline.</span></span> <span data-ttu-id="8ad03-230">Cette propriété est uniquement spécifiée sur les jeux de données d’entrée.</span><span class="sxs-lookup"><span data-stu-id="8ad03-230">This property is only specified on input datasets.</span></span> <span data-ttu-id="8ad03-231">Pour le jeu de données d’entrée de la première activité, choisissez toujours la valeur true.</span><span class="sxs-lookup"><span data-stu-id="8ad03-231">For the input dataset of the first activity, always set it to true.</span></span>
4. <span data-ttu-id="8ad03-232">Enregistrez le fichier **InputDataset.json** .</span><span class="sxs-lookup"><span data-stu-id="8ad03-232">Save the **InputDataset.json** file.</span></span>

#### <a name="create-output-dataset"></a><span data-ttu-id="8ad03-233">Créer un jeu de données de sortie</span><span class="sxs-lookup"><span data-stu-id="8ad03-233">Create output dataset</span></span>
<span data-ttu-id="8ad03-234">Vous allez maintenant créer le jeu de données de sortie pour représenter les données de sortie stockées dans le Stockage Blob Azure.</span><span class="sxs-lookup"><span data-stu-id="8ad03-234">Now, you create the output dataset to represent output data stored in the Azure Blob storage.</span></span>

1. <span data-ttu-id="8ad03-235">Dans l’**Explorateur de solutions**, cliquez avec le bouton droit sur **Tables**, pointez sur **Ajouter**, puis cliquez sur **Nouvel élément**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-235">In the **Solution Explorer**, right-click **tables**, point to **Add**, and click **New Item**.</span></span>
2. <span data-ttu-id="8ad03-236">Sélectionnez **Objet blob Azure** dans la liste, changez le nom du fichier en **OutputDataset.json**, puis cliquez sur **Ajouter**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-236">Select **Azure Blob** from the list, change the name of the file to **OutputDataset.json**, and click **Add**.</span></span>
3. <span data-ttu-id="8ad03-237">Remplacez le code **JSON** dans l’éditeur par le code JSON suivant :</span><span class="sxs-lookup"><span data-stu-id="8ad03-237">Replace the **JSON** in the editor with the following JSON:</span></span>
    
    ```json
    {
        "name": "AzureBlobOutput",
        "properties": {
            "type": "AzureBlob",
            "linkedServiceName": "AzureStorageLinkedService1",
            "typeProperties": {
                "folderPath": "adfgetstarted/partitioneddata",
                "format": {
                    "type": "TextFormat",
                    "columnDelimiter": ","
                }
            },
            "availability": {
                "frequency": "Month",
                "interval": 1
            }
        }
    }
    ```
    <span data-ttu-id="8ad03-238">L’extrait de code JSON définit un jeu de données appelé **AzureBlobOuput** qui représente les données de sortie produites par l’activité Hive dans le pipeline.</span><span class="sxs-lookup"><span data-stu-id="8ad03-238">The JSON snippet defines a dataset called **AzureBlobOutput** that represents output data produced by the hive activity in the pipeline.</span></span> <span data-ttu-id="8ad03-239">Vous indiquez que les données de sortie sont produites par l’activité Hive et placées dans le conteneur de blobs nommé `adfgetstarted` et dans le dossier nommé `partitioneddata`.</span><span class="sxs-lookup"><span data-stu-id="8ad03-239">You specify that the output data is produced by the hive activity is placed in the blob container called `adfgetstarted` and the folder called `partitioneddata`.</span></span> 
    
    <span data-ttu-id="8ad03-240">La section **availability** spécifie que le jeu de données de sortie est produit tous les mois.</span><span class="sxs-lookup"><span data-stu-id="8ad03-240">The **availability** section specifies that the output dataset is produced on a monthly basis.</span></span> <span data-ttu-id="8ad03-241">Le jeu de données de sortie détermine la programmation du pipeline.</span><span class="sxs-lookup"><span data-stu-id="8ad03-241">The output dataset drives the schedule of the pipeline.</span></span> <span data-ttu-id="8ad03-242">Le pipeline s’exécute tous les mois entre ses heures de début et de fin.</span><span class="sxs-lookup"><span data-stu-id="8ad03-242">The pipeline runs monthly between its start and end times.</span></span> 

    <span data-ttu-id="8ad03-243">Consultez la section **Créer le jeu de données d’entrée** pour obtenir une description de ces propriétés.</span><span class="sxs-lookup"><span data-stu-id="8ad03-243">See **Create the input dataset** section for descriptions of these properties.</span></span> <span data-ttu-id="8ad03-244">Vous ne définissez pas la propriété externe sur un jeu de données de sortie, car le jeu de données est produit par le pipeline.</span><span class="sxs-lookup"><span data-stu-id="8ad03-244">You do not set the external property on an output dataset as the dataset is produced by the pipeline.</span></span>
4. <span data-ttu-id="8ad03-245">Enregistrez le fichier **OutputDataset.json** .</span><span class="sxs-lookup"><span data-stu-id="8ad03-245">Save the **OutputDataset.json** file.</span></span>

### <a name="create-pipeline"></a><span data-ttu-id="8ad03-246">Création d’un pipeline</span><span class="sxs-lookup"><span data-stu-id="8ad03-246">Create pipeline</span></span>
<span data-ttu-id="8ad03-247">Jusqu’à présent, vous avez créé le service lié Stockage Azure et les jeux de données d’entrée et de sortie.</span><span class="sxs-lookup"><span data-stu-id="8ad03-247">You have created the Azure Storage linked service, and input and output datasets so far.</span></span> <span data-ttu-id="8ad03-248">Vous allez maintenant créer un pipeline avec une activité **HDInsightHive**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-248">Now, you create a pipeline with a **HDInsightHive** activity.</span></span> <span data-ttu-id="8ad03-249">**L’entrée** de l’activité Hive a la valeur **AzureBlobInput** et la **sortie** a la valeur **AzureBlobOutput**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-249">The **input** for the hive activity is set to **AzureBlobInput** and **output** is set to **AzureBlobOutput**.</span></span> <span data-ttu-id="8ad03-250">Une tranche d’un jeu de données d’entrée est disponible chaque mois (fréquence : mois, intervalle : 1), et la tranche de sortie est générée chaque mois également.</span><span class="sxs-lookup"><span data-stu-id="8ad03-250">A slice of an input dataset is available monthly (frequency: Month, interval: 1), and the output slice is produced monthly too.</span></span> 

1. <span data-ttu-id="8ad03-251">Dans l’**Explorateur de solutions**, cliquez avec le bouton droit sur **Pipelines**, pointez sur **Ajouter**, puis cliquez sur **Nouvel élément.**</span><span class="sxs-lookup"><span data-stu-id="8ad03-251">In the **Solution Explorer**, right-click **Pipelines**, point to **Add**, and click **New Item.**</span></span>
2. <span data-ttu-id="8ad03-252">Sélectionnez **Pipeline de transformation Hive** dans la liste, puis cliquez sur **Ajouter**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-252">Select **Hive Transformation Pipeline** from the list, and click **Add**.</span></span>
3. <span data-ttu-id="8ad03-253">Remplacez le code **JSON** par l’extrait de code suivant :</span><span class="sxs-lookup"><span data-stu-id="8ad03-253">Replace the **JSON** with the following snippet:</span></span>

    > [!IMPORTANT]
    > <span data-ttu-id="8ad03-254">Remplacez `<storageaccountname>` par le nom de votre compte de stockage.</span><span class="sxs-lookup"><span data-stu-id="8ad03-254">Replace `<storageaccountname>` with the name of your storage account.</span></span>

    ```json
    {
        "name": "MyFirstPipeline",
        "properties": {
            "description": "My first Azure Data Factory pipeline",
            "activities": [
                {
                    "type": "HDInsightHive",
                    "typeProperties": {
                        "scriptPath": "adfgetstarted/script/partitionweblogs.hql",
                        "scriptLinkedService": "AzureStorageLinkedService1",
                        "defines": {
                            "inputtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/inputdata",
                            "partitionedtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/partitioneddata"
                        }
                    },
                    "inputs": [
                        {
                            "name": "AzureBlobInput"
                        }
                    ],
                    "outputs": [
                        {
                            "name": "AzureBlobOutput"
                        }
                    ],
                    "policy": {
                        "concurrency": 1,
                        "retry": 3
                    },
                    "scheduler": {
                        "frequency": "Month",
                        "interval": 1
                    },
                    "name": "RunSampleHiveActivity",
                    "linkedServiceName": "HDInsightOnDemandLinkedService"
                }
            ],
            "start": "2016-04-01T00:00:00Z",
            "end": "2016-04-02T00:00:00Z",
            "isPaused": false
        }
    }
    ```

    > [!IMPORTANT]
    > <span data-ttu-id="8ad03-255">Remplacez `<storageaccountname>` par le nom de votre compte de stockage.</span><span class="sxs-lookup"><span data-stu-id="8ad03-255">Replace `<storageaccountname>` with the name of your storage account.</span></span>

    <span data-ttu-id="8ad03-256">L’extrait de code JSON définit un pipeline qui se compose d’une seule activité (activité Hive).</span><span class="sxs-lookup"><span data-stu-id="8ad03-256">The JSON snippet defines a pipeline that consists of a single activity (Hive Activity).</span></span> <span data-ttu-id="8ad03-257">Cette activité exécute un script Hive pour traiter les données d’entrée sur un cluster HDInsight à la demande afin de produire des données de sortie.</span><span class="sxs-lookup"><span data-stu-id="8ad03-257">This activity runs a Hive script to process input data on an on-demand HDInsight cluster to produce output data.</span></span> <span data-ttu-id="8ad03-258">Dans la section des activités du pipeline JSON, vous ne voyez qu’une seule activité dans le tableau avec la valeur de type définie sur **HDInsightHive**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-258">In the activities section of the pipeline JSON, you see only one activity in the array with type set to **HDInsightHive**.</span></span> 

    <span data-ttu-id="8ad03-259">Dans les propriétés de type qui sont spécifiques à l’activité HDInsight Hive, vous indiquez le service lié Stockage Azure disposant du fichier de script Hive, le chemin d’accès au fichier de script et les paramètres au fichier de script.</span><span class="sxs-lookup"><span data-stu-id="8ad03-259">In the type properties that are specific to HDInsight Hive activity, you specify what Azure Storage linked service has the hive script file, the path to the script file, and parameters to the script file.</span></span> 

    <span data-ttu-id="8ad03-260">Le fichier de script Hive, **partitionweblogs.hql**, est stocké dans le compte de stockage Azure (spécifié par scriptLinkedService) et dans le dossier `script` du conteneur `adfgetstarted`.</span><span class="sxs-lookup"><span data-stu-id="8ad03-260">The Hive script file, **partitionweblogs.hql**, is stored in the Azure storage account (specified by the scriptLinkedService), and in the `script` folder in the container `adfgetstarted`.</span></span>

    <span data-ttu-id="8ad03-261">La section `defines` est utilisée pour spécifier les paramètres d’exécution transmis au script Hive comme valeurs de configuration Hive (p. ex. `${hiveconf:inputtable}`, `${hiveconf:partitionedtable})`.</span><span class="sxs-lookup"><span data-stu-id="8ad03-261">The `defines` section is used to specify the runtime settings that are passed to the hive script as Hive configuration values (e.g `${hiveconf:inputtable}`, `${hiveconf:partitionedtable})`.</span></span>

    <span data-ttu-id="8ad03-262">Les propriétés **start** et **end** du pipeline spécifient la période active du pipeline.</span><span class="sxs-lookup"><span data-stu-id="8ad03-262">The **start** and **end** properties of the pipeline specifies the active period of the pipeline.</span></span> <span data-ttu-id="8ad03-263">Vous avez configuré le jeu de données à produire tous les mois, par conséquent, la tranche est produite une fois par le pipeline (car le mois est identique dans les dates de début et de fin).</span><span class="sxs-lookup"><span data-stu-id="8ad03-263">You configured the dataset to be produced monthly, therefore, only once slice is produced by the pipeline (because the month is same in start and end dates).</span></span>

    <span data-ttu-id="8ad03-264">Dans l’activité JSON, vous spécifiez que le script Hive s’exécute sur le calcul spécifié par le service **linkedServiceName** – **HDInsightOnDemandLinkedService**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-264">In the activity JSON, you specify that the Hive script runs on the compute specified by the **linkedServiceName** – **HDInsightOnDemandLinkedService**.</span></span>
4. <span data-ttu-id="8ad03-265">Enregistrez le fichier **HiveActivity1.json** .</span><span class="sxs-lookup"><span data-stu-id="8ad03-265">Save the **HiveActivity1.json** file.</span></span>

### <a name="add-partitionweblogshql-and-inputlog-as-a-dependency"></a><span data-ttu-id="8ad03-266">Ajouter partitionweblogs.hql et input.log comme dépendance</span><span class="sxs-lookup"><span data-stu-id="8ad03-266">Add partitionweblogs.hql and input.log as a dependency</span></span>
1. <span data-ttu-id="8ad03-267">Cliquez avec le bouton droit sur **Dépendances** dans la fenêtre **Explorateur de solutions**, pointez sur **Ajouter**, puis cliquez sur **Élément existant**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-267">Right-click **Dependencies** in the **Solution Explorer** window, point to **Add**, and click **Existing Item**.</span></span>  
2. <span data-ttu-id="8ad03-268">Accédez au dossier **C:\ADFGettingStarted**, sélectionnez les fichiers **partitionweblogs.hql** et **input.log**, puis cliquez sur **Ajouter**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-268">Navigate to the **C:\ADFGettingStarted** and select **partitionweblogs.hql**, **input.log** files, and click **Add**.</span></span> <span data-ttu-id="8ad03-269">Vous avez créé ces deux fichiers dans le cadre des étapes préalables indiquées dans la [Vue d’ensemble du didacticiel](data-factory-build-your-first-pipeline.md).</span><span class="sxs-lookup"><span data-stu-id="8ad03-269">You created these two files as part of prerequisites from the [Tutorial Overview](data-factory-build-your-first-pipeline.md).</span></span>

<span data-ttu-id="8ad03-270">Quand vous publiez la solution à l’étape suivante, le fichier **partitionweblogs.hql** est chargé dans le dossier **script** du conteneur de blobs `adfgetstarted`.</span><span class="sxs-lookup"><span data-stu-id="8ad03-270">When you publish the solution in the next step, the **partitionweblogs.hql** file is uploaded to the **script** folder in the `adfgetstarted` blob container.</span></span>   

### <a name="publishdeploy-data-factory-entities"></a><span data-ttu-id="8ad03-271">Publier/déployer des entités Data Factory</span><span class="sxs-lookup"><span data-stu-id="8ad03-271">Publish/deploy Data Factory entities</span></span>
<span data-ttu-id="8ad03-272">Dans cette étape, vous allez publier les entités Data Factory (services liés, jeux de données et pipeline) dans votre projet pour le service Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="8ad03-272">In this step, you publish the Data Factory entities (linked services, datasets, and pipeline) in your project to the Azure Data Factory service.</span></span> <span data-ttu-id="8ad03-273">Lors du processus de publication, vous spécifiez le nom de votre fabrique de données.</span><span class="sxs-lookup"><span data-stu-id="8ad03-273">In the process of publishing, you specify the name for your data factory.</span></span> 

1. <span data-ttu-id="8ad03-274">Dans l’Explorateur de solutions, cliquez avec le bouton droit sur le projet, puis cliquez sur **Publier**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-274">Right-click project in the Solution Explorer, and click **Publish**.</span></span>
2. <span data-ttu-id="8ad03-275">Si la boîte de dialogue **Connectez-vous à votre compte Microsoft** s’affiche, saisissez vos informations d’identification pour le compte associé à l’abonnement Azure, puis cliquez sur **Se connecter**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-275">If you see **Sign in to your Microsoft account** dialog box, enter your credentials for the account that has Azure subscription, and click **sign in**.</span></span>
3. <span data-ttu-id="8ad03-276">La boîte de dialogue suivante doit s’afficher :</span><span class="sxs-lookup"><span data-stu-id="8ad03-276">You should see the following dialog box:</span></span>

   ![Boîte de dialogue Publier](./media/data-factory-build-your-first-pipeline-using-vs/publish.png)
4. <span data-ttu-id="8ad03-278">Dans la page **Configurer une fabrique de données**, procédez comme suit :</span><span class="sxs-lookup"><span data-stu-id="8ad03-278">In the **Configure data factory** page, do the following steps:</span></span>

    ![Publier - Nouveau paramètres de fabrique de données](media/data-factory-build-your-first-pipeline-using-vs/publish-new-data-factory.png)

   1. <span data-ttu-id="8ad03-280">Sélectionnez l’option **Créer une fabrique de données** .</span><span class="sxs-lookup"><span data-stu-id="8ad03-280">select **Create New Data Factory** option.</span></span>
   2. <span data-ttu-id="8ad03-281">Entrez un **nom** unique pour la fabrique de données.</span><span class="sxs-lookup"><span data-stu-id="8ad03-281">Enter a unique **name** for the data factory.</span></span> <span data-ttu-id="8ad03-282">Par exemple : **DataFactoryUsingVS09152016**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-282">For example: **DataFactoryUsingVS09152016**.</span></span> <span data-ttu-id="8ad03-283">Le nom doit être globalement unique.</span><span class="sxs-lookup"><span data-stu-id="8ad03-283">The name must be globally unique.</span></span>
   3. <span data-ttu-id="8ad03-284">Sélectionnez l’abonnement approprié pour le champ **Abonnement** .</span><span class="sxs-lookup"><span data-stu-id="8ad03-284">Select the right subscription for the **Subscription** field.</span></span> 
        > [!IMPORTANT]
        > <span data-ttu-id="8ad03-285">Si vous ne voyez pas les abonnements, vérifiez que vous êtes connecté à l’aide d’un compte administrateur ou coadministrateur de l’abonnement.</span><span class="sxs-lookup"><span data-stu-id="8ad03-285">If you do not see any subscription, ensure that you logged in using an account that is an admin or co-admin of the subscription.</span></span>
   4. <span data-ttu-id="8ad03-286">Sélectionnez le **groupe de ressources** pour la fabrique de données à créer.</span><span class="sxs-lookup"><span data-stu-id="8ad03-286">Select the **resource group** for the data factory to be created.</span></span>
   5. <span data-ttu-id="8ad03-287">Sélectionnez la **région** pour la fabrique de données.</span><span class="sxs-lookup"><span data-stu-id="8ad03-287">Select the **region** for the data factory.</span></span>
   6. <span data-ttu-id="8ad03-288">Cliquez sur **Suivant** pour basculer vers la page **Publier des éléments**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-288">Click **Next** to switch to the **Publish Items** page.</span></span> <span data-ttu-id="8ad03-289">(Utilisez la touche **TABULATION** pour passer au champ Nom si le bouton **Suivant** est désactivé.)</span><span class="sxs-lookup"><span data-stu-id="8ad03-289">(Press **TAB** to move out of the Name field to if the **Next** button is disabled.)</span></span>

    > [!IMPORTANT]
    > <span data-ttu-id="8ad03-290">Si vous recevez l’erreur **Le nom de la fabrique de données « DataFactoryUsingVS » n’est pas disponible** au moment de la publication, changez le nom (par exemple en votrenomDataFactoryUsingVS).</span><span class="sxs-lookup"><span data-stu-id="8ad03-290">If you receive the error **Data factory name “DataFactoryUsingVS” is not available** when publishing, change the name (for example, yournameDataFactoryUsingVS).</span></span> <span data-ttu-id="8ad03-291">Consultez la rubrique [Data Factory - Règles d'affectation des noms](data-factory-naming-rules.md) pour savoir comment nommer les artefacts Data Factory.</span><span class="sxs-lookup"><span data-stu-id="8ad03-291">See [Data Factory - Naming Rules](data-factory-naming-rules.md) topic for naming rules for Data Factory artifacts.</span></span>   
1. <span data-ttu-id="8ad03-292">Dans la page **Publier des éléments**, vérifiez que toutes les entités de fabriques de données sont sélectionnées, puis cliquez sur **Suivant** pour basculer vers la page **Résumé**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-292">In the **Publish Items** page, ensure that all the Data Factories entities are selected, and click **Next** to switch to the **Summary** page.</span></span>

    ![Page Publier des éléments](media/data-factory-build-your-first-pipeline-using-vs/publish-items-page.png)     
2. <span data-ttu-id="8ad03-294">Passez en revue le résumé, puis cliquez sur **Suivant** pour démarrer le processus de déploiement et afficher l’**état du déploiement**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-294">Review the summary and click **Next** to start the deployment process and view the **Deployment Status**.</span></span>

    ![Page de résumé](media/data-factory-build-your-first-pipeline-using-vs/summary-page.png)
3. <span data-ttu-id="8ad03-296">Dans la page **État du déploiement** , vous devez voir l’état du processus de déploiement.</span><span class="sxs-lookup"><span data-stu-id="8ad03-296">In the **Deployment Status** page, you should see the status of the deployment process.</span></span> <span data-ttu-id="8ad03-297">Une fois le déploiement terminé, cliquez sur Terminer.</span><span class="sxs-lookup"><span data-stu-id="8ad03-297">Click Finish after the deployment is done.</span></span>

<span data-ttu-id="8ad03-298">Quelques points importants à prendre en compte :</span><span class="sxs-lookup"><span data-stu-id="8ad03-298">Important points to note:</span></span>

- <span data-ttu-id="8ad03-299">Si vous recevez le message d’erreur : « **L’abonnement n’est pas inscrit pour utiliser l’espace de noms Microsoft.DataFactory** », effectuez l’une des opérations suivantes et essayez de relancer la publication :</span><span class="sxs-lookup"><span data-stu-id="8ad03-299">If you receive the error: **This subscription is not registered to use namespace Microsoft.DataFactory**, do one of the following and try publishing again:</span></span>
    - <span data-ttu-id="8ad03-300">Dans Azure PowerShell, exécutez la commande suivante pour enregistrer le fournisseur Data Factory.</span><span class="sxs-lookup"><span data-stu-id="8ad03-300">In Azure PowerShell, run the following command to register the Data Factory provider.</span></span>
        ```PowerShell   
        Register-AzureRmResourceProvider -ProviderNamespace Microsoft.DataFactory
        ```
        <span data-ttu-id="8ad03-301">Vous pouvez exécuter la commande suivante pour confirmer que le fournisseur Data Factory est bien enregistré.</span><span class="sxs-lookup"><span data-stu-id="8ad03-301">You can run the following command to confirm that the Data Factory provider is registered.</span></span>

        ```PowerShell
        Get-AzureRmResourceProvider
        ```
    - <span data-ttu-id="8ad03-302">Connectez-vous au [portail Azure](https://portal.azure.com) à l’aide de l’abonnement Azure et accédez à un panneau Data Factory (ou) créez une fabrique de données dans le portail Azure.</span><span class="sxs-lookup"><span data-stu-id="8ad03-302">Login using the Azure subscription in to the [Azure portal](https://portal.azure.com) and navigate to a Data Factory blade (or) create a data factory in the Azure portal.</span></span> <span data-ttu-id="8ad03-303">Cette action enregistre automatiquement le fournisseur.</span><span class="sxs-lookup"><span data-stu-id="8ad03-303">This action automatically registers the provider for you.</span></span>
- <span data-ttu-id="8ad03-304">Le nom de la fabrique de données pourra être enregistré en tant que nom DNS et devenir ainsi visible publiquement.</span><span class="sxs-lookup"><span data-stu-id="8ad03-304">The name of the data factory may be registered as a DNS name in the future and hence become publically visible.</span></span>
- <span data-ttu-id="8ad03-305">Pour créer des instances Data Factory, vous devez être administrateur ou co-administrateur de l’abonnement Azure</span><span class="sxs-lookup"><span data-stu-id="8ad03-305">To create Data Factory instances, you need to be an admin or co-admin of the Azure subscription</span></span>

### <a name="monitor-pipeline"></a><span data-ttu-id="8ad03-306">Surveillance d’un pipeline</span><span class="sxs-lookup"><span data-stu-id="8ad03-306">Monitor pipeline</span></span>
<span data-ttu-id="8ad03-307">Au cours de cette étape, vous allez surveiller le pipeline à l’aide de la Vue de diagramme de la fabrique de données.</span><span class="sxs-lookup"><span data-stu-id="8ad03-307">In this step, you monitor the pipeline using Diagram View of the data factory.</span></span> 

#### <a name="monitor-pipeline-using-diagram-view"></a><span data-ttu-id="8ad03-308">Surveillance d’un pipeline à l’aide de la Vue de diagramme</span><span class="sxs-lookup"><span data-stu-id="8ad03-308">Monitor pipeline using Diagram View</span></span>
1. <span data-ttu-id="8ad03-309">Connectez-vous au [portail Azure](https://portal.azure.com/) et procédez comme suit :</span><span class="sxs-lookup"><span data-stu-id="8ad03-309">Log in to the [Azure portal](https://portal.azure.com/), do the following steps:</span></span>
   1. <span data-ttu-id="8ad03-310">Cliquez sur **Plus de services**, puis sur **Fabriques de données**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-310">Click **More services** and click **Data factories**.</span></span>
       
        ![Parcourir les fabriques de données](./media/data-factory-build-your-first-pipeline-using-vs/browse-datafactories.png)
   2. <span data-ttu-id="8ad03-312">Sélectionnez le nom de votre fabrique de données (par exemple : **DataFactoryUsingVS09152016**) dans la liste des fabriques de données.</span><span class="sxs-lookup"><span data-stu-id="8ad03-312">Select the name of your data factory (for example: **DataFactoryUsingVS09152016**) from the list of data factories.</span></span>
   
       ![Sélectionner votre fabrique de données](./media/data-factory-build-your-first-pipeline-using-vs/select-first-data-factory.png)
2. <span data-ttu-id="8ad03-314">Dans la page d’accueil de votre fabrique de données, cliquez sur **Diagramme**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-314">In the home page for your data factory, click **Diagram**.</span></span>

    ![Vignette de diagramme](./media/data-factory-build-your-first-pipeline-using-vs/diagram-tile.png)
3. <span data-ttu-id="8ad03-316">Dans la Vue de diagramme, une vue d’ensemble des pipelines et des jeux de données utilisés dans ce didacticiel s’affiche.</span><span class="sxs-lookup"><span data-stu-id="8ad03-316">In the Diagram View, you see an overview of the pipelines, and datasets used in this tutorial.</span></span>

    ![Vue du diagramme](./media/data-factory-build-your-first-pipeline-using-vs/diagram-view-2.png)
4. <span data-ttu-id="8ad03-318">Pour afficher toutes les activités du pipeline, cliquez avec le bouton droit sur le pipeline dans le diagramme, puis cliquez sur Ouvrir un pipeline.</span><span class="sxs-lookup"><span data-stu-id="8ad03-318">To view all activities in the pipeline, right-click pipeline in the diagram and click Open Pipeline.</span></span>

    ![Menu Ouvrir un pipeline](./media/data-factory-build-your-first-pipeline-using-vs/open-pipeline-menu.png)
5. <span data-ttu-id="8ad03-320">Vérifiez que l’activité HDInsightHive est bien dans le pipeline.</span><span class="sxs-lookup"><span data-stu-id="8ad03-320">Confirm that you see the HDInsightHive activity in the pipeline.</span></span>

    ![Vue Ouvrir un pipeline](./media/data-factory-build-your-first-pipeline-using-vs/open-pipeline-view.png)

    <span data-ttu-id="8ad03-322">Pour revenir à la vue précédente, cliquez sur **Fabrique de données** dans le menu de navigation du haut.</span><span class="sxs-lookup"><span data-stu-id="8ad03-322">To navigate back to the previous view, click **Data factory** in the breadcrumb menu at the top.</span></span>
6. <span data-ttu-id="8ad03-323">Dans la **Vue de diagramme**, double-cliquez sur le jeu de données **AzureBlobInput**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-323">In the **Diagram View**, double-click the dataset **AzureBlobInput**.</span></span> <span data-ttu-id="8ad03-324">Vérifiez que l’état du segment est **Prêt** .</span><span class="sxs-lookup"><span data-stu-id="8ad03-324">Confirm that the slice is in **Ready** state.</span></span> <span data-ttu-id="8ad03-325">Plusieurs minutes peuvent être nécessaires avant que le segment n’apparaisse avec l’état Prêt.</span><span class="sxs-lookup"><span data-stu-id="8ad03-325">It may take a couple of minutes for the slice to show up in Ready state.</span></span> <span data-ttu-id="8ad03-326">Si rien ne se produit au bout d’un moment, vérifiez que le fichier d’entrée (input.log) est bien placé dans le conteneur (`adfgetstarted`) et le dossier (`inputdata`) appropriés.</span><span class="sxs-lookup"><span data-stu-id="8ad03-326">If it does not happen after you wait for sometime, see if you have the input file (input.log) placed in the right container (`adfgetstarted`) and folder (`inputdata`).</span></span> <span data-ttu-id="8ad03-327">Et assurez-vous que la propriété **externe** du jeu de données d’entrée a la valeur **true**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-327">And, make sure that the **external** property on the input dataset is set to **true**.</span></span> 

   ![Segment d’entrée dans l’état Prêt](./media/data-factory-build-your-first-pipeline-using-vs/input-slice-ready.png)
7. <span data-ttu-id="8ad03-329">Cliquez sur **X** pour fermer le panneau **AzureBlobInput**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-329">Click **X** to close **AzureBlobInput** blade.</span></span>
8. <span data-ttu-id="8ad03-330">Dans la **Vue de diagramme**, double-cliquez sur le jeu de données **AzureBlobOutput**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-330">In the **Diagram View**, double-click the dataset **AzureBlobOutput**.</span></span> <span data-ttu-id="8ad03-331">La tranche est en cours de traitement.</span><span class="sxs-lookup"><span data-stu-id="8ad03-331">You see that the slice that is currently being processed.</span></span>

   ![Jeu de données](./media/data-factory-build-your-first-pipeline-using-vs/dataset-blade.png)
9. <span data-ttu-id="8ad03-333">Quand le traitement est terminé, l’état de la tranche est **Prêt** .</span><span class="sxs-lookup"><span data-stu-id="8ad03-333">When processing is done, you see the slice in **Ready** state.</span></span>

   > [!IMPORTANT]
   > <span data-ttu-id="8ad03-334">La création d’un cluster HDInsight à la demande prend généralement un certain temps (environ 20 minutes).</span><span class="sxs-lookup"><span data-stu-id="8ad03-334">Creation of an on-demand HDInsight cluster usually takes sometime (approximately 20 minutes).</span></span> <span data-ttu-id="8ad03-335">Le pipeline devrait donc traiter la tranche en **30 minutes environ** .</span><span class="sxs-lookup"><span data-stu-id="8ad03-335">Therefore, expect the pipeline to take **approximately 30 minutes** to process the slice.</span></span>  
   
    ![Jeu de données](./media/data-factory-build-your-first-pipeline-using-vs/dataset-slice-ready.png)    
10. <span data-ttu-id="8ad03-337">Lorsque la tranche indique l’état **Prêt**, vérifiez le dossier `partitioneddata` dans le conteneur `adfgetstarted` de votre stockage d’objets blob pour les données de sortie.</span><span class="sxs-lookup"><span data-stu-id="8ad03-337">When the slice is in **Ready** state, check the `partitioneddata` folder in the `adfgetstarted` container in your blob storage for the output data.</span></span>  

    ![données de sortie](./media/data-factory-build-your-first-pipeline-using-vs/three-ouptut-files.png)
11. <span data-ttu-id="8ad03-339">Cliquez sur la tranche pour en afficher les détails dans le panneau **Tranche de données** .</span><span class="sxs-lookup"><span data-stu-id="8ad03-339">Click the slice to see details about it in a **Data slice** blade.</span></span>

    ![Détails de la tranche](./media/data-factory-build-your-first-pipeline-using-vs/data-slice-details.png)  
12. <span data-ttu-id="8ad03-341">Cliquez sur une exécution d’activité (activité Hive dans notre scénario) dans la **liste Exécutions d’activité** pour en afficher les détails dans la fenêtre **Détails de l’exécution d’activité**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-341">Click an activity run in the **Activity runs list** to see details about an activity run (Hive activity in our scenario) in an **Activity run details** window.</span></span> 
  
    ![Détails de l'exécution d'activité](./media/data-factory-build-your-first-pipeline-using-vs/activity-window-blade.png)    

    <span data-ttu-id="8ad03-343">Dans les fichiers journaux, vous pouvez voir la requête Hive qui a été exécutée et son état.</span><span class="sxs-lookup"><span data-stu-id="8ad03-343">From the log files, you can see the Hive query that was executed and status information.</span></span> <span data-ttu-id="8ad03-344">Ces journaux sont utiles pour résoudre les problèmes.</span><span class="sxs-lookup"><span data-stu-id="8ad03-344">These logs are useful for troubleshooting any issues.</span></span>  

<span data-ttu-id="8ad03-345">Consultez [Surveiller les jeux de données et le pipeline](data-factory-monitor-manage-pipelines.md) pour obtenir des instructions sur l’utilisation du portail Azure afin de surveiller le pipeline et les jeux de données que vous avez créés dans ce didacticiel.</span><span class="sxs-lookup"><span data-stu-id="8ad03-345">See [Monitor datasets and pipeline](data-factory-monitor-manage-pipelines.md) for instructions on how to use the Azure portal to monitor the pipeline and datasets you have created in this tutorial.</span></span>

#### <a name="monitor-pipeline-using-monitor--manage-app"></a><span data-ttu-id="8ad03-346">Surveiller le pipeline à l’aide de l’application de surveillance et de gestion</span><span class="sxs-lookup"><span data-stu-id="8ad03-346">Monitor pipeline using Monitor & Manage App</span></span>
<span data-ttu-id="8ad03-347">Vous pouvez également utiliser l’application de surveillance et de gestion pour surveiller vos pipelines.</span><span class="sxs-lookup"><span data-stu-id="8ad03-347">You can also use Monitor & Manage application to monitor your pipelines.</span></span> <span data-ttu-id="8ad03-348">Pour en savoir plus sur l’utilisation de cette application, consultez l’article [Surveiller et gérer les pipelines Azure Data Factory à l’aide de l’application de surveillance et gestion](data-factory-monitor-manage-app.md).</span><span class="sxs-lookup"><span data-stu-id="8ad03-348">For detailed information about using this application, see [Monitor and manage Azure Data Factory pipelines using Monitoring and Management App](data-factory-monitor-manage-app.md).</span></span>

1. <span data-ttu-id="8ad03-349">Cliquez sur la vignette Surveiller et gérer.</span><span class="sxs-lookup"><span data-stu-id="8ad03-349">Click Monitor & Manage tile.</span></span>

    ![Vignette Surveiller et gérer](./media/data-factory-build-your-first-pipeline-using-vs/monitor-and-manage-tile.png)
2. <span data-ttu-id="8ad03-351">L’application de surveillance et de gestion devrait s’afficher.</span><span class="sxs-lookup"><span data-stu-id="8ad03-351">You should see Monitor & Manage application.</span></span> <span data-ttu-id="8ad03-352">Modifiez l’**heure de début** et l’**heure de fin** pour qu’elles correspondent aux heures de début (04-01-2016 12:00 AM) et de fin (04-02-2016 12:00 AM) de votre pipeline, puis cliquez sur **Appliquer**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-352">Change the **Start time** and **End time** to match start (04-01-2016 12:00 AM) and end times (04-02-2016 12:00 AM) of your pipeline, and click **Apply**.</span></span>

    ![Application de surveillance et gestion](./media/data-factory-build-your-first-pipeline-using-vs/monitor-and-manage-app.png)
3. <span data-ttu-id="8ad03-354">Pour afficher des informations sur une fenêtre d’activité, sélectionnez-la dans la **liste des fenêtres d’activité**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-354">To see details about an activity window, select it in the **Activity Windows list** to see details about it.</span></span>
    <span data-ttu-id="8ad03-355">![Détails de la fenêtre d’activité](./media/data-factory-build-your-first-pipeline-using-vs/activity-window-details.png)</span><span class="sxs-lookup"><span data-stu-id="8ad03-355">![Activity window details](./media/data-factory-build-your-first-pipeline-using-vs/activity-window-details.png)</span></span>

> [!IMPORTANT]
> <span data-ttu-id="8ad03-356">Le fichier d’entrée sera supprimé lorsque la tranche est traitée avec succès.</span><span class="sxs-lookup"><span data-stu-id="8ad03-356">The input file gets deleted when the slice is processed successfully.</span></span> <span data-ttu-id="8ad03-357">Par conséquent, si vous souhaitez réexécuter la tranche ou refaire le didacticiel, chargez le fichier d’entrée (input.log) dans le dossier `inputdata` du conteneur `adfgetstarted`.</span><span class="sxs-lookup"><span data-stu-id="8ad03-357">Therefore, if you want to rerun the slice or do the tutorial again, upload the input file (input.log) to the `inputdata` folder of the `adfgetstarted` container.</span></span>

### <a name="additional-notes"></a><span data-ttu-id="8ad03-358">Remarques supplémentaires</span><span class="sxs-lookup"><span data-stu-id="8ad03-358">Additional notes</span></span>
- <span data-ttu-id="8ad03-359">Une fabrique de données peut avoir un ou plusieurs pipelines.</span><span class="sxs-lookup"><span data-stu-id="8ad03-359">A data factory can have one or more pipelines.</span></span> <span data-ttu-id="8ad03-360">Un pipeline peut contenir une ou plusieurs activités.</span><span class="sxs-lookup"><span data-stu-id="8ad03-360">A pipeline can have one or more activities in it.</span></span> <span data-ttu-id="8ad03-361">Par exemple, une activité de copie censée copier des données d’un magasin de données source vers un magasin de données de destination, et une activité Hive HDInsight pour exécuter un script Hive pour transformer des données d’entrée.</span><span class="sxs-lookup"><span data-stu-id="8ad03-361">For example, a Copy Activity to copy data from a source to a destination data store and a HDInsight Hive activity to run a Hive script to transform input data.</span></span> <span data-ttu-id="8ad03-362">Pour connaître l’ensemble des sources et des récepteurs pris en charge par l’activité de copie, consultez [Banques de données et formats pris en charge](data-factory-data-movement-activities.md#supported-data-stores-and-formats) .</span><span class="sxs-lookup"><span data-stu-id="8ad03-362">See [supported data stores](data-factory-data-movement-activities.md#supported-data-stores-and-formats) for all the sources and sinks supported by the Copy Activity.</span></span> <span data-ttu-id="8ad03-363">Pour obtenir la liste des services de calcul pris en charge par Data Factory, consultez [Services liés de calcul](data-factory-compute-linked-services.md) .</span><span class="sxs-lookup"><span data-stu-id="8ad03-363">See [compute linked services](data-factory-compute-linked-services.md) for the list of compute services supported by Data Factory.</span></span>
- <span data-ttu-id="8ad03-364">Les services liés se chargent de lier des magasins de données ou des services de calcul à une fabrique de données Azure.</span><span class="sxs-lookup"><span data-stu-id="8ad03-364">Linked services link data stores or compute services to an Azure data factory.</span></span> <span data-ttu-id="8ad03-365">Pour connaître l’ensemble des sources et des récepteurs pris en charge par l’activité de copie, consultez [Banques de données et formats pris en charge](data-factory-data-movement-activities.md#supported-data-stores-and-formats) .</span><span class="sxs-lookup"><span data-stu-id="8ad03-365">See [supported data stores](data-factory-data-movement-activities.md#supported-data-stores-and-formats) for all the sources and sinks supported by the Copy Activity.</span></span> <span data-ttu-id="8ad03-366">Pour obtenir la liste des services de calcul pris en charge par Data Factory et les [activités de transformation](data-factory-data-transformation-activities.md) qui peuvent s’exécuter sur ceux-ci, consultez [Services liés de calcul](data-factory-compute-linked-services.md).</span><span class="sxs-lookup"><span data-stu-id="8ad03-366">See [compute linked services](data-factory-compute-linked-services.md) for the list of compute services supported by Data Factory and [transformation activities](data-factory-data-transformation-activities.md) that can run on them.</span></span>
- <span data-ttu-id="8ad03-367">Consultez [Déplacer des données depuis et vers le Stockage Blob Azure à l’aide d’Azure Data Factory](data-factory-azure-blob-connector.md#azure-storage-linked-service) pour plus d’informations sur les propriétés JSON utilisées dans la définition de service lié Stockage Azure.</span><span class="sxs-lookup"><span data-stu-id="8ad03-367">See [Move data from/to Azure Blob](data-factory-azure-blob-connector.md#azure-storage-linked-service) for details about JSON properties used in the Azure Storage linked service definition.</span></span>
- <span data-ttu-id="8ad03-368">Vous pouvez utiliser votre propre cluster HDInsight au lieu d’utiliser un cluster HDInsight à la demande.</span><span class="sxs-lookup"><span data-stu-id="8ad03-368">You could use your own HDInsight cluster instead of using an on-demand HDInsight cluster.</span></span> <span data-ttu-id="8ad03-369">Pour plus d’informations, consultez [Services de calcul liés](data-factory-compute-linked-services.md) .</span><span class="sxs-lookup"><span data-stu-id="8ad03-369">See [Compute Linked Services](data-factory-compute-linked-services.md) for details.</span></span>
-  <span data-ttu-id="8ad03-370">La fabrique de données crée pour vous un cluster HDInsight **Linux** avec le code JSON précédent.</span><span class="sxs-lookup"><span data-stu-id="8ad03-370">The Data Factory creates a **Linux-based** HDInsight cluster for you with the preceding JSON.</span></span> <span data-ttu-id="8ad03-371">Pour plus d’informations, voir [Service lié à la demande Azure HDInsight](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service) .</span><span class="sxs-lookup"><span data-stu-id="8ad03-371">See [On-demand HDInsight Linked Service](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service) for details.</span></span>
- <span data-ttu-id="8ad03-372">Le cluster HDInsight crée un **conteneur par défaut** dans le Stockage Blob que vous avez spécifié dans le code JSON (linkedServiceName).</span><span class="sxs-lookup"><span data-stu-id="8ad03-372">The HDInsight cluster creates a **default container** in the blob storage you specified in the JSON (linkedServiceName).</span></span> <span data-ttu-id="8ad03-373">HDInsight ne supprime pas ce conteneur lorsque le cluster est supprimé.</span><span class="sxs-lookup"><span data-stu-id="8ad03-373">HDInsight does not delete this container when the cluster is deleted.</span></span> <span data-ttu-id="8ad03-374">Ce comportement est normal.</span><span class="sxs-lookup"><span data-stu-id="8ad03-374">This behavior is by design.</span></span> <span data-ttu-id="8ad03-375">Avec le service lié HDInsight à la demande, un cluster HDInsight est créé dès qu’une tranche est traitée, à moins qu’il n’existe un cluster actif (timeToLive).</span><span class="sxs-lookup"><span data-stu-id="8ad03-375">With on-demand HDInsight linked service, a HDInsight cluster is created every time a slice is processed unless there is an existing live cluster (timeToLive).</span></span> <span data-ttu-id="8ad03-376">Ce cluster est supprimé, une fois le traitement terminé.</span><span class="sxs-lookup"><span data-stu-id="8ad03-376">The cluster is automatically deleted when the processing is done.</span></span>
    
    <span data-ttu-id="8ad03-377">Comme un nombre croissant de tranches sont traitées, vous voyez un grand nombre de conteneurs dans votre stockage d’objets blob Azure.</span><span class="sxs-lookup"><span data-stu-id="8ad03-377">As more slices are processed, you see many containers in your Azure blob storage.</span></span> <span data-ttu-id="8ad03-378">Si vous n’en avez pas besoin pour dépanner les travaux, il se peut que vous deviez les supprimer pour réduire les frais de stockage.</span><span class="sxs-lookup"><span data-stu-id="8ad03-378">If you do not need them for troubleshooting of the jobs, you may want to delete them to reduce the storage cost.</span></span> <span data-ttu-id="8ad03-379">Les noms de ces conteneurs sont conformes au modèle suivant : `adf**yourdatafactoryname**-**linkedservicename**-datetimestamp`.</span><span class="sxs-lookup"><span data-stu-id="8ad03-379">The names of these containers follow a pattern: `adf**yourdatafactoryname**-**linkedservicename**-datetimestamp`.</span></span> <span data-ttu-id="8ad03-380">Utilisez des outils tels que [Microsoft Storage Explorer](http://storageexplorer.com/) pour supprimer des conteneurs dans votre stockage d’objets blob Azure.</span><span class="sxs-lookup"><span data-stu-id="8ad03-380">Use tools such as [Microsoft Storage Explorer](http://storageexplorer.com/) to delete containers in your Azure blob storage.</span></span>
- <span data-ttu-id="8ad03-381">À ce stade, c'est le jeu de données de sortie qui pilote la planification : vous devez donc créer un jeu de données de sortie même si l’activité ne génère aucune sortie.</span><span class="sxs-lookup"><span data-stu-id="8ad03-381">Currently, output dataset is what drives the schedule, so you must create an output dataset even if the activity does not produce any output.</span></span> <span data-ttu-id="8ad03-382">Si l’activité ne prend aucune entrée, vous pouvez ignorer la création du jeu de données d’entrée.</span><span class="sxs-lookup"><span data-stu-id="8ad03-382">If the activity doesn't take any input, you can skip creating the input dataset.</span></span> 
- <span data-ttu-id="8ad03-383">Ce didacticiel n’explique pas comment copier des données à l’aide d’Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="8ad03-383">This tutorial does not show how copy data by using Azure Data Factory.</span></span> <span data-ttu-id="8ad03-384">Pour un didacticiel sur la copie de données à l’aide d’Azure Data Factory, consultez [Copie de données Blob Storage vers une base de données SQL à l’aide de Data Factory](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="8ad03-384">For a tutorial on how to copy data using Azure Data Factory, see [Tutorial: Copy data from Blob Storage to SQL Database](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>


## <a name="use-server-explorer-to-view-data-factories"></a><span data-ttu-id="8ad03-385">Utiliser l’Explorateur de serveurs pour passer en revue la fabrique des données</span><span class="sxs-lookup"><span data-stu-id="8ad03-385">Use Server Explorer to view data factories</span></span>
1. <span data-ttu-id="8ad03-386">Dans **Visual Studio**, cliquez sur **Affichage** dans le menu, puis sur **Explorateur de serveurs**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-386">In **Visual Studio**, click **View** on the menu, and click **Server Explorer**.</span></span>
2. <span data-ttu-id="8ad03-387">Dans la fenêtre Explorateur de serveurs, développez **Azure**, puis **Data Factory**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-387">In the Server Explorer window, expand **Azure** and expand **Data Factory**.</span></span> <span data-ttu-id="8ad03-388">Si la boîte de dialogue **Connectez-vous à Visual Studio** s’affiche, saisissez le **compte** associé à votre abonnement Azure, puis cliquez sur **Continuer**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-388">If you see **Sign in to Visual Studio**, enter the **account** associated with your Azure subscription and click **Continue**.</span></span> <span data-ttu-id="8ad03-389">Saisissez le **mot de passe**, puis cliquez sur **Se connecter**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-389">Enter **password**, and click **Sign in**.</span></span> <span data-ttu-id="8ad03-390">Visual Studio essaie d’obtenir des informations sur toutes les fabriques de données Azure contenues dans votre abonnement.</span><span class="sxs-lookup"><span data-stu-id="8ad03-390">Visual Studio tries to get information about all Azure data factories in your subscription.</span></span> <span data-ttu-id="8ad03-391">L’état de cette opération s’affiche dans la fenêtre **Liste des tâches de Data Factory** .</span><span class="sxs-lookup"><span data-stu-id="8ad03-391">You see the status of this operation in the **Data Factory Task List** window.</span></span>

    ![Explorateur de serveurs](./media/data-factory-build-your-first-pipeline-using-vs/server-explorer.png)
3. <span data-ttu-id="8ad03-393">Vous pouvez cliquer avec le bouton droit sur une fabrique de données et sélectionner **Exporter la fabrique de données vers le nouveau projet** pour créer un projet Visual Studio basé sur une fabrique de données existante.</span><span class="sxs-lookup"><span data-stu-id="8ad03-393">You can right-click a data factory, and select **Export Data Factory to New Project** to create a Visual Studio project based on an existing data factory.</span></span>

    ![Exporter la fabrique de données](./media/data-factory-build-your-first-pipeline-using-vs/export-data-factory-menu.png)

## <a name="update-data-factory-tools-for-visual-studio"></a><span data-ttu-id="8ad03-395">Mettre à jour des outils Data Factory pour Visual Studio</span><span class="sxs-lookup"><span data-stu-id="8ad03-395">Update Data Factory tools for Visual Studio</span></span>
<span data-ttu-id="8ad03-396">Pour mettre à jour des outils Azure Data Factory pour Visual Studio, procédez comme suit :</span><span class="sxs-lookup"><span data-stu-id="8ad03-396">To update Azure Data Factory tools for Visual Studio, do the following steps:</span></span>

1. <span data-ttu-id="8ad03-397">Dans le menu, cliquez sur **Outils**, puis sélectionnez **Extensions et mises à jour**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-397">Click **Tools** on the menu and select **Extensions and Updates**.</span></span>
2. <span data-ttu-id="8ad03-398">Dans le volet de gauche, sélectionnez **Mises à jour**, puis **Galerie Visual Studio**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-398">Select **Updates** in the left pane and then select **Visual Studio Gallery**.</span></span>
3. <span data-ttu-id="8ad03-399">Sélectionnez **Outils Azure Data Factory pour Visual Studio**, puis cliquez sur **Mettre à jour**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-399">Select **Azure Data Factory tools for Visual Studio** and click **Update**.</span></span> <span data-ttu-id="8ad03-400">Si cette entrée n’est pas affichée, c’est que vous possédez déjà la dernière version de ces outils.</span><span class="sxs-lookup"><span data-stu-id="8ad03-400">If you do not see this entry, you already have the latest version of the tools.</span></span>

## <a name="use-configuration-files"></a><span data-ttu-id="8ad03-401">Utiliser des fichiers de configuration</span><span class="sxs-lookup"><span data-stu-id="8ad03-401">Use configuration files</span></span>
<span data-ttu-id="8ad03-402">Vous pouvez utiliser des fichiers de configuration dans Visual Studio pour configurer les propriétés des services/tableaux/pipelines liés différemment pour chaque environnement.</span><span class="sxs-lookup"><span data-stu-id="8ad03-402">You can use configuration files in Visual Studio to configure properties for linked services/tables/pipelines differently for each environment.</span></span>

<span data-ttu-id="8ad03-403">Examinez la définition JSON suivante pour un service lié Azure Storage.</span><span class="sxs-lookup"><span data-stu-id="8ad03-403">Consider the following JSON definition for an Azure Storage linked service.</span></span> <span data-ttu-id="8ad03-404">Spécifiez **connectionString** avec différentes valeurs pour accountname et accountkey, en fonction de l’environnement (dév./test/production) sur lequel vous déployez des entités Data Factory.</span><span class="sxs-lookup"><span data-stu-id="8ad03-404">To specify **connectionString** with different values for accountname and accountkey based on the environment (Dev/Test/Production) to which you are deploying Data Factory entities.</span></span> <span data-ttu-id="8ad03-405">Vous pouvez parvenir à ce comportement en utilisant un fichier de configuration distinct pour chaque environnement.</span><span class="sxs-lookup"><span data-stu-id="8ad03-405">You can achieve this behavior by using separate configuration file for each environment.</span></span>

```json
{
    "name": "StorageLinkedService",
    "properties": {
        "type": "AzureStorage",
        "description": "",
        "typeProperties": {
            "connectionString": "DefaultEndpointsProtocol=https;AccountName=<accountname>;AccountKey=<accountkey>"
        }
    }
}
```

### <a name="add-a-configuration-file"></a><span data-ttu-id="8ad03-406">Ajouter un fichier de configuration</span><span class="sxs-lookup"><span data-stu-id="8ad03-406">Add a configuration file</span></span>
<span data-ttu-id="8ad03-407">Ajoutez un fichier de configuration pour chaque environnement en effectuant les opérations suivantes :</span><span class="sxs-lookup"><span data-stu-id="8ad03-407">Add a configuration file for each environment by performing the following steps:</span></span>   

1. <span data-ttu-id="8ad03-408">Cliquez avec le bouton droit de la souris sur le projet Data Factory dans votre solution Visual Studio, pointez sur **Ajouter**, puis cliquez sur **Nouvel élément**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-408">Right-click the Data Factory project in your Visual Studio solution, point to **Add**, and click **New item**.</span></span>
2. <span data-ttu-id="8ad03-409">Sélectionnez **Config** dans la liste des modèles installés sur la gauche, choisissez **Fichier de configuration**, entrez un **nom** pour ce fichier, puis cliquez sur **Ajouter**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-409">Select **Config** from the list of installed templates on the left, select **Configuration File**, enter a **name** for the configuration file, and click **Add**.</span></span>

    ![Ajouter un fichier de configuration](./media/data-factory-build-your-first-pipeline-using-vs/add-config-file.png)
3. <span data-ttu-id="8ad03-411">Ajoutez les paramètres de configuration et leurs valeurs au format suivant :</span><span class="sxs-lookup"><span data-stu-id="8ad03-411">Add configuration parameters and their values in the following format:</span></span>

    ```json
    {
        "$schema": "http://datafactories.schema.management.azure.com/vsschemas/V1/Microsoft.DataFactory.Config.json",
        "AzureStorageLinkedService1": [
            {
                "name": "$.properties.typeProperties.connectionString",
                "value": "DefaultEndpointsProtocol=https;AccountName=<accountname>;AccountKey=<accountkey>"
            }
        ],
        "AzureSqlLinkedService1": [
            {
                "name": "$.properties.typeProperties.connectionString",
                "value":  "Server=tcp:spsqlserver.database.windows.net,1433;Database=spsqldb;User ID=spelluru;Password=Sowmya123;Trusted_Connection=False;Encrypt=True;Connection Timeout=30"
            }
        ]
    }
    ```

    <span data-ttu-id="8ad03-412">Cet exemple configure la propriété connectionString d’un service lié Azure Storage et d’un service lié SQL Azure.</span><span class="sxs-lookup"><span data-stu-id="8ad03-412">This example configures connectionString property of an Azure Storage linked service and an Azure SQL linked service.</span></span> <span data-ttu-id="8ad03-413">Notez que la syntaxe de spécification du nom est [JsonPath](http://goessner.net/articles/JsonPath/).</span><span class="sxs-lookup"><span data-stu-id="8ad03-413">Notice that the syntax for specifying name is [JsonPath](http://goessner.net/articles/JsonPath/).</span></span>   

    <span data-ttu-id="8ad03-414">Si JSON est doté d’une propriété ayant un tableau de valeurs comme indiqué dans le code suivant :</span><span class="sxs-lookup"><span data-stu-id="8ad03-414">If JSON has a property that has an array of values as shown in the following code:</span></span>  

    ```json
    "structure": [
          {
              "name": "FirstName",
            "type": "String"
          },
          {
            "name": "LastName",
            "type": "String"
        }
    ],
    ```

    <span data-ttu-id="8ad03-415">Configurez les propriétés comme indiqué dans le fichier de configuration suivant (utilisez indexation de base zéro) :</span><span class="sxs-lookup"><span data-stu-id="8ad03-415">Configure properties as shown in the following configuration file (use zero-based indexing):</span></span>

    ```json
    {
        "name": "$.properties.structure[0].name",
        "value": "FirstName"
    }
    {
        "name": "$.properties.structure[0].type",
        "value": "String"
    }
    {
        "name": "$.properties.structure[1].name",
        "value": "LastName"
    }
    {
        "name": "$.properties.structure[1].type",
        "value": "String"
    }
    ```

### <a name="property-names-with-spaces"></a><span data-ttu-id="8ad03-416">Noms de propriétés avec des espaces</span><span class="sxs-lookup"><span data-stu-id="8ad03-416">Property names with spaces</span></span>
<span data-ttu-id="8ad03-417">Si un nom de propriété comporte des espaces, utilisez des crochets comme indiqué dans l’exemple suivant (nom de serveur de base de données) :</span><span class="sxs-lookup"><span data-stu-id="8ad03-417">If a property name has spaces in it, use square brackets as shown in the following example (Database server name):</span></span>

```json
 {
     "name": "$.properties.activities[1].typeProperties.webServiceParameters.['Database server name']",
     "value": "MyAsqlServer.database.windows.net"
 }
```

### <a name="deploy-solution-using-a-configuration"></a><span data-ttu-id="8ad03-418">Déployer une solution à l’aide d’une configuration</span><span class="sxs-lookup"><span data-stu-id="8ad03-418">Deploy solution using a configuration</span></span>
<span data-ttu-id="8ad03-419">Lorsque vous publiez des entités Azure Data Factory dans Visual Studio, vous pouvez spécifier la configuration que vous souhaitez utiliser pour cette opération de publication.</span><span class="sxs-lookup"><span data-stu-id="8ad03-419">When you are publishing Azure Data Factory entities in VS, you can specify the configuration that you want to use for that publishing operation.</span></span>

<span data-ttu-id="8ad03-420">Pour publier des entités dans un projet Azure Data Factory à l’aide d’un fichier de configuration :</span><span class="sxs-lookup"><span data-stu-id="8ad03-420">To publish entities in an Azure Data Factory project using configuration file:</span></span>   

1. <span data-ttu-id="8ad03-421">Cliquez avec le bouton droit sur le projet Data Factory, puis cliquez sur **Publier** pour afficher la boîte de dialogue **Publier des éléments**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-421">Right-click Data Factory project and click **Publish** to see the **Publish Items** dialog box.</span></span>
2. <span data-ttu-id="8ad03-422">Dans la page **Configurer une fabrique de données**, sélectionnez une fabrique de données existante ou spécifiez les valeurs pour en créer une, puis cliquez sur **Suivant**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-422">Select an existing data factory or specify values for creating a data factory on the **Configure data factory** page, and click **Next**.</span></span>   
3. <span data-ttu-id="8ad03-423">La page **Publier des éléments** contient une liste déroulante avec les configurations disponibles pour le champ **Sélectionner une configuration de déploiement**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-423">On the **Publish Items** page: you see a drop-down list with available configurations for the **Select Deployment Config** field.</span></span>

    ![Sélectionner un fichier de config](./media/data-factory-build-your-first-pipeline-using-vs/select-config-file.png)
4. <span data-ttu-id="8ad03-425">Sélectionnez le **fichier de configuration** que vous souhaitez utiliser, puis cliquez sur **Suivant**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-425">Select the **configuration file** that you would like to use and click **Next**.</span></span>
5. <span data-ttu-id="8ad03-426">Vérifiez que vous voyez bien le nom du fichier JSON dans la page **Résumé**, puis cliquez sur **Suivant**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-426">Confirm that you see the name of JSON file in the **Summary** page and click **Next**.</span></span>
6. <span data-ttu-id="8ad03-427">Une fois l’opération de déploiement terminée, cliquez sur **Terminer** .</span><span class="sxs-lookup"><span data-stu-id="8ad03-427">Click **Finish** after the deployment operation is finished.</span></span>

<span data-ttu-id="8ad03-428">Au cours du déploiement, les valeurs du fichier de configuration sont utilisées pour définir celles des propriétés des fichiers JSON avant que les entités ne soient déployées sur le service Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="8ad03-428">When you deploy, the values from the configuration file are used to set values for properties in the JSON files before the entities are deployed to Azure Data Factory service.</span></span>   

## <a name="use-azure-key-vault"></a><span data-ttu-id="8ad03-429">Utiliser Azure Key Vault</span><span class="sxs-lookup"><span data-stu-id="8ad03-429">Use Azure Key Vault</span></span>
<span data-ttu-id="8ad03-430">Il n’est pas recommandé et souvent déconseillé vis-à-vis de la stratégie de sécurité pour valider des données sensibles telles que des chaînes de connexion au référentiel de code.</span><span class="sxs-lookup"><span data-stu-id="8ad03-430">It is not advisable and often against security policy to commit sensitive data such as connection strings to the code repository.</span></span> <span data-ttu-id="8ad03-431">Consultez l’exemple [ADF Secure Publish](https://github.com/Azure/Azure-DataFactory/tree/master/Samples/ADFSecurePublish) sur GitHub pour en savoir plus sur le stockage d’informations sensibles dans Azure Key Vault et son utilisation lors de la publication des entités Data Factory.</span><span class="sxs-lookup"><span data-stu-id="8ad03-431">See [ADF Secure Publish](https://github.com/Azure/Azure-DataFactory/tree/master/Samples/ADFSecurePublish) sample on GitHub to learn about storing sensitive information in Azure Key Vault and using it while publishing Data Factory entities.</span></span> <span data-ttu-id="8ad03-432">L’extension Secure Publish pour Visual Studio permet de stocker les secrets dans Key Vault, et seules les références à ceux-ci sont spécifiés dans des services / configurations de déploiement liés.</span><span class="sxs-lookup"><span data-stu-id="8ad03-432">The Secure Publish extension for Visual Studio allows the secrets to be stored in Key Vault and only references to them are specified in linked services/ deployment configurations.</span></span> <span data-ttu-id="8ad03-433">Ces références sont résolues lorsque vous publiez des entités Data Factory dans Azure.</span><span class="sxs-lookup"><span data-stu-id="8ad03-433">These references are resolved when you publish Data Factory entities to Azure.</span></span> <span data-ttu-id="8ad03-434">Ces fichiers peuvent ensuite être validés sur le référentiel source sans exposer les secrets.</span><span class="sxs-lookup"><span data-stu-id="8ad03-434">These files can then be committed to source repository without exposing any secrets.</span></span>

## <a name="summary"></a><span data-ttu-id="8ad03-435">Résumé</span><span class="sxs-lookup"><span data-stu-id="8ad03-435">Summary</span></span>
<span data-ttu-id="8ad03-436">Dans ce didacticiel, vous avez créé une fabrique de données Azure pour traiter des données en exécutant le script Hive sur un cluster Hadoop HDInsight.</span><span class="sxs-lookup"><span data-stu-id="8ad03-436">In this tutorial, you created an Azure data factory to process data by running Hive script on a HDInsight hadoop cluster.</span></span> <span data-ttu-id="8ad03-437">Vous avez effectué les étapes suivantes dans le portail Azure à l’aide de Data Factory Editor :</span><span class="sxs-lookup"><span data-stu-id="8ad03-437">You used the Data Factory Editor in the Azure portal to do the following steps:</span></span>  

1. <span data-ttu-id="8ad03-438">Création d’une **fabrique de données**Azure.</span><span class="sxs-lookup"><span data-stu-id="8ad03-438">Created an Azure **data factory**.</span></span>
2. <span data-ttu-id="8ad03-439">Création de deux **services liés**:</span><span class="sxs-lookup"><span data-stu-id="8ad03-439">Created two **linked services**:</span></span>
   1. <span data-ttu-id="8ad03-440">**Azure Storage** pour lier à la fabrique de données votre stockage d’objets blob Azure contenant les fichiers d’entrée/sortie.</span><span class="sxs-lookup"><span data-stu-id="8ad03-440">**Azure Storage** linked service to link your Azure blob storage that holds input/output files to the data factory.</span></span>
   2. <span data-ttu-id="8ad03-441">**Azure HDInsight** à la demande pour lier à la fabrique de données un cluster Hadoop HDInsight à la demande.</span><span class="sxs-lookup"><span data-stu-id="8ad03-441">**Azure HDInsight** on-demand linked service to link an on-demand HDInsight Hadoop cluster to the data factory.</span></span> <span data-ttu-id="8ad03-442">Azure Data Factory crée un cluster Hadoop HDInsight juste-à-temps pour traiter les données d’entrée et produire des données de sortie.</span><span class="sxs-lookup"><span data-stu-id="8ad03-442">Azure Data Factory creates a HDInsight Hadoop cluster just-in-time to process input data and produce output data.</span></span>
3. <span data-ttu-id="8ad03-443">Création de deux **jeux de données**qui décrivent les données d’entrée et de sortie pour l’activité HDInsight Hive dans le pipeline.</span><span class="sxs-lookup"><span data-stu-id="8ad03-443">Created two **datasets**, which describe input and output data for HDInsight Hive activity in the pipeline.</span></span>
4. <span data-ttu-id="8ad03-444">Création d’un **pipeline** avec une activité **Hive HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="8ad03-444">Created a **pipeline** with a **HDInsight Hive** activity.</span></span>  

## <a name="next-steps"></a><span data-ttu-id="8ad03-445">Étapes suivantes</span><span class="sxs-lookup"><span data-stu-id="8ad03-445">Next Steps</span></span>
<span data-ttu-id="8ad03-446">Dans cet article, vous avez créé un pipeline avec une activité de transformation (Activité HDInsight) qui exécute un script Hive sur un cluster HDInsight à la demande.</span><span class="sxs-lookup"><span data-stu-id="8ad03-446">In this article, you have created a pipeline with a transformation activity (HDInsight Activity) that runs a Hive script on an on-demand HDInsight cluster.</span></span> <span data-ttu-id="8ad03-447">Pour voir comment utiliser une activité de copie pour copier des données depuis un objet blob Azure vers Azure SQL, consultez le [Didacticiel : copie de données depuis un objet blob Azure vers Azure SQL](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="8ad03-447">To see how to use a Copy Activity to copy data from an Azure Blob to Azure SQL, see [Tutorial: Copy data from an Azure blob to Azure SQL](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>

<span data-ttu-id="8ad03-448">Vous pouvez chaîner deux activités (une après l’autre) en configurant le jeu de données de sortie d’une activité en tant que jeu de données d’entrée de l’autre activité.</span><span class="sxs-lookup"><span data-stu-id="8ad03-448">You can chain two activities (run one activity after another) by setting the output dataset of one activity as the input dataset of the other activity.</span></span> <span data-ttu-id="8ad03-449">Pour plus d’informations, voir [Planification et exécution dans Data Factory](data-factory-scheduling-and-execution.md).</span><span class="sxs-lookup"><span data-stu-id="8ad03-449">See [Scheduling and execution in Data Factory](data-factory-scheduling-and-execution.md) for detailed information.</span></span> 


## <a name="see-also"></a><span data-ttu-id="8ad03-450">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="8ad03-450">See Also</span></span>
| <span data-ttu-id="8ad03-451">Rubrique</span><span class="sxs-lookup"><span data-stu-id="8ad03-451">Topic</span></span> | <span data-ttu-id="8ad03-452">Description</span><span class="sxs-lookup"><span data-stu-id="8ad03-452">Description</span></span> |
|:--- |:--- |
| [<span data-ttu-id="8ad03-453">Pipelines</span><span class="sxs-lookup"><span data-stu-id="8ad03-453">Pipelines</span></span>](data-factory-create-pipelines.md) |<span data-ttu-id="8ad03-454">Cet article vous aide à comprendre les pipelines et les activités dans Azure Data Factory, et à les utiliser dans l’optique de créer des workflows pilotés par les données pour votre scénario ou votre entreprise.</span><span class="sxs-lookup"><span data-stu-id="8ad03-454">This article helps you understand pipelines and activities in Azure Data Factory and how to use them to construct data-driven workflows for your scenario or business.</span></span> |
| [<span data-ttu-id="8ad03-455">Groupes de données</span><span class="sxs-lookup"><span data-stu-id="8ad03-455">Datasets</span></span>](data-factory-create-datasets.md) |<span data-ttu-id="8ad03-456">Cet article vous aide à comprendre les jeux de données dans Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="8ad03-456">This article helps you understand datasets in Azure Data Factory.</span></span> |
| [<span data-ttu-id="8ad03-457">Activités de transformation des données</span><span class="sxs-lookup"><span data-stu-id="8ad03-457">Data Transformation Activities</span></span>](data-factory-data-transformation-activities.md) |<span data-ttu-id="8ad03-458">Cet article fournit une liste des activités de transformation de données (par exemple, la transformation Hive HDInsight que vous avez utilisée dans ce didacticiel) prises en charge par Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="8ad03-458">This article provides a list of data transformation activities (such as HDInsight Hive transformation you used in this tutorial) supported by Azure Data Factory.</span></span> |
| [<span data-ttu-id="8ad03-459">Planification et exécution</span><span class="sxs-lookup"><span data-stu-id="8ad03-459">Scheduling and execution</span></span>](data-factory-scheduling-and-execution.md) |<span data-ttu-id="8ad03-460">Cet article explique les aspects de la planification et de l’exécution du modèle d’application Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="8ad03-460">This article explains the scheduling and execution aspects of Azure Data Factory application model.</span></span> |
| [<span data-ttu-id="8ad03-461">Surveiller et gérer les pipelines Azure Data Factory à l’aide de la nouvelle application de surveillance et gestion.</span><span class="sxs-lookup"><span data-stu-id="8ad03-461">Monitor and manage pipelines using Monitoring App</span></span>](data-factory-monitor-manage-app.md) |<span data-ttu-id="8ad03-462">Cet article décrit comment surveiller, gérer et déboguer les pipelines à l’aide de l’application de surveillance et gestion.</span><span class="sxs-lookup"><span data-stu-id="8ad03-462">This article describes how to monitor, manage, and debug pipelines using the Monitoring & Management App.</span></span> |
