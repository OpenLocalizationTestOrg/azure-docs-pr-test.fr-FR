---
title: "Ingénierie des caractéristiques dans la science des données | Microsoft Docs"
description: "Explique les finalités de la conception de fonctionnalités et fournit des exemples de son rôle dans le processus d'amélioration des données de l'apprentissage automatique."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 3fde69e8-5e7b-49ad-b3fb-ab8ef6503a4d
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/24/2017
ms.author: zhangya;bradsev
ms.openlocfilehash: f586e8087a246f3bedf5010e8f6ce7aea1c1ec6a
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 07/11/2017
---
# <a name="feature-engineering-in-data-science"></a><span data-ttu-id="762b9-103">Ingénierie des caractéristiques dans la science des données</span><span class="sxs-lookup"><span data-stu-id="762b9-103">Feature engineering in data science</span></span>
<span data-ttu-id="762b9-104">Cette rubrique explique les finalités de la conception de fonctionnalités et fournit des exemples de son rôle dans le processus d’amélioration des données de l’apprentissage automatique.</span><span class="sxs-lookup"><span data-stu-id="762b9-104">This topic explains the purposes of feature engineering and provides examples of its role in the data enhancement process of machine learning.</span></span> <span data-ttu-id="762b9-105">Les exemples utilisés pour illustrer ce processus sont tirés d’Azure Machine Learning Studio.</span><span class="sxs-lookup"><span data-stu-id="762b9-105">The examples used to illustrate this process are drawn from Azure Machine Learning Studio.</span></span> 

[!INCLUDE [cap-create-features-data-selector](../../includes/cap-create-features-selector.md)]

<span data-ttu-id="762b9-106">Ce **menu** pointe vers des rubriques qui expliquent comment créer des fonctionnalités pour les données dans différents environnements.</span><span class="sxs-lookup"><span data-stu-id="762b9-106">This **menu** links to topics that describe how to create features for data in various environments.</span></span> <span data-ttu-id="762b9-107">Cette tâche est une étape du [processus TDSP (Team Data Science Process)](https://azure.microsoft.com/documentation/learning-paths/cortana-analytics-process/).</span><span class="sxs-lookup"><span data-stu-id="762b9-107">This task is a step in the [Team Data Science Process (TDSP)](https://azure.microsoft.com/documentation/learning-paths/cortana-analytics-process/).</span></span>

<span data-ttu-id="762b9-108">La conception de fonctionnalités tente d'augmenter la puissance prédictive des algorithmes d'apprentissage en créant des fonctionnalités à partir de données brutes qui facilitent le processus d'apprentissage.</span><span class="sxs-lookup"><span data-stu-id="762b9-108">Feature engineering attempts to increase the predictive power of learning algorithms by creating features from raw data that help facilitate the learning process.</span></span> <span data-ttu-id="762b9-109">L’ingénierie et la sélection de caractéristiques constituent une partie du processus TDSP présenté dans [Qu’est ce que le cycle de vie du processus TDSP (Team Data Science Process) ?](data-science-process-overview.md).</span><span class="sxs-lookup"><span data-stu-id="762b9-109">The engineering and selection of features is one part of the TDSP outlined in the [What is the Team Data Science Process lifecycle?](data-science-process-overview.md)</span></span> <span data-ttu-id="762b9-110">La conception et la sélection de fonctionnalités sont des parties de l’étape de **développement de fonctionnalités** du processus TDSP.</span><span class="sxs-lookup"><span data-stu-id="762b9-110">Feature engineering and selection are parts of the **Develop features** step of the TDSP.</span></span> 

* <span data-ttu-id="762b9-111">La **conception de fonctionnalités** : ce processus tente de créer des fonctionnalités supplémentaires pertinentes à partir de fonctionnalités brutes existantes dans les données et d’augmenter la performance de prédiction de l’algorithme d’apprentissage.</span><span class="sxs-lookup"><span data-stu-id="762b9-111">**feature engineering**: This process attempts to create additional relevant features from the existing raw features in the data, and to increase the predictive power of the learning algorithm.</span></span>
* <span data-ttu-id="762b9-112">La **sélection de caractéristiques** : ce processus sélectionne le sous-ensemble clé des caractéristiques de données d'origine afin de réduire la dimensionnalité du problème d'apprentissage.</span><span class="sxs-lookup"><span data-stu-id="762b9-112">**feature selection**: This process selects the key subset of original data features in an attempt to reduce the dimensionality of the training problem.</span></span>

<span data-ttu-id="762b9-113">En général, **l’ingénierie des caractéristiques** s’applique d’abord à la génération de caractéristiques supplémentaires. L’étape de **sélection de caractéristiques** est alors effectuée pour éliminer les caractéristiques inutiles, redondantes ou fortement corrélées.</span><span class="sxs-lookup"><span data-stu-id="762b9-113">Normally **feature engineering** is applied first to generate additional features, and then the **feature selection** step is performed to eliminate irrelevant, redundant, or highly correlated features.</span></span>

<span data-ttu-id="762b9-114">Les données d'apprentissage utilisées dans l'apprentissage automatique peuvent souvent être améliorées par l'extraction de fonctionnalités à partir des données brutes collectées.</span><span class="sxs-lookup"><span data-stu-id="762b9-114">The training data used in machine learning can often be enhanced by extraction of features from the raw data collected.</span></span> <span data-ttu-id="762b9-115">Un exemple de conception de fonctionnalité dans le cadre de l'apprentissage de la classification des images de caractères écrits à la main est la création d'une carte de densité de bits construite à partir des données brutes de distribution de bits.</span><span class="sxs-lookup"><span data-stu-id="762b9-115">An example of an engineered feature in the context of learning how to classify the images of handwritten characters is creation of a bit density map constructed from the raw bit distribution data.</span></span> <span data-ttu-id="762b9-116">Cette carte peut aider à localiser les bords des caractères plus efficacement que l'utilisation de la distribution brute directement.</span><span class="sxs-lookup"><span data-stu-id="762b9-116">This map can help locate the edges of the characters more efficiently than simply using the raw distribution directly.</span></span>

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

## <a name="creating-features-from-your-data---feature-engineering"></a><span data-ttu-id="762b9-117">Création de caractéristiques à partir de vos données - Conception de caractéristiques</span><span class="sxs-lookup"><span data-stu-id="762b9-117">Creating Features from Your Data - Feature Engineering</span></span>
<span data-ttu-id="762b9-118">Les données d'apprentissage se constituent d'une matrice composée d'exemples (enregistrements ou observations stockées dans les lignes), chaque exemple disposant d'un ensemble de caractéristiques (variables ou champs stockés dans des colonnes).</span><span class="sxs-lookup"><span data-stu-id="762b9-118">The training data consists of a matrix composed of examples (records or observations stored in rows), each of which has a set of features (variables or fields stored in columns).</span></span> <span data-ttu-id="762b9-119">Les caractéristiques spécifiées dans la conception expérimentale sont supposées caractériser les modèles dans les données.</span><span class="sxs-lookup"><span data-stu-id="762b9-119">The features specified in the experimental design are expected to characterize the patterns in the data.</span></span> <span data-ttu-id="762b9-120">Bien que plusieurs champs de données brutes puissent être directement inclus dans l'ensemble des caractéristiques sélectionnées utilisées pour l'apprentissage d'un modèle, il est fréquent que des caractéristiques supplémentaires (conçues) doivent être construites à partir des caractéristiques dans les données brutes pour générer un jeu de données de formation amélioré.</span><span class="sxs-lookup"><span data-stu-id="762b9-120">Although many of the raw data fields can be directly included in the selected feature set used to train a model, it is often the case that additional (engineered) features need to be constructed from the features in the raw data to generate an enhanced training dataset.</span></span>

<span data-ttu-id="762b9-121">Quelles sont les caractéristiques qui doivent être créées pour améliorer le jeu de données lors de l'apprentissage d'un modèle ?</span><span class="sxs-lookup"><span data-stu-id="762b9-121">What kind of features should be created to enhance the dataset when training a model?</span></span> <span data-ttu-id="762b9-122">Les caractéristiques conçues améliorant l'apprentissage offrent des informations qui permettent de mieux différencier les modèles dans les données.</span><span class="sxs-lookup"><span data-stu-id="762b9-122">Engineered features that enhance the training provide information that better differentiates the patterns in the data.</span></span> <span data-ttu-id="762b9-123">Les nouvelles caractéristiques devraient fournir des informations supplémentaires qui ne sont pas clairement capturées ou facilement visibles dans l'ensemble des caractéristiques existantes ou d'origine.</span><span class="sxs-lookup"><span data-stu-id="762b9-123">We expect the new features to provide additional information that is not clearly captured or easily apparent in the original or existing feature set.</span></span> <span data-ttu-id="762b9-124">Mais ce processus est tout un art.</span><span class="sxs-lookup"><span data-stu-id="762b9-124">But this process is something of an art.</span></span> <span data-ttu-id="762b9-125">Des décisions réfléchies et productives nécessitent souvent une spécialisation dans le domaine.</span><span class="sxs-lookup"><span data-stu-id="762b9-125">Sound and productive decisions often require some domain expertise.</span></span>

<span data-ttu-id="762b9-126">En débutant avec Azure Machine Learning, il est plus facile de comprendre correctement le processus avec des exemples fournis dans le Studio.</span><span class="sxs-lookup"><span data-stu-id="762b9-126">When starting with Azure Machine Learning, it is easiest to grasp this process concretely using samples provided in the Studio.</span></span> <span data-ttu-id="762b9-127">Deux exemples sont présentés ici :</span><span class="sxs-lookup"><span data-stu-id="762b9-127">Two examples are presented here:</span></span>

* <span data-ttu-id="762b9-128">un exemple de régression [Prédiction du nombre de locations de vélo](http://gallery.cortanaintelligence.com/Experiment/Regression-Demand-estimation-4) dans une expérience supervisée, où les valeurs cibles sont connues</span><span class="sxs-lookup"><span data-stu-id="762b9-128">A regression example [Prediction of the number of bike rentals](http://gallery.cortanaintelligence.com/Experiment/Regression-Demand-estimation-4) in a supervised experiment where the target values are known</span></span>
* <span data-ttu-id="762b9-129">un exemple de classification d'exploration de texte utilisant le [hachage de caractéristiques](https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/)</span><span class="sxs-lookup"><span data-stu-id="762b9-129">A text mining classification example using [Feature Hashing](https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/)</span></span>

## <a name="example-1-adding-temporal-features-for-regression-model"></a><span data-ttu-id="762b9-130">Exemple 1 : ajout de caractéristiques temporelles pour le modèle de régression</span><span class="sxs-lookup"><span data-stu-id="762b9-130">Example 1: Adding Temporal Features for Regression Model</span></span>
<span data-ttu-id="762b9-131">Nous allons utiliser l'exemple de « prévision de la demande de vélos » dans Azure Machine Learning Studio afin de démontrer comment concevoir des caractéristiques pour une tâche de régression.</span><span class="sxs-lookup"><span data-stu-id="762b9-131">Let's use the experiment "Demand forecasting of bikes" in Azure Machine Learning Studio to demonstrate how to engineer features for a regression task.</span></span> <span data-ttu-id="762b9-132">L'objectif de cette expérience est de prédire la demande de vélos, autrement dit le nombre de locations de vélo pour un mois/un jour/une heure spécifique.</span><span class="sxs-lookup"><span data-stu-id="762b9-132">The objective of this experiment is to predict the demand for the bikes, that is, the number of bike rentals within a specific month/day/hour.</span></span> <span data-ttu-id="762b9-133">Le « jeu de données de location de vélo UCI »est utilisé en tant que données brutes d'entrée.</span><span class="sxs-lookup"><span data-stu-id="762b9-133">The dataset "Bike Rental UCI dataset" is used as the raw input data.</span></span> <span data-ttu-id="762b9-134">Le jeu de données se base sur des données réelles de la société Capital Bikeshare qui gère un réseau de location de vélos à Washington DC aux États-Unis.</span><span class="sxs-lookup"><span data-stu-id="762b9-134">This dataset is based on real data from the Capital Bikeshare company that maintains a bike rental network in Washington DC in the United States.</span></span> <span data-ttu-id="762b9-135">Ce jeu de données représente le nombre de locations de vélo pour une heure spécifique d'un jour en 2011 et en 2012 et contient 17 379 lignes et 17 colonnes.</span><span class="sxs-lookup"><span data-stu-id="762b9-135">The dataset represents the number of bike rentals within a specific hour of a day in the years 2011 and year 2012 and contains 17379 rows and 17 columns.</span></span> <span data-ttu-id="762b9-136">L'ensemble des caractéristiques brutes contient des conditions météorologiques (température/humidité/vitesse du vent) et le type de jour (vacances/jour de semaine).</span><span class="sxs-lookup"><span data-stu-id="762b9-136">The raw feature set contains weather conditions (temperature/humidity/wind speed) and the type of the day (holiday/weekday).</span></span> <span data-ttu-id="762b9-137">Le champ à prédire est « cnt », un nombre qui représente les locations de vélo pour une heure spécifique et qui est compris entre 1 et 977.</span><span class="sxs-lookup"><span data-stu-id="762b9-137">The field to predict is "cnt", a count which represents the bike rentals within a specific hour and which ranges ranges from 1 to 977.</span></span>

<span data-ttu-id="762b9-138">Afin de construire des caractéristiques efficaces dans les données d'apprentissage, quatre modèles de régression sont générés à l'aide du même algorithme, mais avec quatre jeux de données d'apprentissage différents.</span><span class="sxs-lookup"><span data-stu-id="762b9-138">With the goal of constructing effective features in the training data, four regression models are built using the same algorithm but with four different training datasets.</span></span> <span data-ttu-id="762b9-139">Les quatre jeux de données représentent les mêmes données d'entrée brutes, mais avec un nombre croissant de jeux de caractéristiques.</span><span class="sxs-lookup"><span data-stu-id="762b9-139">The four datasets represent the same raw input data, but with an increasing number of features set.</span></span> <span data-ttu-id="762b9-140">Ces caractéristiques sont regroupées en quatre catégories :</span><span class="sxs-lookup"><span data-stu-id="762b9-140">These features are grouped into four categories:</span></span>

1. <span data-ttu-id="762b9-141">A = caractéristiques météo + vacances + jour de semaine + week-end pour le jour prévu</span><span class="sxs-lookup"><span data-stu-id="762b9-141">A = weather + holiday + weekday + weekend features for the predicted day</span></span>
2. <span data-ttu-id="762b9-142">B = nombre de vélos loués au cours de chacune des 12 dernières heures</span><span class="sxs-lookup"><span data-stu-id="762b9-142">B = number of bikes that were rented in each of the previous 12 hours</span></span>
3. <span data-ttu-id="762b9-143">C = nombre de vélos loués au cours de chacun des 12 derniers jours à la même heure</span><span class="sxs-lookup"><span data-stu-id="762b9-143">C = number of bikes that were rented in each of the previous 12 days at the same hour</span></span>
4. <span data-ttu-id="762b9-144">D = nombre de vélos loués au cours de chacune des 12 dernières semaines le même jour à la même heure</span><span class="sxs-lookup"><span data-stu-id="762b9-144">D = number of bikes that were rented in each of the previous 12 weeks at the same hour and the same day</span></span>

<span data-ttu-id="762b9-145">Excepté l'ensemble de caractéristiques A, qui existe déjà dans les données brutes d'origine, les trois autres ensembles de caractéristiques sont créés via le processus de conception des caractéristiques.</span><span class="sxs-lookup"><span data-stu-id="762b9-145">Besides feature set A, which already exist in the original raw data, the other three sets of features are created through the feature engineering process.</span></span> <span data-ttu-id="762b9-146">L'ensemble de caractéristiques B capture les toutes dernières demandes de vélos.</span><span class="sxs-lookup"><span data-stu-id="762b9-146">Feature set B captures very recent demand for the bikes.</span></span> <span data-ttu-id="762b9-147">L'ensemble de caractéristiques C capture la demande de vélos pour une heure en particulier.</span><span class="sxs-lookup"><span data-stu-id="762b9-147">Feature set C captures the demand for bikes at a particular hour.</span></span> <span data-ttu-id="762b9-148">L'ensemble de caractéristiques D capture la demande de vélos pour une heure particulière et un jour de la semaine particulier.</span><span class="sxs-lookup"><span data-stu-id="762b9-148">Feature set D captures demand for bikes at particular hour and particular day of the week.</span></span> <span data-ttu-id="762b9-149">Chacun des quatre jeux de données d'apprentissage inclut respectivement un ensemble de caractéristiques A, A + B, A + B + C et A + B + C + D.</span><span class="sxs-lookup"><span data-stu-id="762b9-149">The four training datasets each includes feature set A, A+B, A+B+C, and A+B+C+D, respectively.</span></span>

<span data-ttu-id="762b9-150">Dans l'expérience d'Azure Machine Learning, ces quatre jeux de données d'apprentissage sont constitués via quatre branches à partir du jeu de données d'entrée traité au préalable.</span><span class="sxs-lookup"><span data-stu-id="762b9-150">In the Azure Machine Learning experiment, these four training datasets are formed via four branches from the pre-processed input dataset.</span></span> <span data-ttu-id="762b9-151">À l'exception de la branche la plus à gauche, chacune de ces branches contient un module [Exécuter le Script R](https://msdn.microsoft.com/library/azure/30806023-392b-42e0-94d6-6b775a6e0fd5/) , dans lequel un ensemble de caractéristiques dérivées (ensemble de caractéristiques B, C et D) sont respectivement construites et ajoutées au jeu de données importé.</span><span class="sxs-lookup"><span data-stu-id="762b9-151">Except the left most branch, each of these branches contains an [Execute R Script](https://msdn.microsoft.com/library/azure/30806023-392b-42e0-94d6-6b775a6e0fd5/) module, in which a set of derived features (feature set B, C, and D) are respectively constructed and appended to the imported dataset.</span></span> <span data-ttu-id="762b9-152">La figure suivante montre le script R utilisé pour créer un ensemble de caractéristiques B dans la deuxième branche de gauche.</span><span class="sxs-lookup"><span data-stu-id="762b9-152">The following figure demonstrates the R script used to create feature set B in the second left branch.</span></span>

![création de caractéristiques](./media/machine-learning-data-science-create-features/addFeature-Rscripts.png)

<span data-ttu-id="762b9-154">La comparaison des résultats de performance des quatre modèles est résumée dans la table suivante.</span><span class="sxs-lookup"><span data-stu-id="762b9-154">The comparison of the performance results of the four models are summarized in the following table.</span></span> <span data-ttu-id="762b9-155">Les caractéristiques A + B + C affichent les meilleurs résultats.</span><span class="sxs-lookup"><span data-stu-id="762b9-155">The best results are shown by features A+B+C.</span></span> <span data-ttu-id="762b9-156">Notez que le taux d'erreur diminue lorsqu'un ensemble de caractéristiques supplémentaires est inclus dans les données d'apprentissage.</span><span class="sxs-lookup"><span data-stu-id="762b9-156">Note that the error rate decreases when additional feature set are included in the training data.</span></span> <span data-ttu-id="762b9-157">Cela confirme l'idée présupposée que les ensembles de caractéristiques B et C fournissent des informations supplémentaires pertinentes pour la tâche de régression.</span><span class="sxs-lookup"><span data-stu-id="762b9-157">It verifies our presumption that the feature set B, C provide additional relevant information for the regression task.</span></span> <span data-ttu-id="762b9-158">Mais l'ajout de la caractéristique D semble ne pas fournir une réduction du taux d'erreur supplémentaire.</span><span class="sxs-lookup"><span data-stu-id="762b9-158">But adding the D feature does not seem to provide any additional reduction in the error rate.</span></span>

![comparaison des résultats](./media/machine-learning-data-science-create-features/result1.png)

## <span data-ttu-id="762b9-160"><a name="example2"></a> Exemple 2 : création de caractéristiques dans l'exploration de texte</span><span class="sxs-lookup"><span data-stu-id="762b9-160"><a name="example2"></a> Example 2: Creating Features in Text Mining</span></span>
<span data-ttu-id="762b9-161">L'ingénierie de caractéristiques s'applique largement aux tâches liées à l'exploration de texte, telles que la classification de document et l'analyse de sentiments.</span><span class="sxs-lookup"><span data-stu-id="762b9-161">Feature engineering is widely applied in tasks related to text mining, such as document classification and sentiment analysis.</span></span> <span data-ttu-id="762b9-162">Par exemple, lorsque vous souhaitez classer des documents en plusieurs catégories, l'hypothèse typique est que les mots ou expressions inclus dans une catégorie de document sont moins susceptibles de se produire dans une autre catégorie de document.</span><span class="sxs-lookup"><span data-stu-id="762b9-162">For example, when we want to classify documents into several categories, a typical assumption is that the word/phrases included in one doc category are less likely to occur in another doc category.</span></span> <span data-ttu-id="762b9-163">Autrement dit, la fréquence de la distribution de mots ou d'expressions est capable d'identifier les différentes catégories de document.</span><span class="sxs-lookup"><span data-stu-id="762b9-163">In another words, the frequency of the words/phrases distribution is able to characterize different document categories.</span></span> <span data-ttu-id="762b9-164">Dans les applications d'exploration de texte, étant donné que chaque élément des contenus de textes est généralement utilisé en tant que données d'entrée, le processus de conception de caractéristiques est nécessaire pour créer les caractéristiques impliquant des fréquences de mot ou d'expression.</span><span class="sxs-lookup"><span data-stu-id="762b9-164">In text mining applications, because individual pieces of text-contents usually serve as the input data, the feature engineering process is needed to create the features involving word/phrase frequencies.</span></span>

<span data-ttu-id="762b9-165">Pour effectuer cette tâche, une technique appelée **hachage de caractéristiques** est appliquée pour transformer efficacement les caractéristiques de texte arbitraires en index.</span><span class="sxs-lookup"><span data-stu-id="762b9-165">To achieve this task, a technique called **feature hashing** is applied to efficiently turn arbitrary text features into indices.</span></span> <span data-ttu-id="762b9-166">Au lieu d'associer chaque caractéristique de texte (mots ou d'expressions) à un index particulier, cette méthode fonctionne en appliquant une caractéristique de hachage aux caractéristiques et en utilisant directement leurs valeurs de hachage en tant qu'index.</span><span class="sxs-lookup"><span data-stu-id="762b9-166">Instead of associating each text feature (words/phrases) to a particular index, this method functions by applying a hash function to the features and using their hash values as indices directly.</span></span>

<span data-ttu-id="762b9-167">Dans Azure Machine Learning, il existe un module de [hachage de caractéristiques](https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/) qui crée en toute facilité ces caractéristiques de mot ou expression.</span><span class="sxs-lookup"><span data-stu-id="762b9-167">In Azure Machine Learning, there is a [Feature Hashing](https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/) module that creates these word/phrase features conveniently.</span></span> <span data-ttu-id="762b9-168">La figure suivante montre un exemple d'utilisation de ce module.</span><span class="sxs-lookup"><span data-stu-id="762b9-168">Following figure shows an example of using this module.</span></span> <span data-ttu-id="762b9-169">Le jeu de données d'entrée contient deux colonnes : l'évaluation du livre allant de 1 à 5 et le contenu même de la critique.</span><span class="sxs-lookup"><span data-stu-id="762b9-169">The input dataset contains two columns: the book rating ranging from 1 to 5, and the actual review content.</span></span> <span data-ttu-id="762b9-170">L'objectif de ce module de [hachage de caractéristiques](https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/) est de récupérer un ensemble de nouvelles caractéristiques qui montrent la fréquence d'occurrence des mots ou expressions correspondants dans cette critique de livre en particulier.</span><span class="sxs-lookup"><span data-stu-id="762b9-170">The goal of this [Feature Hashing](https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/) module is to retrieve a bunch of new features that show the occurrence frequency of the corresponding word(s)/phrase(s) within the particular book review.</span></span> <span data-ttu-id="762b9-171">Pour utiliser ce module, il est nécessaire d'effectuer les étapes suivantes :</span><span class="sxs-lookup"><span data-stu-id="762b9-171">To use this module, we need to complete the following steps:</span></span>

* <span data-ttu-id="762b9-172">Tout d'abord, sélectionnez la colonne qui contient le texte d'entrée (« Col2 » pour cet exemple).</span><span class="sxs-lookup"><span data-stu-id="762b9-172">First, select the column that contains the input text ("Col2" in this example).</span></span>
* <span data-ttu-id="762b9-173">Ensuite, définissez le « nombre de bits de hachage » sur 8, ce qui signifie que 2 ^ 8 = 256 caractéristiques seront créées.</span><span class="sxs-lookup"><span data-stu-id="762b9-173">Second, set the "Hashing bitsize" to 8, which means 2^8=256 features will be created.</span></span> <span data-ttu-id="762b9-174">Le mot ou l'expression sera haché en 256 index dans tout le texte.</span><span class="sxs-lookup"><span data-stu-id="762b9-174">The word/phase in all the text will be hashed to 256 indices.</span></span> <span data-ttu-id="762b9-175">Le paramètre « hachage du nombre de bits » est compris entre 1 et 31.</span><span class="sxs-lookup"><span data-stu-id="762b9-175">The parameter "Hashing bitsize" ranges from 1 to 31.</span></span> <span data-ttu-id="762b9-176">Les mots ou les phrases sont moins susceptibles d'être hachés dans le même index s'ils sont définis sur un nombre plus grand.</span><span class="sxs-lookup"><span data-stu-id="762b9-176">The word(s)/phrase(s) are less likely to be hashed into the same index if setting it to be a larger number.</span></span>
* <span data-ttu-id="762b9-177">Enfin, définissez le paramètre « N-grammes » sur 2.</span><span class="sxs-lookup"><span data-stu-id="762b9-177">Third, set the parameter "N-grams" to 2.</span></span> <span data-ttu-id="762b9-178">Celui-ci permet d'obtenir la fréquence d'occurrence d'unigrammes (une caractéristique pour chaque mot) et de bigrammes (une caractéristique pour chaque paire de mots juxtaposés) à partir du texte d'entrée.</span><span class="sxs-lookup"><span data-stu-id="762b9-178">This gets the occurrence frequency of unigrams (a feature for every single word) and bigrams (a feature for every pair of adjacent words) from the input text.</span></span> <span data-ttu-id="762b9-179">Le paramètre « N-grammes » est compris entre 0 et 10, ce qui indique le nombre maximum de mots séquentiels à inclure dans une caractéristique.</span><span class="sxs-lookup"><span data-stu-id="762b9-179">The parameter "N-grams" ranges from 0 to 10, which indicates the maximum number of sequential words to be included in a feature.</span></span>  

![Module « hachage de caractéristiques »](./media/machine-learning-data-science-create-features/feature-Hashing1.png)

<span data-ttu-id="762b9-181">La figure suivante montre à quoi ressemblent ces nouvelles caractéristiques.</span><span class="sxs-lookup"><span data-stu-id="762b9-181">The following figure shows what the these new feature look like.</span></span>

![Exemple « hachage de caractéristiques »](./media/machine-learning-data-science-create-features/feature-Hashing2.png)

## <a name="conclusion"></a><span data-ttu-id="762b9-183">Conclusion</span><span class="sxs-lookup"><span data-stu-id="762b9-183">Conclusion</span></span>
<span data-ttu-id="762b9-184">L'ingénierie et la sélection de caractéristiques augmentent l'efficacité du processus d'apprentissage qui tend à extraire les informations essentielles contenues dans les données.</span><span class="sxs-lookup"><span data-stu-id="762b9-184">Engineered and selected features increase the efficiency of the training process which attempts to extract the key information contained in the data.</span></span> <span data-ttu-id="762b9-185">Ces processus améliorent également les performances de ces modèles pour classifier les données d'entrée avec précision et prédire les résultats pertinents de façon plus consistante.</span><span class="sxs-lookup"><span data-stu-id="762b9-185">They also improve the power of these models to classify the input data accurately and to predict outcomes of interest more robustly.</span></span> <span data-ttu-id="762b9-186">L'ingénierie et la sélection de caractéristiques peuvent également être combinées afin de rendre l'apprentissage plus souple d'un point de vue informatique.</span><span class="sxs-lookup"><span data-stu-id="762b9-186">Feature engineering and selection can also combine to make the learning more computationally tractable.</span></span> <span data-ttu-id="762b9-187">Cela se fait grâce à l'amélioration puis à la réduction du nombre de caractéristiques nécessaires à l'étalonnage ou l'apprentissage d'un modèle.</span><span class="sxs-lookup"><span data-stu-id="762b9-187">It does so by enhancing and then reducing the number of features needed to calibrate or train a model.</span></span> <span data-ttu-id="762b9-188">D'un point de vue mathématique, les caractéristiques sélectionnées pour effectuer l'apprentissage du modèle sont un ensemble minimum de variables indépendantes qui expliquent les modèles des données puis prédisent correctement les résultats.</span><span class="sxs-lookup"><span data-stu-id="762b9-188">Mathematically speaking, the features selected to train the model are a minimal set of independent variables that explain the patterns in the data and then predict outcomes successfully.</span></span>

<span data-ttu-id="762b9-189">Notez qu'il n'est pas toujours nécessaire d'effectuer l'ingénierie de caractéristiques ou la sélection des caractéristiques.</span><span class="sxs-lookup"><span data-stu-id="762b9-189">Note that it is not always necessarily to perform feature engineering or feature selection.</span></span> <span data-ttu-id="762b9-190">Que cela soit nécessaire ou non dépend des données que l'on a à disposition ou qui sont collectées, de l'algorithme choisi et des objectifs de l'expérience.</span><span class="sxs-lookup"><span data-stu-id="762b9-190">Whether it is needed or not depends on the data we have or collect, the algorithm we pick, and the objective of the experiment.</span></span>

