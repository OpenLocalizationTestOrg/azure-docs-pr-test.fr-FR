---
title: "Évaluer les performances d’un modèle dans Machine Learning | Microsoft Docs"
description: "Explique comment évaluer l’efficacité d’un modèle dans Azure Machine Learning."
services: machine-learning
documentationcenter: 
author: garyericson
manager: jhubbard
editor: cgronlun
ms.assetid: 5dc5348a-4488-4536-99eb-ff105be9b160
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/20/2017
ms.author: bradsev;garye
ms.openlocfilehash: d9576e0059f2e77a684e518389182e713f0a4f09
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 07/11/2017
---
# <a name="how-to-evaluate-model-performance-in-azure-machine-learning"></a><span data-ttu-id="01e14-103">Évaluation des performances d’un modèle dans Azure Machine Learning</span><span class="sxs-lookup"><span data-stu-id="01e14-103">How to evaluate model performance in Azure Machine Learning</span></span>
<span data-ttu-id="01e14-104">Cet article explique comment évaluer les performances d’un modèle dans Azure Machine Learning Studio et décrit brièvement les métriques disponibles pour cette opération.</span><span class="sxs-lookup"><span data-stu-id="01e14-104">This article demonstrates how to evaluate the performance of a model in Azure Machine Learning Studio and provides a brief explanation of the metrics available for this task.</span></span> <span data-ttu-id="01e14-105">Il vous présente trois scénarios d’apprentissage supervisé courants :</span><span class="sxs-lookup"><span data-stu-id="01e14-105">Three common supervised learning scenarios are presented:</span></span> 

* <span data-ttu-id="01e14-106">régression ;</span><span class="sxs-lookup"><span data-stu-id="01e14-106">regression</span></span>
* <span data-ttu-id="01e14-107">classification binaire ;</span><span class="sxs-lookup"><span data-stu-id="01e14-107">binary classification</span></span> 
* <span data-ttu-id="01e14-108">classification multiclasse.</span><span class="sxs-lookup"><span data-stu-id="01e14-108">multiclass classification</span></span>

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="01e14-109">L’évaluation des performances d’un modèle constitue l’une des étapes clés du processus de science des données.</span><span class="sxs-lookup"><span data-stu-id="01e14-109">Evaluating the performance of a model is one of the core stages in the data science process.</span></span> <span data-ttu-id="01e14-110">Elle indique l’efficacité de la notation (prédictions) d’un jeu de données par un modèle formé.</span><span class="sxs-lookup"><span data-stu-id="01e14-110">It indicates how successful the scoring (predictions) of a dataset has been by a trained model.</span></span> 

<span data-ttu-id="01e14-111">Azure Machine Learning prend en charge l’évaluation des modèles via deux de ses principaux modules d’apprentissage automatique : [Évaluer le modèle][evaluate-model] et [Effectuer la validation croisée du modèle][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="01e14-111">Azure Machine Learning supports model evaluation through two of its main machine learning modules: [Evaluate Model][evaluate-model] and [Cross-Validate Model][cross-validate-model].</span></span> <span data-ttu-id="01e14-112">Ces modules vous permettent de déterminer l’efficacité de votre modèle sur le plan du nombre de métriques couramment utilisées dans les domaines de l’apprentissage automatique et des statistiques.</span><span class="sxs-lookup"><span data-stu-id="01e14-112">These modules allow you to see how your model performs in terms of a number of metrics that are commonly used in machine learning and statistics.</span></span>

## <a name="evaluation-vs-cross-validation"></a><span data-ttu-id="01e14-113">Évaluation et validation croisée</span><span class="sxs-lookup"><span data-stu-id="01e14-113">Evaluation vs. Cross Validation</span></span>
<span data-ttu-id="01e14-114">L’évaluation et la validation croisée constituent deux méthodes standard de mesure des performances d’un modèle.</span><span class="sxs-lookup"><span data-stu-id="01e14-114">Evaluation and cross validation are standard ways to measure the performance of your model.</span></span> <span data-ttu-id="01e14-115">Elles génèrent toutes deux des métriques d’évaluation que vous pouvez inspecter ou comparer avec les métriques d’autres modèles.</span><span class="sxs-lookup"><span data-stu-id="01e14-115">They both generate evaluation metrics that you can inspect or compare against those of other models.</span></span>

<span data-ttu-id="01e14-116">Le module [Évaluer le modèle][evaluate-model] attend un jeu de données noté en entrée (ou 2 jeux si vous souhaitez comparer les performances de 2 modèles distincts).</span><span class="sxs-lookup"><span data-stu-id="01e14-116">[Evaluate Model][evaluate-model] expects a scored dataset as input (or 2 in case you would like to compare the performance of 2 different models).</span></span> <span data-ttu-id="01e14-117">Cela signifie que vous devez effectuer l’apprentissage de votre modèle à l’aide du module [Former le modèle][train-model] et générer des prédictions sur un jeu de données au moyen du module [Noter le modèle][score-model] avant d’être en mesure d’évaluer les résultats.</span><span class="sxs-lookup"><span data-stu-id="01e14-117">This means that you need to train your model using the [Train Model][train-model] module and make predictions on some dataset using the [Score Model][score-model] module, before you can evaluate the results.</span></span> <span data-ttu-id="01e14-118">L’évaluation repose sur les étiquettes/probabilités notées et sur les étiquettes réelles, qui sont toutes produites par le module [Noter le modèle][score-model].</span><span class="sxs-lookup"><span data-stu-id="01e14-118">The evaluation is based on the scored labels/probabilities along with the true labels, all of which are output by the [Score Model][score-model] module.</span></span>

<span data-ttu-id="01e14-119">Une autre possibilité consiste à utiliser la validation croisée pour appliquer automatiquement un certain nombre d’opérations former-noter-évaluer (10 plis) à différents sous-échantillons des données d’entrée.</span><span class="sxs-lookup"><span data-stu-id="01e14-119">Alternatively, you can use cross validation to perform a number of train-score-evaluate operations (10 folds) automatically on different subsets of the input data.</span></span> <span data-ttu-id="01e14-120">Les données d’entrée sont fractionnées en 10 sous-échantillons, dont l’un est destiné au test et les 9 autres à l’apprentissage.</span><span class="sxs-lookup"><span data-stu-id="01e14-120">The input data is split into 10 parts, where one is reserved for testing, and the other 9 for training.</span></span> <span data-ttu-id="01e14-121">Ce processus est répété à 10 reprises, et la moyenne des métriques d’évaluation est calculée.</span><span class="sxs-lookup"><span data-stu-id="01e14-121">This process is repeated 10 times and the evaluation metrics are averaged.</span></span> <span data-ttu-id="01e14-122">Cette méthode permet de déterminer la capacité de généralisation d’un modèle pour de nouveaux jeux de données.</span><span class="sxs-lookup"><span data-stu-id="01e14-122">This helps in determining how well a model would generalize to new datasets.</span></span> <span data-ttu-id="01e14-123">Le module [Effectuer la validation croisée du modèle][cross-validate-model] prend un modèle non formé et un jeu de données étiquetées et génère les résultats d’évaluation de chacun des 10 plis, en complément de la moyenne des résultats.</span><span class="sxs-lookup"><span data-stu-id="01e14-123">The [Cross-Validate Model][cross-validate-model] module takes in an untrained model and some labeled dataset and outputs the evaluation results of each of the 10 folds, in addition to the averaged results.</span></span>

<span data-ttu-id="01e14-124">Dans les sections qui suivent, nous allons générer des modèles de régression et de classification simples et en évaluer les performances à l’aide des modules [Évaluer le modèle][evaluate-model] et [Effectuer la validation croisée du modèle][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="01e14-124">In the following sections, we will build simple regression and classification models and evaluate their performance, using both the [Evaluate Model][evaluate-model] and the [Cross-Validate Model][cross-validate-model] modules.</span></span>

## <a name="evaluating-a-regression-model"></a><span data-ttu-id="01e14-125">Évaluation d’un modèle de régression</span><span class="sxs-lookup"><span data-stu-id="01e14-125">Evaluating a Regression Model</span></span>
<span data-ttu-id="01e14-126">Supposons que vous souhaitiez prédire le prix d’une voiture à l’aide de certaines caractéristiques comme les dimensions, le nombre de chevaux, les spécifications du moteur, etc.</span><span class="sxs-lookup"><span data-stu-id="01e14-126">Assume we want to predict a car’s price using some features such as dimensions, horsepower, engine specs, and so on.</span></span> <span data-ttu-id="01e14-127">Il s’agit d’un problème de régression classique, dans lequel la variable cible, price (*prix*), est une valeur numérique continue.</span><span class="sxs-lookup"><span data-stu-id="01e14-127">This is a typical regression problem, where the target variable (*price*) is a continuous numeric value.</span></span> <span data-ttu-id="01e14-128">Nous pouvons ajuster un modèle de régression linéaire simple nous permettant de prédire le prix d’une voiture spécifique en nous basant sur les valeurs de caractéristiques de cette voiture.</span><span class="sxs-lookup"><span data-stu-id="01e14-128">We can fit a simple linear regression model that, given the feature values of a certain car, can predict the price of that car.</span></span> <span data-ttu-id="01e14-129">Il est possible d’utiliser ce modèle de régression pour noter le même jeu de données que celui sur lequel nous avons effectué l’apprentissage.</span><span class="sxs-lookup"><span data-stu-id="01e14-129">This regression model can be used to score the same dataset we trained on.</span></span> <span data-ttu-id="01e14-130">Une fois que nous avons prédit les prix de toutes les voitures, nous pouvons évaluer les performances du modèle en examinant l’importance de l’écart entre les prédictions et les prix réels en moyenne.</span><span class="sxs-lookup"><span data-stu-id="01e14-130">Once we have the predicted prices for all of the cars, we can evaluate the performance of the model by looking at how much the predictions deviate from the actual prices on average.</span></span> <span data-ttu-id="01e14-131">Pour illustrer cette approche, nous utilisons le jeu de données *Automobile price data (Raw) dataset* disponible à la section **Jeux de données enregistrés** d’Azure Machine Learning Studio.</span><span class="sxs-lookup"><span data-stu-id="01e14-131">To illustrate this, we use the *Automobile price data (Raw) dataset* available in the **Saved Datasets** section in Azure Machine Learning Studio.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="01e14-132">Création de l’expérience</span><span class="sxs-lookup"><span data-stu-id="01e14-132">Creating the Experiment</span></span>
<span data-ttu-id="01e14-133">Ajoutez les modules ci-après à votre espace de travail dans Azure Machine Learning Studio :</span><span class="sxs-lookup"><span data-stu-id="01e14-133">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="01e14-134">Données sur le prix des véhicules automobiles (brutes)</span><span class="sxs-lookup"><span data-stu-id="01e14-134">Automobile price data (Raw)</span></span>
* <span data-ttu-id="01e14-135">[Régression linéaire][linear-regression]</span><span class="sxs-lookup"><span data-stu-id="01e14-135">[Linear Regression][linear-regression]</span></span>
* <span data-ttu-id="01e14-136">[Former le modèle][train-model]</span><span class="sxs-lookup"><span data-stu-id="01e14-136">[Train Model][train-model]</span></span>
* <span data-ttu-id="01e14-137">[Noter le modèle][score-model]</span><span class="sxs-lookup"><span data-stu-id="01e14-137">[Score Model][score-model]</span></span>
* <span data-ttu-id="01e14-138">[Évaluer le modèle][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="01e14-138">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="01e14-139">Connectez les ports comme illustré ci-après à la Figure 1, puis définissez la colonne Étiquette du module [Former le modèle][train-model] sur *price*.</span><span class="sxs-lookup"><span data-stu-id="01e14-139">Connect the ports as shown below in Figure 1 and set the Label column of the [Train Model][train-model] module to *price*.</span></span>

![Évaluation d’un modèle de régression](media/machine-learning-evaluate-model-performance/1.png)

<span data-ttu-id="01e14-141">Figure 1.</span><span class="sxs-lookup"><span data-stu-id="01e14-141">Figure 1.</span></span> <span data-ttu-id="01e14-142">évaluation d’un modèle de régression</span><span class="sxs-lookup"><span data-stu-id="01e14-142">Evaluating a Regression Model.</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="01e14-143">Inspection des résultats de l’évaluation</span><span class="sxs-lookup"><span data-stu-id="01e14-143">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="01e14-144">Après avoir exécuté l’expérience, vous pouvez cliquer sur le port de sortie du module [Évaluer le modèle][evaluate-model] et sélectionner *Visualiser* pour visualiser les résultats de l’évaluation.</span><span class="sxs-lookup"><span data-stu-id="01e14-144">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select *Visualize* to see the evaluation results.</span></span> <span data-ttu-id="01e14-145">Les mesures d’évaluation disponibles pour les modèles de régression sont les suivantes : *Erreur d’absolue moyenne*, *Erreur d’absolue moyenne racine*, *Erreur d’absolue relative*, *Erreur carrée relative* et *Coefficient de détermination*.</span><span class="sxs-lookup"><span data-stu-id="01e14-145">The evaluation metrics available for regression models are: *Mean Absolute Error*, *Root Mean Absolute Error*, *Relative Absolute Error*, *Relative Squared Error*, and the *Coefficient of Determination*.</span></span>

<span data-ttu-id="01e14-146">Le terme « erreur » utilisé ici représente la différence entre la valeur prédite et la valeur réelle.</span><span class="sxs-lookup"><span data-stu-id="01e14-146">The term "error" here represents the difference between the predicted value and the true value.</span></span> <span data-ttu-id="01e14-147">La valeur absolue ou le carré de cette différence sont généralement calculés pour capturer l’ampleur totale de l’erreur sur l’ensemble des instances, car l’écart entre la valeur prédite et la valeur réelle pourrait être négatif dans certains cas.</span><span class="sxs-lookup"><span data-stu-id="01e14-147">The absolute value or the square of this difference are usually computed to capture the total magnitude of error across all instances, as the difference between the predicted and true value could be negative in some cases.</span></span> <span data-ttu-id="01e14-148">Les métriques d’erreur mesurent les performances prédictives d’un modèle de régression en termes d’écart moyen entre ses prédictions et les valeurs réelles.</span><span class="sxs-lookup"><span data-stu-id="01e14-148">The error metrics measure the predictive performance of a regression model in terms of the mean deviation of its predictions from the true values.</span></span> <span data-ttu-id="01e14-149">Plus les valeurs d’erreur sont faibles, plus les prédictions élaborées par le modèle sont exactes.</span><span class="sxs-lookup"><span data-stu-id="01e14-149">Lower error values mean the model is more accurate in making predictions.</span></span> <span data-ttu-id="01e14-150">Une métrique d’erreur globale de 0 signifie que le modèle est parfaitement ajusté par rapport aux données.</span><span class="sxs-lookup"><span data-stu-id="01e14-150">An overall error metric of 0 means that the model fits the data perfectly.</span></span>

<span data-ttu-id="01e14-151">Le coefficient de détermination, également désigné sous le terme « R au carré », constitue également une méthode standard de mesure de l’adéquation entre le modèle et les données observées.</span><span class="sxs-lookup"><span data-stu-id="01e14-151">The coefficient of determination, which is also known as R squared, is also a standard way of measuring how well the model fits the data.</span></span> <span data-ttu-id="01e14-152">Ce coefficient peut être considéré comme la proportion de la variance expliquée par le modèle.</span><span class="sxs-lookup"><span data-stu-id="01e14-152">It can be interpreted as the proportion of variation explained by the model.</span></span> <span data-ttu-id="01e14-153">Dans ce cas précis, plus la proportion est élevée, meilleur est le résultat, la valeur 1 indiquant une adéquation parfaite.</span><span class="sxs-lookup"><span data-stu-id="01e14-153">A higher proportion is better in this case, where 1 indicates a perfect fit.</span></span>

![Métriques d’évaluation de régression linéaire](media/machine-learning-evaluate-model-performance/2.png)

<span data-ttu-id="01e14-155">Figure 2 :</span><span class="sxs-lookup"><span data-stu-id="01e14-155">Figure 2.</span></span> <span data-ttu-id="01e14-156">métriques d’évaluation de régression linéaire</span><span class="sxs-lookup"><span data-stu-id="01e14-156">Linear Regression Evaluation Metrics.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="01e14-157">Utilisation de la validation croisée</span><span class="sxs-lookup"><span data-stu-id="01e14-157">Using Cross Validation</span></span>
<span data-ttu-id="01e14-158">Comme indiqué précédemment, vous pouvez exécuter automatiquement des opérations répétées d’apprentissage, de notation et d’évaluation à l’aide du module [Effectuer la validation croisée du modèle][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="01e14-158">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="01e14-159">Pour mener à bien cette tâche, vous avez simplement besoin d’un jeu de données, d’un modèle non formé et d’un module [Effectuer la validation croisée][cross-validate-model] du modèle (voir la figure ci-après).</span><span class="sxs-lookup"><span data-stu-id="01e14-159">All you need in this case is a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</span></span> <span data-ttu-id="01e14-160">Notez que vous devez définir la colonne Étiquette sur *price* dans les propriétés du module [Effectuer la validation croisée du modèle][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="01e14-160">Note that you need to set the label column to *price* in the [Cross-Validate Model][cross-validate-model] module’s properties.</span></span>

![Validation croisée d’un modèle de régression](media/machine-learning-evaluate-model-performance/3.png)

<span data-ttu-id="01e14-162">Figure 3.</span><span class="sxs-lookup"><span data-stu-id="01e14-162">Figure 3.</span></span> <span data-ttu-id="01e14-163">validation croisée d’un modèle de régression</span><span class="sxs-lookup"><span data-stu-id="01e14-163">Cross-Validating a Regression Model.</span></span>

<span data-ttu-id="01e14-164">Après avoir exécuté l’expérience, vous pouvez inspecter les résultats de l’évaluation en cliquant sur le port de sortie de droite du module [Effectuer la validation croisée du modèle][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="01e14-164">After running the experiment, you can inspect the evaluation results by clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="01e14-165">Vous obtiendrez ainsi une vue détaillée des métriques pour chaque itération (pli), et de la moyenne des résultats de chacun des métriques (Figure 4).</span><span class="sxs-lookup"><span data-stu-id="01e14-165">This will provide a detailed view of the metrics for each iteration (fold), and the averaged results of each of the metrics (Figure 4).</span></span>

![Résultats de la validation croisée d’un modèle de régression](media/machine-learning-evaluate-model-performance/4.png)

<span data-ttu-id="01e14-167">Figure 4.</span><span class="sxs-lookup"><span data-stu-id="01e14-167">Figure 4.</span></span> <span data-ttu-id="01e14-168">résultats de la validation croisée d’un modèle de régression</span><span class="sxs-lookup"><span data-stu-id="01e14-168">Cross-Validation Results of a Regression Model.</span></span>

## <a name="evaluating-a-binary-classification-model"></a><span data-ttu-id="01e14-169">Évaluation d’un modèle de classification binaire</span><span class="sxs-lookup"><span data-stu-id="01e14-169">Evaluating a Binary Classification Model</span></span>
<span data-ttu-id="01e14-170">Dans un scénario de classification binaire, la variable cible ne peut avoir que deux résultats, par exemple : {0, 1} ou {faux, vrai}, {négatif, positif}.</span><span class="sxs-lookup"><span data-stu-id="01e14-170">In a binary classification scenario, the target variable has only two possible outcomes, for example: {0, 1} or {false, true}, {negative, positive}.</span></span> <span data-ttu-id="01e14-171">Supposons que vous disposiez d’un jeu de données sur des employés incluant certaines variables démographiques et d’emploi, et que vous souhaitiez prédire le niveau de revenu, qui constitue une variable binaire avec les valeurs {« <=50K », « >50K »}.</span><span class="sxs-lookup"><span data-stu-id="01e14-171">Assume you are given a dataset of adult employees with some demographic and employment variables, and that you are asked to predict the income level, a binary variable with the values {“<=50K”, “>50K”}.</span></span> <span data-ttu-id="01e14-172">En d’autres termes, la classe négative représente les employés dont le revenu annuel est inférieur ou égal à 50 K, tandis que la classe positive représente tous les autres employés.</span><span class="sxs-lookup"><span data-stu-id="01e14-172">In other words, the negative class represents the employees who make less than or equal to 50K per year, and the positive class represents all other employees.</span></span> <span data-ttu-id="01e14-173">Comme dans le scénario de régression, nous allons former un modèle, noter certaines données, puis évaluer les résultats.</span><span class="sxs-lookup"><span data-stu-id="01e14-173">As in the regression scenario, we would train a model, score some data, and evaluate the results.</span></span> <span data-ttu-id="01e14-174">La principale différence ici réside dans le choix des métriques calculées et générées en sortie par Azure Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="01e14-174">The main difference here is the choice of metrics Azure Machine Learning computes and outputs.</span></span> <span data-ttu-id="01e14-175">Pour illustrer le scénario de prédiction du niveau de revenu, nous allons utiliser le jeu de données [Adult](http://archive.ics.uci.edu/ml/datasets/Adult) afin de créer une expérience Azure Machine Learning et d’évaluer les performances d’un modèle de régression logistique à deux classes, qui constitue un classifieur binaire couramment utilisé.</span><span class="sxs-lookup"><span data-stu-id="01e14-175">To illustrate the income level prediction scenario, we will use the [Adult](http://archive.ics.uci.edu/ml/datasets/Adult) dataset to create an Azure Machine Learning experiment and evaluate the performance of a two-class logistic regression model, a commonly used binary classifier.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="01e14-176">Création de l’expérience</span><span class="sxs-lookup"><span data-stu-id="01e14-176">Creating the Experiment</span></span>
<span data-ttu-id="01e14-177">Ajoutez les modules ci-après à votre espace de travail dans Azure Machine Learning Studio :</span><span class="sxs-lookup"><span data-stu-id="01e14-177">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="01e14-178">Jeu de données Adult Census Income Binary Classification</span><span class="sxs-lookup"><span data-stu-id="01e14-178">Adult Census Income Binary Classification dataset</span></span>
* <span data-ttu-id="01e14-179">[Régression logistique à deux classes][two-class-logistic-regression]</span><span class="sxs-lookup"><span data-stu-id="01e14-179">[Two-Class Logistic Regression][two-class-logistic-regression]</span></span>
* <span data-ttu-id="01e14-180">[Former le modèle][train-model]</span><span class="sxs-lookup"><span data-stu-id="01e14-180">[Train Model][train-model]</span></span>
* <span data-ttu-id="01e14-181">[Noter le modèle][score-model]</span><span class="sxs-lookup"><span data-stu-id="01e14-181">[Score Model][score-model]</span></span>
* <span data-ttu-id="01e14-182">[Évaluer le modèle][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="01e14-182">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="01e14-183">Connectez les ports comme illustré ci-après à la Figure 5, puis définissez la colonne Étiquette du module [Former le modèle][train-model] sur *income*.</span><span class="sxs-lookup"><span data-stu-id="01e14-183">Connect the ports as shown below in Figure 5 and set the Label column of the [Train Model][train-model] module to *income*.</span></span>

![Évaluation d’un modèle de classification binaire](media/machine-learning-evaluate-model-performance/5.png)

<span data-ttu-id="01e14-185">Figure 5.</span><span class="sxs-lookup"><span data-stu-id="01e14-185">Figure 5.</span></span> <span data-ttu-id="01e14-186">évaluation d’un modèle de classification binaire</span><span class="sxs-lookup"><span data-stu-id="01e14-186">Evaluating a Binary Classification Model.</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="01e14-187">Inspection des résultats de l’évaluation</span><span class="sxs-lookup"><span data-stu-id="01e14-187">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="01e14-188">Après avoir exécuté l’expérience, vous pouvez cliquer sur le port de sortie du module [Évaluer le modèle][evaluate-model] et sélectionner *Visualiser* pour visualiser les résultats de l’évaluation (Figure 7).</span><span class="sxs-lookup"><span data-stu-id="01e14-188">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select *Visualize* to see the evaluation results (Figure 7).</span></span> <span data-ttu-id="01e14-189">Les métriques d’évaluation disponibles pour les modèles de classification binaire sont les suivantes : *Accuracy*, *Precision*, *Recall*, *F1 Score* et *AUC*.</span><span class="sxs-lookup"><span data-stu-id="01e14-189">The evaluation metrics available for binary classification models are: *Accuracy*, *Precision*, *Recall*, *F1 Score*, and *AUC*.</span></span> <span data-ttu-id="01e14-190">En outre, le module génère une matrice de confusion présentant le nombre de vrais positifs, de faux négatifs, de faux positifs et de vrais négatifs, ainsi que les courbes *ROC*, *Precision/Recall* et *Lift*.</span><span class="sxs-lookup"><span data-stu-id="01e14-190">In addition, the module outputs a confusion matrix showing the number of true positives, false negatives, false positives, and true negatives, as well as *ROC*, *Precision/Recall*, and *Lift* curves.</span></span>

<span data-ttu-id="01e14-191">La métrique « Accuracy » (Exactitude) désigne simplement la proportion d’instances qui ont été classées correctement.</span><span class="sxs-lookup"><span data-stu-id="01e14-191">Accuracy is simply the proportion of correctly classified instances.</span></span> <span data-ttu-id="01e14-192">Il s’agit généralement du premier métrique que vous examinez quand vous évaluez un classifieur.</span><span class="sxs-lookup"><span data-stu-id="01e14-192">It is usually the first metric you look at when evaluating a classifier.</span></span> <span data-ttu-id="01e14-193">Toutefois, lorsque les données de test sont déséquilibrées (dans les cas où la plupart des instances appartiennent à l’une des classes), ou que vous êtes plus intéressé par les performances d’une seule classe, l’exactitude ne permet pas de déterminer véritablement l’efficacité d’un classifieur.</span><span class="sxs-lookup"><span data-stu-id="01e14-193">However, when the test data is unbalanced (where most of the instances belong to one of the classes), or you are more interested in the performance on either one of the classes, accuracy doesn’t really capture the effectiveness of a classifier.</span></span> <span data-ttu-id="01e14-194">Dans le scénario de classification du niveau de revenu, supposons que vous testiez certaines données où 99 % des instances représentent des employés dont le revenu annuel est inférieur ou égal à 50 K.</span><span class="sxs-lookup"><span data-stu-id="01e14-194">In the income level classification scenario, assume you are testing on some data where 99% of the instances represent people who earn less than or equal to 50K per year.</span></span> <span data-ttu-id="01e14-195">Il est alors possible d’atteindre une valeur d’exactitude de 0,99 en prédisant la classe « <= 50 K » pour toutes les instances.</span><span class="sxs-lookup"><span data-stu-id="01e14-195">It is possible to achieve a 0.99 accuracy by predicting the class “<=50K” for all instances.</span></span> <span data-ttu-id="01e14-196">Dans ce cas, le classifieur semble se révéler globalement efficace, alors qu’en réalité, il classe incorrectement tous les employés dont le revenu est plus élevé (les 1 % restants).</span><span class="sxs-lookup"><span data-stu-id="01e14-196">The classifier in this case appears to be doing a good job overall, but in reality, it fails to classify any of the high-income individuals (the 1%) correctly.</span></span>

<span data-ttu-id="01e14-197">Il est donc utile de calculer d’autres métriques capturant des aspects plus spécifiques de l’évaluation.</span><span class="sxs-lookup"><span data-stu-id="01e14-197">For that reason, it is helpful to compute additional metrics that capture more specific aspects of the evaluation.</span></span> <span data-ttu-id="01e14-198">Avant d’examiner ces métriques en détail, il est important de comprendre en quoi consiste la matrice de confusion d’une évaluation de classification binaire.</span><span class="sxs-lookup"><span data-stu-id="01e14-198">Before going into the details of such metrics, it is important to understand the confusion matrix of a binary classification evaluation.</span></span> <span data-ttu-id="01e14-199">Les étiquettes de classe du jeu de données d’apprentissage ne peuvent prendre que 2 valeurs, que nous désignons généralement en tant que valeurs positives ou négatives.</span><span class="sxs-lookup"><span data-stu-id="01e14-199">The class labels in the training set can take on only 2 possible values, which we usually refer to as positive or negative.</span></span> <span data-ttu-id="01e14-200">Les instances positives et négatives correctement prédites par un classifieur sont respectivement appelées vrais positifs (VP) et vrais négatifs (VN).</span><span class="sxs-lookup"><span data-stu-id="01e14-200">The positive and negative instances that a classifier predicts correctly are called true positives (TP) and true negatives (TN), respectively.</span></span> <span data-ttu-id="01e14-201">De la même façon, les instances classées incorrectement sont appelées faux positifs (FP) et faux négatifs (FN).</span><span class="sxs-lookup"><span data-stu-id="01e14-201">Similarly, the incorrectly classified instances are called false positives (FP) and false negatives (FN).</span></span> <span data-ttu-id="01e14-202">La matrice de confusion est un simple tableau présentant le nombre d’instances appartenant à chacune de ces 4 catégories.</span><span class="sxs-lookup"><span data-stu-id="01e14-202">The confusion matrix is simply a table showing the number of instances that fall under each of these 4 categories.</span></span> <span data-ttu-id="01e14-203">Azure Machine Learning détermine automatiquement celle des deux classes du jeu de données qui correspond à la classe positive.</span><span class="sxs-lookup"><span data-stu-id="01e14-203">Azure Machine Learning automatically decides which of the two classes in the dataset is the positive class.</span></span> <span data-ttu-id="01e14-204">Si les étiquettes de classe correspondent à des valeurs booléennes ou à des entiers, la classe positive est attribuée aux instances étiquetées « true » ou « 1 ».</span><span class="sxs-lookup"><span data-stu-id="01e14-204">If the class labels are Boolean or integers, then the ‘true’ or ‘1’ labeled instances are assigned the positive class.</span></span> <span data-ttu-id="01e14-205">Si les étiquettes sont des chaînes, comme dans le cas du jeu de données de revenu, les étiquettes sont triées dans l’ordre alphabétique, et le premier niveau est désigné comme classe négative, tandis que le second niveau constitue la classe positive.</span><span class="sxs-lookup"><span data-stu-id="01e14-205">If the labels are strings, as in the case of the income dataset, the labels are sorted alphabetically and the first level is chosen to be the negative class while the second level is the positive class.</span></span>

![Matrice de confusion d’une classification binaire](media/machine-learning-evaluate-model-performance/6a.png)

<span data-ttu-id="01e14-207">Figure 6.</span><span class="sxs-lookup"><span data-stu-id="01e14-207">Figure 6.</span></span> <span data-ttu-id="01e14-208">matrice de confusion d’une classification binaire</span><span class="sxs-lookup"><span data-stu-id="01e14-208">Binary Classification Confusion Matrix.</span></span>

<span data-ttu-id="01e14-209">Revenons au problème de classification du revenu et posons-nous plusieurs questions d’évaluation qui nous aideront à comprendre les performances du classifieur utilisé.</span><span class="sxs-lookup"><span data-stu-id="01e14-209">Going back to the income classification problem, we would want to ask several evaluation questions that help us understand the performance of the classifier used.</span></span> <span data-ttu-id="01e14-210">Nous pouvons tout naturellement nous poser la question suivante : sur le nombre d’employés pour lesquels le modèle a prédit un revenu > 50 K (VP+FP), combien ont été classés correctement (VP) ?</span><span class="sxs-lookup"><span data-stu-id="01e14-210">A very natural question is: ‘Out of the individuals whom the model predicted to be earning >50K (TP+FP), how many were classified correctly (TP)?’</span></span> <span data-ttu-id="01e14-211">Nous pouvons répondre à cette question en examinant la métrique **Precision** (Précision) du modèle, qui détermine le taux de positifs qui ont été classés correctement : VP/(VP+FP).</span><span class="sxs-lookup"><span data-stu-id="01e14-211">This question can be answered by looking at the **Precision** of the model, which is the proportion of positives that are classified correctly: TP/(TP+FP).</span></span> <span data-ttu-id="01e14-212">Une autre question courante est la suivante : sur le nombre total d’employés avec un revenu > 50 K (VP+FN), combien ont été classés correctement par le classifieur (VP) ?</span><span class="sxs-lookup"><span data-stu-id="01e14-212">Another common question is “Out of all the high earning employees with income >50k (TP+FN), how many did the classifier classify correctly (TP)”.</span></span> <span data-ttu-id="01e14-213">La réponse nous est donnée par la métrique **Recall**(Rappel), correspondant au taux de vrais positifs : VP/(VP+FN) du classifieur.</span><span class="sxs-lookup"><span data-stu-id="01e14-213">This is actually the **Recall**, or the true positive rate: TP/(TP+FN) of the classifier.</span></span> <span data-ttu-id="01e14-214">Vous pouvez remarquer qu’il existe un compromis évident entre la précision et le rappel.</span><span class="sxs-lookup"><span data-stu-id="01e14-214">You might notice that there is an obvious trade-off between precision and recall.</span></span> <span data-ttu-id="01e14-215">Par exemple, si l’on considère un jeu de données relativement équilibré, un classifieur capable de prédire la plupart des instances positives présente un rappel fort, mais une précision relativement faible, car de nombreuses instances négatives ne seront pas classées correctement, ce qui entraînera un grand nombre de faux positifs.</span><span class="sxs-lookup"><span data-stu-id="01e14-215">For example, given a relatively balanced dataset, a classifier that predicts mostly positive instances, would have a high recall, but a rather low precision as many of the negative instances would be misclassified resulting in a large number of false positives.</span></span> <span data-ttu-id="01e14-216">Pour visualiser un diagramme représentant la variation de ces deux métriques, vous pouvez cliquer sur la courbe « PRECISION/RECALL » (PRÉCISION/RAPPEL) de la page de sortie des résultats de l’évaluation (partie supérieure gauche de la Figure 7).</span><span class="sxs-lookup"><span data-stu-id="01e14-216">To see a plot of how these two metrics vary, you can click on the ‘PRECISION/RECALL’ curve in the evaluation result output page (top left part of Figure 7).</span></span>

![Résultats de l’évaluation de la classification binaire](media/machine-learning-evaluate-model-performance/7.png)

<span data-ttu-id="01e14-218">Figure 7.</span><span class="sxs-lookup"><span data-stu-id="01e14-218">Figure 7.</span></span> <span data-ttu-id="01e14-219">résultats de l’évaluation de la classification binaire</span><span class="sxs-lookup"><span data-stu-id="01e14-219">Binary Classification Evaluation Results.</span></span>

<span data-ttu-id="01e14-220">Un autre métrique connexe fréquemment utilisé est la métrique **F1 Score**(F-mesure), qui prend en compte à la fois la précision et le rappel.</span><span class="sxs-lookup"><span data-stu-id="01e14-220">Another related metric that is often used is the **F1 Score**, which takes both precision and recall into consideration.</span></span> <span data-ttu-id="01e14-221">Il s’agit de la moyenne harmonique de ces 2 métriques, calculée comme suit : F1 = 2 (précision x rappel) / (précision + rappel).</span><span class="sxs-lookup"><span data-stu-id="01e14-221">It is the harmonic mean of these 2 metrics and is computed as such: F1 = 2 (precision x recall) / (precision + recall).</span></span> <span data-ttu-id="01e14-222">La mesure F1 offre un bon moyen de résumer l’évaluation en une seule valeur ; toutefois, il est recommandé d’examiner systématiquement la précision et le rappel simultanément afin de mieux comprendre le comportement d’un classifieur.</span><span class="sxs-lookup"><span data-stu-id="01e14-222">The F1 score is a good way to summarize the evaluation in a single number, but it’s always a good practice to look at both precision and recall together to better understand how a classifier behaves.</span></span>

<span data-ttu-id="01e14-223">En outre, il est possible d’inspecter le taux de vrais positifs par rapport au taux de faux positifs dans la courbe **Receiver Operating Characteristic (ROC) (Fonction d’efficacité de l’observateur)** et la valeur **Area Under the Curve (AUC) (Surface sous la courbe (SSC)** correspondante.</span><span class="sxs-lookup"><span data-stu-id="01e14-223">In addition, one can inspect the true positive rate vs. the false positive rate in the **Receiver Operating Characteristic (ROC)** curve and the corresponding **Area Under the Curve (AUC)** value.</span></span> <span data-ttu-id="01e14-224">Plus cette courbe se rapproche du coin supérieur gauche, plus le classifieur se comporte de manière efficace (autrement dit, il optimise le taux de vrais positifs et minimise le taux de faux positifs).</span><span class="sxs-lookup"><span data-stu-id="01e14-224">The closer this curve is to the upper left corner, the better the classifier’s performance is (that is maximizing the true positive rate while minimizing the false positive rate).</span></span> <span data-ttu-id="01e14-225">Les courbes qui se rapprochent de la diagonale du diagramme résultent de classifieurs tendant à effectuer des prédictions proches d’une supposition aléatoire.</span><span class="sxs-lookup"><span data-stu-id="01e14-225">Curves that are close to the diagonal of the plot, result from classifiers that tend to make predictions that are close to random guessing.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="01e14-226">Utilisation de la validation croisée</span><span class="sxs-lookup"><span data-stu-id="01e14-226">Using Cross Validation</span></span>
<span data-ttu-id="01e14-227">Comme dans l’exemple de régression, nous pouvons effectuer une validation croisée afin d’appliquer automatiquement des opérations répétées d’apprentissage, de notation et d’évaluation à différents sous-échantillons des données.</span><span class="sxs-lookup"><span data-stu-id="01e14-227">As in the regression example, we can perform cross validation to repeatedly train, score and evaluate different subsets of the data automatically.</span></span> <span data-ttu-id="01e14-228">De même, nous pouvons utiliser le module [Effectuer la validation croisée du modèle][cross-validate-model], un modèle de régression logistique non formé et un jeu de données.</span><span class="sxs-lookup"><span data-stu-id="01e14-228">Similarly, we can use the [Cross-Validate Model][cross-validate-model] module, an untrained logistic regression model, and a dataset.</span></span> <span data-ttu-id="01e14-229">La colonne Étiquette doit être définie sur *income* dans les propriétés du module [Effectuer la validation croisée du modèle][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="01e14-229">The label column must be set to *income* in the [Cross-Validate Model][cross-validate-model] module’s properties.</span></span> <span data-ttu-id="01e14-230">Après avoir exécuté l’expérience et avoir cliqué sur le port de sortie de droite du module [Effectuer la validation croisée du modèle][cross-validate-model], nous pouvons visualiser les valeurs des métriques de classification binaire pour chaque pli, en plus de l’écart moyen et de l’écart-type de chacun d’eux.</span><span class="sxs-lookup"><span data-stu-id="01e14-230">After running the experiment and clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module, we can see the binary classification metric values for each fold, in addition to the mean and standard deviation of each.</span></span> 

![Validation croisée d’un modèle de classification binaire](media/machine-learning-evaluate-model-performance/8.png)

<span data-ttu-id="01e14-232">Figure 8.</span><span class="sxs-lookup"><span data-stu-id="01e14-232">Figure 8.</span></span> <span data-ttu-id="01e14-233">validation croisée d’un modèle de classification binaire</span><span class="sxs-lookup"><span data-stu-id="01e14-233">Cross-Validating a Binary Classification Model.</span></span>

![Résultats de la validation croisée d’un classifieur binaire](media/machine-learning-evaluate-model-performance/9.png)

<span data-ttu-id="01e14-235">Figure 9.</span><span class="sxs-lookup"><span data-stu-id="01e14-235">Figure 9.</span></span> <span data-ttu-id="01e14-236">résultats de la validation croisée d’un classifieur binaire</span><span class="sxs-lookup"><span data-stu-id="01e14-236">Cross-Validation Results of a Binary Classifier.</span></span>

## <a name="evaluating-a-multiclass-classification-model"></a><span data-ttu-id="01e14-237">Évaluation d’un modèle de classification multiclasse</span><span class="sxs-lookup"><span data-stu-id="01e14-237">Evaluating a Multiclass Classification Model</span></span>
<span data-ttu-id="01e14-238">Dans cette expérience, nous allons utiliser le fameux jeu de données [Iris](http://archive.ics.uci.edu/ml/datasets/Iris "Iris"), qui contient des instances de 3 différents types (classes) d’iris.</span><span class="sxs-lookup"><span data-stu-id="01e14-238">In this experiment we will use the popular [Iris](http://archive.ics.uci.edu/ml/datasets/Iris "Iris") dataset which contains instances of 3 different types (classes) of the iris plant.</span></span> <span data-ttu-id="01e14-239">Il existe 4 valeurs de caractéristique (longueur et largeur de sépale, longueur et largeur de pétale) pour chaque instance.</span><span class="sxs-lookup"><span data-stu-id="01e14-239">There are 4 feature values (sepal length/width and petal length/width) for each instance.</span></span> <span data-ttu-id="01e14-240">Dans les expériences précédentes, nous avons formé et testé les modèles à l’aide des mêmes jeux de données.</span><span class="sxs-lookup"><span data-stu-id="01e14-240">In the previous experiments we trained and tested the models using the same datasets.</span></span> <span data-ttu-id="01e14-241">Ici, nous allons utiliser le module [Fractionner les données][split] pour créer 2 sous-échantillons des données, former le modèle sur le premier sous-échantillon, puis noter et évaluer le modèle sur le second sous-échantillon.</span><span class="sxs-lookup"><span data-stu-id="01e14-241">Here, we will use the [Split Data][split] module to create 2 subsets of the data, train on the first, and score and evaluate on the second.</span></span> <span data-ttu-id="01e14-242">Le jeu de données Iris est publiquement accessible dans le [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.html) (Référentiel Machine Learning UCI) et peut être téléchargé à l’aide d’un module [Importer les données][import-data].</span><span class="sxs-lookup"><span data-stu-id="01e14-242">The Iris dataset is publicly available on the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.html), and can be downloaded using an [Import Data][import-data] module.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="01e14-243">Création de l’expérience</span><span class="sxs-lookup"><span data-stu-id="01e14-243">Creating the Experiment</span></span>
<span data-ttu-id="01e14-244">Ajoutez les modules ci-après à votre espace de travail dans Azure Machine Learning Studio :</span><span class="sxs-lookup"><span data-stu-id="01e14-244">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="01e14-245">[Importer des données][import-data]</span><span class="sxs-lookup"><span data-stu-id="01e14-245">[Import Data][import-data]</span></span>
* <span data-ttu-id="01e14-246">[Forêt d’arbres de décision multiclasse][multiclass-decision-forest]</span><span class="sxs-lookup"><span data-stu-id="01e14-246">[Multiclass Decision Forest][multiclass-decision-forest]</span></span>
* <span data-ttu-id="01e14-247">[Fractionner les données][split]</span><span class="sxs-lookup"><span data-stu-id="01e14-247">[Split Data][split]</span></span>
* <span data-ttu-id="01e14-248">[Former le modèle][train-model]</span><span class="sxs-lookup"><span data-stu-id="01e14-248">[Train Model][train-model]</span></span>
* <span data-ttu-id="01e14-249">[Noter le modèle][score-model]</span><span class="sxs-lookup"><span data-stu-id="01e14-249">[Score Model][score-model]</span></span>
* <span data-ttu-id="01e14-250">[Évaluer le modèle][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="01e14-250">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="01e14-251">Connectez les ports comme illustré ci-après à la Figure 10.</span><span class="sxs-lookup"><span data-stu-id="01e14-251">Connect the ports as shown below in Figure 10.</span></span>

<span data-ttu-id="01e14-252">Définissez l’index de la colonne Étiquette du module [Former le modèle][train-model] sur 5.</span><span class="sxs-lookup"><span data-stu-id="01e14-252">Set the Label column index of the [Train Model][train-model] module to 5.</span></span> <span data-ttu-id="01e14-253">Le jeu de données ne comporte pas de ligne d’en-tête, mais nous savons que les étiquettes de classe figurent dans la cinquième colonne.</span><span class="sxs-lookup"><span data-stu-id="01e14-253">The dataset has no header row but we know that the class labels are in the fifth column.</span></span>

<span data-ttu-id="01e14-254">Cliquez sur le module [Importer les données][import-data], puis définissez la propriété *Source des données* sur *URL Web via HTTP* et *URL* sur http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</span><span class="sxs-lookup"><span data-stu-id="01e14-254">Click on the [Import Data][import-data] module and set the *Data source* property to *Web URL via HTTP*, and the *URL* to http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</span></span>

<span data-ttu-id="01e14-255">Définissez la fraction d’instances à utiliser pour l’apprentissage dans le module [Fractionner les données][split] (0,7 par exemple).</span><span class="sxs-lookup"><span data-stu-id="01e14-255">Set the fraction of instances to be used for training in the [Split Data][split] module (0.7 for example).</span></span>

![évaluation d’un classifieur multiclasse](media/machine-learning-evaluate-model-performance/10.png)

<span data-ttu-id="01e14-257">Figure 10.</span><span class="sxs-lookup"><span data-stu-id="01e14-257">Figure 10.</span></span> <span data-ttu-id="01e14-258">évaluation d’un classifieur multiclasse</span><span class="sxs-lookup"><span data-stu-id="01e14-258">Evaluating a Multiclass Classifier</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="01e14-259">Inspection des résultats de l’évaluation</span><span class="sxs-lookup"><span data-stu-id="01e14-259">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="01e14-260">Exécutez l’expérience et cliquez sur le port de sortie du module [Évaluer le modèle][evaluate-model].</span><span class="sxs-lookup"><span data-stu-id="01e14-260">Run the experiment and click on the output port of [Evaluate Model][evaluate-model].</span></span> <span data-ttu-id="01e14-261">Dans notre cas, les résultats de l’évaluation sont présentés sous la forme d’une matrice de confusion.</span><span class="sxs-lookup"><span data-stu-id="01e14-261">The evaluation results are presented in the form of a confusion matrix, in this case.</span></span> <span data-ttu-id="01e14-262">Cette matrice présente les instances réelles par rapport aux instances prédites pour les 3 classes.</span><span class="sxs-lookup"><span data-stu-id="01e14-262">The matrix shows the actual vs. predicted instances for all 3 classes.</span></span>

![Résultats de l’évaluation de la classification multiclasse](media/machine-learning-evaluate-model-performance/11.png)

<span data-ttu-id="01e14-264">Figure 11.</span><span class="sxs-lookup"><span data-stu-id="01e14-264">Figure 11.</span></span> <span data-ttu-id="01e14-265">résultats de l’évaluation de la classification multiclasse</span><span class="sxs-lookup"><span data-stu-id="01e14-265">Multiclass Classification Evaluation Results.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="01e14-266">Utilisation de la validation croisée</span><span class="sxs-lookup"><span data-stu-id="01e14-266">Using Cross Validation</span></span>
<span data-ttu-id="01e14-267">Comme indiqué précédemment, vous pouvez exécuter automatiquement des opérations répétées d’apprentissage, de notation et d’évaluation à l’aide du module [Effectuer la validation croisée du modèle][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="01e14-267">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="01e14-268">Pour mener à bien cette tâche, vous avez besoin d’un jeu de données, d’un modèle non formé et d’un module [Effectuer la validation croisée du modèle][cross-validate-model] (voir la figure ci-dessous).</span><span class="sxs-lookup"><span data-stu-id="01e14-268">You would need a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</span></span> <span data-ttu-id="01e14-269">Là encore, vous devez définir la colonne Étiquette du module [Effectuer la validation croisée du modèle][cross-validate-model] (index de colonne 5 dans notre cas).</span><span class="sxs-lookup"><span data-stu-id="01e14-269">Again you need to set the label column of the [Cross-Validate Model][cross-validate-model] module (column index 5 in this case).</span></span> <span data-ttu-id="01e14-270">Après avoir exécuté l’expérience et avoir cliqué sur le port de sortie de droite du module [Effectuer la validation croisée du modèle][cross-validate-model], vous pouvez inspecter les valeurs des métriques pour chaque pli, ainsi que l’écart moyen et l’écart-type de chacun d’eux.</span><span class="sxs-lookup"><span data-stu-id="01e14-270">After running the experiment and clicking the right output port of the [Cross-Validate Model][cross-validate-model], you can inspect the metric values for each fold as well as the mean and standard deviation.</span></span> <span data-ttu-id="01e14-271">Les métriques affichées ici sont semblables à ceux que nous avons présentés dans le cas de classification binaire.</span><span class="sxs-lookup"><span data-stu-id="01e14-271">The metrics displayed here are the similar to the ones discussed in the binary classification case.</span></span> <span data-ttu-id="01e14-272">Toutefois, notez que dans le cadre d’une classification multiclasse, le calcul des vrais positifs/négatifs et des faux positifs/négatifs s’effectue par le biais d’un décompte par classe, car il n’existe aucune classe entièrement positive ou négative.</span><span class="sxs-lookup"><span data-stu-id="01e14-272">However, note that in multiclass classification, computing the true positives/negatives and false positives/negatives is done by counting on a per-class basis, as there is no overall positive or negative class.</span></span> <span data-ttu-id="01e14-273">Par exemple, le calcul de la précision ou du rappel de la classe « Iris-setosa » repose sur l’hypothèse qu’il s’agit de la classe positive, et que toutes les autres classes sont négatives.</span><span class="sxs-lookup"><span data-stu-id="01e14-273">For example, when computing the precision or recall of the ‘Iris-setosa’ class, it is assumed that this is the positive class and all others as negative.</span></span>

![Validation croisée d’un modèle de classification multiclasse](media/machine-learning-evaluate-model-performance/12.png)

<span data-ttu-id="01e14-275">Figure 12 :</span><span class="sxs-lookup"><span data-stu-id="01e14-275">Figure 12.</span></span> <span data-ttu-id="01e14-276">validation croisée d’un modèle de classification multiclasse</span><span class="sxs-lookup"><span data-stu-id="01e14-276">Cross-Validating a Multiclass Classification Model.</span></span>

![Résultats de la validation croisée d’un modèle de classification multiclasse](media/machine-learning-evaluate-model-performance/13.png)

<span data-ttu-id="01e14-278">Figure 13 :</span><span class="sxs-lookup"><span data-stu-id="01e14-278">Figure 13.</span></span> <span data-ttu-id="01e14-279">résultats de la validation croisée d’un modèle de classification multiclasse</span><span class="sxs-lookup"><span data-stu-id="01e14-279">Cross-Validation Results of a Multiclass Classification Model.</span></span>

<!-- Module References -->
[cross-validate-model]: https://msdn.microsoft.com/library/azure/75fb875d-6b86-4d46-8bcc-74261ade5826/
[evaluate-model]: https://msdn.microsoft.com/library/azure/927d65ac-3b50-4694-9903-20f6c1672089/
[linear-regression]: https://msdn.microsoft.com/library/azure/31960a6f-789b-4cf7-88d6-2e1152c0bd1a/
[multiclass-decision-forest]: https://msdn.microsoft.com/library/azure/5e70108d-2e44-45d9-86e8-94f37c68fe86/
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[score-model]: https://msdn.microsoft.com/library/azure/401b4f92-e724-4d5a-be81-d5b0ff9bdb33/
[split]: https://msdn.microsoft.com/library/azure/70530644-c97a-4ab6-85f7-88bf30a8be5f/
[train-model]: https://msdn.microsoft.com/library/azure/5cc7053e-aa30-450d-96c0-dae4be720977/
[two-class-logistic-regression]: https://msdn.microsoft.com/library/azure/b0fd7660-eeed-43c5-9487-20d9cc79ed5d/

