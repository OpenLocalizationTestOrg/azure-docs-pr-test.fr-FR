---
title: "sélection aaaFeature Bonjour processus de science des données équipe | Documents Microsoft"
description: "Explique l’objectif hello de sélection de fonctionnalités et fournit des exemples de leur rôle dans le processus d’amélioration de données hello de l’apprentissage."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 878541f5-1df8-4368-889a-ced6852aba47
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/24/2017
ms.author: zhangya;bradsev
ms.openlocfilehash: 54af93c83e4cc6a3670b3ad62490e0f74082b4ee
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 10/06/2017
---
# <a name="feature-selection-in-hello-team-data-science-process-tdsp"></a><span data-ttu-id="0db4f-103">Sélection des fonctionnalités dans hello processus de science des données équipe (TDSP)</span><span class="sxs-lookup"><span data-stu-id="0db4f-103">Feature selection in hello Team Data Science Process (TDSP)</span></span>
<span data-ttu-id="0db4f-104">Cet article explique à des fins de hello de sélection de fonctionnalités et fournit des exemples de son rôle dans le processus d’amélioration de données hello de l’apprentissage.</span><span class="sxs-lookup"><span data-stu-id="0db4f-104">This article explains hello purposes of feature selection and provides examples of its role in hello data enhancement process of machine learning.</span></span> <span data-ttu-id="0db4f-105">Ces exemples sont tirés d’Azure Machine Learning Studio.</span><span class="sxs-lookup"><span data-stu-id="0db4f-105">These examples are drawn from Azure Machine Learning Studio.</span></span> 

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="0db4f-106">Hello d’ingénierie et sélection de fonctionnalités est un composant d’hello équipe données science des processus (TDSP) décrites dans [What ' s hello processus de science des données équipe ?](data-science-process-overview.md).</span><span class="sxs-lookup"><span data-stu-id="0db4f-106">hello engineering and selection of features is one part of hello Team Data Science Process (TDSP) outlined in [What is hello Team Data Science Process?](data-science-process-overview.md).</span></span> <span data-ttu-id="0db4f-107">Ingénierie de fonctionnalité et de sélection sont les parties de hello **développer les fonctionnalités** étape Hello TDSP.</span><span class="sxs-lookup"><span data-stu-id="0db4f-107">Feature engineering and selection are parts of hello **Develop features** step of hello TDSP.</span></span>

* <span data-ttu-id="0db4f-108">**l’équipe d’ingénierie de fonctionnalité**: ce processus tente de toocreate des fonctionnalités pertinentes supplémentaires à partir de hello existant brutes fonctionnalités dans les données de salutation et algorithme d’apprentissage toohello tooincrease prédictif.</span><span class="sxs-lookup"><span data-stu-id="0db4f-108">**feature engineering**: This process attempts toocreate additional relevant features from hello existing raw features in hello data, and tooincrease predictive power toohello learning algorithm.</span></span>
* <span data-ttu-id="0db4f-109">**sélection des fonctionnalités**: ce processus sélectionne un sous-ensemble de clés de hello des fonctionnalités de données d’origine dans une dimensionnalité de hello tooreduce tentative de problème de formation hello.</span><span class="sxs-lookup"><span data-stu-id="0db4f-109">**feature selection**: This process selects hello key subset of original data features in an attempt tooreduce hello dimensionality of hello training problem.</span></span>

<span data-ttu-id="0db4f-110">Normalement **l’équipe d’ingénierie de fonctionnalité** est appliqué première toogenerate des fonctionnalités supplémentaires, puis hello **sélection des fonctionnalités** étape est effectuée tooeliminate hautement corrélée inutile ou redondante fonctionnalités.</span><span class="sxs-lookup"><span data-stu-id="0db4f-110">Normally **feature engineering** is applied first toogenerate additional features, and then hello **feature selection** step is performed tooeliminate irrelevant, redundant, or highly correlated features.</span></span>

## <a name="filtering-features-from-your-data---feature-selection"></a><span data-ttu-id="0db4f-111">Filtrage des caractéristiques à partir de vos données - Sélection de caractéristiques</span><span class="sxs-lookup"><span data-stu-id="0db4f-111">Filtering Features from Your Data - Feature Selection</span></span>
<span data-ttu-id="0db4f-112">Sélection de fonctionnalités est un processus qui est généralement appliqué pour la construction de hello de jeux de données d’apprentissage pour les tâches de modélisation prédictive comme les tâches de classification ou de régression.</span><span class="sxs-lookup"><span data-stu-id="0db4f-112">Feature selection is a process that is commonly applied for hello construction of training datasets for predictive modeling tasks such as classification or regression tasks.</span></span> <span data-ttu-id="0db4f-113">Hello vise tooselect un sous-ensemble de fonctionnalités hello à partir du jeu de données d’origine hello réduire ses dimensions à l’aide d’un ensemble minimal de fonctionnalités toorepresent hello maximum de variance dans les données de salutation.</span><span class="sxs-lookup"><span data-stu-id="0db4f-113">hello goal is tooselect a subset of hello features from hello original dataset that reduce its dimensions by using a minimal set of features toorepresent hello maximum amount of variance in hello data.</span></span> <span data-ttu-id="0db4f-114">Ce sous-ensemble de fonctionnalités sont ensuite, hello seules fonctionnalités toobe inclus le modèle de hello tootrain.</span><span class="sxs-lookup"><span data-stu-id="0db4f-114">This subset of features are, then, hello only features toobe included tootrain hello model.</span></span> <span data-ttu-id="0db4f-115">La sélection de caractéristiques a deux principaux objectifs.</span><span class="sxs-lookup"><span data-stu-id="0db4f-115">Feature selection serves two main purposes.</span></span>

* <span data-ttu-id="0db4f-116">Tout d'abord, la sélection des caractéristiques augmente souvent la précision de classification en éliminant les caractéristiques non pertinentes, redondantes ou fortement liées.</span><span class="sxs-lookup"><span data-stu-id="0db4f-116">First, feature selection often increases classification accuracy by eliminating irrelevant, redundant, or highly correlated features.</span></span>
* <span data-ttu-id="0db4f-117">En second lieu, il diminue le nombre hello des fonctionnalités qui rend le processus d’apprentissage du modèle plus efficace.</span><span class="sxs-lookup"><span data-stu-id="0db4f-117">Second, it decreases hello number of features which makes model training process more efficient.</span></span> <span data-ttu-id="0db4f-118">Cela est particulièrement important pour les apprenants sont tootrain coûteuse telles que les machines à vecteurs de support.</span><span class="sxs-lookup"><span data-stu-id="0db4f-118">This is particularly important for learners that are expensive tootrain such as support vector machines.</span></span>

<span data-ttu-id="0db4f-119">Bien que la sélection des fonctionnalités vise le nombre de hello tooreduce de fonctionnalités de modèle de hello tootrain hello dataset utilisé, il n’est pas généralement tooby référencé hello terme « réduction de dimensionnalité ».</span><span class="sxs-lookup"><span data-stu-id="0db4f-119">Although feature selection does seek tooreduce hello number of features in hello dataset used tootrain hello model, it is not usually referred tooby hello term "dimensionality reduction".</span></span> <span data-ttu-id="0db4f-120">Méthodes de sélection de fonctionnalité extraire un sous-ensemble de fonctionnalités d’origine dans les données de salutation sans les modifier.</span><span class="sxs-lookup"><span data-stu-id="0db4f-120">Feature selection methods extract a subset of original features in hello data without changing them.</span></span>  <span data-ttu-id="0db4f-121">Méthodes de réduction de dimensionnalité employant ingénierie des fonctionnalités qui peuvent transformer les fonctionnalités d’origine hello et donc de les modifier.</span><span class="sxs-lookup"><span data-stu-id="0db4f-121">Dimensionality reduction methods employ engineered features that can transform hello original features and thus modify them.</span></span> <span data-ttu-id="0db4f-122">Parmi les exemples de méthodes de réduction de la dimensionnalité, on peut noter l'analyse du composant principal, l'analyse canonique des corrélations et la décomposition en valeurs uniques.</span><span class="sxs-lookup"><span data-stu-id="0db4f-122">Examples of dimensionality reduction methods include Principal Component Analysis, canonical correlation analysis, and Singular Value Decomposition.</span></span>

<span data-ttu-id="0db4f-123">Notamment, l'une des méthodes de sélection de caractéristiques de catégorie largement appliquée dans un contexte supervisé est appelée « sélection de caractéristiques basée sur les filtres ».</span><span class="sxs-lookup"><span data-stu-id="0db4f-123">Among others, one widely applied category of feature selection methods in a supervised context is called "filter based feature selection".</span></span> <span data-ttu-id="0db4f-124">Lors de l’évaluation de corrélation hello entre chaque attribut cible de fonctionnalité et de hello, ces méthodes s’appliquent à un tooassign mesure statistique une fonctionnalité tooeach de score.</span><span class="sxs-lookup"><span data-stu-id="0db4f-124">By evaluating hello correlation between each feature and hello target attribute, these methods apply a statistical measure tooassign a score tooeach feature.</span></span> <span data-ttu-id="0db4f-125">fonctionnalités de Hello sont classées par score hello, qui peut être utilisé toohelp ensemble hello seuil pour conserver ou de suppression d’une fonctionnalité spécifique.</span><span class="sxs-lookup"><span data-stu-id="0db4f-125">hello features are then ranked by hello score, which may be used toohelp set hello threshold for keeping or eliminating a specific feature.</span></span> <span data-ttu-id="0db4f-126">Personne corrélation informations réciproques et test de hello Chi carré sont des exemples de mesures statistiques de hello utilisés dans ces méthodes.</span><span class="sxs-lookup"><span data-stu-id="0db4f-126">Examples of hello statistical measures used in these methods include Person correlation, mutual information, and hello Chi squared test.</span></span>

<span data-ttu-id="0db4f-127">Dans Azure Machine Learning Studio, des modules sont fournis pour la sélection des caractéristiques.</span><span class="sxs-lookup"><span data-stu-id="0db4f-127">In Azure Machine Learning Studio, there are modules provided for feature selection.</span></span> <span data-ttu-id="0db4f-128">Comme indiqué dans la figure suivante de hello, ces modules sont [sélection des fonctionnalités par filtrage] [ filter-based-feature-selection] et [analyse discriminante linéaire de Fisher] [ fisher-linear-discriminant-analysis].</span><span class="sxs-lookup"><span data-stu-id="0db4f-128">As shown in hello following figure, these modules include [Filter-Based Feature Selection][filter-based-feature-selection] and [Fisher Linear Discriminant Analysis][fisher-linear-discriminant-analysis].</span></span>

![Exemple de sélection de caractéristiques](./media/machine-learning-data-science-select-features/feature-Selection.png)

<span data-ttu-id="0db4f-130">Considérez, par exemple, utilisez hello Hello [sélection des fonctionnalités par filtrage] [ filter-based-feature-selection] module.</span><span class="sxs-lookup"><span data-stu-id="0db4f-130">Consider, for example, hello use of hello [Filter-Based Feature Selection][filter-based-feature-selection] module.</span></span> <span data-ttu-id="0db4f-131">Pour les besoins de hello de commodité, nous continuons toouse hello texte d’exploration de données exemple présentée ci-dessus.</span><span class="sxs-lookup"><span data-stu-id="0db4f-131">For hello purpose of convenience, we continue toouse hello text mining example outlined above.</span></span> <span data-ttu-id="0db4f-132">Supposons que nous souhaitons toobuild un modèle de régression après un ensemble de 256 fonctionnalités sont créés via hello [Feature Hashing] [ feature-hashing] module et cette variable de réponse hello est hello « Col1 » et représente un livre Passez en revue les évaluations allant de 1 too5.</span><span class="sxs-lookup"><span data-stu-id="0db4f-132">Assume that we want toobuild a regression model after a set of 256 features are created through hello [Feature Hashing][feature-hashing] module, and that hello response variable is hello "Col1" and represents a book review ratings ranging from 1 too5.</span></span> <span data-ttu-id="0db4f-133">En définissant la « Fonctionnalité de calcul de score méthode » toobe « Corrélation de Pearson », hello « Colonne cible » toobe « Col1 » et too50 de « Nombre de fonctionnalités » hello.</span><span class="sxs-lookup"><span data-stu-id="0db4f-133">By setting "Feature scoring method" toobe "Pearson Correlation", hello "Target column" toobe "Col1", and hello "Number of desired features" too50.</span></span> <span data-ttu-id="0db4f-134">Puis hello module [sélection des fonctionnalités par filtrage] [ filter-based-feature-selection] génère un dataset qui contient des 50 fonctionnalités avec l’attribut cible de hello « Col1 ».</span><span class="sxs-lookup"><span data-stu-id="0db4f-134">Then hello module [Filter-Based Feature Selection][filter-based-feature-selection] will produce a dataset containing 50 features together with hello target attribute "Col1".</span></span> <span data-ttu-id="0db4f-135">Voici de Hello figure montre les flux de hello de cette expérience, hello nous venons de voir les paramètres d’entrée.</span><span class="sxs-lookup"><span data-stu-id="0db4f-135">hello following figure shows hello flow of this experiment and hello input parameters we just described.</span></span>

![Exemple de sélection de caractéristiques](./media/machine-learning-data-science-select-features/feature-Selection1.png)

<span data-ttu-id="0db4f-137">Hello figure suivante illustre les jeux de données obtenus hello.</span><span class="sxs-lookup"><span data-stu-id="0db4f-137">hello following figure shows hello resulting datasets.</span></span> <span data-ttu-id="0db4f-138">Chaque fonctionnalité est transformée en fonction de hello de corrélation de Pearson entre lui-même et hello l’attribut cible « Col1 ».</span><span class="sxs-lookup"><span data-stu-id="0db4f-138">Each feature is scored based on hello Pearson Correlation between itself and hello target attribute "Col1".</span></span> <span data-ttu-id="0db4f-139">les fonctions Hello avec les scores les plus élevés sont conservées.</span><span class="sxs-lookup"><span data-stu-id="0db4f-139">hello features with top scores are kept.</span></span>

![Exemple de sélection de caractéristiques](./media/machine-learning-data-science-select-features/feature-Selection2.png)

<span data-ttu-id="0db4f-141">scores de Hello correspondant de fonctionnalités de hello sélectionné sont affichés dans hello figure suivante.</span><span class="sxs-lookup"><span data-stu-id="0db4f-141">hello corresponding scores of hello selected features are shown in hello following figure.</span></span>

![Exemple de sélection de caractéristiques](./media/machine-learning-data-science-select-features/feature-Selection3.png)

<span data-ttu-id="0db4f-143">En appliquant cette [sélection des fonctionnalités par filtrage] [ filter-based-feature-selection] module, 50 de 256 fonctionnalités sont sélectionnées, car ils ont hello plus les fonctionnalités corrélées avec la variable cible de hello « Col1 », en fonction de calcul de score hello méthode « Corrélation de Pearson ».</span><span class="sxs-lookup"><span data-stu-id="0db4f-143">By applying this [Filter-Based Feature Selection][filter-based-feature-selection] module, 50 out of 256 features are selected because they have hello most correlated features with hello target variable "Col1", based on hello scoring method "Pearson Correlation".</span></span>

## <a name="conclusion"></a><span data-ttu-id="0db4f-144">Conclusion</span><span class="sxs-lookup"><span data-stu-id="0db4f-144">Conclusion</span></span>
<span data-ttu-id="0db4f-145">Ingénierie de fonctionnalité et de sélection de fonctionnalités sont deux couramment conçu et de fonctionnalités sélectionnées accroître l’efficacité de hello Hello formation des processus qui essaie d’informations de clé de hello tooextract contenues dans les données de salutation.</span><span class="sxs-lookup"><span data-stu-id="0db4f-145">Feature engineering and feature selection are two commonly Engineered and selected features increase hello efficiency of hello training process which attempts tooextract hello key information contained in hello data.</span></span> <span data-ttu-id="0db4f-146">Ils améliorent également power hello de ces modèles tooclassify hello d’entrée de données avec précision et toopredict des résultats d’intéressent plus efficacement.</span><span class="sxs-lookup"><span data-stu-id="0db4f-146">They also improve hello power of these models tooclassify hello input data accurately and toopredict outcomes of interest more robustly.</span></span> <span data-ttu-id="0db4f-147">Ingénierie de fonctionnalité et de sélection peuvent également combiner des toomake d’apprentissage automatique hello en plus de calculs souple.</span><span class="sxs-lookup"><span data-stu-id="0db4f-147">Feature engineering and selection can also combine toomake hello learning more computationally tractable.</span></span> <span data-ttu-id="0db4f-148">Il le fait en améliorant et réduction de plusieurs fonctionnalités hello nécessaires toocalibrate ou effectuer l’apprentissage d’un modèle.</span><span class="sxs-lookup"><span data-stu-id="0db4f-148">It does so by enhancing and then reducing hello number of features needed toocalibrate or train a model.</span></span> <span data-ttu-id="0db4f-149">Strictement mathématique, modèle de hello hello fonctionnalités tootrain sélectionné sont un ensemble minimal de variables indépendantes qui expliquent les schémas hello dans les données de salutation et puis prédire les résultats avec succès.</span><span class="sxs-lookup"><span data-stu-id="0db4f-149">Mathematically speaking, hello features selected tootrain hello model are a minimal set of independent variables that explain hello patterns in hello data and then predict outcomes successfully.</span></span>

<span data-ttu-id="0db4f-150">Notez qu’il n’est pas toujours nécessairement sélection de fonctionnalité ou de l’équipe d’ingénierie de fonctionnalité tooperform.</span><span class="sxs-lookup"><span data-stu-id="0db4f-150">Note that it is not always necessarily tooperform feature engineering or feature selection.</span></span> <span data-ttu-id="0db4f-151">Si elle est nécessaire ou non dépend des données hello nous avons ou collecter, algorithme hello que prendre, et hello l’objectif de l’expérience de hello.</span><span class="sxs-lookup"><span data-stu-id="0db4f-151">Whether it is needed or not depends on hello data we have or collect, hello algorithm we pick, and hello objective of hello experiment.</span></span>

<!-- Module References -->
[feature-hashing]: https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/
[filter-based-feature-selection]: https://msdn.microsoft.com/library/azure/918b356b-045c-412b-aa12-94a1d2dad90f/
[fisher-linear-discriminant-analysis]: https://msdn.microsoft.com/library/azure/dcaab0b2-59ca-4bec-bb66-79fd23540080/

