---
title: "aaaOverview de la Science des données à l’aide de Spark sur Azure HDInsight | Documents Microsoft"
description: "Hello Spark MLlib toolkit met apprentissage considérable fonctionnalités toohello distribué HDInsight environnement de modélisation."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: a4e1de99-a554-4240-9647-2c6d669593c8
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/15/2017
ms.author: deguhath;bradsev;gokuma
ms.openlocfilehash: 515705684a46917c2741bf063d439b1cda016abb
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 10/06/2017
---
# <a name="overview-of-data-science-using-spark-on-azure-hdinsight"></a><span data-ttu-id="78682-103">Vue d’ensemble de la science des données à l’aide de Spark sur Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="78682-103">Overview of data science using Spark on Azure HDInsight</span></span>
[!INCLUDE [machine-learning-spark-modeling](../../includes/machine-learning-spark-modeling.md)]

<span data-ttu-id="78682-104">Cet ensemble de rubriques illustre des tâches de toouse science des données common HDInsight Spark toocomplete telles que la réception de données, l’ingénierie de fonctionnalité, la modélisation et évaluation du modèle.</span><span class="sxs-lookup"><span data-stu-id="78682-104">This suite of topics shows how toouse HDInsight Spark toocomplete common data science tasks such as data ingestion, feature engineering, modeling, and model evaluation.</span></span> <span data-ttu-id="78682-105">les données de salutation utilisées sont un exemple de hello 2013 NYC taxi voyage et tarif de jeu de données.</span><span class="sxs-lookup"><span data-stu-id="78682-105">hello data used is a sample of hello 2013 NYC taxi trip and fare dataset.</span></span> <span data-ttu-id="78682-106">les modèles de Hello générés incluent la régression logistique et linéaire, les forêts aléatoires et les arbres augmentés dégradés.</span><span class="sxs-lookup"><span data-stu-id="78682-106">hello models built include logistic and linear regression, random forests, and gradient boosted trees.</span></span> <span data-ttu-id="78682-107">Hello rubriques montrent également comment toostore ces modèles dans Azure blob storage (WASB) et la manière dont tooscore et d’évaluer leurs performances prédictive.</span><span class="sxs-lookup"><span data-stu-id="78682-107">hello topics also show how toostore these models in Azure blob storage (WASB) and how tooscore and evaluate their predictive performance.</span></span> <span data-ttu-id="78682-108">D’autres rubriques plus avancées décrivent comment former des modèles par validation croisée et balayage hyperparamétrique.</span><span class="sxs-lookup"><span data-stu-id="78682-108">More advanced topics cover how models can be trained using cross-validation and hyper-parameter sweeping.</span></span> <span data-ttu-id="78682-109">Cette rubrique de présentation fait également référence à des rubriques hello qui décrivent comment tooset des hello cluster Spark dont vous avez besoin d’étapes de hello toocomplete dans les procédures pas à pas hello fourni.</span><span class="sxs-lookup"><span data-stu-id="78682-109">This overview topic also references hello topics that describe how tooset up hello Spark cluster that you need toocomplete hello steps in hello walkthroughs provided.</span></span> 

## <a name="spark-and-mllib"></a><span data-ttu-id="78682-110">Spark et MLlib</span><span class="sxs-lookup"><span data-stu-id="78682-110">Spark and MLlib</span></span>
<span data-ttu-id="78682-111">[Spark](http://spark.apache.org/) est une infrastructure de traitement en parallèle open source qui prend en charge en mémoire traitement tooboost les performances de hello big-applications de données analytiques.</span><span class="sxs-lookup"><span data-stu-id="78682-111">[Spark](http://spark.apache.org/) is an open-source parallel processing framework that supports in-memory processing tooboost hello performance of big-data analytic applications.</span></span> <span data-ttu-id="78682-112">moteur de traitement Spark Hello est créé pour la vitesse, la facilité d’utilisation et analytique sophistiquées.</span><span class="sxs-lookup"><span data-stu-id="78682-112">hello Spark processing engine is built for speed, ease of use, and sophisticated analytics.</span></span> <span data-ttu-id="78682-113">Fonctionnalités de répartition du calcul en mémoire de Spark constituent un bon choix pour les algorithmes itératif hello utilisée dans les calculs machine learning et graphique.</span><span class="sxs-lookup"><span data-stu-id="78682-113">Spark's in-memory distributed computation capabilities make it a good choice for hello iterative algorithms used in machine learning and graph computations.</span></span> <span data-ttu-id="78682-114">[MLlib](http://spark.apache.org/mllib/) est environnement distribué toothis de fonctionnalités de modélisation évolutive machine learning bibliothèque de Spark qui apporte hello algorithmique.</span><span class="sxs-lookup"><span data-stu-id="78682-114">[MLlib](http://spark.apache.org/mllib/) is Spark's scalable machine learning library that brings hello algorithmic modeling capabilities toothis distributed environment.</span></span> 

## <a name="hdinsight-spark"></a><span data-ttu-id="78682-115">HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="78682-115">HDInsight Spark</span></span>
<span data-ttu-id="78682-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) hello Azure hébergé offrant d’open source Spark.</span><span class="sxs-lookup"><span data-stu-id="78682-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) is hello Azure hosted offering of open-source Spark.</span></span> <span data-ttu-id="78682-117">Il prend également en charge **Jupyter PySpark blocs-notes** sur cluster Spark hello qui peut exécuter des requêtes interactives de Spark SQL pour la transformation, de filtrage et de visualisation des données stockées dans les objets BLOB Azure (WASB).</span><span class="sxs-lookup"><span data-stu-id="78682-117">It also includes support for **Jupyter PySpark notebooks** on hello Spark cluster that can run Spark SQL interactive queries for transforming, filtering, and visualizing data stored in Azure Blobs (WASB).</span></span> <span data-ttu-id="78682-118">PySpark est hello API Python pour Spark.</span><span class="sxs-lookup"><span data-stu-id="78682-118">PySpark is hello Python API for Spark.</span></span> <span data-ttu-id="78682-119">extraits de code Hello qui fournissent des solutions de hello et affichent les données de hello hello tracés pertinentes toovisualize ici s’exécutent dans les blocs-notes Notebook installés sur des clusters de Spark hello.</span><span class="sxs-lookup"><span data-stu-id="78682-119">hello code snippets that provide hello solutions and show hello relevant plots toovisualize hello data here run in Jupyter notebooks installed on hello Spark clusters.</span></span> <span data-ttu-id="78682-120">étapes de modélisation Hello dans ces rubriques contiennent le code qui montre comment tootrain, évaluer, enregistrer et utiliser chaque type de modèle.</span><span class="sxs-lookup"><span data-stu-id="78682-120">hello modeling steps in these topics contain code that shows how tootrain, evaluate, save, and consume each type of model.</span></span> 

## <a name="setup-spark-clusters-and-jupyter-notebooks"></a><span data-ttu-id="78682-121">Installation des clusters Spark et notebooks Jupyter</span><span class="sxs-lookup"><span data-stu-id="78682-121">Setup: Spark clusters and Jupyter notebooks</span></span>
<span data-ttu-id="78682-122">Les étapes de configuration et le code fournis dans cette procédure pas à pas concernent HDInsight Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="78682-122">Setup steps and code are provided in this walkthrough for using an HDInsight Spark 1.6.</span></span> <span data-ttu-id="78682-123">Mais des notebooks Jupyter sont fournis pour les clusters HDInsight Spark 1.6 et Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="78682-123">But Jupyter notebooks are provided for both HDInsight Spark 1.6 and Spark 2.0 clusters.</span></span> <span data-ttu-id="78682-124">Obtenir une description de toothem blocs-notes et des liens de hello sont fournies dans hello [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) pour le référentiel GitHub de hello qui les contiennent.</span><span class="sxs-lookup"><span data-stu-id="78682-124">A description of hello notebooks and links toothem are provided in hello [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) for hello GitHub repository containing them.</span></span> <span data-ttu-id="78682-125">En outre, hello code ici et dans les blocs-notes hello lié est générique et doit fonctionner sur n’importe quel cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="78682-125">Moreover, hello code here and in hello linked notebooks is generic and should work on any Spark cluster.</span></span> <span data-ttu-id="78682-126">Si vous n’utilisez pas HDInsight Spark, les étapes de configuration et la gestion de cluster de hello peuvent être légèrement différents de celui indiqué ici.</span><span class="sxs-lookup"><span data-stu-id="78682-126">If you are not using HDInsight Spark, hello cluster setup and management steps may be slightly different from what is shown here.</span></span> <span data-ttu-id="78682-127">Pour des raisons pratiques, voici les liens hello blocs-notes de Notebook toohello pour Spark 1.6 (toobe exécuter dans le noyau pySpark hello Hello server de bloc-notes Jupyter) et Spark 2.0 (toobe exécuter dans le noyau pySpark3 hello Hello server de bloc-notes Jupyter) :</span><span class="sxs-lookup"><span data-stu-id="78682-127">For convenience, here are hello links toohello Jupyter notebooks for Spark 1.6 (toobe run in hello pySpark kernel of hello Jupyter Notebook server) and  Spark 2.0 (toobe run in hello pySpark3 kernel of hello Jupyter Notebook server):</span></span>

### <a name="spark-16-notebooks"></a><span data-ttu-id="78682-128">Notebooks Spark 1.6</span><span class="sxs-lookup"><span data-stu-id="78682-128">Spark 1.6 notebooks</span></span>
<span data-ttu-id="78682-129">Ces ordinateurs portables sont toobe exécuter dans le noyau pySpark hello du serveur jupyter Notebook.</span><span class="sxs-lookup"><span data-stu-id="78682-129">These notebooks are toobe run in hello pySpark kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="78682-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): fournit des informations sur l’exploration de données tooperform, de modélisation et de calcul de score avec plusieurs algorithmes différents.</span><span class="sxs-lookup"><span data-stu-id="78682-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): Provides information on how tooperform data exploration, modeling, and scoring with several different algorithms.</span></span>
- <span data-ttu-id="78682-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) : inclut les thèmes du notebook 1 et traite également du développement de modèles à l’aide de l’ajustement des hyperparamètres et de la validation croisée.</span><span class="sxs-lookup"><span data-stu-id="78682-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Includes topics in notebook #1, and model development using hyperparameter tuning and cross-validation.</span></span>
- <span data-ttu-id="78682-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): montre comment toooperationalize un modèle enregistré à l’aide de Python sur HDInsight clusters.</span><span class="sxs-lookup"><span data-stu-id="78682-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): Shows how toooperationalize a saved model using Python on HDInsight clusters.</span></span>

### <a name="spark-20-notebooks"></a><span data-ttu-id="78682-133">Notebooks Spark 2.0</span><span class="sxs-lookup"><span data-stu-id="78682-133">Spark 2.0 notebooks</span></span>
<span data-ttu-id="78682-134">Ces ordinateurs portables sont toobe exécuter dans le noyau pySpark3 hello du serveur jupyter Notebook.</span><span class="sxs-lookup"><span data-stu-id="78682-134">These notebooks are toobe run in hello pySpark3 kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="78682-135">[Spark2.0-pySpark3-machine-Learning-Data-science-Spark-Advanced-Data-exploration-Modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): ce fichier fournit des informations sur comment tooperform l’exploration de données, de modélisation et de calcul de score dans Spark 2.0 des clusters à l’aide de hello voyage de NYC Taxi et tarif-jeu de données décrit [ici](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="78682-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): This file provides information on how tooperform data exploration, modeling, and scoring in Spark 2.0 clusters using hello NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span> <span data-ttu-id="78682-136">Cet ordinateur portable peut être un bon point de départ pour Explorer rapidement le code de hello que nous fournissons à Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="78682-136">This notebook may be a good starting point for quickly exploring hello code we have provided for Spark 2.0.</span></span> <span data-ttu-id="78682-137">Pour un ordinateur portable plu analyse hello les données NYC Taxi, consultez bloc-notes suivant de hello dans cette liste.</span><span class="sxs-lookup"><span data-stu-id="78682-137">For a more detailed notebook analyzes hello NYC Taxi data, see hello next notebook in this list.</span></span> <span data-ttu-id="78682-138">Consultez les remarques hello suit cette liste qui comparent ces ordinateurs portables.</span><span class="sxs-lookup"><span data-stu-id="78682-138">See hello notes following this list that compare these notebooks.</span></span> 
- <span data-ttu-id="78682-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): ce fichier montre comment tooperform données ensuivirent (opérations Spark SQL et de la trame de données), exploration, de modélisation et de calcul de score à l’aide de hello voyage de NYC Taxi et tarif de jeu de données décrites [ ici](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="78682-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): This file shows how tooperform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using hello NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span>
- <span data-ttu-id="78682-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): ce fichier montre comment tooperform données ensuivirent (opérations Spark SQL et de la trame de données), exploration, de modélisation et de calcul de score à l’aide de hello connu départ à temps de billet d’avion jeu de données à partir de 2011 et 2012.</span><span class="sxs-lookup"><span data-stu-id="78682-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): This file shows how tooperform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using hello well-known Airline On-time departure dataset from 2011 and 2012.</span></span> <span data-ttu-id="78682-141">Nous l’intégration hello compagnie aérienne dataset avec hello aéroport météo (par exemple, vitesse du vent, la température, altitude, etc.) de données préalable toomodeling, ces fonctionnalités météo peuvent être incluses dans le modèle de hello.</span><span class="sxs-lookup"><span data-stu-id="78682-141">We integrated hello airline dataset with hello airport weather data (e.g. windspeed, temperature, altitude etc.) prior toomodeling, so these weather features can be included in hello model.</span></span>

<!-- -->

> [!NOTE]
> <span data-ttu-id="78682-142">Hello compagnie aérienne dataset a été ajouté toohello Spark 2.0 blocs-notes toobetter illustrer l’utilisation de hello des algorithmes de classification.</span><span class="sxs-lookup"><span data-stu-id="78682-142">hello airline dataset was added toohello Spark 2.0 notebooks toobetter illustrate hello use of classification algorithms.</span></span> <span data-ttu-id="78682-143">Consultez hello suivant les liens pour plus d’informations sur le jeu de données de départ de délais compagnie aérienne et jeu de données météo :</span><span class="sxs-lookup"><span data-stu-id="78682-143">See hello following links for information about airline on-time departure dataset and weather dataset:</span></span>

>- <span data-ttu-id="78682-144">Données sur les départs à l’heure des compagnies aériennes : [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span><span class="sxs-lookup"><span data-stu-id="78682-144">Airline on-time departure data: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span></span>

>- <span data-ttu-id="78682-145">Données météorologiques des aéroports : [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span><span class="sxs-lookup"><span data-stu-id="78682-145">Airport weather data: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span></span> 
> 
> 

<!-- -->

<!-- -->

> [!NOTE]
<span data-ttu-id="78682-146">ordinateurs portables de Spark 2.0 Hello sur hello taxi de NYC et compagnie aérienne flight delay-jeux de données peuvent prendre 10 minutes ou plus toorun (selon la taille de votre cluster HDI de hello).</span><span class="sxs-lookup"><span data-stu-id="78682-146">hello Spark 2.0 notebooks on hello NYC taxi and airline flight delay data-sets can take 10 mins or more toorun (depending on hello size of your HDI cluster).</span></span> <span data-ttu-id="78682-147">Hello premier bloc-notes Bonjour au-dessus de liste affiche nombreux aspects d’exploration de données hello, ML de visualisation et de modèle d’apprentissage dans un ordinateur portable qui prend moins toorun temps avec échantillonnées en bas NYC jeu de données, dans quel hello taxi et tarif de fichiers ont été déjà joints : [ Spark2.0-pySpark3-machine-Learning-Data-science-Spark-Advanced-Data-exploration-Modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) ce bloc-notes prend une quantité plus court toofinish de temps (2 à 3 minutes) et peut être un bon point de départ pour Explorer rapidement le code de hello nous avons fourni pour Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="78682-147">hello first notebook in hello above list shows many aspects of hello data exploration, visualization and ML model training in a notebook that takes less time toorun with down-sampled NYC data set, in which hello taxi and fare files have been pre-joined: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) This notebook takes a much shorter time toofinish (2-3 mins) and may be a good starting point for quickly exploring hello code we have provided for Spark 2.0.</span></span> 

<!-- -->

<span data-ttu-id="78682-148">Pour obtenir des conseils sur à l’Opérationnalisation hello d’un modèle Spark 2.0 et la consommation de modèle pour calculer les scores, consultez hello [document Spark 1.6 sur la consommation](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) pour obtenir un exemple de mise en relief les étapes hello requises.</span><span class="sxs-lookup"><span data-stu-id="78682-148">For guidance on hello operationalization of a Spark 2.0 model and model consumption for scoring, see hello [Spark 1.6 document on consumption](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) for an example outlining hello steps required.</span></span> <span data-ttu-id="78682-149">toouse cela sur Spark 2.0, remplacez les fichier de code Python hello avec [ce fichier](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span><span class="sxs-lookup"><span data-stu-id="78682-149">toouse this on Spark 2.0, replace hello Python code file with [this file](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span></span>

### <a name="prerequisites"></a><span data-ttu-id="78682-150">Composants requis</span><span class="sxs-lookup"><span data-stu-id="78682-150">Prerequisites</span></span>
<span data-ttu-id="78682-151">Hello procédures suivantes est associée tooSpark 1.6.</span><span class="sxs-lookup"><span data-stu-id="78682-151">hello following procedures are related tooSpark 1.6.</span></span> <span data-ttu-id="78682-152">Pour la version de hello Spark 2.0, utilisez hello blocs-notes décrivent et lié toopreviously.</span><span class="sxs-lookup"><span data-stu-id="78682-152">For  hello Spark 2.0 version, use hello notebooks described and linked toopreviously.</span></span> 

<span data-ttu-id="78682-153">1. Vous devez avoir un abonnement Azure.</span><span class="sxs-lookup"><span data-stu-id="78682-153">1.You must have an Azure subscription.</span></span> <span data-ttu-id="78682-154">Si vous n’en avez pas, consultez [Obtenir une version d’évaluation gratuite Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="78682-154">If you do not already have one, see [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>

<span data-ttu-id="78682-155">2. vous devez un toocomplete de cluster Spark 1.6 cette procédure pas à pas.</span><span class="sxs-lookup"><span data-stu-id="78682-155">2.You need a Spark 1.6 cluster toocomplete this walkthrough.</span></span> <span data-ttu-id="78682-156">toocreate, consultez les instructions hello fournies dans [mise en route : créer Apache Spark sur Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="78682-156">toocreate one, see hello instructions provided in [Get started: create Apache Spark on Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> <span data-ttu-id="78682-157">type de cluster Hello et la version est spécifié à partir de hello **sélectionner le Type de Cluster** menu.</span><span class="sxs-lookup"><span data-stu-id="78682-157">hello cluster type and version is specified from hello **Select Cluster Type** menu.</span></span> 

![Configurer le cluster](./media/machine-learning-data-science-spark-overview/spark-cluster-on-portal.png)

<!-- -->

> [!NOTE]
> <span data-ttu-id="78682-159">Pour une rubrique qui présente des tâches de toocomplete de Scala plutôt que de Python toouse pour un processus de science des données de bout en bout, consultez hello [Science des données à l’aide de Scala avec Spark sur Azure](machine-learning-data-science-process-scala-walkthrough.md).</span><span class="sxs-lookup"><span data-stu-id="78682-159">For a topic that shows how toouse Scala rather than Python toocomplete tasks for an end-to-end data science process, see hello [Data Science using Scala with Spark on Azure](machine-learning-data-science-process-scala-walkthrough.md).</span></span>
> 
> 

<!-- -->

> [!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]
> 
> 

## <a name="hello-nyc-2013-taxi-data"></a><span data-ttu-id="78682-160">Hello les données NYC 2013 Taxi</span><span class="sxs-lookup"><span data-stu-id="78682-160">hello NYC 2013 Taxi data</span></span>
<span data-ttu-id="78682-161">Hello les données NYC Taxi voyage est d’environ 20 Go de fichiers de valeurs compressées séparées par des virgules (CSV) (non compressé en ~ 48 Go), qui comprend plus de 173 millions hello et des boucles tarifs payé pour chaque sortie.</span><span class="sxs-lookup"><span data-stu-id="78682-161">hello NYC Taxi Trip data is about 20 GB of compressed comma-separated values (CSV) files (~48 GB uncompressed), comprising more than 173 million individual trips and hello fares paid for each trip.</span></span> <span data-ttu-id="78682-162">Chaque enregistrement de voyage comprend hello de prélèvement et emplacement de dépôt et l’heure, hack rendues anonymes (pilote) numéro de licence et nombre de medallion (id unique de taxi).</span><span class="sxs-lookup"><span data-stu-id="78682-162">Each trip record includes hello pick up and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</span></span> <span data-ttu-id="78682-163">les données de salutation couvre toutes les boucles dans l’année hello 2013 et sont fournies dans hello suivant deux jeux de données pour chaque mois :</span><span class="sxs-lookup"><span data-stu-id="78682-163">hello data covers all trips in hello year 2013 and is provided in hello following two datasets for each month:</span></span>

1. <span data-ttu-id="78682-164">les fichiers CSV Hello 'trip_data' contient les détails de voyage, telles que le nombre de personnes, récupèrent et cette chute pointe, déclenchement durée et la longueur de voyage.</span><span class="sxs-lookup"><span data-stu-id="78682-164">hello 'trip_data' CSV files contain trip details, such as number of passengers, pick up and dropoff points, trip duration, and trip length.</span></span> <span data-ttu-id="78682-165">Voici quelques exemples d’enregistrements :</span><span class="sxs-lookup"><span data-stu-id="78682-165">Here are a few sample records:</span></span>
   
        medallion,hack_license,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,1,N,2013-01-01 15:11:48,2013-01-01 15:18:10,4,382,1.00,-73.978165,40.757977,-73.989838,40.751171
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-06 00:18:35,2013-01-06 00:22:54,1,259,1.50,-74.006683,40.731781,-73.994499,40.75066
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-05 18:49:41,2013-01-05 18:54:23,1,282,1.10,-74.004707,40.73777,-74.009834,40.726002
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:54:15,2013-01-07 23:58:20,2,244,.70,-73.974602,40.759945,-73.984734,40.759388
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:25:03,2013-01-07 23:34:24,1,560,2.10,-73.97625,40.748528,-74.002586,40.747868
2. <span data-ttu-id="78682-166">fichiers de Hello 'trip_fare' CSV contenant les détails de tarif de hello payé pour chaque sortie, comme type de paiement, montant de frais, surcharge et taxes, conseils et péage et montant total de hello payé.</span><span class="sxs-lookup"><span data-stu-id="78682-166">hello 'trip_fare' CSV files contain details of hello fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and hello total amount paid.</span></span> <span data-ttu-id="78682-167">Voici quelques exemples d’enregistrements :</span><span class="sxs-lookup"><span data-stu-id="78682-167">Here are a few sample records:</span></span>
   
        medallion, hack_license, vendor_id, pickup_datetime, payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,2013-01-01 15:11:48,CSH,6.5,0,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-06 00:18:35,CSH,6,0.5,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-05 18:49:41,CSH,5.5,1,0.5,0,0,7
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:54:15,CSH,5,0.5,0.5,0,0,6
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:25:03,CSH,9.5,0.5,0.5,0,0,10.5

<span data-ttu-id="78682-168">Nous avons pris un échantillon de 0,1 % de ces fichiers et de voyage de hello jointes\_données et voyage\_serrées les fichiers CSV dans un seul jeu de données toouse en tant que jeu de données d’entrée hello pour cette procédure pas à pas.</span><span class="sxs-lookup"><span data-stu-id="78682-168">We have taken a 0.1% sample of these files and joined hello trip\_data and trip\_fare CVS files into a single dataset toouse as hello input dataset for this walkthrough.</span></span> <span data-ttu-id="78682-169">voyage toojoin de clé unique de Hello\_données et voyage\_tarif est composée de champs de hello : medallion, hack\_certificat et pickup\_datetime.</span><span class="sxs-lookup"><span data-stu-id="78682-169">hello unique key toojoin trip\_data and trip\_fare is composed of hello fields: medallion, hack\_licence and pickup\_datetime.</span></span> <span data-ttu-id="78682-170">Chaque enregistrement du jeu de données hello contient hello suivant des attributs représentant un déplacement NYC Taxi :</span><span class="sxs-lookup"><span data-stu-id="78682-170">Each record of hello dataset contains hello following attributes representing a NYC Taxi trip:</span></span>

| <span data-ttu-id="78682-171">Champ</span><span class="sxs-lookup"><span data-stu-id="78682-171">Field</span></span> | <span data-ttu-id="78682-172">Brève description</span><span class="sxs-lookup"><span data-stu-id="78682-172">Brief Description</span></span> |
| --- | --- |
| <span data-ttu-id="78682-173">medallion</span><span class="sxs-lookup"><span data-stu-id="78682-173">medallion</span></span> |<span data-ttu-id="78682-174">Médaillon de taxi anonymisé (id unique de taxi)</span><span class="sxs-lookup"><span data-stu-id="78682-174">Anonymized taxi medallion (unique taxi id)</span></span> |
| <span data-ttu-id="78682-175">hack_license</span><span class="sxs-lookup"><span data-stu-id="78682-175">hack_license</span></span> |<span data-ttu-id="78682-176">Numéro de licence Hackney Transport anonymisé</span><span class="sxs-lookup"><span data-stu-id="78682-176">Anonymized Hackney Carriage License number</span></span> |
| <span data-ttu-id="78682-177">vendor_id</span><span class="sxs-lookup"><span data-stu-id="78682-177">vendor_id</span></span> |<span data-ttu-id="78682-178">ID du fournisseur de taxi</span><span class="sxs-lookup"><span data-stu-id="78682-178">Taxi vendor id</span></span> |
| <span data-ttu-id="78682-179">rate_code</span><span class="sxs-lookup"><span data-stu-id="78682-179">rate_code</span></span> |<span data-ttu-id="78682-180">Tarification du taxi NYC</span><span class="sxs-lookup"><span data-stu-id="78682-180">NYC taxi rate of fare</span></span> |
| <span data-ttu-id="78682-181">store_and_fwd_flag</span><span class="sxs-lookup"><span data-stu-id="78682-181">store_and_fwd_flag</span></span> |<span data-ttu-id="78682-182">Indicateur de stockage et de transmission</span><span class="sxs-lookup"><span data-stu-id="78682-182">Store and forward flag</span></span> |
| <span data-ttu-id="78682-183">pickup_datetime</span><span class="sxs-lookup"><span data-stu-id="78682-183">pickup_datetime</span></span> |<span data-ttu-id="78682-184">Date et heure de départ</span><span class="sxs-lookup"><span data-stu-id="78682-184">Pick up date & time</span></span> |
| <span data-ttu-id="78682-185">dropoff_datetime</span><span class="sxs-lookup"><span data-stu-id="78682-185">dropoff_datetime</span></span> |<span data-ttu-id="78682-186">Date et heure d’arrivée</span><span class="sxs-lookup"><span data-stu-id="78682-186">Dropoff date & time</span></span> |
| <span data-ttu-id="78682-187">pickup_hour</span><span class="sxs-lookup"><span data-stu-id="78682-187">pickup_hour</span></span> |<span data-ttu-id="78682-188">Heure de départ</span><span class="sxs-lookup"><span data-stu-id="78682-188">Pick up hour</span></span> |
| <span data-ttu-id="78682-189">pickup_week</span><span class="sxs-lookup"><span data-stu-id="78682-189">pickup_week</span></span> |<span data-ttu-id="78682-190">Choisir une semaine de l’année de hello</span><span class="sxs-lookup"><span data-stu-id="78682-190">Pick up week of hello year</span></span> |
| <span data-ttu-id="78682-191">weekday</span><span class="sxs-lookup"><span data-stu-id="78682-191">weekday</span></span> |<span data-ttu-id="78682-192">Jour de la semaine (de 1 à 7)</span><span class="sxs-lookup"><span data-stu-id="78682-192">Weekday (range 1-7)</span></span> |
| <span data-ttu-id="78682-193">passenger_count</span><span class="sxs-lookup"><span data-stu-id="78682-193">passenger_count</span></span> |<span data-ttu-id="78682-194">Nombre de passagers dans un trajet en taxi</span><span class="sxs-lookup"><span data-stu-id="78682-194">Number of passengers in a taxi trip</span></span> |
| <span data-ttu-id="78682-195">trip_time_in_secs</span><span class="sxs-lookup"><span data-stu-id="78682-195">trip_time_in_secs</span></span> |<span data-ttu-id="78682-196">Durée du trajet en secondes</span><span class="sxs-lookup"><span data-stu-id="78682-196">Trip time in seconds</span></span> |
| <span data-ttu-id="78682-197">trip_distance</span><span class="sxs-lookup"><span data-stu-id="78682-197">trip_distance</span></span> |<span data-ttu-id="78682-198">Distance du trajet en miles</span><span class="sxs-lookup"><span data-stu-id="78682-198">Trip distance traveled in miles</span></span> |
| <span data-ttu-id="78682-199">pickup_longitude</span><span class="sxs-lookup"><span data-stu-id="78682-199">pickup_longitude</span></span> |<span data-ttu-id="78682-200">Longitude de départ</span><span class="sxs-lookup"><span data-stu-id="78682-200">Pick up longitude</span></span> |
| <span data-ttu-id="78682-201">pickup_latitude</span><span class="sxs-lookup"><span data-stu-id="78682-201">pickup_latitude</span></span> |<span data-ttu-id="78682-202">Latitude de départ</span><span class="sxs-lookup"><span data-stu-id="78682-202">Pick up latitude</span></span> |
| <span data-ttu-id="78682-203">dropoff_longitude</span><span class="sxs-lookup"><span data-stu-id="78682-203">dropoff_longitude</span></span> |<span data-ttu-id="78682-204">Longitude d’arrivée</span><span class="sxs-lookup"><span data-stu-id="78682-204">Dropoff longitude</span></span> |
| <span data-ttu-id="78682-205">dropoff_latitude</span><span class="sxs-lookup"><span data-stu-id="78682-205">dropoff_latitude</span></span> |<span data-ttu-id="78682-206">Latitude d’arrivée</span><span class="sxs-lookup"><span data-stu-id="78682-206">Dropoff latitude</span></span> |
| <span data-ttu-id="78682-207">direct_distance</span><span class="sxs-lookup"><span data-stu-id="78682-207">direct_distance</span></span> |<span data-ttu-id="78682-208">Distance directe entre les emplacements de départ et d’arrivée</span><span class="sxs-lookup"><span data-stu-id="78682-208">Direct distance between pick up and dropoff locations</span></span> |
| <span data-ttu-id="78682-209">payment_type</span><span class="sxs-lookup"><span data-stu-id="78682-209">payment_type</span></span> |<span data-ttu-id="78682-210">Type de paiement (espèces, carte de crédit, etc.).</span><span class="sxs-lookup"><span data-stu-id="78682-210">Payment type (cas, credit-card etc.)</span></span> |
| <span data-ttu-id="78682-211">fare_amount</span><span class="sxs-lookup"><span data-stu-id="78682-211">fare_amount</span></span> |<span data-ttu-id="78682-212">Montant du trajet</span><span class="sxs-lookup"><span data-stu-id="78682-212">Fare amount in</span></span> |
| <span data-ttu-id="78682-213">surcharge</span><span class="sxs-lookup"><span data-stu-id="78682-213">surcharge</span></span> |<span data-ttu-id="78682-214">Surcharge</span><span class="sxs-lookup"><span data-stu-id="78682-214">Surcharge</span></span> |
| <span data-ttu-id="78682-215">mta_tax</span><span class="sxs-lookup"><span data-stu-id="78682-215">mta_tax</span></span> |<span data-ttu-id="78682-216">Taxe du MTA</span><span class="sxs-lookup"><span data-stu-id="78682-216">Mta tax</span></span> |
| <span data-ttu-id="78682-217">tip_amount</span><span class="sxs-lookup"><span data-stu-id="78682-217">tip_amount</span></span> |<span data-ttu-id="78682-218">Montant du pourboire</span><span class="sxs-lookup"><span data-stu-id="78682-218">Tip amount</span></span> |
| <span data-ttu-id="78682-219">tolls_amount</span><span class="sxs-lookup"><span data-stu-id="78682-219">tolls_amount</span></span> |<span data-ttu-id="78682-220">Montant des péages</span><span class="sxs-lookup"><span data-stu-id="78682-220">Tolls amount</span></span> |
| <span data-ttu-id="78682-221">total_amount</span><span class="sxs-lookup"><span data-stu-id="78682-221">total_amount</span></span> |<span data-ttu-id="78682-222">Montant total</span><span class="sxs-lookup"><span data-stu-id="78682-222">Total amount</span></span> |
| <span data-ttu-id="78682-223">tipped</span><span class="sxs-lookup"><span data-stu-id="78682-223">tipped</span></span> |<span data-ttu-id="78682-224">Pourboire payé (0/1 pour non ou oui)</span><span class="sxs-lookup"><span data-stu-id="78682-224">Tipped (0/1 for no or yes)</span></span> |
| <span data-ttu-id="78682-225">tip_class</span><span class="sxs-lookup"><span data-stu-id="78682-225">tip_class</span></span> |<span data-ttu-id="78682-226">Classe de pourboire (0 : 0 $, 1 : 0-5 $ 2 : 6-10 $, 3 : 11 à 20 $, 4: 20 $ et +)</span><span class="sxs-lookup"><span data-stu-id="78682-226">Tip class (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span></span> |

## <a name="execute-code-from-a-jupyter-notebook-on-hello-spark-cluster"></a><span data-ttu-id="78682-227">Exécutez le code à partir d’un bloc-notes jupyter sur cluster Spark de hello</span><span class="sxs-lookup"><span data-stu-id="78682-227">Execute code from a Jupyter notebook on hello Spark cluster</span></span>
<span data-ttu-id="78682-228">Vous pouvez lancer hello bloc-notes Jupyter de hello portail Azure.</span><span class="sxs-lookup"><span data-stu-id="78682-228">You can launch hello Jupyter Notebook from hello Azure portal.</span></span> <span data-ttu-id="78682-229">Votre cluster Spark sur votre tableau de bord et cliquez sur cette page de gestion tooenter pour votre cluster.</span><span class="sxs-lookup"><span data-stu-id="78682-229">Find your Spark cluster on your dashboard and click it tooenter management page for your cluster.</span></span> <span data-ttu-id="78682-230">bloc-notes de hello tooopen associé hello Spark cluster, cliquez sur **tableaux de bord de Cluster** -> **bloc-notes Jupyter** .</span><span class="sxs-lookup"><span data-stu-id="78682-230">tooopen hello notebook associated with hello Spark cluster, click **Cluster Dashboards** -> **Jupyter Notebook** .</span></span>

![Tableaux de bord des clusters](./media/machine-learning-data-science-spark-overview/spark-jupyter-on-portal.png)

<span data-ttu-id="78682-232">Vous pouvez également parcourir trop***https://CLUSTERNAME.azurehdinsight.net/jupyter*** tooaccess hello Notebook portables.</span><span class="sxs-lookup"><span data-stu-id="78682-232">You can also browse too***https://CLUSTERNAME.azurehdinsight.net/jupyter*** tooaccess hello Jupyter Notebooks.</span></span> <span data-ttu-id="78682-233">Remplacer hello CLUSTERNAME de cette URL par nom hello de votre propre cluster.</span><span class="sxs-lookup"><span data-stu-id="78682-233">Replace hello CLUSTERNAME part of this URL with hello name of your own cluster.</span></span> <span data-ttu-id="78682-234">Vous avez besoin d’un mot de passe hello pour vos blocs-notes de hello admin compte tooaccess.</span><span class="sxs-lookup"><span data-stu-id="78682-234">You need hello password for your admin account tooaccess hello notebooks.</span></span>

![Parcourez Jupyter Notebooks](./media/machine-learning-data-science-spark-overview/spark-jupyter-notebook.png)

<span data-ttu-id="78682-236">Sélectionnez PySpark toosee un répertoire qui contient quelques exemples d’ordinateurs portables prédéfinis qui utilisent hello PySpark API.hello portables qui contiennent des exemples de code hello pour cette suite de rubrique de Spark sont disponibles au [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span><span class="sxs-lookup"><span data-stu-id="78682-236">Select PySpark toosee a directory that contains a few examples of pre-packaged notebooks that use hello PySpark API.hello notebooks that contain hello code samples for this suite of Spark topic are available at [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span></span>

<span data-ttu-id="78682-237">Vous pouvez télécharger les blocs-notes hello directement à partir de [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) toohello serveur de jupyter Notebook sur votre cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="78682-237">You can upload hello notebooks directly from [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) toohello Jupyter notebook server on your Spark cluster.</span></span> <span data-ttu-id="78682-238">Sur la page d’accueil hello de votre bloc-notes, cliquez sur hello **télécharger** bouton sur hello à droite dans le cadre de l’écran hello.</span><span class="sxs-lookup"><span data-stu-id="78682-238">On hello home page of your Jupyter, click hello **Upload** button on hello right part of hello screen.</span></span> <span data-ttu-id="78682-239">Cette action ouvre un explorateur de fichiers.</span><span class="sxs-lookup"><span data-stu-id="78682-239">It opens a file explorer.</span></span> <span data-ttu-id="78682-240">Vous pouvez coller des URL de GitHub (contenu brut) hello de hello bloc-notes, cliquez sur **ouvrir**.</span><span class="sxs-lookup"><span data-stu-id="78682-240">Here you can paste hello GitHub (raw content) URL of hello Notebook and click **Open**.</span></span> 

<span data-ttu-id="78682-241">Vous voyez le nom de fichier hello sur votre liste de fichiers Notebook avec un **télécharger** bouton Nouveau.</span><span class="sxs-lookup"><span data-stu-id="78682-241">You see hello file name on your Jupyter file list with an **Upload** button again.</span></span> <span data-ttu-id="78682-242">Cliquez sur ce bouton **Télécharger** .</span><span class="sxs-lookup"><span data-stu-id="78682-242">Click this **Upload** button.</span></span> <span data-ttu-id="78682-243">Maintenant, vous avez importé les bloc-notes hello.</span><span class="sxs-lookup"><span data-stu-id="78682-243">Now you have imported hello notebook.</span></span> <span data-ttu-id="78682-244">Répétez ces hello de tooupload étapes autres ordinateurs portables à partir de cette procédure pas à pas.</span><span class="sxs-lookup"><span data-stu-id="78682-244">Repeat these steps tooupload hello other notebooks from this walkthrough.</span></span>

> [!TIP]
> <span data-ttu-id="78682-245">Vous pouvez cliquer sur les liens hello sur votre navigateur, puis sélectionnez **copier le lien** tooget hello URL contenu brute de github.</span><span class="sxs-lookup"><span data-stu-id="78682-245">You can right-click hello links on your browser and select **Copy Link** tooget hello github raw content URL.</span></span> <span data-ttu-id="78682-246">Vous pouvez coller cette URL dans hello Notebook Télécharger fichier boîte de dialogue correspondante.</span><span class="sxs-lookup"><span data-stu-id="78682-246">You can paste this URL into hello Jupyter Upload file explorer dialog box.</span></span>
> 
> 

<span data-ttu-id="78682-247">Vous pouvez désormais :</span><span class="sxs-lookup"><span data-stu-id="78682-247">Now you can:</span></span>

* <span data-ttu-id="78682-248">Consultez le code de hello en cliquant sur ordinateur portable de hello.</span><span class="sxs-lookup"><span data-stu-id="78682-248">See hello code by clicking hello notebook.</span></span>
* <span data-ttu-id="78682-249">Exécutez chaque cellule en appuyant sur **MAJ-ENTRÉE**.</span><span class="sxs-lookup"><span data-stu-id="78682-249">Execute each cell by pressing **SHIFT-ENTER**.</span></span>
* <span data-ttu-id="78682-250">Exécuter le bloc-notes hello en cliquant sur **cellule** -> **exécuter**.</span><span class="sxs-lookup"><span data-stu-id="78682-250">Run hello entire notebook by clicking on **Cell** -> **Run**.</span></span>
* <span data-ttu-id="78682-251">Utiliser hello de visualisation automatique des requêtes.</span><span class="sxs-lookup"><span data-stu-id="78682-251">Use hello automatic visualization of queries.</span></span>

> [!TIP]
> <span data-ttu-id="78682-252">noyau de PySpark Hello visualise automatiquement sortie hello des requêtes SQL (HiveQL).</span><span class="sxs-lookup"><span data-stu-id="78682-252">hello PySpark kernel automatically visualizes hello output of SQL (HiveQL) queries.</span></span> <span data-ttu-id="78682-253">Vous pouvez soit tooselect d’option hello entre différents types de visualisations (Table, à secteurs, ligne, zone ou barre) à l’aide de hello **Type** des boutons de menu dans le bloc-notes de hello :</span><span class="sxs-lookup"><span data-stu-id="78682-253">You are given hello option tooselect among several different types of visualizations (Table, Pie, Line, Area, or Bar) by using hello **Type** menu buttons in hello notebook:</span></span>
> 
> 

![Courbe ROC de régression logistique pour une approche générique](./media/machine-learning-data-science-spark-overview/pyspark-jupyter-autovisualization.png)

## <a name="whats-next"></a><span data-ttu-id="78682-255">Et ensuite ?</span><span class="sxs-lookup"><span data-stu-id="78682-255">What's next?</span></span>
<span data-ttu-id="78682-256">Maintenant que vous sont configurés avec un cluster HDInsight Spark et que vous avez téléchargées blocs-notes de Notebook hello, vous êtes prêt toowork dans les rubriques hello qui correspondent toohello PySpark trois ordinateurs portables.</span><span class="sxs-lookup"><span data-stu-id="78682-256">Now that you are set up with an HDInsight Spark cluster and have uploaded hello Jupyter notebooks, you are ready toowork through hello topics that correspond toohello three PySpark notebooks.</span></span> <span data-ttu-id="78682-257">Elles montrent comment tooexplore vos données et la procédure puis toocreate et utiliser des modèles.</span><span class="sxs-lookup"><span data-stu-id="78682-257">They show how tooexplore your data and then how toocreate and consume models.</span></span> <span data-ttu-id="78682-258">Hello avancé d’exploration de données et modélisation bloc-notes montre comment tooinclude la validation croisée, hyper-paramètre de balayage et évaluation du modèle.</span><span class="sxs-lookup"><span data-stu-id="78682-258">hello advanced data exploration and modeling notebook shows how tooinclude cross-validation, hyper-parameter sweeping, and model evaluation.</span></span> 

<span data-ttu-id="78682-259">**Exploration de données et modélisation avec Spark :** Explorer hello le jeu de données, de créer, d’évaluer et d’évaluer les modèles d’apprentissage automatique hello en passant par hello [créer des modèles de classification et de régression binaire pour les données avec hello Spark Outils d’analyse MLlib](machine-learning-data-science-spark-data-exploration-modeling.md) rubrique.</span><span class="sxs-lookup"><span data-stu-id="78682-259">**Data Exploration and modeling with Spark:** Explore hello dataset and create, score, and evaluate hello machine learning models by working through hello [Create binary classification and regression models for data with hello Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) topic.</span></span>

<span data-ttu-id="78682-260">**La consommation de modèle :** toolearn comment créer des modèles de classification et la régression de hello tooscore dans cette rubrique, consultez [Score et évaluer les modèles d’apprentissage automatique de Spark intégrée](machine-learning-data-science-spark-model-consumption.md).</span><span class="sxs-lookup"><span data-stu-id="78682-260">**Model consumption:** toolearn how tooscore hello classification and regression models created in this topic, see [Score and evaluate Spark-built machine learning models](machine-learning-data-science-spark-model-consumption.md).</span></span>

<span data-ttu-id="78682-261">**Validation croisée et balayage hyperparamétrique**: consultez [Exploration et modélisation avancées des données avec Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) pour savoir comment effectuer la formation des modèles à l’aide de la validation croisée et du balayage hyperparamétrique</span><span class="sxs-lookup"><span data-stu-id="78682-261">**Cross-validation and hyperparameter sweeping**: See [Advanced data exploration and modeling with Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) on how models can be trained using cross-validation and hyper-parameter sweeping</span></span>

