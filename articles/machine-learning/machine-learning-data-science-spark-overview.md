---
title: "Vue d’ensemble de la science des données à l’aide de Spark sur Azure HDInsight | Microsoft Docs"
description: "La boîte à outils MLlib de Spark offre de nombreuses fonctionnalités de modélisation Machine Learning (ML) à cet environnement distribué."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: a4e1de99-a554-4240-9647-2c6d669593c8
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/15/2017
ms.author: deguhath;bradsev;gokuma
ms.openlocfilehash: 379b32f4e533f48f1593a97e73737a0c5bfb9135
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 07/11/2017
---
# <a name="overview-of-data-science-using-spark-on-azure-hdinsight"></a><span data-ttu-id="1931c-103">Vue d’ensemble de la science des données à l’aide de Spark sur Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="1931c-103">Overview of data science using Spark on Azure HDInsight</span></span>
[!INCLUDE [machine-learning-spark-modeling](../../includes/machine-learning-spark-modeling.md)]

<span data-ttu-id="1931c-104">Cet ensemble de rubriques montre comment utiliser HDInsight Spark pour effectuer des tâches de science des données courantes, telles que l’ingestion de données, la conception de fonctionnalités, la modélisation et l’évaluation de modèle.</span><span class="sxs-lookup"><span data-stu-id="1931c-104">This suite of topics shows how to use HDInsight Spark to complete common data science tasks such as data ingestion, feature engineering, modeling, and model evaluation.</span></span> <span data-ttu-id="1931c-105">Les données utilisées sont un échantillon du jeu de données NYC Taxi Trip and Fare 2013.</span><span class="sxs-lookup"><span data-stu-id="1931c-105">The data used is a sample of the 2013 NYC taxi trip and fare dataset.</span></span> <span data-ttu-id="1931c-106">Les modèles conçus incluent la régression logistique, la régression linéaire, les forêts aléatoires et les arbres GBT (Gradient Boosted Tree).</span><span class="sxs-lookup"><span data-stu-id="1931c-106">The models built include logistic and linear regression, random forests, and gradient boosted trees.</span></span> <span data-ttu-id="1931c-107">Les rubriques montrent également comment stocker ces modèles dans le stockage d’objets blob Azure (WASB) et comment noter et évaluer leurs performances de prédiction.</span><span class="sxs-lookup"><span data-stu-id="1931c-107">The topics also show how to store these models in Azure blob storage (WASB) and how to score and evaluate their predictive performance.</span></span> <span data-ttu-id="1931c-108">D’autres rubriques plus avancées décrivent comment former des modèles par validation croisée et balayage hyperparamétrique.</span><span class="sxs-lookup"><span data-stu-id="1931c-108">More advanced topics cover how models can be trained using cross-validation and hyper-parameter sweeping.</span></span> <span data-ttu-id="1931c-109">Cette rubrique de présentation référence également les rubriques qui décrivent comment configurer le cluster Spark dont vous avez besoin pour effectuer les étapes des procédures pas à pas fournies.</span><span class="sxs-lookup"><span data-stu-id="1931c-109">This overview topic also references the topics that describe how to set up the Spark cluster that you need to complete the steps in the walkthroughs provided.</span></span> 

## <a name="spark-and-mllib"></a><span data-ttu-id="1931c-110">Spark et MLlib</span><span class="sxs-lookup"><span data-stu-id="1931c-110">Spark and MLlib</span></span>
<span data-ttu-id="1931c-111">[Spark](http://spark.apache.org/) est une infrastructure de traitement en parallèle open source qui prend en charge le traitement en mémoire pour accroître les performances des applications d’analyse de Big Data.</span><span class="sxs-lookup"><span data-stu-id="1931c-111">[Spark](http://spark.apache.org/) is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span></span> <span data-ttu-id="1931c-112">Le moteur de traitement Spark est élaboré pour permettre des analyses rapides, simples d’utilisation et sophistiquées.</span><span class="sxs-lookup"><span data-stu-id="1931c-112">The Spark processing engine is built for speed, ease of use, and sophisticated analytics.</span></span> <span data-ttu-id="1931c-113">De par ses capacités de calcul distribué en mémoire, Spark constitue le choix idéal pour les algorithmes itératifs utilisés dans l’apprentissage automatique et les calculs de graphiques.</span><span class="sxs-lookup"><span data-stu-id="1931c-113">Spark's in-memory distributed computation capabilities make it a good choice for the iterative algorithms used in machine learning and graph computations.</span></span> <span data-ttu-id="1931c-114">[MLlib](http://spark.apache.org/mllib/) est la bibliothèque évolutive d’apprentissage automatique de Spark. Elle apporte des fonctionnalités de modélisation d’algorithme à cet environnement distribué.</span><span class="sxs-lookup"><span data-stu-id="1931c-114">[MLlib](http://spark.apache.org/mllib/) is Spark's scalable machine learning library that brings the algorithmic modeling capabilities to this distributed environment.</span></span> 

## <a name="hdinsight-spark"></a><span data-ttu-id="1931c-115">HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="1931c-115">HDInsight Spark</span></span>
<span data-ttu-id="1931c-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) est l’offre Azure de Spark Open Source.</span><span class="sxs-lookup"><span data-stu-id="1931c-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) is the Azure hosted offering of open-source Spark.</span></span> <span data-ttu-id="1931c-117">Elle prend également en charge les **blocs-notes Jupyter PySpark** sur le cluster Spark, qui peuvent exécuter des requêtes interactives SQL Spark pour transformer, filtrer et visualiser les données stockées dans des objets blob Azure (WASB).</span><span class="sxs-lookup"><span data-stu-id="1931c-117">It also includes support for **Jupyter PySpark notebooks** on the Spark cluster that can run Spark SQL interactive queries for transforming, filtering, and visualizing data stored in Azure Blobs (WASB).</span></span> <span data-ttu-id="1931c-118">PySpark est l’API Python pour Spark.</span><span class="sxs-lookup"><span data-stu-id="1931c-118">PySpark is the Python API for Spark.</span></span> <span data-ttu-id="1931c-119">Les extraits de code qui fournissent les solutions et montrent les tracés pertinents permettant de visualiser les données ici s’exécutent dans des notebooks Jupyter installés sur les clusters Spark.</span><span class="sxs-lookup"><span data-stu-id="1931c-119">The code snippets that provide the solutions and show the relevant plots to visualize the data here run in Jupyter notebooks installed on the Spark clusters.</span></span> <span data-ttu-id="1931c-120">Les étapes de modélisation dans ces rubriques contiennent du code qui montre comment former, évaluer, enregistrer et consommer chaque type de modèle.</span><span class="sxs-lookup"><span data-stu-id="1931c-120">The modeling steps in these topics contain code that shows how to train, evaluate, save, and consume each type of model.</span></span> 

## <a name="setup-spark-clusters-and-jupyter-notebooks"></a><span data-ttu-id="1931c-121">Installation des clusters Spark et notebooks Jupyter</span><span class="sxs-lookup"><span data-stu-id="1931c-121">Setup: Spark clusters and Jupyter notebooks</span></span>
<span data-ttu-id="1931c-122">Les étapes de configuration et le code fournis dans cette procédure pas à pas concernent HDInsight Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="1931c-122">Setup steps and code are provided in this walkthrough for using an HDInsight Spark 1.6.</span></span> <span data-ttu-id="1931c-123">Mais des notebooks Jupyter sont fournis pour les clusters HDInsight Spark 1.6 et Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="1931c-123">But Jupyter notebooks are provided for both HDInsight Spark 1.6 and Spark 2.0 clusters.</span></span> <span data-ttu-id="1931c-124">Une description des notebooks et des liens vers ceux-ci sont fournis dans le fichier [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) correspondant au dépôt GitHub qui les contient.</span><span class="sxs-lookup"><span data-stu-id="1931c-124">A description of the notebooks and links to them are provided in the [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) for the GitHub repository containing them.</span></span> <span data-ttu-id="1931c-125">En outre, le code présenté ici et dans les notebooks liés est générique et doit fonctionner sur n’importe quel cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="1931c-125">Moreover, the code here and in the linked notebooks is generic and should work on any Spark cluster.</span></span> <span data-ttu-id="1931c-126">Si vous n’utilisez pas HDInsight Spark, les étapes de configuration et de gestion de cluster peuvent être légèrement différentes de celles indiquées ici.</span><span class="sxs-lookup"><span data-stu-id="1931c-126">If you are not using HDInsight Spark, the cluster setup and management steps may be slightly different from what is shown here.</span></span> <span data-ttu-id="1931c-127">Pour plus de commodité, voici les liens vers les Blocs-notes Jupyter pour Spark 1.6 (à exécuter dans le noyau pySpark du serveur de Bloc-notes Jupyter) et 2.0 (à exécuter dans le noyau pySpark3 du serveur de Bloc-notes Jupyter) :</span><span class="sxs-lookup"><span data-stu-id="1931c-127">For convenience, here are the links to the Jupyter notebooks for Spark 1.6 (to be run in the pySpark kernel of the Jupyter Notebook server) and  Spark 2.0 (to be run in the pySpark3 kernel of the Jupyter Notebook server):</span></span>

### <a name="spark-16-notebooks"></a><span data-ttu-id="1931c-128">Notebooks Spark 1.6</span><span class="sxs-lookup"><span data-stu-id="1931c-128">Spark 1.6 notebooks</span></span>
<span data-ttu-id="1931c-129">Ces blocs-notes doivent être exécutés dans le noyau pySpark du serveur de Bloc-notes Jupyter.</span><span class="sxs-lookup"><span data-stu-id="1931c-129">These notebooks are to be run in the pySpark kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="1931c-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb) : fournit des informations sur l’exploration des données, la modélisation et la notation avec plusieurs algorithmes différents.</span><span class="sxs-lookup"><span data-stu-id="1931c-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): Provides information on how to perform data exploration, modeling, and scoring with several different algorithms.</span></span>
- <span data-ttu-id="1931c-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) : inclut les thèmes du notebook 1 et traite également du développement de modèles à l’aide de l’ajustement des hyperparamètres et de la validation croisée.</span><span class="sxs-lookup"><span data-stu-id="1931c-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Includes topics in notebook #1, and model development using hyperparameter tuning and cross-validation.</span></span>
- <span data-ttu-id="1931c-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) : montre comment utiliser un modèle enregistré à l’aide de Python sur des clusters HDInsight.</span><span class="sxs-lookup"><span data-stu-id="1931c-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): Shows how to operationalize a saved model using Python on HDInsight clusters.</span></span>

### <a name="spark-20-notebooks"></a><span data-ttu-id="1931c-133">Notebooks Spark 2.0</span><span class="sxs-lookup"><span data-stu-id="1931c-133">Spark 2.0 notebooks</span></span>
<span data-ttu-id="1931c-134">Ces blocs-notes doivent être exécutés dans le noyau pySpark3 du serveur de Bloc-notes Jupyter.</span><span class="sxs-lookup"><span data-stu-id="1931c-134">These notebooks are to be run in the pySpark3 kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="1931c-135">[Spark2.0-pySpark3-machine-Learning-Data-science-Spark-Advanced-Data-exploration-Modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) : ce fichier fournit des informations sur l’exploration des données, la modélisation et la notation dans les clusters Spark 2.0 utilisant le jeu de données des courses et tarifs de taxi à New York décrit [ici](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="1931c-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): This file provides information on how to perform data exploration, modeling, and scoring in Spark 2.0 clusters using the NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span> <span data-ttu-id="1931c-136">Ce bloc-notes peut être un bon point de départ pour explorer rapidement le code que nous avons fourni pour Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="1931c-136">This notebook may be a good starting point for quickly exploring the code we have provided for Spark 2.0.</span></span> <span data-ttu-id="1931c-137">Pour un bloc-notes plus détaillé analysant les données sur les taxis de New York, consultez le bloc-notes suivant de cette liste.</span><span class="sxs-lookup"><span data-stu-id="1931c-137">For a more detailed notebook analyzes the NYC Taxi data, see the next notebook in this list.</span></span> <span data-ttu-id="1931c-138">Consultez les notes comparatives de ces blocs-notes indiquées à la suite de cette liste.</span><span class="sxs-lookup"><span data-stu-id="1931c-138">See the notes following this list that compare these notebooks.</span></span> 
- <span data-ttu-id="1931c-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb) : ce fichier montre comment effectuer des opérations de retraitement, ou « wrangling », (Spark SQL et tableaux de données) et fournit des informations sur l’exploration, la modélisation et la notation à l’aide du jeu de données « NYC Taxi trip and fare » décrit [ici](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="1931c-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): This file shows how to perform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using the NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span>
- <span data-ttu-id="1931c-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb) : ce fichier montre comment effectuer des opérations de retraitement, ou « wrangling », (Spark SQL et tableaux de données) et fournit des informations sur l’exploration, la modélisation et la notation à l’aide du jeu de données bien connu sur les départs à l’heure des compagnies aériennes pour les années 2011 et 2012.</span><span class="sxs-lookup"><span data-stu-id="1931c-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): This file shows how to perform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using the well-known Airline On-time departure dataset from 2011 and 2012.</span></span> <span data-ttu-id="1931c-141">Nous avons intégré le jeu de données de compagnies aériennes avec les données météorologiques des aéroports (vitesse du vent, température, altitude, etc.) avant la modélisation. Ces fonctionnalités météo peuvent donc à présent être incluses dans le modèle.</span><span class="sxs-lookup"><span data-stu-id="1931c-141">We integrated the airline dataset with the airport weather data (e.g. windspeed, temperature, altitude etc.) prior to modeling, so these weather features can be included in the model.</span></span>

<!-- -->

> [!NOTE]
> <span data-ttu-id="1931c-142">Le jeu de données de compagnies aériennes a été ajouté aux notebooks Spark 2.0 pour mieux illustrer l’utilisation des algorithmes de classification.</span><span class="sxs-lookup"><span data-stu-id="1931c-142">The airline dataset was added to the Spark 2.0 notebooks to better illustrate the use of classification algorithms.</span></span> <span data-ttu-id="1931c-143">Consultez les liens suivants pour plus d’informations sur le jeu de données sur les compagnies aériennes et celui sur les données météorologiques :</span><span class="sxs-lookup"><span data-stu-id="1931c-143">See the following links for information about airline on-time departure dataset and weather dataset:</span></span>

>- <span data-ttu-id="1931c-144">Données sur les départs à l’heure des compagnies aériennes : [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span><span class="sxs-lookup"><span data-stu-id="1931c-144">Airline on-time departure data: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span></span>

>- <span data-ttu-id="1931c-145">Données météorologiques des aéroports : [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span><span class="sxs-lookup"><span data-stu-id="1931c-145">Airport weather data: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span></span> 
> 
> 

<!-- -->

<!-- -->

> [!NOTE]
<span data-ttu-id="1931c-146">L’exécution des blocs-notes Spark 2.0 sur les jeux de données « NYC taxi and airline flight delay » peut prendre 10 minutes ou plus (selon la taille de votre cluster HDI).</span><span class="sxs-lookup"><span data-stu-id="1931c-146">The Spark 2.0 notebooks on the NYC taxi and airline flight delay data-sets can take 10 mins or more to run (depending on the size of your HDI cluster).</span></span> <span data-ttu-id="1931c-147">Le premier bloc-notes dans la liste ci-dessus présente de nombreux aspects de l’exploration de données, de la visualisation et de l’apprentissage du modèle ML dans un bloc-notes qui s’exécute plus rapidement avec un jeu de données échantillonné dans lequel ont été préalablement regroupés les fichiers sur les taxis et les tarifs à New York : [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) Ce bloc-notes bien plus rapide (2 à 3 minutes) peut être un bon point de départ pour explorer rapidement le code que nous avons fourni pour Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="1931c-147">The first notebook in the above list shows many aspects of the data exploration, visualization and ML model training in a notebook that takes less time to run with down-sampled NYC data set, in which the taxi and fare files have been pre-joined: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) This notebook takes a much shorter time to finish (2-3 mins) and may be a good starting point for quickly exploring the code we have provided for Spark 2.0.</span></span> 

<!-- -->

<span data-ttu-id="1931c-148">Pour obtenir des conseils sur l’utilisation d’un modèle Spark 2.0 et la consommation de modèle à des fins de notation, consultez le [document Spark 1.6 sur la consommation](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) pour obtenir un exemple des étapes requises.</span><span class="sxs-lookup"><span data-stu-id="1931c-148">For guidance on the operationalization of a Spark 2.0 model and model consumption for scoring, see the [Spark 1.6 document on consumption](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) for an example outlining the steps required.</span></span> <span data-ttu-id="1931c-149">Pour utiliser cette option sur Spark 2.0, remplacez le fichier de code Python par [ce fichier](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span><span class="sxs-lookup"><span data-stu-id="1931c-149">To use this on Spark 2.0, replace the Python code file with [this file](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span></span>

### <a name="prerequisites"></a><span data-ttu-id="1931c-150">Composants requis</span><span class="sxs-lookup"><span data-stu-id="1931c-150">Prerequisites</span></span>
<span data-ttu-id="1931c-151">Les procédures ci-dessous sont relatives à Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="1931c-151">The following procedures are related to Spark 1.6.</span></span> <span data-ttu-id="1931c-152">Pour la version Spark 2.0, utilisez les blocs-notes décrits et référencés précédemment.</span><span class="sxs-lookup"><span data-stu-id="1931c-152">For  the Spark 2.0 version, use the notebooks described and linked to previously.</span></span> 

<span data-ttu-id="1931c-153">1. Vous devez avoir un abonnement Azure.</span><span class="sxs-lookup"><span data-stu-id="1931c-153">1.You must have an Azure subscription.</span></span> <span data-ttu-id="1931c-154">Si vous n’en avez pas, consultez [Obtenir une version d’évaluation gratuite Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="1931c-154">If you do not already have one, see [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>

<span data-ttu-id="1931c-155">2. Vous avez besoin d’un cluster Spark 1.6 pour effectuer cette procédure pas à pas.</span><span class="sxs-lookup"><span data-stu-id="1931c-155">2.You need a Spark 1.6 cluster to complete this walkthrough.</span></span> <span data-ttu-id="1931c-156">Pour en créer un, consultez les instructions fournies dans [Prise en main : Créer Apache Spark sur Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="1931c-156">To create one, see the instructions provided in [Get started: create Apache Spark on Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> <span data-ttu-id="1931c-157">Vous spécifiez le type et la version du cluster à partir du menu **Sélectionner le type de cluster** .</span><span class="sxs-lookup"><span data-stu-id="1931c-157">The cluster type and version is specified from the **Select Cluster Type** menu.</span></span> 

![Configurer le cluster](./media/machine-learning-data-science-spark-overview/spark-cluster-on-portal.png)

<!-- -->

> [!NOTE]
> <span data-ttu-id="1931c-159">Pour une rubrique qui montre comment utiliser Scala plutôt que Python pour effectuer des tâches de processus de science des données de bout en bout, consultez [Science des données à l’aide de Scala avec Spark sur Azure](machine-learning-data-science-process-scala-walkthrough.md).</span><span class="sxs-lookup"><span data-stu-id="1931c-159">For a topic that shows how to use Scala rather than Python to complete tasks for an end-to-end data science process, see the [Data Science using Scala with Spark on Azure](machine-learning-data-science-process-scala-walkthrough.md).</span></span>
> 
> 

<!-- -->

> [!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]
> 
> 

## <a name="the-nyc-2013-taxi-data"></a><span data-ttu-id="1931c-160">Données de NYC 2013 Taxi</span><span class="sxs-lookup"><span data-stu-id="1931c-160">The NYC 2013 Taxi data</span></span>
<span data-ttu-id="1931c-161">Pesant environ 20 Go au format compressé (ou 48 Go au format non compressé), le jeu de données NYC Taxi Trip contient des fichiers CSV (valeurs séparées par des virgules) concernant plus de 173 millions de trajets et le prix réglé pour chacun d’entre eux.</span><span class="sxs-lookup"><span data-stu-id="1931c-161">The NYC Taxi Trip data is about 20 GB of compressed comma-separated values (CSV) files (~48 GB uncompressed), comprising more than 173 million individual trips and the fares paid for each trip.</span></span> <span data-ttu-id="1931c-162">Chaque enregistrement de course inclut le lieu et l’heure d’embarquement et de débarquement, le numéro de licence (du chauffeur) rendu anonyme et le numéro de médaillon (numéro d’identification unique) du taxi.</span><span class="sxs-lookup"><span data-stu-id="1931c-162">Each trip record includes the pick up and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</span></span> <span data-ttu-id="1931c-163">Les données portent sur toutes les courses effectuées en 2013 et sont fournies dans les deux jeux de données ci-après pour chaque mois :</span><span class="sxs-lookup"><span data-stu-id="1931c-163">The data covers all trips in the year 2013 and is provided in the following two datasets for each month:</span></span>

1. <span data-ttu-id="1931c-164">Les fichiers CSV trip_data contiennent les détails de chaque course, comme le nombre de passagers, les points d’embarquement et de débarquement, la durée du trajet et la distance parcourue.</span><span class="sxs-lookup"><span data-stu-id="1931c-164">The 'trip_data' CSV files contain trip details, such as number of passengers, pick up and dropoff points, trip duration, and trip length.</span></span> <span data-ttu-id="1931c-165">Voici quelques exemples d’enregistrements :</span><span class="sxs-lookup"><span data-stu-id="1931c-165">Here are a few sample records:</span></span>
   
        medallion,hack_license,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,1,N,2013-01-01 15:11:48,2013-01-01 15:18:10,4,382,1.00,-73.978165,40.757977,-73.989838,40.751171
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-06 00:18:35,2013-01-06 00:22:54,1,259,1.50,-74.006683,40.731781,-73.994499,40.75066
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-05 18:49:41,2013-01-05 18:54:23,1,282,1.10,-74.004707,40.73777,-74.009834,40.726002
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:54:15,2013-01-07 23:58:20,2,244,.70,-73.974602,40.759945,-73.984734,40.759388
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:25:03,2013-01-07 23:34:24,1,560,2.10,-73.97625,40.748528,-74.002586,40.747868
2. <span data-ttu-id="1931c-166">Les fichiers CSV trip_fare contiennent des informations sur le prix payé pour chaque trajet, comme le type de paiement, le montant, la surcharge et les taxes, les pourboires et péages, ainsi que le montant total réglé.</span><span class="sxs-lookup"><span data-stu-id="1931c-166">The 'trip_fare' CSV files contain details of the fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and the total amount paid.</span></span> <span data-ttu-id="1931c-167">Voici quelques exemples d’enregistrements :</span><span class="sxs-lookup"><span data-stu-id="1931c-167">Here are a few sample records:</span></span>
   
        medallion, hack_license, vendor_id, pickup_datetime, payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,2013-01-01 15:11:48,CSH,6.5,0,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-06 00:18:35,CSH,6,0.5,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-05 18:49:41,CSH,5.5,1,0.5,0,0,7
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:54:15,CSH,5,0.5,0.5,0,0,6
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:25:03,CSH,9.5,0.5,0.5,0,0,10.5

<span data-ttu-id="1931c-168">Nous avons pris un échantillon représentant 0,1 % de ces fichiers, et joint les fichiers CSV trip\_data et trip\_fare dans un jeu de données unique à utiliser comme jeu de données d’entrée pour cette procédure pas à pas.</span><span class="sxs-lookup"><span data-stu-id="1931c-168">We have taken a 0.1% sample of these files and joined the trip\_data and trip\_fare CVS files into a single dataset to use as the input dataset for this walkthrough.</span></span> <span data-ttu-id="1931c-169">La clé unique permettant de joindre trip\_data et trip\_fare se compose des champs suivants : medallion (médaillon), hack\_licence (licence de taxi) et pickup\_datetime (date et heure d’embarquement).</span><span class="sxs-lookup"><span data-stu-id="1931c-169">The unique key to join trip\_data and trip\_fare is composed of the fields: medallion, hack\_licence and pickup\_datetime.</span></span> <span data-ttu-id="1931c-170">Chaque enregistrement du jeu de données contient les attributs suivants qui représentent un trajet NYC Taxy :</span><span class="sxs-lookup"><span data-stu-id="1931c-170">Each record of the dataset contains the following attributes representing a NYC Taxi trip:</span></span>

| <span data-ttu-id="1931c-171">Champ</span><span class="sxs-lookup"><span data-stu-id="1931c-171">Field</span></span> | <span data-ttu-id="1931c-172">Brève description</span><span class="sxs-lookup"><span data-stu-id="1931c-172">Brief Description</span></span> |
| --- | --- |
| <span data-ttu-id="1931c-173">medallion</span><span class="sxs-lookup"><span data-stu-id="1931c-173">medallion</span></span> |<span data-ttu-id="1931c-174">Médaillon de taxi anonymisé (id unique de taxi)</span><span class="sxs-lookup"><span data-stu-id="1931c-174">Anonymized taxi medallion (unique taxi id)</span></span> |
| <span data-ttu-id="1931c-175">hack_license</span><span class="sxs-lookup"><span data-stu-id="1931c-175">hack_license</span></span> |<span data-ttu-id="1931c-176">Numéro de licence Hackney Transport anonymisé</span><span class="sxs-lookup"><span data-stu-id="1931c-176">Anonymized Hackney Carriage License number</span></span> |
| <span data-ttu-id="1931c-177">vendor_id</span><span class="sxs-lookup"><span data-stu-id="1931c-177">vendor_id</span></span> |<span data-ttu-id="1931c-178">ID du fournisseur de taxi</span><span class="sxs-lookup"><span data-stu-id="1931c-178">Taxi vendor id</span></span> |
| <span data-ttu-id="1931c-179">rate_code</span><span class="sxs-lookup"><span data-stu-id="1931c-179">rate_code</span></span> |<span data-ttu-id="1931c-180">Tarification du taxi NYC</span><span class="sxs-lookup"><span data-stu-id="1931c-180">NYC taxi rate of fare</span></span> |
| <span data-ttu-id="1931c-181">store_and_fwd_flag</span><span class="sxs-lookup"><span data-stu-id="1931c-181">store_and_fwd_flag</span></span> |<span data-ttu-id="1931c-182">Indicateur de stockage et de transmission</span><span class="sxs-lookup"><span data-stu-id="1931c-182">Store and forward flag</span></span> |
| <span data-ttu-id="1931c-183">pickup_datetime</span><span class="sxs-lookup"><span data-stu-id="1931c-183">pickup_datetime</span></span> |<span data-ttu-id="1931c-184">Date et heure de départ</span><span class="sxs-lookup"><span data-stu-id="1931c-184">Pick up date & time</span></span> |
| <span data-ttu-id="1931c-185">dropoff_datetime</span><span class="sxs-lookup"><span data-stu-id="1931c-185">dropoff_datetime</span></span> |<span data-ttu-id="1931c-186">Date et heure d’arrivée</span><span class="sxs-lookup"><span data-stu-id="1931c-186">Dropoff date & time</span></span> |
| <span data-ttu-id="1931c-187">pickup_hour</span><span class="sxs-lookup"><span data-stu-id="1931c-187">pickup_hour</span></span> |<span data-ttu-id="1931c-188">Heure de départ</span><span class="sxs-lookup"><span data-stu-id="1931c-188">Pick up hour</span></span> |
| <span data-ttu-id="1931c-189">pickup_week</span><span class="sxs-lookup"><span data-stu-id="1931c-189">pickup_week</span></span> |<span data-ttu-id="1931c-190">Semaine de l’année correspondant au départ</span><span class="sxs-lookup"><span data-stu-id="1931c-190">Pick up week of the year</span></span> |
| <span data-ttu-id="1931c-191">weekday</span><span class="sxs-lookup"><span data-stu-id="1931c-191">weekday</span></span> |<span data-ttu-id="1931c-192">Jour de la semaine (de 1 à 7)</span><span class="sxs-lookup"><span data-stu-id="1931c-192">Weekday (range 1-7)</span></span> |
| <span data-ttu-id="1931c-193">passenger_count</span><span class="sxs-lookup"><span data-stu-id="1931c-193">passenger_count</span></span> |<span data-ttu-id="1931c-194">Nombre de passagers dans un trajet en taxi</span><span class="sxs-lookup"><span data-stu-id="1931c-194">Number of passengers in a taxi trip</span></span> |
| <span data-ttu-id="1931c-195">trip_time_in_secs</span><span class="sxs-lookup"><span data-stu-id="1931c-195">trip_time_in_secs</span></span> |<span data-ttu-id="1931c-196">Durée du trajet en secondes</span><span class="sxs-lookup"><span data-stu-id="1931c-196">Trip time in seconds</span></span> |
| <span data-ttu-id="1931c-197">trip_distance</span><span class="sxs-lookup"><span data-stu-id="1931c-197">trip_distance</span></span> |<span data-ttu-id="1931c-198">Distance du trajet en miles</span><span class="sxs-lookup"><span data-stu-id="1931c-198">Trip distance traveled in miles</span></span> |
| <span data-ttu-id="1931c-199">pickup_longitude</span><span class="sxs-lookup"><span data-stu-id="1931c-199">pickup_longitude</span></span> |<span data-ttu-id="1931c-200">Longitude de départ</span><span class="sxs-lookup"><span data-stu-id="1931c-200">Pick up longitude</span></span> |
| <span data-ttu-id="1931c-201">pickup_latitude</span><span class="sxs-lookup"><span data-stu-id="1931c-201">pickup_latitude</span></span> |<span data-ttu-id="1931c-202">Latitude de départ</span><span class="sxs-lookup"><span data-stu-id="1931c-202">Pick up latitude</span></span> |
| <span data-ttu-id="1931c-203">dropoff_longitude</span><span class="sxs-lookup"><span data-stu-id="1931c-203">dropoff_longitude</span></span> |<span data-ttu-id="1931c-204">Longitude d’arrivée</span><span class="sxs-lookup"><span data-stu-id="1931c-204">Dropoff longitude</span></span> |
| <span data-ttu-id="1931c-205">dropoff_latitude</span><span class="sxs-lookup"><span data-stu-id="1931c-205">dropoff_latitude</span></span> |<span data-ttu-id="1931c-206">Latitude d’arrivée</span><span class="sxs-lookup"><span data-stu-id="1931c-206">Dropoff latitude</span></span> |
| <span data-ttu-id="1931c-207">direct_distance</span><span class="sxs-lookup"><span data-stu-id="1931c-207">direct_distance</span></span> |<span data-ttu-id="1931c-208">Distance directe entre les emplacements de départ et d’arrivée</span><span class="sxs-lookup"><span data-stu-id="1931c-208">Direct distance between pick up and dropoff locations</span></span> |
| <span data-ttu-id="1931c-209">payment_type</span><span class="sxs-lookup"><span data-stu-id="1931c-209">payment_type</span></span> |<span data-ttu-id="1931c-210">Type de paiement (espèces, carte de crédit, etc.).</span><span class="sxs-lookup"><span data-stu-id="1931c-210">Payment type (cas, credit-card etc.)</span></span> |
| <span data-ttu-id="1931c-211">fare_amount</span><span class="sxs-lookup"><span data-stu-id="1931c-211">fare_amount</span></span> |<span data-ttu-id="1931c-212">Montant du trajet</span><span class="sxs-lookup"><span data-stu-id="1931c-212">Fare amount in</span></span> |
| <span data-ttu-id="1931c-213">surcharge</span><span class="sxs-lookup"><span data-stu-id="1931c-213">surcharge</span></span> |<span data-ttu-id="1931c-214">Surcharge</span><span class="sxs-lookup"><span data-stu-id="1931c-214">Surcharge</span></span> |
| <span data-ttu-id="1931c-215">mta_tax</span><span class="sxs-lookup"><span data-stu-id="1931c-215">mta_tax</span></span> |<span data-ttu-id="1931c-216">Taxe du MTA</span><span class="sxs-lookup"><span data-stu-id="1931c-216">Mta tax</span></span> |
| <span data-ttu-id="1931c-217">tip_amount</span><span class="sxs-lookup"><span data-stu-id="1931c-217">tip_amount</span></span> |<span data-ttu-id="1931c-218">Montant du pourboire</span><span class="sxs-lookup"><span data-stu-id="1931c-218">Tip amount</span></span> |
| <span data-ttu-id="1931c-219">tolls_amount</span><span class="sxs-lookup"><span data-stu-id="1931c-219">tolls_amount</span></span> |<span data-ttu-id="1931c-220">Montant des péages</span><span class="sxs-lookup"><span data-stu-id="1931c-220">Tolls amount</span></span> |
| <span data-ttu-id="1931c-221">total_amount</span><span class="sxs-lookup"><span data-stu-id="1931c-221">total_amount</span></span> |<span data-ttu-id="1931c-222">Montant total</span><span class="sxs-lookup"><span data-stu-id="1931c-222">Total amount</span></span> |
| <span data-ttu-id="1931c-223">tipped</span><span class="sxs-lookup"><span data-stu-id="1931c-223">tipped</span></span> |<span data-ttu-id="1931c-224">Pourboire payé (0/1 pour non ou oui)</span><span class="sxs-lookup"><span data-stu-id="1931c-224">Tipped (0/1 for no or yes)</span></span> |
| <span data-ttu-id="1931c-225">tip_class</span><span class="sxs-lookup"><span data-stu-id="1931c-225">tip_class</span></span> |<span data-ttu-id="1931c-226">Classe de pourboire (0 : 0 $, 1 : 0-5 $ 2 : 6-10 $, 3 : 11 à 20 $, 4: 20 $ et +)</span><span class="sxs-lookup"><span data-stu-id="1931c-226">Tip class (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span></span> |

## <a name="execute-code-from-a-jupyter-notebook-on-the-spark-cluster"></a><span data-ttu-id="1931c-227">Exécuter le code à partir d’un notebook Jupyter sur le cluster Spark</span><span class="sxs-lookup"><span data-stu-id="1931c-227">Execute code from a Jupyter notebook on the Spark cluster</span></span>
<span data-ttu-id="1931c-228">Vous pouvez lancer le notebook Jupyter à partir du portail Azure.</span><span class="sxs-lookup"><span data-stu-id="1931c-228">You can launch the Jupyter Notebook from the Azure portal.</span></span> <span data-ttu-id="1931c-229">Recherchez votre cluster Spark sur votre tableau de bord, puis cliquez dessus pour accéder à la page de gestion de votre cluster.</span><span class="sxs-lookup"><span data-stu-id="1931c-229">Find your Spark cluster on your dashboard and click it to enter management page for your cluster.</span></span> <span data-ttu-id="1931c-230">Pour ouvrir le bloc-notes associé au cluster Spark, cliquez sur **Tableaux de bord du cluster** -> **loc-notes Jupyter** .</span><span class="sxs-lookup"><span data-stu-id="1931c-230">To open the notebook associated with the Spark cluster, click **Cluster Dashboards** -> **Jupyter Notebook** .</span></span>

![Tableaux de bord des clusters](./media/machine-learning-data-science-spark-overview/spark-jupyter-on-portal.png)

<span data-ttu-id="1931c-232">Vous pouvez également naviguer vers ***https://CLUSTERNAME.azurehdinsight.net/jupyter*** pour accéder aux Blocs-notes Jupyter.</span><span class="sxs-lookup"><span data-stu-id="1931c-232">You can also browse to ***https://CLUSTERNAME.azurehdinsight.net/jupyter*** to access the Jupyter Notebooks.</span></span> <span data-ttu-id="1931c-233">Remplacez la partie CLUSTERNAME de cette URL par le nom de votre propre cluster.</span><span class="sxs-lookup"><span data-stu-id="1931c-233">Replace the CLUSTERNAME part of this URL with the name of your own cluster.</span></span> <span data-ttu-id="1931c-234">Pour accéder aux blocs-notes, vous avez besoin du mot de passe de votre compte d’administrateur.</span><span class="sxs-lookup"><span data-stu-id="1931c-234">You need the password for your admin account to access the notebooks.</span></span>

![Parcourez Jupyter Notebooks](./media/machine-learning-data-science-spark-overview/spark-jupyter-notebook.png)

<span data-ttu-id="1931c-236">Sélectionnez PySpark pour afficher un répertoire contenant quelques exemples de blocs-notes prédéfinis qui utilisent l’API PySpark. Les blocs-notes qui contiennent les exemples de code pour cet ensemble de rubriques Spark sont disponibles sur [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span><span class="sxs-lookup"><span data-stu-id="1931c-236">Select PySpark to see a directory that contains a few examples of pre-packaged notebooks that use the PySpark API.The notebooks that contain the code samples for this suite of Spark topic are available at [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span></span>

<span data-ttu-id="1931c-237">Vous pouvez télécharger les notebooks directement de [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) sur le serveur de notebooks Jupyter de votre cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="1931c-237">You can upload the notebooks directly from [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) to the Jupyter notebook server on your Spark cluster.</span></span> <span data-ttu-id="1931c-238">Dans la page d’accueil de votre Jupyter, cliquez sur le bouton **Télécharger** dans la partie droite de l’écran.</span><span class="sxs-lookup"><span data-stu-id="1931c-238">On the home page of your Jupyter, click the **Upload** button on the right part of the screen.</span></span> <span data-ttu-id="1931c-239">Cette action ouvre un explorateur de fichiers.</span><span class="sxs-lookup"><span data-stu-id="1931c-239">It opens a file explorer.</span></span> <span data-ttu-id="1931c-240">Vous pouvez coller l’URL GitHub (contenu brut) du notebook et cliquer sur **Ouvrir**.</span><span class="sxs-lookup"><span data-stu-id="1931c-240">Here you can paste the GitHub (raw content) URL of the Notebook and click **Open**.</span></span> 

<span data-ttu-id="1931c-241">Le nom de fichier réapparaît dans votre liste de fichiers Jupyter avec un bouton **Charger**.</span><span class="sxs-lookup"><span data-stu-id="1931c-241">You see the file name on your Jupyter file list with an **Upload** button again.</span></span> <span data-ttu-id="1931c-242">Cliquez sur ce bouton **Télécharger** .</span><span class="sxs-lookup"><span data-stu-id="1931c-242">Click this **Upload** button.</span></span> <span data-ttu-id="1931c-243">Le bloc-notes a été importé.</span><span class="sxs-lookup"><span data-stu-id="1931c-243">Now you have imported the notebook.</span></span> <span data-ttu-id="1931c-244">Répétez ces étapes pour télécharger les autres blocs-notes de cette procédure.</span><span class="sxs-lookup"><span data-stu-id="1931c-244">Repeat these steps to upload the other notebooks from this walkthrough.</span></span>

> [!TIP]
> <span data-ttu-id="1931c-245">Vous pouvez cliquer sur les liens de votre navigateur, puis sélectionner **Copier le lien** pour obtenir l’URL du contenu brut de github.</span><span class="sxs-lookup"><span data-stu-id="1931c-245">You can right-click the links on your browser and select **Copy Link** to get the github raw content URL.</span></span> <span data-ttu-id="1931c-246">Vous pouvez coller celle-ci dans la boîte de dialogue Charger de l’Explorateur de fichiers de Jupyter.</span><span class="sxs-lookup"><span data-stu-id="1931c-246">You can paste this URL into the Jupyter Upload file explorer dialog box.</span></span>
> 
> 

<span data-ttu-id="1931c-247">Vous pouvez désormais :</span><span class="sxs-lookup"><span data-stu-id="1931c-247">Now you can:</span></span>

* <span data-ttu-id="1931c-248">Consultez le code en cliquant sur le bloc-notes.</span><span class="sxs-lookup"><span data-stu-id="1931c-248">See the code by clicking the notebook.</span></span>
* <span data-ttu-id="1931c-249">Exécutez chaque cellule en appuyant sur **MAJ-ENTRÉE**.</span><span class="sxs-lookup"><span data-stu-id="1931c-249">Execute each cell by pressing **SHIFT-ENTER**.</span></span>
* <span data-ttu-id="1931c-250">Exécutez le bloc-notes entier en cliquant sur **Cellule** -> **Exécuter**.</span><span class="sxs-lookup"><span data-stu-id="1931c-250">Run the entire notebook by clicking on **Cell** -> **Run**.</span></span>
* <span data-ttu-id="1931c-251">Utilisez la visualisation automatique des requêtes.</span><span class="sxs-lookup"><span data-stu-id="1931c-251">Use the automatic visualization of queries.</span></span>

> [!TIP]
> <span data-ttu-id="1931c-252">Le noyau Pyspark visualise automatiquement la sortie des requêtes SQL (HiveQL).</span><span class="sxs-lookup"><span data-stu-id="1931c-252">The PySpark kernel automatically visualizes the output of SQL (HiveQL) queries.</span></span> <span data-ttu-id="1931c-253">Vous pouvez sélectionner différents types de visualisations (tables, secteurs, lignes, zones ou barres) à l’aide des boutons de menu **Type** dans le notebook :</span><span class="sxs-lookup"><span data-stu-id="1931c-253">You are given the option to select among several different types of visualizations (Table, Pie, Line, Area, or Bar) by using the **Type** menu buttons in the notebook:</span></span>
> 
> 

![Courbe ROC de régression logistique pour une approche générique](./media/machine-learning-data-science-spark-overview/pyspark-jupyter-autovisualization.png)

## <a name="whats-next"></a><span data-ttu-id="1931c-255">Et ensuite ?</span><span class="sxs-lookup"><span data-stu-id="1931c-255">What's next?</span></span>
<span data-ttu-id="1931c-256">Maintenant que vous avez configuré un cluster HDInsight Spark et téléchargé les blocs-notes Jupyter, vous êtes prêt à appliquer les procédures correspondant aux trois blocs-notes PySpark.</span><span class="sxs-lookup"><span data-stu-id="1931c-256">Now that you are set up with an HDInsight Spark cluster and have uploaded the Jupyter notebooks, you are ready to work through the topics that correspond to the three PySpark notebooks.</span></span> <span data-ttu-id="1931c-257">Elles montrent comment explorer vos données, puis créer et utiliser des modèles.</span><span class="sxs-lookup"><span data-stu-id="1931c-257">They show how to explore your data and then how to create and consume models.</span></span> <span data-ttu-id="1931c-258">Le bloc-notes d’exploration et de modélisation avancées des données montre comment inclure une validation croisée, un balayage hyperparamétrique et une évaluation du modèle.</span><span class="sxs-lookup"><span data-stu-id="1931c-258">The advanced data exploration and modeling notebook shows how to include cross-validation, hyper-parameter sweeping, and model evaluation.</span></span> 

<span data-ttu-id="1931c-259">**Exploration et modélisation des données avec Spark :** explorez le jeu de données, puis créez, notez et à évaluez les modèles Machine Learning, en procédant de la manière décrite dans la rubrique [Créer des modèles de classification et de régression binaires pour des données avec la boîte à outils MLlib de Spark](machine-learning-data-science-spark-data-exploration-modeling.md) .</span><span class="sxs-lookup"><span data-stu-id="1931c-259">**Data Exploration and modeling with Spark:** Explore the dataset and create, score, and evaluate the machine learning models by working through the [Create binary classification and regression models for data with the Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) topic.</span></span>

<span data-ttu-id="1931c-260">**Consommation de modèles :** pour apprendre à noter les modèles de classification et de régression créés dans cette rubrique, consultez [Noter et évaluer des modèles Machine Learning créés avec Spark](machine-learning-data-science-spark-model-consumption.md).</span><span class="sxs-lookup"><span data-stu-id="1931c-260">**Model consumption:** To learn how to score the classification and regression models created in this topic, see [Score and evaluate Spark-built machine learning models](machine-learning-data-science-spark-model-consumption.md).</span></span>

<span data-ttu-id="1931c-261">**Validation croisée et balayage hyperparamétrique**: consultez [Exploration et modélisation avancées des données avec Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) pour savoir comment effectuer la formation des modèles à l’aide de la validation croisée et du balayage hyperparamétrique</span><span class="sxs-lookup"><span data-stu-id="1931c-261">**Cross-validation and hyperparameter sweeping**: See [Advanced data exploration and modeling with Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) on how models can be trained using cross-validation and hyper-parameter sweeping</span></span>

