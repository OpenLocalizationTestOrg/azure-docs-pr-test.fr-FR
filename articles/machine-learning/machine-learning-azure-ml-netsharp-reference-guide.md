---
title: "aaaGuide toohello réseau neuronal réseaux langage de spécification | Documents Microsoft"
description: "Syntaxe de hello Net # neural networks langage de spécification, ainsi que des exemples de comment toocreate un réseau neuronal personnalisé modèle dans Microsoft Azure ML à l’aide de Net #"
services: machine-learning
documentationcenter: 
author: jeannt
manager: jhubbard
editor: cgronlun
ms.assetid: cfd1454b-47df-4745-b064-ce5f9b3be303
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/31/2017
ms.author: jeannt
ms.openlocfilehash: 3493247ecc39ca3a1382510ad520d7017159ff62
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 10/06/2017
---
# <a name="guide-toonet-neural-network-specification-language-for-azure-machine-learning"></a><span data-ttu-id="6000c-103">Guide du langage de spécification de réseau neuronal tooNet # pour Azure Machine Learning</span><span class="sxs-lookup"><span data-stu-id="6000c-103">Guide tooNet# neural network specification language for Azure Machine Learning</span></span>
## <a name="overview"></a><span data-ttu-id="6000c-104">Vue d'ensemble</span><span class="sxs-lookup"><span data-stu-id="6000c-104">Overview</span></span>
<span data-ttu-id="6000c-105">NET # est un langage développé par Microsoft, qui est utilisé toodefine d’architectures réseau neuronal.</span><span class="sxs-lookup"><span data-stu-id="6000c-105">Net# is a language developed by Microsoft that is used toodefine neural network architectures.</span></span> <span data-ttu-id="6000c-106">Vous pouvez utiliser Net# dans des modules de réseau neuronal dans Microsoft Azure Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="6000c-106">You can use Net# in neural network modules in Microsoft Azure Machine Learning.</span></span>

<!-- This function doesn't currentlyappear in hello MicrosoftML documentation. If it is added in a future update, we can uncomment this text.

, or in hello `rxNeuralNetwork()` function in [MicrosoftML](https://msdn.microsoft.com/microsoft-r/microsoftml/microsoftml). 

-->

<span data-ttu-id="6000c-107">Dans cet article, vous allez apprendre les concepts de base nécessaires toodevelop un réseau neuronal personnalisé :</span><span class="sxs-lookup"><span data-stu-id="6000c-107">In this article, you will learn basic concepts needed toodevelop a custom neural network:</span></span> 

* <span data-ttu-id="6000c-108">Configuration requise du réseau neuronal et comment toodefine hello composants principaux</span><span class="sxs-lookup"><span data-stu-id="6000c-108">Neural network requirements and how toodefine hello primary components</span></span>
* <span data-ttu-id="6000c-109">syntaxe de Hello et les mots clés de langage de spécification de Net # de hello</span><span class="sxs-lookup"><span data-stu-id="6000c-109">hello syntax and keywords of hello Net# specification language</span></span>
* <span data-ttu-id="6000c-110">Exemples de réseaux neuronaux personnalisés créés avec Net#</span><span class="sxs-lookup"><span data-stu-id="6000c-110">Examples of custom neural networks created using Net#</span></span> 

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

## <a name="neural-network-basics"></a><span data-ttu-id="6000c-111">Principes fondamentaux des réseaux neuronaux</span><span class="sxs-lookup"><span data-stu-id="6000c-111">Neural network basics</span></span>
<span data-ttu-id="6000c-112">Consistant en une structure de réseau neuronal ***nœuds*** qui sont organisés en ***couches***et pondérées ***connexions*** (ou ***bords***) entre nœuds Hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-112">A neural network structure consists of ***nodes*** that are organized in ***layers***, and weighted ***connections*** (or ***edges***) between hello nodes.</span></span> <span data-ttu-id="6000c-113">connexions de Hello sont directionnelles, et chaque connexion possède un ***source*** nœud et un ***destination*** nœud.</span><span class="sxs-lookup"><span data-stu-id="6000c-113">hello connections are directional, and each connection has a ***source*** node and a ***destination*** node.</span></span>  

<span data-ttu-id="6000c-114">Chaque ***couche apte à l’apprentissage*** (couche masquée ou de sortie) présente un ou plusieurs ***faisceaux de connexions***.</span><span class="sxs-lookup"><span data-stu-id="6000c-114">Each ***trainable layer*** (a hidden or an output layer) has one or more ***connection bundles***.</span></span> <span data-ttu-id="6000c-115">Un regroupement de connexion se compose d’une couche source et une spécification de connexions hello de cette couche source.</span><span class="sxs-lookup"><span data-stu-id="6000c-115">A connection bundle consists of a source layer and a specification of hello connections from that source layer.</span></span> <span data-ttu-id="6000c-116">Toutes les connexions hello dans un partage de lot donné hello même ***couche source*** et même hello ***calque de destination***.</span><span class="sxs-lookup"><span data-stu-id="6000c-116">All hello connections in a given bundle share hello same ***source layer*** and hello same ***destination layer***.</span></span> <span data-ttu-id="6000c-117">Dans Net #, un regroupement de connexion est considéré comme couche de destination du regroupement appartenant toohello.</span><span class="sxs-lookup"><span data-stu-id="6000c-117">In Net#, a connection bundle is considered as belonging toohello bundle's destination layer.</span></span>  

<span data-ttu-id="6000c-118">NET # prend en charge différents types de paquets de connexion, ce qui vous permet de personnaliser la façon hello entrées sont mappés toohidden couches et fournit en sortie toohello mappé.</span><span class="sxs-lookup"><span data-stu-id="6000c-118">Net# supports various kinds of connection bundles, which lets you customize hello way inputs are mapped toohidden layers and mapped toohello outputs.</span></span>   

<span data-ttu-id="6000c-119">par défaut de Hello ou de groupe standard est un **offre complète**, dans chaque nœud qui Bonjour couche source est le nœud connecté tooevery hello calque de destination.</span><span class="sxs-lookup"><span data-stu-id="6000c-119">hello default or standard bundle is a **full bundle**, in which each node in hello source layer is connected tooevery node in hello destination layer.</span></span>  

<span data-ttu-id="6000c-120">En outre, Net # prend en charge hello suivant quatre types de paquets de connexion avancées :</span><span class="sxs-lookup"><span data-stu-id="6000c-120">Additionally, Net# supports hello following four kinds of advanced connection bundles:</span></span>  

* <span data-ttu-id="6000c-121">**Faisceaux filtrés**.</span><span class="sxs-lookup"><span data-stu-id="6000c-121">**Filtered bundles**.</span></span> <span data-ttu-id="6000c-122">utilisateur de la Hello peut définir un prédicat à l’aide des emplacements de nœud de couche source hello et nœud de couche hello destination hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-122">hello user can define a predicate by using hello locations of hello source layer node and hello destination layer node.</span></span> <span data-ttu-id="6000c-123">Nœuds sont connectés à chaque fois que le prédicat de hello a la valeur True.</span><span class="sxs-lookup"><span data-stu-id="6000c-123">Nodes are connected whenever hello predicate is True.</span></span>
* <span data-ttu-id="6000c-124">**Faisceaux convolutionnels**.</span><span class="sxs-lookup"><span data-stu-id="6000c-124">**Convolutional bundles**.</span></span> <span data-ttu-id="6000c-125">utilisateur de Hello peut définir des petits cercles de nœuds dans la couche de source de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-125">hello user can define small neighborhoods of nodes in hello source layer.</span></span> <span data-ttu-id="6000c-126">Chaque nœud de couche de destination hello est voisinage tooone connecté de nœuds de couche de source de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-126">Each node in hello destination layer is connected tooone neighborhood of nodes in hello source layer.</span></span>
* <span data-ttu-id="6000c-127">**Faisceaux de regroupement** et **faisceaux de normalisation de réponse**.</span><span class="sxs-lookup"><span data-stu-id="6000c-127">**Pooling bundles** and **Response normalization bundles**.</span></span> <span data-ttu-id="6000c-128">Il s’agit des regroupements tooconvolutional similaire qui Bonjour utilisateur définit des petits cercles de nœuds de couche de source de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-128">These are similar tooconvolutional bundles in that hello user defines small neighborhoods of nodes in hello source layer.</span></span> <span data-ttu-id="6000c-129">Hello différence est que les poids hello des bords hello dans ces offres ne sont pas capable d’apprentissage.</span><span class="sxs-lookup"><span data-stu-id="6000c-129">hello difference is that hello weights of hello edges in these bundles are not trainable.</span></span> <span data-ttu-id="6000c-130">Au lieu de cela, une fonction prédéfinie est appliquée toohello nœud de source de valeurs de la valeur de nœud de destination de hello toodetermine.</span><span class="sxs-lookup"><span data-stu-id="6000c-130">Instead, a predefined function is applied toohello source node values toodetermine hello destination node value.</span></span>  

<span data-ttu-id="6000c-131">À l’aide de Net # structure de hello toodefine d’un réseau neuronal rend possible toodefine des structures complexes telles que les réseaux neuronaux ou des structures de dimensions arbitraires, qui sont connues learning tooimprove sur des données telles que l’image, audio ou vidéo.</span><span class="sxs-lookup"><span data-stu-id="6000c-131">Using Net# toodefine hello structure of a neural network makes it possible toodefine complex structures such as deep neural networks or convolutions of arbitrary dimensions, which are known tooimprove learning on data such as image, audio, or video.</span></span>  

## <a name="supported-customizations"></a><span data-ttu-id="6000c-132">Personnalisations prises en charge</span><span class="sxs-lookup"><span data-stu-id="6000c-132">Supported customizations</span></span>
<span data-ttu-id="6000c-133">architecture de Hello des modèles de réseau neuronal que vous créez dans Azure Machine Learning peut être largement personnalisé à l’aide de Net #.</span><span class="sxs-lookup"><span data-stu-id="6000c-133">hello architecture of neural network models that you create in Azure Machine Learning can be extensively customized by using Net#.</span></span> <span data-ttu-id="6000c-134">Vous pouvez :</span><span class="sxs-lookup"><span data-stu-id="6000c-134">You can:</span></span>  

* <span data-ttu-id="6000c-135">Créer des couches masquées et le nombre de nœuds hello de contrôle dans chaque couche.</span><span class="sxs-lookup"><span data-stu-id="6000c-135">Create hidden layers and control hello number of nodes in each layer.</span></span>
* <span data-ttu-id="6000c-136">Spécifiez comment les couches sont toobe connecté tooeach autres.</span><span class="sxs-lookup"><span data-stu-id="6000c-136">Specify how layers are toobe connected tooeach other.</span></span>
* <span data-ttu-id="6000c-137">définir des structures de connectivité spéciales, telles que des convolutions et des faisceaux à poids partagé ;</span><span class="sxs-lookup"><span data-stu-id="6000c-137">Define special connectivity structures, such as convolutions and weight sharing bundles.</span></span>
* <span data-ttu-id="6000c-138">spécifier différentes fonctions d'activation.</span><span class="sxs-lookup"><span data-stu-id="6000c-138">Specify different activation functions.</span></span>  

<span data-ttu-id="6000c-139">Pour plus d’informations de syntaxe du langage de spécification hello, consultez [spécification de la Structure](#Structure-specifications).</span><span class="sxs-lookup"><span data-stu-id="6000c-139">For details of hello specification language syntax, see [Structure Specification](#Structure-specifications).</span></span>  

<span data-ttu-id="6000c-140">Pour obtenir des exemples de définition de réseaux neuronaux pour certaines tâches, à partir de toocomplex simplex, d’apprentissage courantes, consultez [exemples](#Examples-of-Net#-usage).</span><span class="sxs-lookup"><span data-stu-id="6000c-140">For examples of defining neural networks for some common machine learning tasks, from simplex toocomplex, see [Examples](#Examples-of-Net#-usage).</span></span>  

## <a name="general-requirements"></a><span data-ttu-id="6000c-141">Conditions générales</span><span class="sxs-lookup"><span data-stu-id="6000c-141">General requirements</span></span>
* <span data-ttu-id="6000c-142">Il doit y avoir exactement une couche de sortie, au moins une couche d’entrée et aucune ou plusieurs couches masquées.</span><span class="sxs-lookup"><span data-stu-id="6000c-142">There must be exactly one output layer, at least one input layer, and zero or more hidden layers.</span></span> 
* <span data-ttu-id="6000c-143">Chaque couche a un nombre fixe de nœuds, organisés de façon conceptuelle dans un tableau rectangulaire aux dimensions arbitraires.</span><span class="sxs-lookup"><span data-stu-id="6000c-143">Each layer has a fixed number of nodes, conceptually arranged in a rectangular array of arbitrary dimensions.</span></span> 
* <span data-ttu-id="6000c-144">Les couches d’entrée n’ont aucun paramètre formé associé et point hello où les données d’instance entre le réseau de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-144">Input layers have no associated trained parameters and represent hello point where instance data enters hello network.</span></span> 
* <span data-ttu-id="6000c-145">Paramètres formés, appelés poids et des écarts ont associés à des couches capable d’apprentissage (hello couches masquées et de sortie).</span><span class="sxs-lookup"><span data-stu-id="6000c-145">Trainable layers (hello hidden and output layers) have associated trained parameters, known as weights and biases.</span></span> 
* <span data-ttu-id="6000c-146">les nœuds source et de destination Hello doivent être dans des couches distinctes.</span><span class="sxs-lookup"><span data-stu-id="6000c-146">hello source and destination nodes must be in separate layers.</span></span> 
* <span data-ttu-id="6000c-147">Les connexions doivent être acycliques ; en d’autres termes, il ne peut pas être une chaîne de connexions de début du nœud source initial de toohello précédent.</span><span class="sxs-lookup"><span data-stu-id="6000c-147">Connections must be acyclic; in other words, there cannot be a chain of connections leading back toohello initial source node.</span></span>
* <span data-ttu-id="6000c-148">couche de sortie Hello ne peut pas être une source d’un groupe de connexion.</span><span class="sxs-lookup"><span data-stu-id="6000c-148">hello output layer cannot be a source layer of a connection bundle.</span></span>  

## <a name="structure-specifications"></a><span data-ttu-id="6000c-149">Spécifications de structures</span><span class="sxs-lookup"><span data-stu-id="6000c-149">Structure specifications</span></span>
<span data-ttu-id="6000c-150">Une spécification de structure de réseau neuronal est composée de trois sections : hello **déclaration de constante**, hello **déclaration de couche**, hello **déclaration de connexion**.</span><span class="sxs-lookup"><span data-stu-id="6000c-150">A neural network structure specification is composed of three sections: hello **constant declaration**, hello **layer declaration**, hello **connection declaration**.</span></span> <span data-ttu-id="6000c-151">Il existe également une section de **déclaration de partage**, qui est facultative.</span><span class="sxs-lookup"><span data-stu-id="6000c-151">There is also an optional **share declaration** section.</span></span> <span data-ttu-id="6000c-152">les sections Hello peuvent être spécifiées dans n’importe quel ordre.</span><span class="sxs-lookup"><span data-stu-id="6000c-152">hello sections can be specified in any order.</span></span>  

## <a name="constant-declaration"></a><span data-ttu-id="6000c-153">Déclaration de constante</span><span class="sxs-lookup"><span data-stu-id="6000c-153">Constant declaration</span></span>
<span data-ttu-id="6000c-154">Ce type de déclaration est facultatif.</span><span class="sxs-lookup"><span data-stu-id="6000c-154">A constant declaration is optional.</span></span> <span data-ttu-id="6000c-155">Il fournit un moyen toodefine utilisées ailleurs dans la définition du réseau neuronal hello des valeurs.</span><span class="sxs-lookup"><span data-stu-id="6000c-155">It provides a means toodefine values used elsewhere in hello neural network definition.</span></span> <span data-ttu-id="6000c-156">instruction de déclaration Hello se compose d’un identificateur suivi par un signe égal et une expression de valeur.</span><span class="sxs-lookup"><span data-stu-id="6000c-156">hello declaration statement consists of an identifier followed by an equal sign and a value expression.</span></span>   

<span data-ttu-id="6000c-157">Par exemple, après l’instruction de hello définit une constante **x**:</span><span class="sxs-lookup"><span data-stu-id="6000c-157">For example, hello following statement defines a constant **x**:</span></span>  

    Const X = 28;  

<span data-ttu-id="6000c-158">toodefine deux ou plusieurs constantes simultanément, placez les valeurs et les noms d’identificateur hello entre accolades et séparés par des points-virgules.</span><span class="sxs-lookup"><span data-stu-id="6000c-158">toodefine two or more constants simultaneously, enclose hello identifier names and values in braces, and separate them by using semicolons.</span></span> <span data-ttu-id="6000c-159">Par exemple :</span><span class="sxs-lookup"><span data-stu-id="6000c-159">For example:</span></span>  

    Const { X = 28; Y = 4; }  

<span data-ttu-id="6000c-160">côté droit de Hello de chaque expression d’assignation peut être un entier, un nombre réel, une valeur booléenne (True ou False) ou une expression mathématique.</span><span class="sxs-lookup"><span data-stu-id="6000c-160">hello right-hand side of each assignment expression can be an integer, a real number, a Boolean value (True or False), or a mathematical expression.</span></span> <span data-ttu-id="6000c-161">Par exemple :</span><span class="sxs-lookup"><span data-stu-id="6000c-161">For example:</span></span>  

    Const { X = 17 * 2; Y = true; }  

## <a name="layer-declaration"></a><span data-ttu-id="6000c-162">Déclaration de couche</span><span class="sxs-lookup"><span data-stu-id="6000c-162">Layer declaration</span></span>
<span data-ttu-id="6000c-163">déclaration de couche Hello est obligatoire.</span><span class="sxs-lookup"><span data-stu-id="6000c-163">hello layer declaration is required.</span></span> <span data-ttu-id="6000c-164">Il définit la taille de hello et de la source de la couche de hello, y compris ses attributs et groupes de connexion.</span><span class="sxs-lookup"><span data-stu-id="6000c-164">It defines hello size and source of hello layer, including its connection bundles and attributes.</span></span> <span data-ttu-id="6000c-165">Hello commence d’instruction de déclaration par nom hello de couche hello (entrée, masqués ou de sortie), suivis de dimensions hello de couche de hello (il s’agit d’un tuple d’entiers positifs).</span><span class="sxs-lookup"><span data-stu-id="6000c-165">hello declaration statement starts with hello name of hello layer (input, hidden, or output), followed by hello dimensions of hello layer (a tuple of positive integers).</span></span> <span data-ttu-id="6000c-166">Par exemple :</span><span class="sxs-lookup"><span data-stu-id="6000c-166">For example:</span></span>  

    input Data auto;
    hidden Hidden[5,20] from Data all;
    output Result[2] from Hidden all;  

* <span data-ttu-id="6000c-167">Hello de dimensions de hello est nombre hello de nœuds de couche de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-167">hello product of hello dimensions is hello number of nodes in hello layer.</span></span> <span data-ttu-id="6000c-168">Dans cet exemple, il existe deux dimensions [5,20], ce qui signifie qu’il existe 100 nœuds dans la couche de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-168">In this example, there are two dimensions [5,20], which means there are  100 nodes in hello layer.</span></span>
* <span data-ttu-id="6000c-169">les couches Hello peuvent être déclarés dans n’importe quel ordre, à une exception près : Si plusieurs couches d’entrée est défini, hello dans lequel ils sont déclarés doivent suivre hello ordre de fonctionnalités dans les données d’entrée hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-169">hello layers can be declared in any order, with one exception: If more than one input layer is defined, hello order in which they are declared must match hello order of features in hello input data.</span></span>  

<span data-ttu-id="6000c-170">toospecify hello le nombre de nœuds dans une couche être déterminé automatiquement, utilisez hello **automatique** (mot clé).</span><span class="sxs-lookup"><span data-stu-id="6000c-170">toospecify that hello number of nodes in a layer be determined automatically, use hello **auto** keyword.</span></span> <span data-ttu-id="6000c-171">Hello **automatique** (mot clé) a des effets différents, selon la couche de hello :</span><span class="sxs-lookup"><span data-stu-id="6000c-171">hello **auto** keyword has different effects, depending on hello layer:</span></span>  

* <span data-ttu-id="6000c-172">Dans une déclaration de la couche d’entrée, nombre de hello de nœuds est nombre hello de fonctionnalités dans les données d’entrée hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-172">In an input layer declaration, hello number of nodes is hello number of features in hello input data.</span></span>
* <span data-ttu-id="6000c-173">Dans une déclaration de la couche masquée, nombre hello de nœuds est nombre hello spécifié par la valeur du paramètre hello pour **nombre de nœuds masqués**.</span><span class="sxs-lookup"><span data-stu-id="6000c-173">In a hidden layer declaration, hello number of nodes is hello number that is specified by hello parameter value for **Number of hidden nodes**.</span></span> 
* <span data-ttu-id="6000c-174">Dans une déclaration de couche de sortie, nombre hello de nœuds est 2 pour la classification de deux classes, 1 pour la régression et le numéro de toohello égale de nœuds de sortie pour la classification multiclasse.</span><span class="sxs-lookup"><span data-stu-id="6000c-174">In an output layer declaration, hello number of nodes is 2 for two-class classification, 1 for regression, and equal toohello number of output nodes for multiclass classification.</span></span>   

<span data-ttu-id="6000c-175">Par exemple, hello définition de réseau suivant autorise hello taille de toutes les couches toobe déterminé automatiquement :</span><span class="sxs-lookup"><span data-stu-id="6000c-175">For example, hello following network definition allows hello size of all layers toobe automatically determined:</span></span>  

    input Data auto;
    hidden Hidden auto from Data all;
    output Result auto from Hidden all;  


<span data-ttu-id="6000c-176">Une déclaration de la couche d’une couche capable d’apprentissage (hello couches masquées ou de sortie) peut éventuellement inclure hello sortie (fonction) (également appelée une fonction d’activation), qui utilise par défaut trop**sigmoïde** pour les modèles de classification et **linéaire** pour les modèles de régression.</span><span class="sxs-lookup"><span data-stu-id="6000c-176">A layer declaration for a trainable layer (hello hidden or output layers) can optionally include hello output function (also called an activation function), which defaults too**sigmoid** for classification models, and **linear** for regression models.</span></span> <span data-ttu-id="6000c-177">(Même si vous utilisez la valeur par défaut de hello, vous pouvez déclarer explicitement fonction d’activation de hello, si vous le souhaitez pour plus de clarté.)</span><span class="sxs-lookup"><span data-stu-id="6000c-177">(Even if you use hello default, you can explicitly state hello activation function, if desired for clarity.)</span></span>

<span data-ttu-id="6000c-178">Hello des fonctions de sortie suivantes sont prises en charge :</span><span class="sxs-lookup"><span data-stu-id="6000c-178">hello following output functions are supported:</span></span>  

* <span data-ttu-id="6000c-179">sigmoid</span><span class="sxs-lookup"><span data-stu-id="6000c-179">sigmoid</span></span>
* <span data-ttu-id="6000c-180">linear</span><span class="sxs-lookup"><span data-stu-id="6000c-180">linear</span></span>
* <span data-ttu-id="6000c-181">softmax</span><span class="sxs-lookup"><span data-stu-id="6000c-181">softmax</span></span>
* <span data-ttu-id="6000c-182">rlinear</span><span class="sxs-lookup"><span data-stu-id="6000c-182">rlinear</span></span>
* <span data-ttu-id="6000c-183">square</span><span class="sxs-lookup"><span data-stu-id="6000c-183">square</span></span>
* <span data-ttu-id="6000c-184">sqrt</span><span class="sxs-lookup"><span data-stu-id="6000c-184">sqrt</span></span>
* <span data-ttu-id="6000c-185">srlinear</span><span class="sxs-lookup"><span data-stu-id="6000c-185">srlinear</span></span>
* <span data-ttu-id="6000c-186">abs</span><span class="sxs-lookup"><span data-stu-id="6000c-186">abs</span></span>
* <span data-ttu-id="6000c-187">tanh</span><span class="sxs-lookup"><span data-stu-id="6000c-187">tanh</span></span> 
* <span data-ttu-id="6000c-188">brlinear</span><span class="sxs-lookup"><span data-stu-id="6000c-188">brlinear</span></span>  

<span data-ttu-id="6000c-189">Par exemple, hello suit déclaration utilise hello **softmax** fonction :</span><span class="sxs-lookup"><span data-stu-id="6000c-189">For example, hello following declaration uses hello **softmax** function:</span></span>  

    output Result [100] softmax from Hidden all;  

## <a name="connection-declaration"></a><span data-ttu-id="6000c-190">Déclaration de connexion</span><span class="sxs-lookup"><span data-stu-id="6000c-190">Connection declaration</span></span>
<span data-ttu-id="6000c-191">Immédiatement après la définition de couche capable d’apprentissage de hello, vous devez déclarer les connexions entre les couches hello que vous avez défini.</span><span class="sxs-lookup"><span data-stu-id="6000c-191">Immediately after defining hello trainable layer, you must declare connections among hello layers you have defined.</span></span> <span data-ttu-id="6000c-192">déclaration de regroupement de connexion Hello commence par le mot clé de hello **de**, suivi par nom hello de type de couche et hello de source de toocreate de regroupement de connexion du regroupement hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-192">hello connection bundle declaration starts with hello keyword **from**, followed by hello name of hello bundle's source layer and hello kind of connection bundle toocreate.</span></span>   

<span data-ttu-id="6000c-193">À ce jour, cinq types de faisceau de connexions sont pris en charge :</span><span class="sxs-lookup"><span data-stu-id="6000c-193">Currently, five kinds of connection bundles are supported:</span></span>  

* <span data-ttu-id="6000c-194">**Complète** lots, indiqués par le mot clé de hello **toutes les**</span><span class="sxs-lookup"><span data-stu-id="6000c-194">**Full** bundles, indicated by hello keyword **all**</span></span>
* <span data-ttu-id="6000c-195">**Filtré** lots, indiqués par le mot clé de hello **où**, suivi d’une expression de prédicat</span><span class="sxs-lookup"><span data-stu-id="6000c-195">**Filtered** bundles, indicated by hello keyword **where**, followed by a predicate expression</span></span>
* <span data-ttu-id="6000c-196">**À convolution** lots, indiqués par le mot clé de hello **convolve**, suivi par les attributs de convolution hello</span><span class="sxs-lookup"><span data-stu-id="6000c-196">**Convolutional** bundles, indicated by hello keyword **convolve**, followed by hello convolution attributes</span></span>
* <span data-ttu-id="6000c-197">**Le regroupement de** lots, indiquées par mots clés de hello **max pool** ou **signifie pool**</span><span class="sxs-lookup"><span data-stu-id="6000c-197">**Pooling** bundles, indicated by hello keywords **max pool** or **mean pool**</span></span>
* <span data-ttu-id="6000c-198">**Normalisation de la réponse** lots, indiqués par le mot clé de hello **normales de réponse**</span><span class="sxs-lookup"><span data-stu-id="6000c-198">**Response normalization** bundles, indicated by hello keyword **response norm**</span></span>      

## <a name="full-bundles"></a><span data-ttu-id="6000c-199">Faisceaux complets</span><span class="sxs-lookup"><span data-stu-id="6000c-199">Full bundles</span></span>
<span data-ttu-id="6000c-200">Un regroupement de connexion complète inclut une connexion à partir de chaque nœud dans le nœud de tooeach hello source couche hello calque de destination.</span><span class="sxs-lookup"><span data-stu-id="6000c-200">A full connection bundle includes a connection from each node in hello source layer tooeach node in hello destination layer.</span></span> <span data-ttu-id="6000c-201">Il s’agit de type de connexion réseau hello par défaut.</span><span class="sxs-lookup"><span data-stu-id="6000c-201">This is hello default network connection type.</span></span>  

## <a name="filtered-bundles"></a><span data-ttu-id="6000c-202">Faisceaux filtrés</span><span class="sxs-lookup"><span data-stu-id="6000c-202">Filtered bundles</span></span>
<span data-ttu-id="6000c-203">Une spécification de faisceau de connexion filtré inclut un prédicat, dont la syntaxe est assez similaire à celle d'une expression lambda C#.</span><span class="sxs-lookup"><span data-stu-id="6000c-203">A filtered connection bundle specification includes a predicate, expressed syntactically, much like a C# lambda expression.</span></span> <span data-ttu-id="6000c-204">Hello exemple suivant définit deux groupes filtrées :</span><span class="sxs-lookup"><span data-stu-id="6000c-204">hello following example defines two filtered bundles:</span></span>  

    input Pixels [10, 20];
    hidden ByRow[10, 12] from Pixels where (s,d) => s[0] == d[0];
    hidden ByCol[5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;  

* <span data-ttu-id="6000c-205">Dans le prédicat hello pour *ByRow*, **s** est un paramètre représentant un index dans un tableau rectangulaire de hello des nœuds de la couche d’entrée de hello, *Pixels*, et **d**  est un paramètre représentant un index dans le tableau hello des nœuds de couche masquée de hello, *ByRow*.</span><span class="sxs-lookup"><span data-stu-id="6000c-205">In hello predicate for *ByRow*, **s** is a parameter representing an index into hello rectangular array of nodes of hello input layer, *Pixels*, and **d** is a parameter representing an index into hello array of nodes of hello hidden layer, *ByRow*.</span></span> <span data-ttu-id="6000c-206">Hello type des deux **s** et **d** est un tuple d’entiers de longueur deux.</span><span class="sxs-lookup"><span data-stu-id="6000c-206">hello type of both **s** and **d** is a tuple of integers of length two.</span></span> <span data-ttu-id="6000c-207">D’un point de vue conceptuel, **s** couvre toutes les paires d’entiers avec *0 <= s[0] < 10* et *0 <= s[1] < 20*, tandis que **d** couvre toutes les paires d’entiers avec *0 <= d[0] < 10* et *0 <= d[1] < 12*.</span><span class="sxs-lookup"><span data-stu-id="6000c-207">Conceptually, **s** ranges over all pairs of integers with *0 <= s[0] < 10* and *0 <= s[1] < 20*, and **d** ranges over all pairs of integers, with *0 <= d[0] < 10* and *0 <= d[1] < 12*.</span></span> 
* <span data-ttu-id="6000c-208">Sur le côté droit de hello d’expression de prédicat hello, il existe une condition.</span><span class="sxs-lookup"><span data-stu-id="6000c-208">On hello right-hand side of hello predicate expression, there is a condition.</span></span> <span data-ttu-id="6000c-209">Dans cet exemple, pour chaque valeur de **s** et **d** telles que hello condition est True, il est un bord à partir du nœud de destination couche toohello hello source couche nœud.</span><span class="sxs-lookup"><span data-stu-id="6000c-209">In this example, for every value of **s** and **d** such that hello condition is True, there is an edge from hello source layer node toohello destination layer node.</span></span> <span data-ttu-id="6000c-210">Par conséquent, cette expression de filtre indique cette offre groupée hello inclut une connexion à partir du nœud hello défini par **s** nœud toohello défini par **d** dans tous les cas où s [0] est égale alimentaire [0].</span><span class="sxs-lookup"><span data-stu-id="6000c-210">Thus, this filter expression indicates that hello bundle includes a connection from hello node defined by **s** toohello node defined by **d** in all cases where s[0] is equal tood[0].</span></span>  

<span data-ttu-id="6000c-211">Vous pouvez également spécifier un ensemble de poids pour un faisceau filtré.</span><span class="sxs-lookup"><span data-stu-id="6000c-211">Optionally, you can specify a set of weights for a filtered bundle.</span></span> <span data-ttu-id="6000c-212">Hello valeur hello **poids** l’attribut doit être un tuple de valeurs à virgule flottante dont la longueur correspond au nombre de hello de connexions définis par l’offre groupée de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-212">hello value for hello **Weights** attribute must be a tuple of floating point values with a length that matches hello number of connections defined by hello bundle.</span></span> <span data-ttu-id="6000c-213">Par défaut, les poids sont générés de façon aléatoire.</span><span class="sxs-lookup"><span data-stu-id="6000c-213">By default, weights are randomly generated.</span></span>  

<span data-ttu-id="6000c-214">Valeurs de pondération sont regroupés par index hello du nœud de destination.</span><span class="sxs-lookup"><span data-stu-id="6000c-214">Weight values are grouped by hello destination node index.</span></span> <span data-ttu-id="6000c-215">Autrement dit, si le premier nœud de destination hello est connecté a duré nœuds sources, hello tout d’abord *K* éléments Hello **poids** tuple sont les poids hello pour hello premier nœud de destination, dans l’ordre d’index source.</span><span class="sxs-lookup"><span data-stu-id="6000c-215">That is, if hello first destination node is connected tooK source nodes, hello first *K* elements of hello **Weights** tuple are hello weights for hello first destination node, in source index order.</span></span> <span data-ttu-id="6000c-216">Hello que va de même pour hello restant des nœuds de destination.</span><span class="sxs-lookup"><span data-stu-id="6000c-216">hello same applies for hello remaining destination nodes.</span></span>  

<span data-ttu-id="6000c-217">Il est possible de toospecify poids directement en tant que valeurs de constante.</span><span class="sxs-lookup"><span data-stu-id="6000c-217">It's possible toospecify weights directly as constant values.</span></span> <span data-ttu-id="6000c-218">Par exemple, si vous avez appris les poids hello précédemment, vous pouvez les spécifier en tant que constantes à l’aide de cette syntaxe :</span><span class="sxs-lookup"><span data-stu-id="6000c-218">For example, if you learned hello weights previously, you can specify them as constants using this syntax:</span></span>

    const Weights_1 = [0.0188045055, 0.130500451, ...]


## <a name="convolutional-bundles"></a><span data-ttu-id="6000c-219">Faisceaux convolutionnels</span><span class="sxs-lookup"><span data-stu-id="6000c-219">Convolutional bundles</span></span>
<span data-ttu-id="6000c-220">Lorsque les données d’apprentissage hello possèdent une structure homogène, les connexions à convolution sont couramment utilisés toolearn les fonctionnalités de haut niveau de données de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-220">When hello training data has a homogeneous structure, convolutional connections are commonly used toolearn high-level features of hello data.</span></span> <span data-ttu-id="6000c-221">Par exemple, pour les données images, audio ou vidéo, la dimensionnalité spatiale ou temporelle peut être assez uniforme.</span><span class="sxs-lookup"><span data-stu-id="6000c-221">For example, in image, audio, or video data, spatial or temporal dimensionality can be fairly uniform.</span></span>  

<span data-ttu-id="6000c-222">Les regroupements à convolution employant rectangulaire **noyaux** qui sont glissé des dimensions de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-222">Convolutional bundles employ rectangular **kernels** that are slid through hello dimensions.</span></span> <span data-ttu-id="6000c-223">Essentiellement, chaque noyau définit un ensemble de poids appliquées dans les cercles locales, tooas référencé **applications du noyau**.</span><span class="sxs-lookup"><span data-stu-id="6000c-223">Essentially, each kernel defines a set of weights applied in local neighborhoods, referred tooas **kernel applications**.</span></span> <span data-ttu-id="6000c-224">Chaque application de noyau correspond nœud tooa dans la couche de source de hello, qui est référencé tooas hello **nœud central**.</span><span class="sxs-lookup"><span data-stu-id="6000c-224">Each kernel application corresponds tooa node in hello source layer, which is referred tooas hello **central node**.</span></span> <span data-ttu-id="6000c-225">poids Hello d’un noyau sont partagés entre plusieurs connexions.</span><span class="sxs-lookup"><span data-stu-id="6000c-225">hello weights of a kernel are shared among many connections.</span></span> <span data-ttu-id="6000c-226">Dans un regroupement à convolution, chaque noyau est rectangulaire et toutes les applications du noyau sont hello même taille.</span><span class="sxs-lookup"><span data-stu-id="6000c-226">In a convolutional bundle, each kernel is rectangular and all kernel applications are hello same size.</span></span>  

<span data-ttu-id="6000c-227">Les regroupements à convolution prennent en charge hello suivant d’attributs :</span><span class="sxs-lookup"><span data-stu-id="6000c-227">Convolutional bundles support hello following attributes:</span></span>

<span data-ttu-id="6000c-228">**InputShape** définit la dimensionnalité hello de couche de source de hello pour les besoins de hello de ce groupe à convolution.</span><span class="sxs-lookup"><span data-stu-id="6000c-228">**InputShape** defines hello dimensionality of hello source layer for hello purposes of this convolutional bundle.</span></span> <span data-ttu-id="6000c-229">valeur de Hello doit être un tuple d’entiers positifs.</span><span class="sxs-lookup"><span data-stu-id="6000c-229">hello value must be a tuple of positive integers.</span></span> <span data-ttu-id="6000c-230">produit Hello d’entiers de hello doit être égal à nombre hello de nœuds de couche de source de hello, mais dans le cas contraire, il n’a pas besoin dimensionnalité de hello toomatch déclarée pour la couche de source de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-230">hello product of hello integers must equal hello number of nodes in hello source layer, but otherwise, it does not need toomatch hello dimensionality declared for hello source layer.</span></span> <span data-ttu-id="6000c-231">la longueur de ce tuple Hello devient hello **arité** valeur pour le regroupement à convolution de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-231">hello length of this tuple becomes hello **arity** value for hello convolutional bundle.</span></span> <span data-ttu-id="6000c-232">(Généralement une arité fait référence toohello nombre d’arguments ou les opérandes qu’une fonction peut prendre).</span><span class="sxs-lookup"><span data-stu-id="6000c-232">(Typically arity refers toohello number of arguments or operands that a function can take.)</span></span>  

<span data-ttu-id="6000c-233">forme de hello toodefine et les emplacements des noyaux de hello, utiliser les attributs de hello **KernelShape**, **Stride**, **remplissage**, **LowerPad**, et **UpperPad**:</span><span class="sxs-lookup"><span data-stu-id="6000c-233">toodefine hello shape and locations of hello kernels, use hello attributes **KernelShape**, **Stride**, **Padding**, **LowerPad**, and **UpperPad**:</span></span>   

* <span data-ttu-id="6000c-234">**KernelShape**: dimensionnalité de hello définit (obligatoire) de chaque noyau pour le regroupement à convolution de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-234">**KernelShape**: (required) Defines hello dimensionality of each kernel for hello convolutional bundle.</span></span> <span data-ttu-id="6000c-235">valeur de Hello doit être un tuple d’entiers positifs avec une longueur égale à arité hello du groupement de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-235">hello value must be a tuple of positive integers with a length that equals hello arity of hello bundle.</span></span> <span data-ttu-id="6000c-236">Chaque composant de ce tuple doit pas être supérieure à composant correspondant de hello de **InputShape**.</span><span class="sxs-lookup"><span data-stu-id="6000c-236">Each component of this tuple must be no greater than hello corresponding component of **InputShape**.</span></span> 
* <span data-ttu-id="6000c-237">**STRIDE**: (facultatif) définit hello glissante tailles d’étape de la convolution de hello (taille d’une seule étape pour chaque dimension), qui est la distance entre les nœuds de centrale hello hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-237">**Stride**: (optional) Defines hello sliding step sizes of hello convolution (one step size for each dimension), that is hello distance between hello central nodes.</span></span> <span data-ttu-id="6000c-238">valeur de Hello doit être un tuple d’entiers positifs avec une longueur arité hello du groupement de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-238">hello value must be a tuple of positive integers with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="6000c-239">Chaque composant de ce tuple doit pas être supérieure à composant correspondant de hello de **KernelShape**.</span><span class="sxs-lookup"><span data-stu-id="6000c-239">Each component of this tuple must be no greater than hello corresponding component of **KernelShape**.</span></span> <span data-ttu-id="6000c-240">valeur par défaut de Hello est un tuple avec tous les tooone égale de composants.</span><span class="sxs-lookup"><span data-stu-id="6000c-240">hello default value is a tuple with all components equal tooone.</span></span> 
* <span data-ttu-id="6000c-241">**Partage**: (facultatif) définit hello partage de la pondération pour chaque dimension de la convolution de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-241">**Sharing**: (optional) Defines hello weight sharing for each dimension of hello convolution.</span></span> <span data-ttu-id="6000c-242">valeur de Hello peut être une valeur booléenne unique ou un tuple de valeurs booléennes avec une longueur arité hello du groupement de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-242">hello value can be a single Boolean value or a tuple of Boolean values with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="6000c-243">Une valeur booléenne est étendue toobe un tuple de longueur correcte de hello avec tous les composants toohello égale de valeur spécifiée.</span><span class="sxs-lookup"><span data-stu-id="6000c-243">A single Boolean value is extended toobe a tuple of hello correct length with all components equal toohello specified value.</span></span> <span data-ttu-id="6000c-244">valeur par défaut de Hello est un tuple qui se compose de toutes les valeurs True.</span><span class="sxs-lookup"><span data-stu-id="6000c-244">hello default value is a tuple that consists of all True values.</span></span> 
* <span data-ttu-id="6000c-245">**MapCount**: (facultatif) définit hello nombre de fonctionnalité de mappages pour l’offre groupée à convolution de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-245">**MapCount**: (optional) Defines hello number of feature maps for hello convolutional bundle.</span></span> <span data-ttu-id="6000c-246">valeur de Hello peut être un entier positif unique ou un tuple d’entiers positifs avec une longueur arité hello du groupement de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-246">hello value can be a single positive integer or a tuple of positive integers with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="6000c-247">Une seule valeur entière est étendue toobe un tuple de longueur correcte de hello avec hello première composants égal toohello spécifié de valeur et tous les hello tooone égale des composants restants.</span><span class="sxs-lookup"><span data-stu-id="6000c-247">A single integer value is extended toobe a tuple of hello correct length with hello first components equal toohello specified value and all hello remaining components equal tooone.</span></span> <span data-ttu-id="6000c-248">Hello par défaut est 1.</span><span class="sxs-lookup"><span data-stu-id="6000c-248">hello default value is one.</span></span> <span data-ttu-id="6000c-249">Nombre total de Hello des mappages de fonction est produit hello des composants hello de hello tuple.</span><span class="sxs-lookup"><span data-stu-id="6000c-249">hello total number of feature maps is hello product of hello components of hello tuple.</span></span> <span data-ttu-id="6000c-250">Hello factorisation de ce nombre total entre les composants de hello détermine comment les valeurs de mappage de fonction hello sont regroupés dans les nœuds de destination hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-250">hello factoring of this total number across hello components determines how hello feature map values are grouped in hello destination nodes.</span></span> 
* <span data-ttu-id="6000c-251">**Poids**: (facultatif) définit hello initiales poids pour le groupe de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-251">**Weights**: (optional) Defines hello initial weights for hello bundle.</span></span> <span data-ttu-id="6000c-252">valeur de Hello doit être un tuple de valeurs à virgule flottante avec une longueur de hello nombre de noyaux fois hello poids par noyau, tel que défini plus loin dans cet article.</span><span class="sxs-lookup"><span data-stu-id="6000c-252">hello value must be a tuple of floating point values with a length that is hello number of kernels times hello number of weights per kernel, as defined later in this article.</span></span> <span data-ttu-id="6000c-253">poids par défaut de Hello sont générés de façon aléatoire.</span><span class="sxs-lookup"><span data-stu-id="6000c-253">hello default weights are randomly generated.</span></span>  

<span data-ttu-id="6000c-254">Il existe deux ensembles de propriétés qui contrôlent la marge intérieure, propriétés hello en cours s’excluent mutuellement :</span><span class="sxs-lookup"><span data-stu-id="6000c-254">There are two sets of properties that control padding, hello properties being mutually exclusive:</span></span>

* <span data-ttu-id="6000c-255">**Marge intérieure**: (facultatif) détermine si hello d’entrée doit être remplie à l’aide un **modèle de remplissage par défaut**.</span><span class="sxs-lookup"><span data-stu-id="6000c-255">**Padding**: (optional) Determines whether hello input should be padded by using a **default padding scheme**.</span></span> <span data-ttu-id="6000c-256">valeur de Hello peut être une valeur booléenne unique, ou il peut être un tuple de valeurs booléennes avec une longueur arité hello du groupement de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-256">hello value can be a single Boolean value, or it can be a tuple of Boolean values with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="6000c-257">Une valeur booléenne est étendue toobe un tuple de longueur correcte de hello avec tous les composants toohello égale de valeur spécifiée.</span><span class="sxs-lookup"><span data-stu-id="6000c-257">A single Boolean value is extended toobe a tuple of hello correct length with all components equal toohello specified value.</span></span> <span data-ttu-id="6000c-258">Si la valeur hello pour une dimension a la valeur True, source de hello logiquement remplie dans la dimension avec des applications de cellules de valeur zéro toosupport noyau supplémentaires, telles que hello des nœuds central des noyaux de première et dernières hello dans la dimension sont des nœuds de premier et derniers de hello dans la dimension dans la couche de source de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-258">If hello value for a dimension is True, hello source is logically padded in that dimension with zero-valued cells toosupport additional kernel applications, such that hello central nodes of hello first and last kernels in that dimension are hello first and last nodes in that dimension in hello source layer.</span></span> <span data-ttu-id="6000c-259">Par conséquent, le nombre hello de nœuds de « factices » dans chaque dimension est déterminé automatiquement, toofit exactement *(InputShape [d] - 1) / Stride [d] + 1* noyaux dans la couche de source de hello complétée.</span><span class="sxs-lookup"><span data-stu-id="6000c-259">Thus, hello number of "dummy" nodes in each dimension is determined automatically, toofit exactly *(InputShape[d] - 1) / Stride[d] + 1* kernels into hello padded source layer.</span></span> <span data-ttu-id="6000c-260">Si la valeur hello pour une dimension a la valeur False, hello noyaux définies de sorte que le nombre de hello de nœuds de chaque côté sont omis est même hello (haut tooa la différence de 1).</span><span class="sxs-lookup"><span data-stu-id="6000c-260">If hello value for a dimension is False, hello kernels are defined so that hello number of nodes on each side that are left out is hello same (up tooa difference of 1).</span></span> <span data-ttu-id="6000c-261">Hello par défaut de cet attribut est un tuple avec tous les tooFalse égale de composants.</span><span class="sxs-lookup"><span data-stu-id="6000c-261">hello default value of this attribute is a tuple with all components equal tooFalse.</span></span>
* <span data-ttu-id="6000c-262">**UpperPad** et **LowerPad**: (facultatif) indiquez mieux contrôler durée hello toouse de remplissage.</span><span class="sxs-lookup"><span data-stu-id="6000c-262">**UpperPad** and **LowerPad**: (optional) Provide greater control over hello amount of padding toouse.</span></span> <span data-ttu-id="6000c-263">**Important :** ces attributs peuvent être définis si et seulement si hello **remplissage** propriété ci-dessus est ***pas*** défini.</span><span class="sxs-lookup"><span data-stu-id="6000c-263">**Important:** These attributes can be defined if and only if hello **Padding** property above is ***not*** defined.</span></span> <span data-ttu-id="6000c-264">les valeurs de Hello doivent être des valeurs entières de tuples avec des longueurs qui sont arité hello du groupement de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-264">hello values should be integer-valued tuples with lengths that are hello arity of hello bundle.</span></span> <span data-ttu-id="6000c-265">Lorsque ces attributs sont spécifiés, « factices » nœuds sont ajoutés toohello inférieur et supérieures extrémités de chaque dimension du hello d’entrée couche.</span><span class="sxs-lookup"><span data-stu-id="6000c-265">When these attributes are specified, "dummy" nodes are added toohello lower and upper ends of each dimension of hello input layer.</span></span> <span data-ttu-id="6000c-266">Hello nombre de nœuds ajoutés toohello inférieure et supérieure se termine dans chaque dimension est déterminée par **LowerPad**[i] et **UpperPad**[i] respectivement.</span><span class="sxs-lookup"><span data-stu-id="6000c-266">hello number of nodes added toohello lower and upper ends in each dimension is determined by **LowerPad**[i] and **UpperPad**[i] respectively.</span></span> <span data-ttu-id="6000c-267">tooensure que noyaux correspondent uniquement trop « réels » nœuds et pas trop « factice », hello conditions suivantes doit être remplie :</span><span class="sxs-lookup"><span data-stu-id="6000c-267">tooensure that kernels correspond only too"real" nodes and not too"dummy" nodes, hello following conditions must be met:</span></span>
  * <span data-ttu-id="6000c-268">Chaque élément de **LowerPad** doit être strictement inférieur à KernelShape[d]/2.</span><span class="sxs-lookup"><span data-stu-id="6000c-268">Each component of **LowerPad** must be strictly less than KernelShape[d]/2.</span></span> 
  * <span data-ttu-id="6000c-269">Chaque élément de **UpperPad** ne doit pas être supérieur à KernelShape[d]/2.</span><span class="sxs-lookup"><span data-stu-id="6000c-269">Each component of **UpperPad** must be no greater than KernelShape[d]/2.</span></span> 
  * <span data-ttu-id="6000c-270">Hello par défaut de ces attributs est un tuple avec tous les too0 égale de composants.</span><span class="sxs-lookup"><span data-stu-id="6000c-270">hello default value of these attributes is a tuple with all components equal too0.</span></span> 

<span data-ttu-id="6000c-271">paramètre de Hello **remplissage** = true permet de marge intérieure est besoins tookeep hello « center » du noyau de hello à l’intérieur de hello à « réal » d’entrée.</span><span class="sxs-lookup"><span data-stu-id="6000c-271">hello setting **Padding** = true allows as much padding as is needed tookeep hello "center" of hello kernel inside hello "real" input.</span></span> <span data-ttu-id="6000c-272">Cela modifie mathématiques hello un bit pour le calcul de taille de la sortie hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-272">This changes hello math a bit for computing hello output size.</span></span> <span data-ttu-id="6000c-273">En règle générale, la taille de sortie hello *D* est calculée en tant que *D = (I - K) / S + 1*, où *I* est la taille de l’entrée hello, *K* est la taille du noyau de hello, *S* est stride de hello, et  */*  est la division d’entier (arrondi vers zéro).</span><span class="sxs-lookup"><span data-stu-id="6000c-273">Generally, hello output size *D* is computed as *D = (I - K) / S + 1*, where *I* is hello input size, *K* is hello kernel size, *S* is hello stride, and */* is integer division (round toward zero).</span></span> <span data-ttu-id="6000c-274">Si vous définissez UpperPad = [1, 1], hello entrée taille *I* est effectivement 29 et par conséquent *D = (29-5) / 2 + 1 = 13*.</span><span class="sxs-lookup"><span data-stu-id="6000c-274">If you set UpperPad = [1, 1], hello input size *I* is effectively 29, and thus *D = (29 - 5) / 2 + 1 = 13*.</span></span> <span data-ttu-id="6000c-275">Toutefois, quand **Padding** = true, *I* est essentiellement augmenté de *K - 1* ; donc *D = ((28 + 4) - 5) / 2 + 1 = 27 / 2 + 1 = 13 + 1 = 14*.</span><span class="sxs-lookup"><span data-stu-id="6000c-275">However, when **Padding** = true, essentially *I* gets bumped up by *K - 1*; hence *D = ((28 + 4) - 5) / 2 + 1 = 27 / 2 + 1 = 13 + 1 = 14*.</span></span> <span data-ttu-id="6000c-276">En spécifiant des valeurs pour **UpperPad** et **LowerPad** vous contrôlez beaucoup plus hello de remplissage qu’if vous venez de définir **remplissage** = true.</span><span class="sxs-lookup"><span data-stu-id="6000c-276">By specifying values for **UpperPad** and **LowerPad** you get much more control over hello padding than if you just set **Padding** = true.</span></span>

<span data-ttu-id="6000c-277">Pour plus d’informations sur les réseaux convolutionnels et leurs applications, consultez les articles suivants :</span><span class="sxs-lookup"><span data-stu-id="6000c-277">For more information about convolutional networks and their applications, see these articles:</span></span>  

* [<span data-ttu-id="6000c-278">http://deeplearning.net/tutorial/lenet.html </span><span class="sxs-lookup"><span data-stu-id="6000c-278">http://deeplearning.net/tutorial/lenet.html </span></span>](http://deeplearning.net/tutorial/lenet.html)
* [<span data-ttu-id="6000c-279">http://research.microsoft.com/pubs/68920/icdar03.pdf</span><span class="sxs-lookup"><span data-stu-id="6000c-279">http://research.microsoft.com/pubs/68920/icdar03.pdf</span></span>](http://research.microsoft.com/pubs/68920/icdar03.pdf) 
* [<span data-ttu-id="6000c-280">http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf</span><span class="sxs-lookup"><span data-stu-id="6000c-280">http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf</span></span>](http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf)  

## <a name="pooling-bundles"></a><span data-ttu-id="6000c-281">Faisceaux de regroupement</span><span class="sxs-lookup"><span data-stu-id="6000c-281">Pooling bundles</span></span>
<span data-ttu-id="6000c-282">A **le regroupement de regroupement** s’applique à la connectivité tooconvolutional similaire geometry, mais il utilise la valeur de nœud destination valeurs tooderive hello fonctions prédéfinies toosource nœud.</span><span class="sxs-lookup"><span data-stu-id="6000c-282">A **pooling bundle** applies geometry similar tooconvolutional connectivity, but it uses predefined functions toosource node values tooderive hello destination node value.</span></span> <span data-ttu-id="6000c-283">De ce fait, les faisceaux de regroupement n’ont pas d’état entraînable (poids ou biais).</span><span class="sxs-lookup"><span data-stu-id="6000c-283">Hence, pooling bundles have no trainable state (weights or biases).</span></span> <span data-ttu-id="6000c-284">Le regroupement tous hello à convolution attributs à l’exception de la prise en charge regroupements **partage**, **MapCount**, et **poids**.</span><span class="sxs-lookup"><span data-stu-id="6000c-284">Pooling bundles support all hello convolutional attributes except **Sharing**, **MapCount**, and **Weights**.</span></span>  

<span data-ttu-id="6000c-285">En règle générale, les noyaux hello résumées par unités regroupement adjacentes ne se chevauchent pas.</span><span class="sxs-lookup"><span data-stu-id="6000c-285">Typically, hello kernels summarized by adjacent pooling units do not overlap.</span></span> <span data-ttu-id="6000c-286">Si Stride [d] est égale tooKernelShape [d] dans chaque dimension, une couche hello obtenue est hello traditionnelle locale regroupement couche, qui est couramment employé dans les réseaux neuronaux à convolution.</span><span class="sxs-lookup"><span data-stu-id="6000c-286">If Stride[d] is equal tooKernelShape[d] in each dimension, hello layer obtained is hello traditional local pooling layer, which is commonly employed in convolutional neural networks.</span></span> <span data-ttu-id="6000c-287">Chaque nœud de destination calcule hello maximale ou moyenne hello des activités de hello de son noyau dans la couche de source de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-287">Each destination node computes hello maximum or hello mean of hello activities of its kernel in hello source layer.</span></span>  

<span data-ttu-id="6000c-288">Hello, l’exemple suivant illustre un ensemble de regroupement :</span><span class="sxs-lookup"><span data-stu-id="6000c-288">hello following example illustrates a pooling bundle:</span></span> 

    hidden P1 [5, 12, 12]
      from C1 max pool {
        InputShape  = [ 5, 24, 24];
        KernelShape = [ 1,  2,  2];
        Stride      = [ 1,  2,  2];
      }  

* <span data-ttu-id="6000c-289">arité Hello du groupement de hello est 3 (hello longueur de hello tuples **InputShape**, **KernelShape**, et **Stride**).</span><span class="sxs-lookup"><span data-stu-id="6000c-289">hello arity of hello bundle is 3 (hello length of hello tuples **InputShape**, **KernelShape**, and **Stride**).</span></span> 
* <span data-ttu-id="6000c-290">nombre de Hello de nœuds de couche de source de hello est *5 * 24 * 24 = 2880*.</span><span class="sxs-lookup"><span data-stu-id="6000c-290">hello number of nodes in hello source layer is *5 * 24 * 24 = 2880*.</span></span> 
* <span data-ttu-id="6000c-291">Il s’agit d’une couche de regroupement locale traditionnelle, car les valeurs **KernelShape** et **Stride** sont égales.</span><span class="sxs-lookup"><span data-stu-id="6000c-291">This is a traditional local pooling layer because **KernelShape** and **Stride** are equal.</span></span> 
* <span data-ttu-id="6000c-292">nombre de Hello de nœuds de couche de destination hello est *5 * 12 * 12 = 1 440*.</span><span class="sxs-lookup"><span data-stu-id="6000c-292">hello number of nodes in hello destination layer is *5 * 12 * 12 = 1440*.</span></span>  

<span data-ttu-id="6000c-293">Pour plus d’informations sur les couches de regroupement, consultez les articles suivants :</span><span class="sxs-lookup"><span data-stu-id="6000c-293">For more information about pooling layers, see these articles:</span></span>  

* <span data-ttu-id="6000c-294">[http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (Section 3.4)</span><span class="sxs-lookup"><span data-stu-id="6000c-294">[http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (Section 3.4)</span></span>
* [<span data-ttu-id="6000c-295">http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf</span><span class="sxs-lookup"><span data-stu-id="6000c-295">http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf</span></span>](http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf) 
* [<span data-ttu-id="6000c-296">http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf</span><span class="sxs-lookup"><span data-stu-id="6000c-296">http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf</span></span>](http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf)

## <a name="response-normalization-bundles"></a><span data-ttu-id="6000c-297">Faisceaux de normalisation de réponse</span><span class="sxs-lookup"><span data-stu-id="6000c-297">Response normalization bundles</span></span>
<span data-ttu-id="6000c-298">**Normalisation de la réponse** est un modèle de normalisation local qui a été introduit par Geoffrey Hinton, et autres, dans le livre de hello [ImageNet Classiﬁcation avec des réseaux neuronaux à convolution approfondie](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf).</span><span class="sxs-lookup"><span data-stu-id="6000c-298">**Response normalization** is a local normalization scheme that was first introduced by Geoffrey Hinton, et al, in hello paper [ImageNet Classiﬁcation with Deep Convolutional Neural Networks](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf).</span></span> <span data-ttu-id="6000c-299">Normalisation de la réponse est généralisation tooaid utilisés dans les réseaux neurones.</span><span class="sxs-lookup"><span data-stu-id="6000c-299">Response normalization is used tooaid generalization in neural nets.</span></span> <span data-ttu-id="6000c-300">Lorsqu’un neurone déclenche à un niveau très élevé d’activation, une couche de normalisation de réponse local supprime au niveau de l’activation de hello Hello entourant les neurones.</span><span class="sxs-lookup"><span data-stu-id="6000c-300">When one neuron is firing at a very high activation level, a local response normalization layer suppresses hello activation level of hello surrounding neurons.</span></span> <span data-ttu-id="6000c-301">Cette opération s’effectue à l’aide de trois paramètres (***α***, ***β*** et ***k***) et d’une structure convolutionnelle (ou forme de voisinage).</span><span class="sxs-lookup"><span data-stu-id="6000c-301">This is done by using three parameters (***α***, ***β***, and ***k***) and a convolutional structure (or neighborhood shape).</span></span> <span data-ttu-id="6000c-302">Chaque neurone hello calque de destination ***y*** correspond tooa neurone ***x*** dans la couche de source de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-302">Every neuron in hello destination layer ***y*** corresponds tooa neuron ***x*** in hello source layer.</span></span> <span data-ttu-id="6000c-303">Hello au niveau de l’activation de ***y*** est donnée par hello formule, suivante où ***f*** est au niveau de l’activation de hello d’un neurone, et ***Nx*** est noyau de hello (ou un ensemble de hello contenant hello neurones dans le voisinage hello de ***x***), comme défini par hello suivant à convolution structure :</span><span class="sxs-lookup"><span data-stu-id="6000c-303">hello activation level of ***y*** is given by hello following formula, where ***f*** is hello activation level of a neuron, and ***Nx*** is hello kernel (or hello set that contains hello neurons in hello neighborhood of ***x***), as defined by hello following convolutional structure:</span></span>  

![][1]  

<span data-ttu-id="6000c-304">Groupes de normalisation de réponse prend en charge tous les attributs à convolution hello sauf **partage**, **MapCount**, et **poids**.</span><span class="sxs-lookup"><span data-stu-id="6000c-304">Response normalization bundles support all hello convolutional attributes except **Sharing**, **MapCount**, and **Weights**.</span></span>  

* <span data-ttu-id="6000c-305">Si le noyau de hello contient neurones hello même mapper en tant que ***x***, schéma de normalisation hello est référencé tooas **même mapper normalisation**.</span><span class="sxs-lookup"><span data-stu-id="6000c-305">If hello kernel contains neurons in hello same map as ***x***, hello normalization scheme is referred tooas **same map normalization**.</span></span> <span data-ttu-id="6000c-306">toodefine même mapper normalisation, dans la première coordonnée hello **InputShape** doit avoir hello valeur 1.</span><span class="sxs-lookup"><span data-stu-id="6000c-306">toodefine same map normalization, hello first coordinate in **InputShape** must have hello value 1.</span></span>
* <span data-ttu-id="6000c-307">Si le noyau de hello contient neurones hello même position spatiale ***x***, mais les neurones hello se trouvent dans d’autres mappages, schéma de normalisation hello est appelée **mappe à travers de normalisation**.</span><span class="sxs-lookup"><span data-stu-id="6000c-307">If hello kernel contains neurons in hello same spatial position as ***x***, but hello neurons are in other maps, hello normalization scheme is called **across maps normalization**.</span></span> <span data-ttu-id="6000c-308">Ce type de normalisation de la réponse implémente un formulaire d’inhiber latéral inspiré par type de hello trouvé dans les neurones réels, création de concurrence pour les niveaux d’activation big dans la liste de sorties neurone calculées sur des cartes de différents.</span><span class="sxs-lookup"><span data-stu-id="6000c-308">This type of response normalization implements a form of lateral inhibition inspired by hello type found in real neurons, creating competition for big activation levels amongst neuron outputs computed on different maps.</span></span> <span data-ttu-id="6000c-309">toodefine entre mappe la normalisation et la première coordonnée hello doit être un entier supérieur à un et ne supérieur au nombre de hello des mappages reste hello de coordonnées de hello doit avoir la valeur de hello 1.</span><span class="sxs-lookup"><span data-stu-id="6000c-309">toodefine across maps normalization, hello first coordinate must be an integer greater than one and no greater than hello number of maps, and hello rest of hello coordinates must have hello value 1.</span></span>  

<span data-ttu-id="6000c-310">Étant donné que les offres groupées de normalisation de réponse s’appliquent à une fonction prédéfinie toosource nœud valeurs toodetermine hello nœud valeur de destination, ils n’ont aucun état capable d’apprentissage (poids ou écarts).</span><span class="sxs-lookup"><span data-stu-id="6000c-310">Because response normalization bundles apply a predefined function toosource node values toodetermine hello destination node value, they have no trainable state (weights or biases).</span></span>   

<span data-ttu-id="6000c-311">**Alerte**: nœuds hello hello calque de destination correspondent tooneurons qui sont des nœuds de centrale hello des noyaux de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-311">**Alert**: hello nodes in hello destination layer correspond tooneurons that are hello central nodes of hello kernels.</span></span> <span data-ttu-id="6000c-312">Par exemple, si KernelShape [d] est impair, puis *KernelShape [d] / 2* correspond le nœud de noyau central toohello.</span><span class="sxs-lookup"><span data-stu-id="6000c-312">For example, if KernelShape[d] is odd, then *KernelShape[d]/2* corresponds toohello central kernel node.</span></span> <span data-ttu-id="6000c-313">Si *KernelShape [d]* est pair, nœud central de hello est *KernelShape [d] / 2-1*.</span><span class="sxs-lookup"><span data-stu-id="6000c-313">If *KernelShape[d]* is even, hello central node is at *KernelShape[d]/2 - 1*.</span></span> <span data-ttu-id="6000c-314">Par conséquent, si **remplissage**[d] est False, hello tout d’abord et hello dernière *KernelShape [d] / 2* nœuds n’ont pas de nœuds correspondants hello calque de destination.</span><span class="sxs-lookup"><span data-stu-id="6000c-314">Therefore, if **Padding**[d] is False, hello first and hello last *KernelShape[d]/2* nodes do not have corresponding nodes in hello destination layer.</span></span> <span data-ttu-id="6000c-315">tooavoid cette situation, définissez **remplissage** en tant que [valeur est true, la valeur true,..., true].</span><span class="sxs-lookup"><span data-stu-id="6000c-315">tooavoid this situation, define **Padding** as [true, true, …, true].</span></span>  

<span data-ttu-id="6000c-316">En outre toohello quatre attributs décrits précédemment, groupes de normalisation de réponse également hello prise en charge suivant d’attributs :</span><span class="sxs-lookup"><span data-stu-id="6000c-316">In addition toohello four attributes described earlier, response normalization bundles also support hello following attributes:</span></span>  

* <span data-ttu-id="6000c-317">**Alpha**: (obligatoire) spécifie une valeur à virgule flottante qui correspond trop***α*** dans la formule précédente de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-317">**Alpha**: (required) Specifies a floating-point value that corresponds too***α*** in hello previous formula.</span></span> 
* <span data-ttu-id="6000c-318">**Version bêta**: (obligatoire) spécifie une valeur à virgule flottante qui correspond trop***β*** dans la formule précédente de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-318">**Beta**: (required) Specifies a floating-point value that corresponds too***β*** in hello previous formula.</span></span> 
* <span data-ttu-id="6000c-319">**Décalage**: (facultatif) spécifie une valeur à virgule flottante qui correspond trop***k*** dans la formule précédente de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-319">**Offset**: (optional) Specifies a floating-point value that corresponds too***k*** in hello previous formula.</span></span> <span data-ttu-id="6000c-320">Too1 la valeur par défaut.</span><span class="sxs-lookup"><span data-stu-id="6000c-320">It defaults too1.</span></span>  

<span data-ttu-id="6000c-321">Hello exemple suivant définit un groupe de normalisation de réponse à l’aide de ces attributs :</span><span class="sxs-lookup"><span data-stu-id="6000c-321">hello following example defines a response normalization bundle using these attributes:</span></span>  

    hidden RN1 [5, 10, 10]
      from P1 response norm {
        InputShape  = [ 5, 12, 12];
        KernelShape = [ 1,  3,  3];
        Alpha = 0.001;
        Beta = 0.75;
      }  

* <span data-ttu-id="6000c-322">couche de source de Hello inclut cinq tables, chaque dimension unede 12 x 12, total de nœuds de 1440.</span><span class="sxs-lookup"><span data-stu-id="6000c-322">hello source layer includes five maps, each with aof dimension of 12x12, totaling in 1440 nodes.</span></span> 
* <span data-ttu-id="6000c-323">Hello valeur **KernelShape** indique qu’il s’agit d’une même normalisation couche, où les voisinage hello est un rectangle 3 x 3.</span><span class="sxs-lookup"><span data-stu-id="6000c-323">hello value of **KernelShape** indicates that this is a same map normalization layer, where hello neighborhood is a 3x3 rectangle.</span></span> 
* <span data-ttu-id="6000c-324">Hello la valeur par défaut de **remplissage** est False, par conséquent, la couche de destination hello est uniquement 10 nœuds dans chaque dimension.</span><span class="sxs-lookup"><span data-stu-id="6000c-324">hello default value of **Padding** is False, thus hello destination layer has only 10 nodes in each dimension.</span></span> <span data-ttu-id="6000c-325">un nœud de tooinclude hello calque de destination qui correspond à nœud tooevery dans la couche de source de hello, ajouter une marge intérieure = [true, true, true] ; et également modifier taille hello de RN1 [5, 12, 12].</span><span class="sxs-lookup"><span data-stu-id="6000c-325">tooinclude one node in hello destination layer that corresponds tooevery node in hello source layer, add Padding = [true, true, true]; and change hello size of RN1 too[5, 12, 12].</span></span>  

## <a name="share-declaration"></a><span data-ttu-id="6000c-326">Déclaration de partage</span><span class="sxs-lookup"><span data-stu-id="6000c-326">Share declaration</span></span>
<span data-ttu-id="6000c-327">Net# peut prendre en charge la définition de plusieurs faisceaux avec des poids partagés.</span><span class="sxs-lookup"><span data-stu-id="6000c-327">Net# optionally supports defining multiple bundles with shared weights.</span></span> <span data-ttu-id="6000c-328">poids Hello de n’importe quel deux regroupements peuvent être partagées si leurs structures sont hello identiques.</span><span class="sxs-lookup"><span data-stu-id="6000c-328">hello weights of any two bundles can be shared if their structures are hello same.</span></span> <span data-ttu-id="6000c-329">Hello syntaxe définit les regroupements avec des poids partagés :</span><span class="sxs-lookup"><span data-stu-id="6000c-329">hello following syntax defines bundles with shared weights:</span></span>  

    share-declaration:
        share    {    layer-list    }
        share    {    bundle-list    }
       share    {    bias-list    }

    layer-list:
        layer-name    ,    layer-name
        layer-list    ,    layer-name

    bundle-list:
       bundle-spec    ,    bundle-spec
        bundle-list    ,    bundle-spec

    bundle-spec:
       layer-name    =>     layer-name

    bias-list:
        bias-spec    ,    bias-spec
        bias-list    ,    bias-spec

    bias-spec:
        1    =>    layer-name

    layer-name:
        identifier  

<span data-ttu-id="6000c-330">Par exemple, hello partage-déclaration suivante spécifie les noms de couches hello, qui indique que le poids et biais doivent être partagés :</span><span class="sxs-lookup"><span data-stu-id="6000c-330">For example, hello following share-declaration specifies hello layer names, indicating that both weights and biases should be shared:</span></span>  

    Const {
      InputSize = 37;
      HiddenSize = 50;
    }
    input {
      Data1 [InputSize];
      Data2 [InputSize];
    }
    hidden {
      H1 [HiddenSize] from Data1 all;
      H2 [HiddenSize] from Data2 all;
    }
    output Result [2] {
      from H1 all;
      from H2 all;
    }
    share { H1, H2 } // share both weights and biases  

* <span data-ttu-id="6000c-331">les fonctionnalités d’entrée Hello sont répartis dans deux couches d’entrée tailles égales.</span><span class="sxs-lookup"><span data-stu-id="6000c-331">hello input features are partitioned into two equal sized input layers.</span></span> 
* <span data-ttu-id="6000c-332">les couches Hello masqué calculez des fonctionnalités au niveau supérieures sur deux couches de d’entrée hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-332">hello hidden layers then compute higher level features on hello two input layers.</span></span> 
* <span data-ttu-id="6000c-333">Hello partage-déclaration spécifie que *H1* et *H2* doivent être calculées Bonjour même de façon à partir de leurs entrées respectives.</span><span class="sxs-lookup"><span data-stu-id="6000c-333">hello share-declaration specifies that *H1* and *H2* must be computed in hello same way from their respective inputs.</span></span>  

<span data-ttu-id="6000c-334">Il est également possible de spécifier cet élément avec deux déclarations de partage indépendantes, comme suit :</span><span class="sxs-lookup"><span data-stu-id="6000c-334">Alternatively, this could be specified with two separate share-declarations as follows:</span></span>  

    share { Data1 => H1, Data2 => H2 } // share weights  

<!-- -->

    share { 1 => H1, 1 => H2 } // share biases  

<span data-ttu-id="6000c-335">Vous pouvez utiliser la forme abrégée de hello uniquement lorsque les couches hello contient un lot unique.</span><span class="sxs-lookup"><span data-stu-id="6000c-335">You can use hello short form only when hello layers contain a single bundle.</span></span> <span data-ttu-id="6000c-336">En règle générale, de partage est possible uniquement lorsque la structure pertinentes de hello est identique, ce qui signifie que leur ont hello même taille, de même geometry à convolution et ainsi de suite.</span><span class="sxs-lookup"><span data-stu-id="6000c-336">In general, sharing is possible only when hello relevant structure is identical, meaning that they have hello same size, same convolutional geometry, and so forth.</span></span>  

## <a name="examples-of-net-usage"></a><span data-ttu-id="6000c-337">Exemples d’utilisation de Net#</span><span class="sxs-lookup"><span data-stu-id="6000c-337">Examples of Net# usage</span></span>
<span data-ttu-id="6000c-338">Cette section fournit quelques exemples de la façon dont vous pouvez utiliser Net # tooadd masqué couches, qui définissent la façon de hello que couches masquées interagissent avec d’autres couches et créer des réseaux à convolution.</span><span class="sxs-lookup"><span data-stu-id="6000c-338">This section provides some examples of how you can use Net# tooadd hidden layers, define hello way that hidden layers interact with other layers, and build convolutional networks.</span></span>   

### <a name="define-a-simple-custom-neural-network-hello-world-example"></a><span data-ttu-id="6000c-339">Définition d'un réseau neuronal personnalisé simple : exemple « Hello World »</span><span class="sxs-lookup"><span data-stu-id="6000c-339">Define a simple custom neural network: "Hello World" example</span></span>
<span data-ttu-id="6000c-340">Cet exemple simple montre comment toocreate un neuronal réseau modèle qui a une seule couche cachée.</span><span class="sxs-lookup"><span data-stu-id="6000c-340">This simple example demonstrates how toocreate a neural network model that has a single hidden layer.</span></span>  

    input Data auto;
    hidden H [200] from Data all;
    output Out [10] sigmoid from H all;  

<span data-ttu-id="6000c-341">Hello illustre certaines commandes de base comme suit :</span><span class="sxs-lookup"><span data-stu-id="6000c-341">hello example illustrates some basic commands as follows:</span></span>  

* <span data-ttu-id="6000c-342">première ligne Hello définit couche d’entrée de hello (nommé *données*).</span><span class="sxs-lookup"><span data-stu-id="6000c-342">hello first line defines hello input layer (named *Data*).</span></span> <span data-ttu-id="6000c-343">Lorsque vous utilisez hello **automatique** (mot clé), les réseaux neuronaux hello inclut automatiquement toutes les colonnes de fonctionnalités dans les exemples d’entrée hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-343">When you use hello  **auto** keyword, hello neural network automatically includes all feature columns in hello input examples.</span></span> 
* <span data-ttu-id="6000c-344">Hello deuxième ligne crée la couche masquée de hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-344">hello second line creates hello hidden layer.</span></span> <span data-ttu-id="6000c-345">nom de Hello *H* est attribué toohello couche masquée, qui possède des nœuds de 200.</span><span class="sxs-lookup"><span data-stu-id="6000c-345">hello name *H* is assigned toohello hidden layer, which has 200 nodes.</span></span> <span data-ttu-id="6000c-346">Cette couche est totalement connecté toohello d’entrée.</span><span class="sxs-lookup"><span data-stu-id="6000c-346">This layer is fully connected toohello input layer.</span></span>
* <span data-ttu-id="6000c-347">troisième ligne de Hello définit la couche de sortie hello (nommé *O*), qui contient 10 nœuds de sortie.</span><span class="sxs-lookup"><span data-stu-id="6000c-347">hello third line defines hello output layer (named *O*), which contains 10 output nodes.</span></span> <span data-ttu-id="6000c-348">Si le réseau neuronal de hello est utilisé pour la classification, il est un nœud de sortie par la classe.</span><span class="sxs-lookup"><span data-stu-id="6000c-348">If hello neural network is used for classification, there is one output node per class.</span></span> <span data-ttu-id="6000c-349">mot clé de Hello **sigmoïde** indique que la fonction de sortie hello est couche de sortie toohello appliqué.</span><span class="sxs-lookup"><span data-stu-id="6000c-349">hello keyword **sigmoid** indicates that hello output function is applied toohello output layer.</span></span>   

### <a name="define-multiple-hidden-layers-computer-vision-example"></a><span data-ttu-id="6000c-350">Définir plusieurs couches masquées : exemple de vision</span><span class="sxs-lookup"><span data-stu-id="6000c-350">Define multiple hidden layers: computer vision example</span></span>
<span data-ttu-id="6000c-351">Hello exemple suivant montre comment toodefine un réseau neuronal légèrement plus complexe, avec plusieurs couches masquées personnalisés.</span><span class="sxs-lookup"><span data-stu-id="6000c-351">hello following example demonstrates how toodefine a slightly more complex neural network, with multiple custom hidden layers.</span></span>  

    // Define hello input layers 
    input Pixels [10, 20];
    input MetaData [7];

    // Define hello first two hidden layers, using data only from hello Pixels input
    hidden ByRow [10, 12] from Pixels where (s,d) => s[0] == d[0];
    hidden ByCol [5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;

    // Define hello third hidden layer, which uses as source hello hidden layers ByRow and ByCol
    hidden Gather [100] 
    {
      from ByRow all;
      from ByCol all;
    }

    // Define hello output layer and its sources
    output Result [10]  
    {
      from Gather all;
      from MetaData all;
    }  

<span data-ttu-id="6000c-352">Cet exemple illustre plusieurs fonctionnalités du langage de spécification de réseaux neuronaux hello :</span><span class="sxs-lookup"><span data-stu-id="6000c-352">This example illustrates several features of hello neural networks specification language:</span></span>  

* <span data-ttu-id="6000c-353">structure de Hello possède deux couches d’entrée, *Pixels* et *métadonnées*.</span><span class="sxs-lookup"><span data-stu-id="6000c-353">hello structure has two input layers, *Pixels* and *MetaData*.</span></span>
* <span data-ttu-id="6000c-354">Hello *Pixels* couche est une couche de source pour les deux groupes de connexion, avec des couches de destination, *ByRow* et *ByCol*.</span><span class="sxs-lookup"><span data-stu-id="6000c-354">hello *Pixels* layer is a source layer for two connection bundles, with destination layers, *ByRow* and *ByCol*.</span></span>
* <span data-ttu-id="6000c-355">Hello couches *collecter* et *résultat* sont des couches de destination dans plusieurs groupes de connexion.</span><span class="sxs-lookup"><span data-stu-id="6000c-355">hello layers *Gather* and *Result* are destination layers in multiple connection bundles.</span></span>
* <span data-ttu-id="6000c-356">couche de sortie Hello *résultat*, est une couche de destination dans deux groupes de connexion, une par hello masqué (regroupement) de second niveau comme une couche de destination et hello autre avec la couche d’entrée de hello (métadonnées) comme une couche de destination.</span><span class="sxs-lookup"><span data-stu-id="6000c-356">hello output layer, *Result*, is a destination layer in two connection bundles; one with hello second level hidden (Gather) as a destination layer, and hello other with hello input layer (MetaData) as a destination layer.</span></span>
* <span data-ttu-id="6000c-357">Hello couches masquées, *ByRow* et *ByCol*, spécifiez la connectivité filtrée à l’aide d’expressions de prédicat.</span><span class="sxs-lookup"><span data-stu-id="6000c-357">hello hidden layers, *ByRow* and *ByCol*, specify filtered connectivity by using predicate expressions.</span></span> <span data-ttu-id="6000c-358">Plus précisément, le nœud de hello dans *ByRow* à [x, y] est nœuds connectés toohello *Pixels* qui ont le premier x de coordonnées, hello premier index toohello égal coordonnées du nœud.</span><span class="sxs-lookup"><span data-stu-id="6000c-358">More precisely, hello node in *ByRow* at [x, y] is connected toohello nodes in *Pixels* that have hello first index coordinate equal toohello node's first coordinate, x.</span></span> <span data-ttu-id="6000c-359">De même, le nœud de hello dans *ByCol à [x, y] est nœuds connectés toohello _Pixels* qui ont des coordonnées d’index deuxième hello dans une des coordonnées de deuxième du nœud hello, y.</span><span class="sxs-lookup"><span data-stu-id="6000c-359">Similarly, hello node in *ByCol at [x, y] is connected toohello nodes in _Pixels* that have hello second index coordinate within one of hello node's second coordinate, y.</span></span>  

### <a name="define-a-convolutional-network-for-multiclass-classification-digit-recognition-example"></a><span data-ttu-id="6000c-360">Définir un réseau convolutionnel pour la classification multiclasse : exemple de reconnaissance de chiffre</span><span class="sxs-lookup"><span data-stu-id="6000c-360">Define a convolutional network for multiclass classification: digit recognition example</span></span>
<span data-ttu-id="6000c-361">définition de Hello Hello suivant réseau est conçue toorecognize numéros et il illustre des techniques avancées pour la personnalisation d’un réseau neuronal.</span><span class="sxs-lookup"><span data-stu-id="6000c-361">hello definition of hello following network is designed toorecognize numbers, and it illustrates some advanced techniques for customizing a neural network.</span></span>  

    input Image [29, 29];
    hidden Conv1 [5, 13, 13] from Image convolve 
    {
       InputShape  = [29, 29];
       KernelShape = [ 5,  5];
       Stride      = [ 2,  2];
       MapCount    = 5;
    }
    hidden Conv2 [50, 5, 5]
    from Conv1 convolve 
    {
       InputShape  = [ 5, 13, 13];
       KernelShape = [ 1,  5,  5];
       Stride      = [ 1,  2,  2];
       Sharing     = [false, true, true];
       MapCount    = 10;
    }
    hidden Hid3 [100] from Conv2 all;
    output Digit [10] from Hid3 all;  


* <span data-ttu-id="6000c-362">structure de Hello dispose d’une couche d’entrée unique, *Image*.</span><span class="sxs-lookup"><span data-stu-id="6000c-362">hello structure has a single input layer, *Image*.</span></span>
* <span data-ttu-id="6000c-363">Hello mot clé **convolve** indique que les couches hello *Conv1* et *Conv2* sont des couches à convolution.</span><span class="sxs-lookup"><span data-stu-id="6000c-363">hello keyword **convolve** indicates that hello layers named *Conv1* and *Conv2* are convolutional layers.</span></span> <span data-ttu-id="6000c-364">Chacune de ces déclarations de couche est suivie d’une liste d’attributs de convolution hello.</span><span class="sxs-lookup"><span data-stu-id="6000c-364">Each of these layer declarations is followed by a list of hello convolution attributes.</span></span>
* <span data-ttu-id="6000c-365">Hello net a une troisième masquée couche, *Hid3*, qui est entièrement connecté toohello deuxième couche masquée, *Conv2*.</span><span class="sxs-lookup"><span data-stu-id="6000c-365">hello net has a third hidden layer, *Hid3*, which is fully connected toohello second hidden layer, *Conv2*.</span></span>
* <span data-ttu-id="6000c-366">couche de sortie Hello *chiffre*, est la troisième couche masquée toohello uniquement connecté, *Hid3*.</span><span class="sxs-lookup"><span data-stu-id="6000c-366">hello output layer, *Digit*, is connected only toohello third hidden layer, *Hid3*.</span></span> <span data-ttu-id="6000c-367">mot clé de Hello **tous les** indique cette couche de sortie hello est entièrement connectée trop*Hid3*.</span><span class="sxs-lookup"><span data-stu-id="6000c-367">hello keyword **all** indicates that hello output layer is fully connected too*Hid3*.</span></span>
* <span data-ttu-id="6000c-368">Hello arité de convolution de hello est trois (hello longueur de hello tuples **InputShape**, **KernelShape**, **Stride**, et **partage**).</span><span class="sxs-lookup"><span data-stu-id="6000c-368">hello arity of hello convolution is three (hello length of hello tuples **InputShape**, **KernelShape**, **Stride**, and **Sharing**).</span></span> 
* <span data-ttu-id="6000c-369">nombre de Hello de poids par noyau est *1 + **KernelShape**\[0] * **KernelShape**\[1] * **KernelShape** \[2] = 1 + 1 * 5 * 5 = 26. Ou 26 * 50 = 1 300*.</span><span class="sxs-lookup"><span data-stu-id="6000c-369">hello number of weights per kernel is *1 + **KernelShape**\[0] * **KernelShape**\[1] * **KernelShape**\[2] = 1 + 1 * 5 * 5 = 26. Or 26 * 50 = 1300*.</span></span>
* <span data-ttu-id="6000c-370">Vous pouvez calculer les nœuds hello dans chaque couche masquée comme suit :</span><span class="sxs-lookup"><span data-stu-id="6000c-370">You can calculate hello nodes in each hidden layer as follows:</span></span>
  * <span data-ttu-id="6000c-371">**NodeCount**\[0] = (5 - 1) / 1 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="6000c-371">**NodeCount**\[0] = (5 - 1) / 1 + 1 = 5.</span></span>
  * <span data-ttu-id="6000c-372">**NodeCount**\[1] = (13 - 5) / 2 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="6000c-372">**NodeCount**\[1] = (13 - 5) / 2 + 1 = 5.</span></span> 
  * <span data-ttu-id="6000c-373">**NodeCount**\[2] = (13 - 5) / 2 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="6000c-373">**NodeCount**\[2] = (13 - 5) / 2 + 1 = 5.</span></span> 
* <span data-ttu-id="6000c-374">Hello nombre total de nœuds peut être calculée à l’aide de hello déclaré la dimensionnalité de hello de couche, [50, 5, 5], comme suit :  ***MapCount** * **NodeCount** \[ 0] * **NodeCount**\[1] * **NodeCount**\[2] = 10 * 5 * 5 * 5*</span><span class="sxs-lookup"><span data-stu-id="6000c-374">hello total number of nodes can be calculated by using hello declared dimensionality of hello layer, [50, 5, 5], as follows: ***MapCount** * **NodeCount**\[0] * **NodeCount**\[1] * **NodeCount**\[2] = 10 * 5 * 5 * 5*</span></span>
* <span data-ttu-id="6000c-375">Étant donné que **partage**[d] a la valeur False uniquement pour *d == 0*, nombre de hello de noyaux est  ***MapCount** * **NodeCount** \[0] = 10 * 5 = 50*.</span><span class="sxs-lookup"><span data-stu-id="6000c-375">Because **Sharing**[d] is False only for *d == 0*, hello number of kernels is ***MapCount** * **NodeCount**\[0] = 10 * 5 = 50*.</span></span> 

## <a name="acknowledgements"></a><span data-ttu-id="6000c-376">Remerciements</span><span class="sxs-lookup"><span data-stu-id="6000c-376">Acknowledgements</span></span>
<span data-ttu-id="6000c-377">Hello langage Net # pour personnaliser l’architecture hello des réseaux neuronaux a été développé à Microsoft par Shon Katzenberger (architecte, apprentissage) et Alexey Kamenev (Software Engineer, Microsoft Research).</span><span class="sxs-lookup"><span data-stu-id="6000c-377">hello Net# language for customizing hello architecture of neural networks was developed at Microsoft by Shon Katzenberger (Architect, Machine Learning) and Alexey Kamenev (Software Engineer, Microsoft Research).</span></span> <span data-ttu-id="6000c-378">Il est utilisé en interne pour l’apprentissage de projets et des applications allant des analytique de tootext détection image.</span><span class="sxs-lookup"><span data-stu-id="6000c-378">It is used internally for machine learning projects and applications ranging from image detection tootext analytics.</span></span> <span data-ttu-id="6000c-379">Pour plus d’informations, consultez [réseaux neuronaux dans Azure ML - Introduction tooNet #](http://blogs.technet.com/b/machinelearning/archive/2015/02/16/neural-nets-in-azure-ml-introduction-to-net.aspx)</span><span class="sxs-lookup"><span data-stu-id="6000c-379">For more information, see [Neural Nets in Azure ML - Introduction tooNet#](http://blogs.technet.com/b/machinelearning/archive/2015/02/16/neural-nets-in-azure-ml-introduction-to-net.aspx)</span></span>

[1]:./media/machine-learning-azure-ml-netsharp-reference-guide/formula_large.gif

