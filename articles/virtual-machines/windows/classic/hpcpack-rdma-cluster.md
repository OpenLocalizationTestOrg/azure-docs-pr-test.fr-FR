---
title: "Configuration d’un cluster Windows RDMA pour exécuter des applications MPI | Microsoft Docs"
description: "Apprenez à créer un cluster Windows HPC Pack avec des machines virtuelles de taille H16r, H16mr, A8 ou A9 pour utiliser le réseau Azure RDMA afin d’exécuter des applications MPI."
services: virtual-machines-windows
documentationcenter: 
author: dlepow
manager: timlt
editor: 
tags: azure-service-management,hpc-pack
ms.assetid: 7d9f5bc8-012f-48dd-b290-db81c7592215
ms.service: virtual-machines-windows
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: vm-windows
ms.workload: big-compute
ms.date: 06/01/2017
ms.author: danlep
ms.openlocfilehash: 19be1d693fe13af0f6c1ab0cb6f7bc829b9fad5a
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 08/03/2017
---
# <a name="set-up-a-windows-rdma-cluster-with-hpc-pack-to-run-mpi-applications"></a><span data-ttu-id="9f391-103">Configuration d’un cluster Windows RDMA avec HPC Pack pour exécuter des applications MPI</span><span class="sxs-lookup"><span data-stu-id="9f391-103">Set up a Windows RDMA cluster with HPC Pack to run MPI applications</span></span>
<span data-ttu-id="9f391-104">Configurez un cluster RDMA Windows dans Azure avec [Microsoft HPC Pack](https://technet.microsoft.com/library/cc514029) et des [tailles de machines virtuelles de calcul haute performance](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json) pour exécuter des applications MPI (Message Passing Interface) parallèles.</span><span class="sxs-lookup"><span data-stu-id="9f391-104">Set up a Windows RDMA cluster in Azure with [Microsoft HPC Pack](https://technet.microsoft.com/library/cc514029) and [High performance compute VM sizes](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json) to run parallel Message Passing Interface (MPI) applications.</span></span> <span data-ttu-id="9f391-105">Lorsque vous configurez des nœuds Windows Server compatibles RDMA dans un cluster HPC Pack, les applications MPI communiquent efficacement sur un réseau à latence faible et à débit élevé dans Azure, reposant sur la technologie d’accès direct à la mémoire à distance (RDMA).</span><span class="sxs-lookup"><span data-stu-id="9f391-105">When you set up RDMA-capable, Windows Server-based nodes in an HPC Pack cluster, MPI applications communicate efficiently over a low latency, high throughput network in Azure that is based on remote direct memory access (RDMA) technology.</span></span>

<span data-ttu-id="9f391-106">Si vous souhaitez exécuter des charges de travail MPI sur des machines virtuelles Linux qui accèdent au réseau Azure RDMA, consultez [Configuration d’un cluster Linux RDMA pour exécuter des applications MPI](../../linux/classic/rdma-cluster.md).</span><span class="sxs-lookup"><span data-stu-id="9f391-106">If you want to run MPI workloads on Linux VMs that access the Azure RDMA network, see [Set up a Linux RDMA cluster to run MPI applications](../../linux/classic/rdma-cluster.md).</span></span>

## <a name="hpc-pack-cluster-deployment-options"></a><span data-ttu-id="9f391-107">Options de déploiement de cluster HPC Pack</span><span class="sxs-lookup"><span data-stu-id="9f391-107">HPC Pack cluster deployment options</span></span>
<span data-ttu-id="9f391-108">Microsoft HPC Pack est un outil fourni sans frais supplémentaires pour créer des clusters HPC locaux ou dans Azure afin d’exécuter des applications HPC Windows ou Linux.</span><span class="sxs-lookup"><span data-stu-id="9f391-108">Microsoft HPC Pack is a tool provided at no additional cost to create HPC clusters on-premises or in Azure to run Windows or Linux HPC applications.</span></span> <span data-ttu-id="9f391-109">HPC Pack comprend un environnement d'exécution pour l'implémentation Microsoft de MPI pour Windows (MS-MPI).</span><span class="sxs-lookup"><span data-stu-id="9f391-109">HPC Pack includes a runtime environment for the Microsoft implementation of the Message Passing Interface for Windows (MS-MPI).</span></span> <span data-ttu-id="9f391-110">Dans le cas d’une utilisation d’instances compatibles RDMA exécutant un système d’exploitation Windows Server pris en charge, HPC Pack est un moyen efficace d’exécuter des applications MPI Windows qui accèdent au réseau Azure compatible RDMA.</span><span class="sxs-lookup"><span data-stu-id="9f391-110">When used with RDMA-capable instances running a supported Windows Server operating system, HPC Pack provides an efficient option to run Windows MPI applications that access the Azure RDMA network.</span></span> 

<span data-ttu-id="9f391-111">Cet article présente deux scénarios, ainsi que des liens vers des instructions détaillées, pour configurer un cluster RDMA Windows avec Microsoft HPC Pack.</span><span class="sxs-lookup"><span data-stu-id="9f391-111">This article introduces two scenarios and links to detailed guidance to set up a Windows RDMA cluster with Microsoft HPC Pack.</span></span> 

* <span data-ttu-id="9f391-112">Scénario 1</span><span class="sxs-lookup"><span data-stu-id="9f391-112">Scenario 1.</span></span> <span data-ttu-id="9f391-113">Déployer des instances de rôle de travail nécessitant beaucoup de ressources système (PaaS)</span><span class="sxs-lookup"><span data-stu-id="9f391-113">Deploy compute-intensive worker role instances (PaaS)</span></span>
* <span data-ttu-id="9f391-114">Scénario 2</span><span class="sxs-lookup"><span data-stu-id="9f391-114">Scenario 2.</span></span> <span data-ttu-id="9f391-115">Déployer des nœuds de calcul sur des machines virtuelles nécessitant beaucoup de ressources système (IaaS)</span><span class="sxs-lookup"><span data-stu-id="9f391-115">Deploy compute nodes in compute-intensive VMs (IaaS)</span></span>

<span data-ttu-id="9f391-116">Pour connaître les conditions préalables à l’utilisation d’instances nécessitant beaucoup de ressources système avec Windows, consultez [Tailles de machines virtuelles de calcul haute performance](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span><span class="sxs-lookup"><span data-stu-id="9f391-116">For general prerequisites to use compute-intensive instances with Windows, see [High performance compute VM sizes](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span></span>

## <a name="scenario-1-deploy-compute-intensive-worker-role-instances-paas"></a><span data-ttu-id="9f391-117">Scénario 1 : Déployer des instances de rôle de travail nécessitant beaucoup de ressources système (PaaS)</span><span class="sxs-lookup"><span data-stu-id="9f391-117">Scenario 1: Deploy compute-intensive worker role instances (PaaS)</span></span>
<span data-ttu-id="9f391-118">À partir d’un cluster HPC Pack existant, ajoutez des ressources de calcul supplémentaires dans les instances de rôle de travail Azure (nœuds Azure) en cours d’exécution dans un service cloud (PaaS).</span><span class="sxs-lookup"><span data-stu-id="9f391-118">From an existing HPC Pack cluster, add extra compute resources in Azure worker role instances (Azure nodes) running in a cloud service (PaaS).</span></span> <span data-ttu-id="9f391-119">Cette fonctionnalité, également appelée « Intégration à Azure » à partir de HPC Pack, prend en charge une plage de tailles d’instances de rôle de travail.</span><span class="sxs-lookup"><span data-stu-id="9f391-119">This feature, also called “burst to Azure” from HPC Pack, supports a range of sizes for the worker role instances.</span></span> <span data-ttu-id="9f391-120">Lors de l’ajout des nœuds Azure, spécifiez l’une des tailles compatibles RDMA.</span><span class="sxs-lookup"><span data-stu-id="9f391-120">When adding the Azure nodes, specify one of the RDMA-capable sizes.</span></span>

<span data-ttu-id="9f391-121">Voici les considérations et les étapes pour l’intégration aux instances Azure compatibles avec RDMA à partir d’un cluster existant (généralement local).</span><span class="sxs-lookup"><span data-stu-id="9f391-121">Following are considerations and steps to burst to RDMA-capable Azure instances from an existing (typically on-premises) cluster.</span></span> <span data-ttu-id="9f391-122">Utilisez des procédures similaires pour ajouter des instances de rôle de travail à un nœud principal HPC Pack déployé dans une machine virtuelle Azure.</span><span class="sxs-lookup"><span data-stu-id="9f391-122">Use similar procedures to add worker role instances to an HPC Pack head node that is deployed in an Azure VM.</span></span>

> [!NOTE]
> <span data-ttu-id="9f391-123">Pour obtenir un didacticiel sur l’intégration à Azure avec HPC Pack, consultez [Configurer un cluster hybride avec HPC Pack](../../../cloud-services/cloud-services-setup-hybrid-hpcpack-cluster.md).</span><span class="sxs-lookup"><span data-stu-id="9f391-123">For a tutorial to burst to Azure with HPC Pack, see [Set up a hybrid cluster with HPC Pack](../../../cloud-services/cloud-services-setup-hybrid-hpcpack-cluster.md).</span></span> <span data-ttu-id="9f391-124">Tenez compte des considérations dans les étapes suivantes qui s’appliquent spécifiquement aux nœuds Azure compatibles RDMA.</span><span class="sxs-lookup"><span data-stu-id="9f391-124">Note the considerations in the following steps that apply specifically to RDMA-capable Azure nodes.</span></span>
> 
> 

![Intégration à Azure][burst]

### <a name="steps"></a><span data-ttu-id="9f391-126">Étapes</span><span class="sxs-lookup"><span data-stu-id="9f391-126">Steps</span></span>
1. <span data-ttu-id="9f391-127">**Déployer et configurer un nœud principal HPC Pack 2012 R2**</span><span class="sxs-lookup"><span data-stu-id="9f391-127">**Deploy and configure an HPC Pack 2012 R2 head node**</span></span>
   
    <span data-ttu-id="9f391-128">Téléchargez le dernier package d’installation de HPC Pack à partir du [Centre de téléchargement Microsoft](https://www.microsoft.com/download/details.aspx?id=49922).</span><span class="sxs-lookup"><span data-stu-id="9f391-128">Download the latest HPC Pack installation package from the [Microsoft Download Center](https://www.microsoft.com/download/details.aspx?id=49922).</span></span> <span data-ttu-id="9f391-129">Pour plus d’informations sur la configuration requise et des instructions de préparation pour le déploiement d’intégrations à Azure, consultez [Burst to Azure with Microsoft HPC Pack (Intégration à Azure avec Microsoft HPC Pack)](https://technet.microsoft.com/library/gg481749.aspx).</span><span class="sxs-lookup"><span data-stu-id="9f391-129">For requirements and instructions to prepare for an Azure burst deployment, see [Burst to Azure Worker Instances with Microsoft HPC Pack](https://technet.microsoft.com/library/gg481749.aspx).</span></span>
2. <span data-ttu-id="9f391-130">**Configurer un certificat de gestion dans l’abonnement Azure**</span><span class="sxs-lookup"><span data-stu-id="9f391-130">**Configure a management certificate in the Azure subscription**</span></span>
   
    <span data-ttu-id="9f391-131">Configurez un certificat pour sécuriser la connexion entre le nœud principal et Azure.</span><span class="sxs-lookup"><span data-stu-id="9f391-131">Configure a certificate to secure the connection between the head node and Azure.</span></span> <span data-ttu-id="9f391-132">Pour connaître les options et les procédures, consultez [Scénarios pour configurer le certificat de gestion Azure pour HPC Pack](http://technet.microsoft.com/library/gg481759.aspx).</span><span class="sxs-lookup"><span data-stu-id="9f391-132">For options and procedures, see [Scenarios to Configure the Azure Management Certificate for HPC Pack](http://technet.microsoft.com/library/gg481759.aspx).</span></span> <span data-ttu-id="9f391-133">Pour les déploiements de test, HPC Pack installe un certificat Microsoft HPC Azure Management par défaut que vous pouvez télécharger rapidement dans votre abonnement Azure.</span><span class="sxs-lookup"><span data-stu-id="9f391-133">For test deployments, HPC Pack installs a Default Microsoft HPC Azure Management Certificate you can quickly upload to your Azure subscription.</span></span>
3. <span data-ttu-id="9f391-134">**Créer un nouveau service cloud et un compte de stockage**</span><span class="sxs-lookup"><span data-stu-id="9f391-134">**Create a new cloud service and a storage account**</span></span>
   
    <span data-ttu-id="9f391-135">Utilisez le portail Azure pour créer un service cloud et un compte de stockage pour le déploiement dans une région où les instances compatibles RDMA sont disponibles.</span><span class="sxs-lookup"><span data-stu-id="9f391-135">Use the Azure portal to create a cloud service and a storage account for the deployment in a region where the RDMA-capable instances are available.</span></span>
4. <span data-ttu-id="9f391-136">**Créer un modèle de nœud Azure**</span><span class="sxs-lookup"><span data-stu-id="9f391-136">**Create an Azure node template**</span></span>
   
    <span data-ttu-id="9f391-137">Utilisez l’Assistant Créer un modèle de nœud dans HPC Cluster Manager.</span><span class="sxs-lookup"><span data-stu-id="9f391-137">Use the Create Node Template Wizard in HPC Cluster Manager.</span></span> <span data-ttu-id="9f391-138">Pour les étapes, consultez [Créer un modèle de nœud Azure](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Templ) dans « Étapes à suivre pour déployer des nœuds Azure avec Microsoft HPC Pack ».</span><span class="sxs-lookup"><span data-stu-id="9f391-138">For steps, see [Create an Azure node template](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Templ) in “Steps to Deploy Azure Nodes with Microsoft HPC Pack”.</span></span>
   
    <span data-ttu-id="9f391-139">Pour les premiers tests, nous vous suggérons de configurer une stratégie de disponibilité manuelle dans le modèle.</span><span class="sxs-lookup"><span data-stu-id="9f391-139">For initial tests, we suggest configuring a manual availability policy in the template.</span></span>
5. <span data-ttu-id="9f391-140">**Ajouter un nœud au cluster**</span><span class="sxs-lookup"><span data-stu-id="9f391-140">**Add nodes to the cluster**</span></span>
   
    <span data-ttu-id="9f391-141">Utilisez l’Assistant Ajouter un nœud dans HPC Cluster Manager.</span><span class="sxs-lookup"><span data-stu-id="9f391-141">Use the Add Node Wizard in HPC Cluster Manager.</span></span> <span data-ttu-id="9f391-142">Pour plus d’informations, consultez [Ajout des nœuds Azure au cluster Windows HPC](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Add).</span><span class="sxs-lookup"><span data-stu-id="9f391-142">For more information, see [Add Azure Nodes to the Windows HPC Cluster](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Add).</span></span>
   
    <span data-ttu-id="9f391-143">Lorsque vous spécifiez la taille des nœuds, sélectionnez des tailles d’instance compatibles RDMA.</span><span class="sxs-lookup"><span data-stu-id="9f391-143">When specifying the size of the nodes, select one of the RDMA-capable instance sizes.</span></span>
   
   > [!NOTE]
   > <span data-ttu-id="9f391-144">Dans chaque déploiement d’intégration à Azure avec les instances nécessitant beaucoup de ressources système, HPC Pack déploie automatiquement un minimum de deux instances compatibles RDMA (de taille A8) comme nœuds proxy, en plus des instances de rôle de travail Azure que vous spécifiez.</span><span class="sxs-lookup"><span data-stu-id="9f391-144">In each burst to Azure deployment with the compute-intensive instances, HPC Pack automatically deploys a minimum of two RDMA-capable instances (such as A8) as proxy nodes, in addition to the Azure worker role instances you specify.</span></span> <span data-ttu-id="9f391-145">Les nœuds proxy utilisent des cœurs qui sont affectés à l’abonnement et occasionnent des frais avec les instances de rôle de travail Azure.</span><span class="sxs-lookup"><span data-stu-id="9f391-145">The proxy nodes use cores that are allocated to the subscription and incur charges along with the Azure worker role instances.</span></span>
   > 
   > 
6. <span data-ttu-id="9f391-146">**Démarrer (approvisionner) les nœuds et les mettre en ligne pour exécuter des travaux**</span><span class="sxs-lookup"><span data-stu-id="9f391-146">**Start (provision) the nodes and bring them online to run jobs**</span></span>
   
    <span data-ttu-id="9f391-147">Sélectionnez les nœuds et utilisez l’action **Démarrer** dans HPC Cluster Manager.</span><span class="sxs-lookup"><span data-stu-id="9f391-147">Select the nodes and use the **Start** action in HPC Cluster Manager.</span></span> <span data-ttu-id="9f391-148">Lorsque l’approvisionnement est terminé, sélectionnez les nœuds et utilisez l’action **Mettre en ligne** dans HPC Cluster Manager.</span><span class="sxs-lookup"><span data-stu-id="9f391-148">When provisioning is complete, select the nodes and use the **Bring Online** action in HPC Cluster Manager.</span></span> <span data-ttu-id="9f391-149">Les nœuds sont prêts à exécuter des travaux.</span><span class="sxs-lookup"><span data-stu-id="9f391-149">The nodes are ready to run jobs.</span></span>
7. <span data-ttu-id="9f391-150">**Envoyer des travaux au cluster**</span><span class="sxs-lookup"><span data-stu-id="9f391-150">**Submit jobs to the cluster**</span></span>
   
   <span data-ttu-id="9f391-151">Utilisez les outils de soumission de travaux HPC Pack pour exécuter des travaux de cluster.</span><span class="sxs-lookup"><span data-stu-id="9f391-151">Use HPC Pack job submission tools to run cluster jobs.</span></span> <span data-ttu-id="9f391-152">Consultez [Microsoft HPC Pack : gestion des travaux](http://technet.microsoft.com/library/jj899585.aspx).</span><span class="sxs-lookup"><span data-stu-id="9f391-152">See [Microsoft HPC Pack: Job Management](http://technet.microsoft.com/library/jj899585.aspx).</span></span>
8. <span data-ttu-id="9f391-153">**Arrêter (annuler le déploiement) les nœuds**</span><span class="sxs-lookup"><span data-stu-id="9f391-153">**Stop (deprovision) the nodes**</span></span>
   
   <span data-ttu-id="9f391-154">Lorsque vous avez terminé l’exécution des travaux, déconnectez les nœuds et utilisez l’action **Arrêter** dans HPC Cluster Manager.</span><span class="sxs-lookup"><span data-stu-id="9f391-154">When you are done running jobs, take the nodes offline and use the **Stop** action in HPC Cluster Manager.</span></span>

## <a name="scenario-2-deploy-compute-nodes-in-compute-intensive-vms-iaas"></a><span data-ttu-id="9f391-155">Scénario 2 : Déployer des nœuds de calcul sur des machines virtuelles nécessitant beaucoup de ressources système (IaaS)</span><span class="sxs-lookup"><span data-stu-id="9f391-155">Scenario 2: Deploy compute nodes in compute-intensive VMs (IaaS)</span></span>
<span data-ttu-id="9f391-156">Dans ce scénario, vous déployez le nœud principal HPC Pack et les nœuds de calcul de cluster sur des machines virtuelles dans un réseau virtuel Azure.</span><span class="sxs-lookup"><span data-stu-id="9f391-156">In this scenario, you deploy the HPC Pack head node and cluster compute nodes on VMs in an Azure virtual network.</span></span> <span data-ttu-id="9f391-157">HPC Pack fournit un certain nombre [d’options de déploiement sur les machines virtuelles Azure](../../linux/hpcpack-cluster-options.md), y compris les scripts de déploiement automatisé et les modèles de démarrage rapide Azure.</span><span class="sxs-lookup"><span data-stu-id="9f391-157">HPC Pack provides several [deployment options in Azure VMs](../../linux/hpcpack-cluster-options.md), including automated deployment scripts and Azure quickstart templates.</span></span> <span data-ttu-id="9f391-158">Par exemple, les considérations et procédures suivantes vous guident dans l’utilisation du [script de déploiement de HPC Pack IaaS](hpcpack-cluster-powershell-script.md) pour automatiser le déploiement d’un cluster HPC Pack 2012 R2 dans Azure.</span><span class="sxs-lookup"><span data-stu-id="9f391-158">As an example, the following considerations and steps guide you to use the [HPC Pack IaaS deployment script](hpcpack-cluster-powershell-script.md) to automate the deployment of an HPC Pack 2012 R2 cluster in Azure.</span></span>

![Cluster sur les machines virtuelles Azure][iaas]

### <a name="steps"></a><span data-ttu-id="9f391-160">Étapes</span><span class="sxs-lookup"><span data-stu-id="9f391-160">Steps</span></span>
1. <span data-ttu-id="9f391-161">**Créer un nœud principal de cluster et des machines virtuelles à nœud de calcul en exécutant le script de déploiement de HPC Pack IaaS sur un ordinateur client**</span><span class="sxs-lookup"><span data-stu-id="9f391-161">**Create a cluster head node and compute node VMs by running the HPC Pack IaaS deployment script on a client computer**</span></span>
   
    <span data-ttu-id="9f391-162">Téléchargez le package de script de déploiement de HPC Pack IaaS à partir du [Centre de téléchargement Microsoft](https://www.microsoft.com/download/details.aspx?id=49922).</span><span class="sxs-lookup"><span data-stu-id="9f391-162">Download the HPC Pack IaaS Deployment Script package from the [Microsoft Download Center](https://www.microsoft.com/download/details.aspx?id=49922).</span></span>
   
    <span data-ttu-id="9f391-163">Pour préparer l’ordinateur client, créez le fichier de configuration de script, puis exécutez le script. Consultez [Créer un cluster de calcul haute performance (HPC) Windows avec le script de déploiement du HPC Pack IaaS](hpcpack-cluster-powershell-script.md).</span><span class="sxs-lookup"><span data-stu-id="9f391-163">To prepare the client computer, create the script configuration file, and run the script, see [Create an HPC Cluster with the HPC Pack IaaS deployment script](hpcpack-cluster-powershell-script.md).</span></span> 
   
    <span data-ttu-id="9f391-164">Pour déployer les nœuds de calcul compatibles RDMA, notez les considérations supplémentaires suivantes :</span><span class="sxs-lookup"><span data-stu-id="9f391-164">To deploy RDMA-capable compute nodes, note the following additional considerations:</span></span>
   
   * <span data-ttu-id="9f391-165">**Réseau virtuel** : spécifiez un nouveau réseau virtuel dans une région dans laquelle la taille d’instance compatible RDMA souhaitée est disponible.</span><span class="sxs-lookup"><span data-stu-id="9f391-165">**Virtual network**: Specify a new virtual network in a region in which the RDMA-capable instance size you want to use is available.</span></span>
   * <span data-ttu-id="9f391-166">**Système d’exploitation Windows Server** : pour prendre en charge la connectivité RDMA, spécifiez un système d’exploitation Windows Server 2012 R2 ou Windows Server 2012 pour les machines virtuelles de nœud de calcul.</span><span class="sxs-lookup"><span data-stu-id="9f391-166">**Windows Server operating system**: To support RDMA connectivity, specify a Windows Server 2012 R2 or Windows Server 2012 operating system for the compute node VMs.</span></span>
   * <span data-ttu-id="9f391-167">**Services cloud** : nous vous recommandons de déployer votre nœud principal dans un service cloud et vos nœuds de calcul dans un autre service cloud.</span><span class="sxs-lookup"><span data-stu-id="9f391-167">**Cloud services**: We recommend deploying your head node in one cloud service and your compute nodes in a different cloud service.</span></span>
   * <span data-ttu-id="9f391-168">**Taille du nœud principal** : pour ce scénario, considérez une taille d’au moins A4 (très grande) pour le nœud principal.</span><span class="sxs-lookup"><span data-stu-id="9f391-168">**Head node size**: For this scenario, consider a size of at least A4 (Extra Large) for the head node.</span></span>
   * <span data-ttu-id="9f391-169">**Extension HpcVmDrivers** : le script de déploiement installe l’agent de machine virtuelle Azure et l’extension HpcVmDrivers automatiquement lors du déploiement de nœuds de calcul de taille A8 ou A9 avec un système d’exploitation Windows Server.</span><span class="sxs-lookup"><span data-stu-id="9f391-169">**HpcVmDrivers extension**: The deployment script installs the Azure VM Agent and the HpcVmDrivers extension automatically when you deploy size A8 or A9 compute nodes with a Windows Server operating system.</span></span> <span data-ttu-id="9f391-170">HpcVmDrivers installe des pilotes sur des machines virtuelles à nœud de calcul afin qu’ils puissent se connecter au réseau RDMA.</span><span class="sxs-lookup"><span data-stu-id="9f391-170">HpcVmDrivers installs drivers on the compute node VMs so they can connect to the RDMA network.</span></span> <span data-ttu-id="9f391-171">Sur les machines virtuelles de série H compatibles RDMA, vous devez installer manuellement l’extension HpcVmDrivers.</span><span class="sxs-lookup"><span data-stu-id="9f391-171">On RDMA-capable H-series VMs, you must manually install the HpcVmDrivers extension.</span></span> <span data-ttu-id="9f391-172">Consultez [Tailles de machines virtuelles de calcul haute performance](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span><span class="sxs-lookup"><span data-stu-id="9f391-172">See [High performance compute VM sizes](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span></span>
   * <span data-ttu-id="9f391-173">**Configuration du réseau de clusters** : le script de déploiement définit automatiquement le cluster HPC Pack dans la topologie 5 (tous les nœuds sur le réseau d’entreprise).</span><span class="sxs-lookup"><span data-stu-id="9f391-173">**Cluster network configuration**: The deployment script automatically sets up the HPC Pack cluster in Topology 5 (all nodes on the Enterprise network).</span></span> <span data-ttu-id="9f391-174">Cette topologie est requise pour tous les déploiements de cluster HPC Pack dans les machines virtuelles.</span><span class="sxs-lookup"><span data-stu-id="9f391-174">This topology is required for all HPC Pack cluster deployments in VMs.</span></span> <span data-ttu-id="9f391-175">Ne modifiez pas la topologie de réseau de clusters ultérieurement.</span><span class="sxs-lookup"><span data-stu-id="9f391-175">Do not change the cluster network topology later.</span></span>
2. <span data-ttu-id="9f391-176">**Mettre en ligne les nœuds de calcul pour exécuter des travaux**</span><span class="sxs-lookup"><span data-stu-id="9f391-176">**Bring the compute nodes online to run jobs**</span></span>
   
    <span data-ttu-id="9f391-177">Sélectionnez les nœuds et utilisez l’action **Mettre en ligne** dans HPC Cluster Manager.</span><span class="sxs-lookup"><span data-stu-id="9f391-177">Select the nodes and use the **Bring Online** action in HPC Cluster Manager.</span></span> <span data-ttu-id="9f391-178">Les nœuds sont prêts à exécuter des travaux.</span><span class="sxs-lookup"><span data-stu-id="9f391-178">The nodes are ready to run jobs.</span></span>
3. <span data-ttu-id="9f391-179">**Envoyer des travaux au cluster**</span><span class="sxs-lookup"><span data-stu-id="9f391-179">**Submit jobs to the cluster**</span></span>
   
    <span data-ttu-id="9f391-180">Connectez-vous au nœud principal pour soumettre des travaux, ou configurez un ordinateur local pour ce faire.</span><span class="sxs-lookup"><span data-stu-id="9f391-180">Connect to the head node to submit jobs, or set up an on-premises computer to do this.</span></span> <span data-ttu-id="9f391-181">Pour plus d’informations, consultez [Envoyer des travaux à un cluster HPC dans Azure](../../virtual-machines-windows-hpcpack-cluster-submit-jobs.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span><span class="sxs-lookup"><span data-stu-id="9f391-181">For information, see [Submit Jobs to an HPC cluster in Azure](../../virtual-machines-windows-hpcpack-cluster-submit-jobs.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span></span>
4. <span data-ttu-id="9f391-182">**Déconnecter les nœuds et les arrêter (désallouer)**</span><span class="sxs-lookup"><span data-stu-id="9f391-182">**Take the nodes offline and stop (deallocate) them**</span></span>
   
    <span data-ttu-id="9f391-183">Lorsque vous avez terminé l’exécution des travaux, déconnectez les nœuds dans HPC Cluster Manager.</span><span class="sxs-lookup"><span data-stu-id="9f391-183">When you are done running jobs, take the nodes offline in HPC Cluster Manager.</span></span> <span data-ttu-id="9f391-184">Puis, utilisez les outils de gestion Azure pour les arrêter.</span><span class="sxs-lookup"><span data-stu-id="9f391-184">Then, use Azure management tools to shut them down.</span></span>

## <a name="run-mpi-applications-on-the-cluster"></a><span data-ttu-id="9f391-185">Exécuter des applications MPI sur le cluster</span><span class="sxs-lookup"><span data-stu-id="9f391-185">Run MPI applications on the cluster</span></span>
### <a name="example-run-mpipingpong-on-an-hpc-pack-cluster"></a><span data-ttu-id="9f391-186">Exemple : Exécuter mpipingpong sur un cluster HPC Pack</span><span class="sxs-lookup"><span data-stu-id="9f391-186">Example: Run mpipingpong on an HPC Pack cluster</span></span>
<span data-ttu-id="9f391-187">Pour vérifier un déploiement HPC Pack des instances compatibles RDMA, exécutez la commande HPC Pack **mpipingpong** sur le cluster.</span><span class="sxs-lookup"><span data-stu-id="9f391-187">To verify an HPC Pack deployment of the RDMA-capable instances, run the HPC Pack **mpipingpong** command on the cluster.</span></span> <span data-ttu-id="9f391-188">**mpipingpong** envoie des paquets de données entre des nœuds associés de façon répétée pour calculer la latence et les mesures et statistiques de débit sur le réseau d’application RDMA.</span><span class="sxs-lookup"><span data-stu-id="9f391-188">**mpipingpong** sends packets of data between paired nodes repeatedly to calculate latency and throughput measurements and statistics for the RDMA-enabled application network.</span></span> <span data-ttu-id="9f391-189">Cet exemple montre un modèle classique d’exécution d’un travail MPI (dans ce cas, **mpipingpong**) à l’aide de la commande de cluster **mpiexec**.</span><span class="sxs-lookup"><span data-stu-id="9f391-189">This example shows a typical pattern for running an MPI job (in this case, **mpipingpong**) by using the cluster **mpiexec** command.</span></span>

<span data-ttu-id="9f391-190">Cet exemple suppose que vous ayez ajouté des nœuds Azure dans une configuration de type « intégration à Azure» ([scénario 1](#scenario-1.-deploy-compute-intensive-worker-role-instances-\(PaaS\) in this article).</span><span class="sxs-lookup"><span data-stu-id="9f391-190">This example assumes you added Azure nodes in a “burst to Azure” configuration ([Scenario 1](#scenario-1.-deploy-compute-intensive-worker-role-instances-\(PaaS\) in this article).</span></span> <span data-ttu-id="9f391-191">Si vous avez déployé HPC Pack sur un cluster de machines virtuelles Azure, vous devez modifier la syntaxe de commande pour spécifier un autre groupe de nœuds et définir des variables d’environnement supplémentaires pour diriger le trafic réseau vers le réseau RDMA.</span><span class="sxs-lookup"><span data-stu-id="9f391-191">If you deployed HPC Pack on a cluster of Azure VMs, you’ll need to modify the command syntax to specify a different node group and set additional environment variables to direct network traffic to the RDMA network.</span></span>

<span data-ttu-id="9f391-192">Pour exécuter mpipingpong sur le cluster :</span><span class="sxs-lookup"><span data-stu-id="9f391-192">To run mpipingpong on the cluster:</span></span>

1. <span data-ttu-id="9f391-193">Sur le nœud principal ou sur un ordinateur client correctement configuré, ouvrez une invite de commande.</span><span class="sxs-lookup"><span data-stu-id="9f391-193">On the head node or on a properly configured client computer, open a Command Prompt.</span></span>
2. <span data-ttu-id="9f391-194">Pour estimer la latence entre les paires de nœuds dans un déploiement d’intégration à Azure de quatre nœuds, tapez la commande suivante afin de soumettre un travail pour exécuter mpipingpong avec une petite taille de paquet et un grand nombre d’itérations :</span><span class="sxs-lookup"><span data-stu-id="9f391-194">To estimate latency between pairs of nodes in an Azure burst deployment of four nodes, type the following command to submit a job to run mpipingpong with a small packet size and many iterations:</span></span>
   
    ```Command
    job submit /nodegroup:azurenodes /numnodes:4 mpiexec -c 1 -affinity mpipingpong -p 1:100000 -op -s nul
    ```
   
    <span data-ttu-id="9f391-195">La commande retourne l’ID du travail soumis.</span><span class="sxs-lookup"><span data-stu-id="9f391-195">The command returns the ID of the job that is submitted.</span></span>
   
    <span data-ttu-id="9f391-196">Si vous avez déployé le cluster HPC Pack déployé sur les machines virtuelles Azure, spécifiez un groupe de nœuds qui contient des machines virtuelles à nœud de calcul déployées dans un même service cloud et modifiez la commande **mpiexec** comme suit :</span><span class="sxs-lookup"><span data-stu-id="9f391-196">If you deployed the HPC Pack cluster deployed on Azure VMs, specify a node group that contains compute node VMs deployed in a single cloud service, and modify the **mpiexec** command as follows:</span></span>
   
    ```Command
    job submit /nodegroup:vmcomputenodes /numnodes:4 mpiexec -c 1 -affinity -env MSMPI_DISABLE_SOCK 1 -env MSMPI_PRECONNECT all -env MPICH_NETMASK 172.16.0.0/255.255.0.0 mpipingpong -p 1:100000 -op -s nul
    ```
3. <span data-ttu-id="9f391-197">Lorsque le travail est terminé, pour afficher le résultat (dans ce cas, la sortie de la tâche 1 du travail), tapez la commande suivante :</span><span class="sxs-lookup"><span data-stu-id="9f391-197">When the job completes, to view the output (in this case, the output of task 1 of the job), type the following</span></span>
   
    ```Command
    task view <JobID>.1
    ```
   
    <span data-ttu-id="9f391-198">où &lt;*JobID*&gt; est l’ID du travail qui a été soumis.</span><span class="sxs-lookup"><span data-stu-id="9f391-198">where &lt;*JobID*&gt; is the ID of the job that was submitted.</span></span>
   
    <span data-ttu-id="9f391-199">La sortie indiquera des résultats de latence semblables à ceci :</span><span class="sxs-lookup"><span data-stu-id="9f391-199">The output includes latency results similar to the following.</span></span>
   
    ![Latence ping pong][pingpong1]
4. <span data-ttu-id="9f391-201">Pour estimer le débit entre les paires de nœuds d’extension Azure, tapez la commande suivante afin de soumettre un travail pour exécuter **mpipingpong** avec une grande taille de paquet et quelques itérations :</span><span class="sxs-lookup"><span data-stu-id="9f391-201">To estimate throughput between pairs of Azure burst nodes, type the following command to submit a job to run **mpipingpong** with a large packet size and a few iterations:</span></span>
   
    ```Command
    job submit /nodegroup:azurenodes /numnodes:4 mpiexec -c 1 -affinity mpipingpong -p 4000000:1000 -op -s nul
    ```
   
    <span data-ttu-id="9f391-202">La commande retourne l’ID du travail soumis.</span><span class="sxs-lookup"><span data-stu-id="9f391-202">The command returns the ID of the job that is submitted.</span></span>
   
    <span data-ttu-id="9f391-203">Sur un cluster HPC Pack déployé sur les machines virtuelles Azure, modifiez la commande comme indiqué à l’étape 2.</span><span class="sxs-lookup"><span data-stu-id="9f391-203">On an HPC Pack cluster deployed on Azure VMs, modify the command as noted in step 2.</span></span>
5. <span data-ttu-id="9f391-204">Une fois le travail terminé, pour afficher le résultat (dans ce cas, la sortie de la tâche 1 du travail), tapez la commande suivante :</span><span class="sxs-lookup"><span data-stu-id="9f391-204">When the job completes, to view the output (in this case, the output of task 1 of the job), type the following:</span></span>
   
    ```Command
    task view <JobID>.1
    ```
   
   <span data-ttu-id="9f391-205">La sortie indiquera des résultats de débit semblables à ceci :</span><span class="sxs-lookup"><span data-stu-id="9f391-205">The output includes throughput results similar to the following.</span></span>
   
   ![Débit ping pong][pingpong2]

### <a name="mpi-application-considerations"></a><span data-ttu-id="9f391-207">Considérations sur les applications MPI</span><span class="sxs-lookup"><span data-stu-id="9f391-207">MPI application considerations</span></span>
<span data-ttu-id="9f391-208">Vous trouverez ci-dessous des considérations relatives à l’exécution d’applications MPI avec le HPC Pack dans Azure.</span><span class="sxs-lookup"><span data-stu-id="9f391-208">Following are considerations for running MPI applications with HPC Pack in Azure.</span></span> <span data-ttu-id="9f391-209">Certaines s’appliquent uniquement aux déploiements de nœuds Azure (instances de rôle de travail ajoutées dans une configuration de type « intégration à Azure »).</span><span class="sxs-lookup"><span data-stu-id="9f391-209">Some apply only to deployments of Azure nodes (worker role instances added in a “burst to Azure” configuration).</span></span>

* <span data-ttu-id="9f391-210">Les instances de rôle de travail dans un service cloud sont régulièrement réapprovisionnées sans préavis par Azure (par exemple, pour la maintenance du système ou en cas d’échec d’une instance).</span><span class="sxs-lookup"><span data-stu-id="9f391-210">Worker role instances in a cloud service are periodically reprovisioned without notice by Azure (for example, for system maintenance, or in case an instance fails).</span></span> <span data-ttu-id="9f391-211">Si une instance est réapprovisionnée alors qu’elle exécute un travail MPI, elle perd ses données et retourne à l’état de son premier déploiement, ce qui peut entraîner l’échec du travail MPI.</span><span class="sxs-lookup"><span data-stu-id="9f391-211">If an instance is reprovisioned while it is running an MPI job, the instance loses its data and returns to the state when it was first deployed, which can cause the MPI job to fail.</span></span> <span data-ttu-id="9f391-212">Plus vous utilisez de nœuds pour un même travail MPI et plus le travail sera long, plus la probabilité de réapprovisionnement de l’une des instances au cours d’un travail sera élevée.</span><span class="sxs-lookup"><span data-stu-id="9f391-212">The more nodes that you use for a single MPI job, and the longer the job runs, the more likely that one of the instances is reprovisioned while a job is running.</span></span> <span data-ttu-id="9f391-213">Prenez également ce point en considération si vous désignez un seul nœud dans le déploiement comme serveur de fichiers.</span><span class="sxs-lookup"><span data-stu-id="9f391-213">Also consider this if you designate a single node in the deployment as a file server.</span></span>
* <span data-ttu-id="9f391-214">Pour exécuter des travaux MPI dans Azure, vous n’avez pas besoin d’utiliser des instances compatibles RDMA.</span><span class="sxs-lookup"><span data-stu-id="9f391-214">To run MPI jobs in Azure, you don't have to use the RDMA-capable instances.</span></span> <span data-ttu-id="9f391-215">Vous pouvez utiliser n’importe quelle taille d’instance prise en charge par HPC Pack.</span><span class="sxs-lookup"><span data-stu-id="9f391-215">You can use any instance size that is supported by HPC Pack.</span></span> <span data-ttu-id="9f391-216">Toutefois, les instances compatibles RDMA sont recommandées pour l’exécution de travaux MPI relativement volumineux qui sont sensibles à la latence et à la bande passante du réseau qui connecte les nœuds.</span><span class="sxs-lookup"><span data-stu-id="9f391-216">However, the RDMA-capable instances are recommended for running relatively large-scale MPI jobs that are sensitive to the latency and the bandwidth of the network that connects the nodes.</span></span> <span data-ttu-id="9f391-217">Si vous utilisez d’autres tailles pour exécuter des travaux MPI pour lesquels la bande passante et la latence sont essentiels, nous vous recommandons d’exécuter de petits travaux où une tâche donnée s’exécute sur quelques nœuds seulement.</span><span class="sxs-lookup"><span data-stu-id="9f391-217">If you use other sizes to run latency- and bandwidth-sensitive MPI jobs, we recommend running small jobs, in which a single task runs on only a few nodes.</span></span>
* <span data-ttu-id="9f391-218">Les applications déployées sur des instances Azure sont soumises aux termes du contrat de licence associés à l’application.</span><span class="sxs-lookup"><span data-stu-id="9f391-218">Applications deployed to Azure instances are subject to the licensing terms associated with the application.</span></span> <span data-ttu-id="9f391-219">Vérifiez auprès du fournisseur de toute application commerciale les questions de licence ou toute autre restriction relative à l’exécution dans le cloud.</span><span class="sxs-lookup"><span data-stu-id="9f391-219">Check with the vendor of any commercial application for licensing or other restrictions for running in the cloud.</span></span> <span data-ttu-id="9f391-220">Tous les fournisseurs ne proposent pas le paiement à l'utilisation pour les licences.</span><span class="sxs-lookup"><span data-stu-id="9f391-220">Not all vendors offer pay-as-you-go licensing.</span></span>
* <span data-ttu-id="9f391-221">Les instances Azure nécessitent une configuration supplémentaire pour accéder aux nœuds locaux, partages et serveurs de licences.</span><span class="sxs-lookup"><span data-stu-id="9f391-221">Azure instances need further setup to access on-premises nodes, shares, and license servers.</span></span> <span data-ttu-id="9f391-222">Par exemple, pour activer les nœuds Azure pour accéder à un serveur de licences local, vous pouvez configurer un réseau virtuel Azure de site à site.</span><span class="sxs-lookup"><span data-stu-id="9f391-222">For example, to enable the Azure nodes to access an on-premises license server, you can configure a site-to-site Azure virtual network.</span></span>
* <span data-ttu-id="9f391-223">Pour exécuter des applications MPI sur des instances Azure, enregistrez chaque application MPI sur les instances avec le pare-feu Windows en exécutant la commande **hpcfwutil** .</span><span class="sxs-lookup"><span data-stu-id="9f391-223">To run MPI applications on Azure instances, register each MPI application with Windows Firewall on the instances by running the **hpcfwutil** command.</span></span> <span data-ttu-id="9f391-224">Cela permet aux communications MPI d’avoir lieu sur un port affecté dynamiquement par le pare-feu.</span><span class="sxs-lookup"><span data-stu-id="9f391-224">This allows MPI communications to take place on a port that is assigned dynamically by the firewall.</span></span>
  
  > [!NOTE]
  > <span data-ttu-id="9f391-225">Pour des déploiements d’intégration à Azure, vous pouvez également configurer une commande d’exception de pare-feu pour qu’elle s’exécute automatiquement sur tous les nouveaux nœuds Azure ajoutés à votre cluster.</span><span class="sxs-lookup"><span data-stu-id="9f391-225">For burst to Azure deployments, you can also configure a firewall exception command to run automatically on all new Azure nodes that are added to your cluster.</span></span> <span data-ttu-id="9f391-226">Après avoir exécuté la commande **hpcfwutil** et vérifié que votre application fonctionne, ajoutez la commande à un script de démarrage pour vos nœuds Azure.</span><span class="sxs-lookup"><span data-stu-id="9f391-226">After you run the **hpcfwutil** command and verify that your application works, add the command to a startup script for your Azure nodes.</span></span> <span data-ttu-id="9f391-227">Pour plus d'informations, consultez [Utiliser un script de démarrage pour les nœuds Azure](https://technet.microsoft.com/library/jj899632.aspx).</span><span class="sxs-lookup"><span data-stu-id="9f391-227">For more information, see [Use a Startup Script for Azure Nodes](https://technet.microsoft.com/library/jj899632.aspx).</span></span>
  > 
  > 
* <span data-ttu-id="9f391-228">HPC Pack utilise la variable d’environnement de cluster CCP_MPI_NETMASK pour spécifier une plage d’adresses acceptables pour la communication MPI.</span><span class="sxs-lookup"><span data-stu-id="9f391-228">HPC Pack uses the CCP_MPI_NETMASK cluster environment variable to specify a range of acceptable addresses for MPI communication.</span></span> <span data-ttu-id="9f391-229">Depuis HPC Pack 2012 R2, la variable d’environnement de cluster CCP_MPI_NETMASK affecte uniquement la communication MPI entre les nœuds de calcul cluster appartenant à un domaine (localement ou sur des machines virtuelles Azure).</span><span class="sxs-lookup"><span data-stu-id="9f391-229">Starting in HPC Pack 2012 R2, the CCP_MPI_NETMASK cluster environment variable only affects MPI communication between domain-joined cluster compute nodes (either on-premises or in Azure VMs).</span></span> <span data-ttu-id="9f391-230">La variable est ignorée par les nœuds ajoutés dans une configuration d’intégration à Azure.</span><span class="sxs-lookup"><span data-stu-id="9f391-230">The variable is ignored by nodes added in a burst to Azure configuration.</span></span>
* <span data-ttu-id="9f391-231">Les travaux MPI ne peuvent pas s’exécuter sur des instances Azure déployées dans différents services cloud (par exemple, dans des déploiements d’intégration à Azure avec différents modèles de nœud ou des nœuds de calcul dans des machines virtuelles Azure déployés dans plusieurs services cloud).</span><span class="sxs-lookup"><span data-stu-id="9f391-231">MPI jobs can't run across Azure instances that are deployed in different cloud services (for example, in burst to Azure deployments with different node templates, or Azure VM compute nodes deployed in multiple cloud services).</span></span> <span data-ttu-id="9f391-232">Si vous avez plusieurs déploiements de nœuds Azure démarrés avec différents modèles de nœud, le travail MPI doit s’exécuter sur un seul ensemble de nœuds Azure.</span><span class="sxs-lookup"><span data-stu-id="9f391-232">If you have multiple Azure node deployments that are started with different node templates, the MPI job must run on only one set of Azure nodes.</span></span>
* <span data-ttu-id="9f391-233">Lorsque vous ajoutez des nœuds Azure à votre cluster et que vous les mettez en ligne, le service de planification de travaux HPC essaie immédiatement de démarrer les travaux sur les nœuds.</span><span class="sxs-lookup"><span data-stu-id="9f391-233">When you add Azure nodes to your cluster and bring them online, the HPC Job Scheduler Service immediately tries to start jobs on the nodes.</span></span> <span data-ttu-id="9f391-234">Si seulement une partie de votre charge de travail peut s’exécuter sur Azure, assurez-vous de mettre à jour ou de créer des modèles de projet pour définir les types de travaux qui peuvent s’exécuter sur Azure.</span><span class="sxs-lookup"><span data-stu-id="9f391-234">If only a portion of your workload can run on Azure, ensure that you update or create job templates to define what job types can run on Azure.</span></span> <span data-ttu-id="9f391-235">Par exemple, pour vous assurer que les travaux soumis avec un modèle de travail s’exécutent uniquement sur des nœuds Azure, ajoutez la propriété Node Groups au modèle de travail et sélectionnez AzureNodes comme valeur requise.</span><span class="sxs-lookup"><span data-stu-id="9f391-235">For example, to ensure that jobs submitted with a job template only run on Azure nodes, add the Node Groups property to the job template and select AzureNodes as the required value.</span></span> <span data-ttu-id="9f391-236">Pour créer des groupes personnalisés pour vos nœuds Azure, utilisez l'applet de commande Add-HpcGroup HPC PowerShell.</span><span class="sxs-lookup"><span data-stu-id="9f391-236">To create custom groups for your Azure nodes, use the Add-HpcGroup HPC PowerShell cmdlet.</span></span>

## <a name="next-steps"></a><span data-ttu-id="9f391-237">Étapes suivantes</span><span class="sxs-lookup"><span data-stu-id="9f391-237">Next steps</span></span>
* <span data-ttu-id="9f391-238">Comme alternative à l'utilisation de HPC Pack, développez avec le service Azure Batch pour exécuter des applications MPI sur des pools gérés de nœuds de calcul dans Azure.</span><span class="sxs-lookup"><span data-stu-id="9f391-238">As an alternative to using HPC Pack, develop with the Azure Batch service to run MPI applications on managed pools of compute nodes in Azure.</span></span> <span data-ttu-id="9f391-239">Consultez [Utiliser les tâches multi-instances pour exécuter des applications MPI (Message Passing Interface) dans Azure Batch](../../../batch/batch-mpi.md).</span><span class="sxs-lookup"><span data-stu-id="9f391-239">See [Use multi-instance tasks to run Message Passing Interface (MPI) applications in Azure Batch](../../../batch/batch-mpi.md).</span></span>
* <span data-ttu-id="9f391-240">Si vous souhaitez exécuter des applications MPI qui accèdent au réseau Azure RDMA, consultez [Configuration d’un cluster Linux RDMA pour exécuter des applications MPI](../../linux/classic/rdma-cluster.md).</span><span class="sxs-lookup"><span data-stu-id="9f391-240">If you want to run Linux MPI applications that access the Azure RDMA network, see [Set up a Linux RDMA cluster to run MPI applications](../../linux/classic/rdma-cluster.md).</span></span>

<!--Image references-->
[burst]:media/hpcpack-rdma-cluster/burst.png
[iaas]:media/hpcpack-rdma-cluster/iaas.png
[pingpong1]:media/hpcpack-rdma-cluster/pingpong1.png
[pingpong2]:media/hpcpack-rdma-cluster/pingpong2.png
